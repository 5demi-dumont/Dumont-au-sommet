\documentclass{book}
\input{usepackage}
\linespread{1.05}
\geometry{
	paperwidth=17cm,
	paperheight=23.9cm,
	top=2.5cm,
	bottom=2.5cm,
	left=1.5cm,
	right=1.5cm,
	headheight=14pt,
	headsep=1cm,
	footskip=1.5cm
}

\usepackage[Bjornstrup]{fncychap}
\input{fonction}
\AddToShipoutPictureBG*{
	\begin{tikzpicture}[remember picture,overlay]
		\fill[blue!60] 
		([xshift=0cm,yshift=0cm]current page.south west) 
		rectangle 
		([xshift=1.5cm,yshift=0cm]current page.north west);
	\end{tikzpicture}
}
\begin{document}
	
	\thispagestyle{empty}
	
	\setcounter{page}{0}
	%page de garde
	\begin{center}
		
		
		
		{\huge \textbf{Liste non exhaustive de classiques}}\\[0.5cm]
		{\Large \textit{Tome I : Analyse}}\\[0.8cm]
		
		{\normalsize Une compilation d'exercice mathématiques \\pour étudiants de classe préparatoire MP, PSI et PC}\\[1.5cm]
		
		
		\includegraphics[width=0.80\textwidth]{Minerve-Meduse}\\[0.2cm]
		
		\vfill
		{\large \textbf{Auteur :} Marconot Lorenzo , Esteve Arthur}\\[1cm]
		{\Large \textit{Collection Prépas – Mathématiques}}\\[0.5cm]
	\end{center}
	
	\vspace*{0.5cm}
	\begin{flushright}
		\includegraphics[width=0.30\textwidth]{lycee_dumont_urville-1-copie.jpg}\\
	\end{flushright}
	\newpage
	\thispagestyle{empty}
	\setcounter{page}{0}
	\vspace*{7.5cm}
	\begin{flushright}
		A M. Garcin et M. Teyssier, \\
		à Tan, la légende,\\
		à Arsinoé, Félix et Célian qui nous ont inspiré,\\
		et aux 5/2 de la promo 2024-2025. \\
		"La prépa, c'est du sang, des larmes et de la sueur".
	\end{flushright}
	\newpage
	\thispagestyle{empty}
	\setcounter{page}{0}
	\begin{center}
		\Large Avant Propos\\
	\end{center}
		Salut à toi jeune CPGEiste, alors si aujourd’hui je me permets de te contacter, c’est pour une raison très simple : savais-tu que 95 \% des étudiants en prépa ne savent pas comment aborder un problème ? Alors, est-ce que tu veux en faire partie ? Il faut que tu te poses les bonnes questions. Est-ce que tu préfères faire pitié ou commencer très rapidement à accumuler du savoir avec moi grâce à ton téléphone et pouvoir faire partie de l’élite ? Moi, je pense que la question, elle est vite répondue.\\
		
		Bon, en vrai sans déconner, Arthur et moi-même sommes passés par-là, on a fait 3 ans de classe préparatoire au lycée Dumont d’Urville, donc on connaît très bien la prépa et ses enjeux. On a voulu transmettre un morceau de ce que l’on pense qui vous sera utile, à l’instar de nos 5/2 (s/o Arsinoé Payet, Félix Gauci et Célian Rosello) qui ont écrit un formulaire en Chimie et en SI (que je ne saurais trop vous conseiller de lire avant chaque DS pour revoir les formules à connaître). On souhaite que soit transmis un héritage au sein de Dumont pour que chaque année, les prédécesseurs aident les suivants.\\
		
		Déjà, à qui servent-ils ? Il est utile à tout étudiant peu importe son niveau ou son ambition. Dans cet ouvrage, on a essayé de compiler tous les exercices classiques (vus en colle, en DS ou en TD) que l’on a trouvés pertinents, car ils sont soit omniprésents aux concours, soit demandant un raisonnement qu’il est impératif d’avoir vu pour acquérir des réflexes très utiles si l’on est bloqué. Il est vrai que ce recueil d’exercices contient énormément d’exercices difficiles, mais il ne faut pas avoir peur : il y a énormément d’exercices abordables et que vous devez impérativement faire et puis, pour réussir en prépa, il faut « avoir les dents qui rayent le parquet », faut vouloir tout déchirer pour obtenir ce que l’on veut et c’est à cela que servent ces ouvrages : vous proposer une liste d’exercices qu'il faut voir (et revoir autant de fois que nécessaire) avant les concours. Ces ouvrages sont également destinés aux étudiants ne souhaitant pas faire d’études d’ingénieur et qui souhaitent aller en licence. Ils permettent d’avoir toutes les bases nécessaires pour appréhender en toute confiance les chapitres de la L3.\\
		
		Bon, cet ouvrage est uniquement là en complément de cours : il faut d’abord assimiler le cours avec le prof pour pouvoir s’en sortir en prépa, donc on privilégie les exos du TD. On a créé ce recueil pour que les théorèmes ou résultats classiques soient recensés au même endroit.\\
		
		P.-S. : On essaie de compléter au fur et à mesure les corrections des deux livres, cela demande un temps de dingue mais on promet de proposer un maximum de corrigés avant les concours.\\
		
		P.-P.-S. : Ce message est destiné à tous les futurs 5/2, je souhaiterais que pendant votre temps de révision, vous envisagiez de perpétuer l’héritage pour que d’ici quelques années Dumont d’Urville soit au sommet. Je ne vous demande pas de faire un aussi gros projet, mais cela serait vraiment super de pouvoir aider les futurs élèves à relever le défi qu’est la prépa en toute confiance. 
	
	\newpage
	\begin{center}\large{Légende et notations}\end{center}
	Un exercice est affilié d'un certain nombre d'étoiles $\etoile{1}$ relativement à sa difficulté :\\
	\begin{itemize}
		\item $\etoile{1}$ Démonstration ou application directe du cours (le plus souvent E3A, CCINP);
		\item $\etoile{2}$ Application du cours/de méthodes usuelles (le plus souvent CCINP, Mines-Télécom);
		\item $\etoile{3}$ Application du cours/de méthodes usuelles (le plus souvent Centrale, Mines-Ponts);
		\item $\etoile{4}$ Exercice exotique/peu ou pas guidé (Centrale, Mines-Pont, X-ENS);
		\item $\etoile{5}$ Exercice exotique/peu ou pas guidé (le plus souvent X-ENS).
	\end{itemize}
	Ces étoiles suivent un code couleur indicatif du concours auquel l'exercice aurait le plus de chance d'être posé, à l'écrit ou à l'oral :
	\begin{itemize}
		\item Aucun concours spécifique $\etoile{1}$
		\item E3A/CCINP $\ccinp{1}$
		\item Mines-Télécom $\telecom{1}$
		\item Mines-Ponts/Centrale $\centraleponts{1}$
		\item X-ENS $\xens{1}$
	\end{itemize}
	Pour des exercices considérés comme des "classiques" qui tombent régulièrement, le titre de l'exercice sera \underline{souligné}.\\
	Par exemple \underline{Série harmonique :} $\ccinp{3}$ indique que l'exercice nommé "Série harmonique" est un immanquable de tous les candidats qui se préparent à E3A/CCINP.\\
	Enfin, un exercice qui utilise ou traite des notions hors du programme (de MP) sera suivi d'un label (HP).
	
	\setcounter{tocdepth}{1}
	
	\tableofcontents
	\newpage
	
\chapter{Suite et série numérique}
	
	\section{Lemme de Césarò \ccinp{2}} 
	\textcolor{blue}{\hyperref[sec:lemme-de-cesaro-etoile2]{[Corrigé]}}\\
	\label{Lemme de Cesaro}
	Soit $(u_n)\in \C^\N$ une suite de limite $\ell\in \overline{\R}$.\\
	 Démontrer que $(\sigma_n)_{n\in \N}$ définie par $\forall n \in \N,\  \sigma_n=\displaystyle\frac{1}{n+1}\displaystyle\sum\limits_{k=0}^nu_k$  tend également vers $\ell$.
	\subsection{Lemme de l'escalier\etoile{1}}
	Montrer que si $u_{n+1}-u_n$ tend vers un nombre $\ell\ne0$. Alors $u_n\sim\ell n$.
	
	\section{Théorèmes Taubériens d'Hardy \etoile{1}}
	\textcolor{blue}{\hyperref[sec:theoremes-tauberiens-dhardy-etoile1]{[Corrigé]}}\\
	\label{Théorèmes Taubériens d'Hardy}
	Soit $(u_n)_{n\in \N}$ une suite quelconque à valeurs complexe.
	\\On pose $\forall n \in \N,\ \sigma_n=\displaystyle\frac{1}{n+1}\displaystyle\sum\limits_{k=0}^nu_k \ \text{et}\ \varepsilon_n=u_{n+1}-u_n$
	\\Vérifier que la réciproque du lemme de Césarò n'est pas toujours vraie en exhibant une suite $(u_n) \in\R^\N$ qui ne converge pas et telle que $(\sigma_n)$ converge dans $\R$.
	
	\subsection{Hardy Faible \etoile{2}}
	Soit $\ell\in\C$.
	\\Démontrer que si $\lim\limits_{n\to+\infty} \sigma_n=\ell$ et $\varepsilon_n\unfty{=}\smallo{\displaystyle\frac{1}{n}}$ alors $\lim\limits_{n\to+\infty} u_n=\ell$.
	\\Indication: on pourra démontrer que pour tout $n\geq 1 \displaystyle\sum\limits_{k=0}^n k\varepsilon_k=nu_{n+1}-\sum\limits_{k=1}^nu_k$.
	
	\subsection{Hardy Fort \xens{3}}
	Soit $(u_n)\in \C^\N$ et $\ell\in\C$.
	\\On souhaite démontrer que si $\lim\limits_{n\to+\infty} \sigma_n=\ell$ et $\varepsilon_n\unfty{=}\bigO{\displaystyle\frac{1}{n}}$ alors $\lim\limits_{n\to+\infty} u_n=\ell$.
	\begin{enumerate}[leftmargin=*]
		\item Soit $0\leq n<m$ deux entiers. Démontrer que $\displaystyle\sum\limits_{k=n+1}^mu_k-(m-n)u_n=\sum\limits_{k=n}^{m-1}(m-k)\varepsilon_k$
		\item En déduire qu'il existe un entier positif $N$ et une constante $C>0$ telle que pour tous entier $m$ et $n$ tels que $N\leq n<m$, on ai: $$\left|\displaystyle\frac{(m+1)\sigma_m-(n+1)\sigma_n}{m-n}-u_n\right|\leq C\ln\left(\frac{m-1}{n-1}\right)$$
		\\et 
		$$|u_n-\ell|\leq C\ln\left(\frac{m-1}{n-1}\right)+\frac{m+1}{m-n}(|\sigma_m-\ell|+|\sigma_n-\ell|)$$
		\item En déduire le théorème Taubérien de Hardy (Fort). \\Indication: on pourra prendre $m=1+\left\lfloor{\alpha n}\right\rfloor$ avec un paramètre $\alpha>1$ à choisir, où $\left\lfloor{x}\right\rfloor$ désigne la partie entière de $x\in\R$.
	\end{enumerate}
	
	\section{Série harmonique \ccinp{3}}
	\textcolor{blue}{\hyperref[sec:serie-harmonique-etoile3]{[Corrigé]}}\\
	\label{Série harmonique}
	Soit $(H_n)_{n\in \N^*}$ la suite définie par $\forall n \in \N^*, \ H_n=\displaystyle\sum\limits_{k=1}^{n}\frac{1}{k}$.\\
	\begin{enumerate}
		\item Déterminer un équivalent simple de $H_n$.
		\item On pose pour tout $n\in \N^*,\ v_n=H_n-\ln n$.\\
		Montrer que $(v_n)_{n\in \N^*}$ converge. On notera $\gamma$ sa limite.
		\item Déterminer un développement asymptotique à $3$ termes de $H_n$.
		\item On pose pour tout $n\in \N^*,\ w_n=v_n-\displaystyle\frac{1}{2n}$.\\
		Déterminer un développement asymptotique à $4$ termes de $H_n$.
		\item On note pour $n\in \N^*,\ k_n=\min\{k\in \N,\ H_k\geq n\}$.\\
		Déterminer $\lim\limits_{\nfty}\displaystyle\frac{k_{n+1}}{k_n}$.
	\end{enumerate}
	
	\section{Suite récurrente (1) \telecom{3}}
	\textcolor{blue}{\hyperref[sec:suite-recurrente-1-etoile3]{[Corrigé]}}\\
	\label{Suite récurrente 1}
	\begin{enumerate}[leftmargin=*]
		\item Déterminer un équivalent simple de $(u_n)_{n\in \N}$ définie par $u_0\in \R$ et $\forall n\in \N,\ u_{n+1}=\sin(u_n)$. 
		\item Déterminer un développement asymptotique de cette même suite à l'ordre 2.
	\end{enumerate}
	
	\section{Suite récurrente (2) \telecom{3}}
	\textcolor{blue}{\hyperref[sec:suite-recurrente-2]{[Corrigé]}}\\
	\label{Suite récurrente 2}
	\begin{enumerate}[leftmargin=*]
		\item Déterminer un équivalent simple de $(u_n)_{n\in \N}$ définie par $u_0\in \R$ et $\forall n\in \N,\ u_{n+1}=\arctan(u_n)$. 
		\item Déterminer un développement asymptotique de cette même suite à l'ordre 2.
	\end{enumerate}
	
	\section{Suite récurrente (3) \etoile{3}}
	\textcolor{blue}{\hyperref[sec:suite-recurrente-3]{[Corrigé]}}\\
	\label{Suite récurrente 3}
	\begin{enumerate}[leftmargin=*]
		\item Déterminer un équivalent simple de $(u_n)_{n\in \N}$ définie par $u_0>-1$ et $\forall n\in \N,\ u_{n+1}=\ln(1+u_n)$. 
		\item Déterminer un développement asymptotique de cette même suite à l'ordre 2.
	\end{enumerate}
	
	\section{Suite récurrente (4) \etoile{2}}
	\textcolor{blue}{\hyperref[sec:suite-recurrente-4-etoile3]{[Corrigé]}}\\
	\label{Suite récurrente 4}
	Soit $\alpha >-1$.\\
	Déterminer un équivalent simple de $(u_n)_{n\in \N}$ définie par $u_0>0$ et $\forall n\in \N,\ u_{n+1}=u_n+\displaystyle\frac{1}{u_n^\alpha}$.
	
	\section{Suite récurrente (5) \centraleponts{4}}
	\textcolor{blue}{\hyperref[sec:suite-recurrente-5]{[Corrigé]}}\\
	\label{Suite récurrente 5}
	Trouver un équivalent de la suite récurrente $(x_n)$ qui vérifie: $\begin{cases}
		x_0=1\\
		x_{n+1}=x_n+\displaystyle \int_{x_n}^{+\infty}e^{\frac{-x^2}{2}}dx
	\end{cases}$
	
	\section{Suite récurrente (6) \telecom{3}}
	\textcolor{blue}{\hyperref[sec:suite-recurrente-6]{[Corrigé]}}\\
	\label{Suite récurrente 6}
	Soient $(a_n)_{n\in \N}$ et $(b_n)_{n\in \N}$ définies par $a_0>0,\ b_0>0$ et :
	$$\forall n\in \N,\begin{cases} \displaystyle a_{n+1}=\frac{a_n+b_n}{2}  \\ \displaystyle b_{n+1}=\frac{1}{2}\left(\frac{1}{a_n}+\frac{1}{b_n}\right)\end{cases}$$
	\begin{enumerate}
		\item Etudier la convergence des suites $(a_n)_{n\in \N}$ et $(b_n)_{n\in \N}$.
		\item En notant $\ell=\unfty\lim a_n$, déterminer un équivalent de $(a_n-\ell)_{n\in \N}$.
	\end{enumerate}
	
	\section{Suite définie implicitement (1) \ccinp{2}}
	\textcolor{blue}{\hyperref[sec:suite-definie-implicitement-1etoile2]{[Corrigé]}}\\
	\label{Suite définie implicitment 1}
	\begin{enumerate}[leftmargin=*]
		\item Montrer que pour tout $n\in\N^*$, l'équation $\cos(x)=nx$ possède une unique solution $x_n\in[0,1]$.
		\item Déterminer la limite de $(x_n)$.
		\item Etudier la monotonie de $(x_n)$.
		\item Etablir que $x_n \unfty{\sim}\displaystyle\frac{1}{n}$.
		\item Déterminer un équivalent de $x_n-\displaystyle\frac{1}{n}$.
	\end{enumerate}
	
	\section{Suite définie implicitement (2) \ccinp{2}}
	\textcolor{blue}{\hyperref[sec:suite-definie-implicitement-2]{[Corrigé]}}\\
	\label{Suite définie implicitement 2}
	\begin{enumerate}[leftmargin=*]
		\item Montrer que si $n$ est un entier supérieur ou égal à $2$ alors l'équation
		$$\sin(x)=\frac{x}{n}$$
		admet une unique solution $x_n\in ]0,\pi[$.
		\item Montrer que $(x_n)_{n\geq 2}$ converge. Quelle est sa limite ?
		\item Déterminer un équivalent de $(x_n)_{n\geq 2}$.
		\item Déterminer un développement asymptotique de $(x_n)_{n\geq 2}$ en $\smallo{\displaystyle\frac{1}{n^3}}$.
	\end{enumerate}
	
	\section{Suite définie implicitement (3) \ccinp{2}}
	\textcolor{blue}{\hyperref[sec:suite-definie-implicitement-3]{[Corrigé]}}\\
	\label{Suite définie implicitement 3}
	\begin{enumerate}[leftmargin=*]
		\item Montrer que si $n$ est un entier supérieur ou égal à $2$ alors l'équation
		$$x^n-nx+1=0$$
		admet une unique solution $x_n\in [0,1]$.
		\item Etudier la monotonie et la convergence de $(x_n)_{n\geq 2}$.
		\item Déterminer un équivalent de $(x_n)_{n\geq 2}$.
		\item Déterminer un développement asymptotique à $2$ termes de $(x_n)_{n\geq 2}$.
	\end{enumerate}
	
	\section{Suite définie implicitement (4) \telecom{2}}
	\textcolor{blue}{\hyperref[sec:suite-definie-implicitement-4]{[Corrigé]}}\\
	\label{Suite définie implicitement 4}
	\begin{enumerate}[leftmargin=*]
		\item Montrer que $\forall n\in \N^*,\ \exists!\ x_n\in \displaystyle\left]n\pi-\frac{\pi}{2},n\pi+\frac{\pi}{2}\right[,\ \tan(x_n)=x_n$.
		\item Déterminer un équivalent de $(x_n)_{n\in \N^*}$.
		\item Déterminer un développement asymptotique de $(x_n)_{n\in \N^*}$ en $\smallo{\displaystyle\frac{1}{n^2}}$.
	\end{enumerate}
	
	\section{Suite définie implicitement (5) \centraleponts{3}}
	\textcolor{blue}{\hyperref[sec:suite-definie-implicitement-5-etoile3]{[Corrigé]}}\\
	\label{Suite définie implicitement 5}
	\begin{enumerate}[leftmargin=*]
		\item Montrer que si $n\in \N^*$ alors l'équation
		$$\sum_{k=1}^n\frac{x^k}{k}=1$$
		admet une unique solution $x_n\in \R_+$.
		\item Etudier la convergence de la suite $(x_n)_{n\in \N^*}$.
		\item Calculer sa limite.
	\end{enumerate}
	
	\section{Formule d'inversion de Pascal}
	\textcolor{blue}{\hyperref[sec:formule-dinversion-de-pascal-etoile2]{[Corrigé]}}\\
	\label{Formule d'inversion de Pascal}
	Soit $(a_n)_{n\in \N}$ et $(b_n)_{n\in \N}$ deux suites complexes telles que pour tout entier naturel $n$, on ait: $$\forall p\in\crblanc{0}{n},\ b_p=\displaystyle\sum\limits_{k=0}^p\binom{p}{k}a_k$$
	On souhaite démontrer la formule d'inversion de Pascal : $\forall p\in \crblanc{0}{n},\ a_p=\displaystyle\sum\limits_{k=0}^p(-1)^{p-k}\binom{p}{k}b_k$.
	
	\subsection{Première méthode : matrice de passage \ccinp{1}}
	\begin{enumerate}
		\item Justifier que les familles $\B_c=(1,X,\dots,X^m)$ et $\B_t=(1,(X-1),\dots,(X-1)^m)$ sont des bases de $\R_m[X]$.
		\item Calculer la matrice de passage de $\B_c$ vers $\B_t$ et calculer son inverse.
		\item Conclure.
	\end{enumerate}
	
	\subsection{Deuxième méthode : binôme de Newton \ccinp{2}}
	On pose $\fonction{S}{\C^\N}{\C^\N}{(u_n)_{n\in \N}}{(u_{n+1})_{n\in \N}}$. Pour simplifier les notations on note $a=(a_n)_{n\in \N}$ et $b=(b_n)_{n\in \N}$.\\
	Démontrer la formule d'inversion de Pascal à l'aide de $S$.
	
	\subsection{Troisième méthode : par le calcul \ccinp{2}}
	\begin{enumerate}
		\item Montrer que $\displaystyle\sum_{i=0}^p(-1)^{p-i}\binom{p}{i}b_i=\sum_{j=0}^p\sum_{i=j}^p(-1)^{p-i}\binom{p}{i}\binom{j}{i}a_j$.
		\item Montrer que $\displaystyle\sum_{i=0}^p(-1)^{p-i}\binom{p}{i}b_i=\sum_{j=0}^p\binom{p}{j}a_j\sum_{i=0}^{p-j}(-1)^{p-j-i}\binom{p-j}{i}$.
		\item Conclure.
	\end{enumerate}
	
	\subsection{Dérangements \ccinp{3}}
	Soit $n\in \N^*$. On appelle dérangement de $\crblanc{1}{n}$ toute permutation $\sigma\in \mathcal S_n$ qui ne possède pas de point fixe.\\
	Donner une expression du nombre de dérangement $D_n$ de $\mathcal S_n$ sous la forme d'une somme.\\
	En déduire $\unfty\lim\displaystyle\frac{D_n}{n!}$ et interpréter.
	
	\section{Théorème de Pringsheim \centraleponts{3}}
	\textcolor{blue}{\hyperref[sec:theoreme-de-pringsheim-etoile3]{[Corrigé]}}\\
	\label{Théorème de Pringsheim}
	
	Soit $(a_n)_{n\in \N}$ une suite positive et décroissante telle que $\displaystyle\sum\limits_{n\in \N} a_n$ converge. \\Montrer que $(na_n)_{n\in \N}$ converge vers 0.
	
	\section{Lemme de Fekete \centraleponts{3}}
	\label{Lemme de Fekete}
	\textcolor{blue}{\hyperref[sec:lemme-de-fekete]{[Corrigé]}}\\
	Soit $(u_n)_{n\in \N}$ une suite réelle vérifiant
	$$\forall m,n\in \N,\ u_{n+m}\leq u_n+u_m$$
	\textit{On dit que la suite est sous-additive.}\\
	On veut montrer que la suite $\left(\dfrac{u_n}{n}\right)_{n\in \N^*}$ tend vers $\ell:=\inf\limits_{n\in \N^*}\dfrac{u_n}{n}$.
	\begin{enumerate}
		\item Soient $n\leq N$ des entiers positifs. On note $n=qN+r$ la division euclidienne de $n$ par $N$.\\
		Montrer que $u_n\leq qu_N+\max\limits_{0\leq k<N}u_k$.
		\item Conclure en distinguant les cas $\left(\dfrac{u_n}{n}\right)_{n\in \N^*}$ minorée ou non.
	\end{enumerate}
	
	\subsection{Chemins auto-évitant}
	\textcolor{blue}{\hyperref[Chemins auto-évitant corrigé]{[Corrigé]}}\\
	\label{Chemins auto-évitant}
	On considère le réseau carré $\Z^2$ : les voisins du point $(i,j)$ sont exactement $(i-1,j),\ (i+1,j),\ (i,j-1)$ et $(i,j+1)$.\\
	On appelle chemin de longueur $n$ tout $n$-uplet $(M_1,\dots,M_n)$ de points de $\Z^2$ où $M_1=(0,0)$ (les chemins partent de l'origine) et où pour tout $i$, $M_{i+1}$ est un voisin de $M_i$.\\
	Enfin on dit qu'un chemin $(M_1,\dots,M_n)$ est auto-évitant si les $M_i$ sont distincts. On note $c_n$ le nombre de chemins auto-évitant de longueurs $n$.\\\\
	Montrer que la suite $(c_n)_{n\in \N^*}$ converge vers $\mu:=\inf\limits_{n\in \N^*}c_n^{1/n}$.
	
	\section{Théorème de Bolzano-Weierstrass \etoile{3}}
	\textcolor{blue}{\hyperref[sec:theoreme-de-bolzano-weierstrass-etoile3]{[Corrigé]}}\\
	\label{Théorème de Bolzano-Weierstrass}
	Le but de cet exercice est de démontrer le théorème de Bolzano-Weierstrass puis de l'étendre au cas des suites complexes. Soit $(u_n)\in \C^\N$ une suite bornée.
	\begin{enumerate}
		\item Démontrer le lemme des pics : "De toute suite réelle on peut extraire une suite monotone".
		\item En déduire que l'on peut extraire de $(u_n)_{n\in \N}$ une suite convergente.
	\end{enumerate}
	
	\section{$\R$ est complet \etoile{2}}
	\textcolor{blue}{\hyperref[sec:r-est-complet-etoile2]{[Corrigé]}}\\
	\label{R est complet}
	On dit qu'une suite $(u_n)\in \R^\N$ est de Cauchy lorsqu'elle vérifie :
	$$\forall \varepsilon>0,\ \exists N\in \N,\ \forall p,q\in \llbracket N;+\infty\llbracket,\ |u_p-u_q|\leq \varepsilon$$
	\\Démontrer qu'une suite réelle est de Cauchy si et seulement si elle converge.
	
	\section{Récurrence de Cauchy \etoile{3}}
	\textcolor{blue}{\hyperref[sec:recurrence-de-cauchy]{[Corrigé]}}\\
	\label{Récurrence de Cauchy}
	\begin{enumerate}[leftmargin=*]
		\item Soit $A$ une partie de $\N$ telle que :
		\begin{itemize}
			\item $1\in A$;
			\item $\forall n\in A\setminus\{0\},\ n-1\in A$;
			\item $\forall n\in A,\ 2n\in A$.
		\end{itemize}
		Montrer que $A=\N$.
		\item En déduire l'inégalité arithmético-géométrique :\\
		$\forall (a_n)\in \left(\R^+\right)^{\N^*},\ \forall n\in\N^*,\ \displaystyle\frac{1}{n}\sum\limits_{k=1}^na_k\geq \left(\prod\limits_{k=1}^na_k\right)^{1/n}$.
	\end{enumerate}
	
	\section{Sommes de Riemann \etoile{2}}
	\textcolor{blue}{\hyperref[sec:sommes-de-riemann]{[Corrigé]}}\\
	\label{Sommes de Riemann}
	Démontrer que $\forall f \in \mathcal{C}^1([0,1],\R),\ \displaystyle\int_0^1 f(t)dt\unfty{=}\displaystyle\frac{1}{n}\displaystyle\sum\limits_{k=1}^{n} f\left(\frac{k}{n}\right)-\displaystyle\frac{1}{2n}(f(1)-f(0))+\smallo{\frac{1}{n}}$.
	
	\section{Formule d'Euler-Maclaurin \etoile{3}}
	\textcolor{blue}{\hyperref[sec:formule-deuler-maclaurin]{[Corrigé]}}\\
	\label{Formule d'Euler-Maclaurin}
	Soient $(m,n) \in \Z^2$ tel que $m<n$, $r \in \N^*$ et $f:[m,n] \to \C$ de classe $\mathcal{C}^r$.
	\\Montrer que $$\sum_{i=m}^{n} f(i)=\int_m^n f(t)dt +\frac{1}{2}(f(m)+f(n))+\sum_{i=2}^{r}\frac{b_i}{2}\left[f^{(i-1)}(m)-f^{(i-1)}(n)\right]+\frac{(-1)^{r+1}}{r!}\int_m^n \overset{\sim}{B_r}(t)f^{(r)}(t)dt$$
	\\ \underline{Application:} Déterminer un développement asymptotique à tout ordre de la série harmonique.
	
	\section{Nature d'une suite \telecom{2}}
	\textcolor{blue}{\hyperref[sec:nature-dune-suite]{[Corrigé]}}\\
	\label{Nature d'une suite}
	Déterminer la nature de la suite $(\sin n)_{n\in \N}$.
	
	\section{Valeurs d'adhérence d'une suite \centraleponts{4}}
	\label{Valeurs d'adhérence d'une suite}
	\textcolor{blue}{\hyperref[sec:valeurs-dadherence-dune-suite]{[Corrigé]}}\\
	On pose pour $n\in \N^*,\ z_n=\displaystyle\prod_{k=1}^n\left(1+\frac{i}{k}\right)$.
	\begin{enumerate}
		\item Rappeler le théorème de sommation de relation de comparaison pour des suites équivalentes.
		\item Montrer que la suite $(|z_n|)_{n\in \N^*}$ converge.
		\item Déterminer l'ensemble des valeurs d'adhérence de la suite $(z_n)_{n\in \N^*}$.
	\end{enumerate}
	
	\section{Nature d'une série (1) \ccinp{1}}
	\textcolor{blue}{\hyperref[sec:nature-dune-serie-1etoile1]{[Corrigé]}}\\
	\label{Nature d'une série 1}
	Déterminer la nature de la série $\displaystyle\sum\limits_{n\geq 0} \sin\left(\pi\sqrt{1+n^2}\right)$.
	
	\section{Nature d'une série (2) \telecom{2}}
	\textcolor{blue}{\hyperref[sec:nature-dune-serie-2-etoile2]{[Corrigé]}}\\
	\label{Nature d'une série 2}
	Déterminer la nature de la série $\displaystyle\sum\limits_{n\geq 0}\sin\left(\pi(2+\sqrt 3)^n\right)$.
	\\On pourra s'intéresser pour $n\in \N$ à la quantité $(2+\sqrt 3)^n+(2-\sqrt 3)^n$.
	
	\section{Nature d'une série (3) \centraleponts{3}}
	\textcolor{blue}{\hyperref[sec:nature-dune-serie-3-etoile3]{[Corrigé]}}\\
	\label{Nature d'une série 3}
	Déterminer la nature de la série $\displaystyle\sum_{n\geq 1}\arccos\left(\frac{n^\alpha}{1+n^\alpha}\right)$ en fonction de la valeur de $\alpha\in \R$.
	
	\section{Nature d'une série (4) \xens{3}}
	\label{Nature d'une série 4}
	\textcolor{blue}{\hyperref[sec:nature-dune-serie-4]{[Corrigé]}}\\
	Soit $(a_n)_{n\in \N^*}$ une suite strictement croissante d'entiers naturels non nuls.\\
	Déterminer la nature de la série $\displaystyle\sum\limits_{n\geq 1}\frac{1}{\ppcm(a_1,\dots,a_n)}$.
	
	\section{Nature d'une série (5) \xens{3}}
	\label{Nature d'une série 5}
	\textcolor{blue}{\hyperref[sec:nature-dune-serie-5]{[Corrigé]}}\\
	Soit $(\alpha_n)_{n\in \N^*}$ une suite d'entiers strictement positifs deux à deux distincts. Déterminer la nature de la série
	$$\sum_{n\geq 1}\frac{\alpha_n}{n^2}$$
	
	\section{Calcul d'un équivalent \xens{4}}
	\textcolor{blue}{\hyperref[sec:calcul-dun-equivalent-etoile3]{[Corrigé]}}\\
	\label{Calcul d'un équivalent}
	Déterminer un équivalent de $u_n=\left(\displaystyle\prod\limits_{k=1}^nk^k\right)^{1/n}$.
	
	\section{Sommation de relations de comparaison \ccinp{1}}
	\textcolor{blue}{\hyperref[sec:sommation-de-relations-de-comparaison]{[Corrigé]}}\\
	\label{Sommation de relations de comparaison}
	Soient $(u_n)_{n\in \N}$ et $(v_n)_{n\in \N}$ deux suites équivalentes.\\
	Peut-on affirmer que $\displaystyle\sum\limits_{n\in \N}u_n$ et $\displaystyle\sum\limits_{n\in \N}v_n$ sont de mêmes natures ? Justifier.
	
	\section{\underline{Equivalent de séries de Riemann} \ccinp{1}}
	\textcolor{blue}{\hyperref[sec:equivalent-de-series-de-riemann]{[Corrigé]}}\\
	\label{Equivalent de séries de Riemann}
	On considère pour $\alpha\in \R$ la série $\displaystyle\sum_{n\in \N^*}\frac{1}{n^\alpha}$.\\
	Déterminer un équivalent simple de la somme partielle pour $\alpha<1$ et du reste pour $\alpha>1$.
	
	\section{\underline{Séries de Bertrand} \ccinp{2}}
	\textcolor{blue}{\hyperref[sec:series-de-bertrand]{[Corrigé]}}\\
	\label{Séries de Bertrand}
	Démontrer que $\displaystyle\sum\limits_{n\geq 2}\frac{1}{n^\alpha\ln(n)^\beta}$ converge $\iff\alpha>1$ ou $(\alpha=1$ et $\beta >1)$.
	
	\section{Critère de Raabe-Duhamel \ccinp{2}}
	\textcolor{blue}{\hyperref[sec:critere-de-raabe-duhamel-etoile2]{[Corrigé]}}\\
	\label{Critère de Raabe-Duhamel}
	\begin{enumerate}[leftmargin=*]
		\item Soient $(u_n)$ et $(v_n)$ de suites réels strictement positifs vérifiant $\displaystyle\frac{u_{n+1}}{u_n}\leq \frac{v_{n+1}}{v_n}$ à partir d'un certain rang.\\Montrer que $u_n\unfty{=}\bigO{v_n}$.
		\item
		Soit $(u_n)\in\C^\N$ tel que $\displaystyle\frac{u_{n+1}}{u_n}\unfty{=}1-\frac{a}{n}+\smallo{\frac{1}{n}}$
		Démontrer que:
		\begin{itemize}
			\item si $a>1$ alors $\displaystyle\sum\limits_{n\in \N} u_n$ converge;
			\item si $a<1$ alors $\displaystyle\sum\limits_{n\in \N} u_n$ diverge;
			\item Si $a=1$ alors on ne peut pas conclure quant à la nature de $\displaystyle\sum\limits_{n\in \N} u_n$.
		\end{itemize}
	\end{enumerate}
	
	\section{Règle de d'Alembert \ccinp{2}}
	\textcolor{blue}{\hyperref[sec:regle-de-dalembert]{[Corrigé]}}\\
	\label{Règle de d'Alembert}
	Soit $(u_n)\in(\R^*_+)^\N$ telle que $\unfty{\lim}\displaystyle\frac{u_{n+1}}{u_n}=\ell\in\R_+\cup\{+\infty\}$.
	\\Démontrer que :
	\begin{itemize}
		\item si $\ell<1$ alors $\displaystyle\sum_{n\in \N} u_n$ converge;
		\item si $\ell>1$ alors $\displaystyle\sum_{n\in \N} u_n$ diverge;
		\item Si $\ell=1$ alors on ne peut pas conclure quant à la nature de $\displaystyle\sum_{n\in \N} u_n$.
	\end{itemize}
	
	\section{Règle de Cauchy \ccinp{2}}
	\textcolor{blue}{\hyperref[sec:regle-de-cauchy]{[Corrigé]}}\\
	\label{Règle de Cauchy}
	Soit $(u_n)\in(\R_+)^\N$ telle que $\unfty{\lim}\displaystyle\sqrt[n]{u_n}=\ell\in\R_+\cup\{+\infty\}$.
	\\Démontrer que :
	\begin{itemize}
		\item si $\ell<1$ alors $\displaystyle\sum_{n\in \N} u_n$ converge;
		\item si $\ell>1$ alors $\displaystyle\sum_{n\in \N} u_n$ diverge;
		\item Si $\ell=1$ alors on ne peut pas conclure quant à la nature de $\displaystyle\sum_{n\in \N} u_n$.
	\end{itemize}
	
	\section{d'Alembert $\implies$ Cauchy \centraleponts{3}}
	\textcolor{blue}{\hyperref[sec:dalembert-rightarrow-cauchy]{[Corrigé]}}\\
	\label{d'Alembert implique Cauchy}
	Soit $\displaystyle\sum\limits_{n\in \N} u_n$ une série à termes strictement positifs.
	\\ Montrer que si $\unfty{\lim} \displaystyle\frac{u_{n+1}}{u_n}=\ell$ alors $\unfty{\lim}\sqrt[n]{u_n}=\ell$.
	
	\section{\underline{Transformation et règle d'Abel} \centraleponts{2}}
	\textcolor{blue}{\hyperref[sec:transformation-dabel-et-regle-dabel]{[Corrigé]}}\\
	\label{Transformation et règle d'Abel}
	Soit $(a_n)_{n\geq n_0}$ et $(B_n)_{n\geq n_0}$ deux suites complexes. On définit $(A_n)_{n\geq n_0}$ et $(b_n)_{n\geq n_0}$ telles que: \\$\forall n \geq n_0$, $A_n=\displaystyle\sum\limits_{k=n_0}^na_k$ et $b_n=B_{n+1}-B_n$
	\begin{enumerate}
		\item Démontrer que: $ \forall n\geq n_{0},\ \displaystyle\sum\limits_{k=n_0}^na_kB_k=A_nB_n-\sum\limits_{k=n_0}^{n-1} A_kb_k$
		\item Démontrer que si $(A_n)_{n\geq n_0}$ est bornée, si $\displaystyle\sum|b_n-b_{n+1}|$ converge et si $(b_n)_{n\geq n_0}$ tend vers 0 alors $\displaystyle\sum_{n\geq n_0}a_nb_n$ converge.
	\end{enumerate}
	\underline{Remarque}: On remarquera la ressemblance entre la transformation d'Abel et l'intégration par parties.
	
	\subsection{Une série de Dirichlet \centraleponts{3}}
	Déterminer la nature de la série $\displaystyle\sum_{n\in \N^*}\frac{\sin n}{n^\alpha}$ suivant la valeur du paramètre $\alpha\in \R$.
	
	\section{Equation différentielle discrète \centraleponts{3}}
	\textcolor{blue}{\hyperref[sec:equation-differentielle-discreteetoile3]{[Corrigé]}}\\
	\label{Equation différentielle discrète}
	Soit $(a_n)_{n\in\N^*}$ une suite de réels strictement positifs telle que: $\lim\limits_{n\to\infty}a_n(a_1^2+\dots+a_n^2)=1$
	\begin{enumerate}[leftmargin=*]
		\item Montrer que la suite $(a_n)_{n\in \N^*}$ converge vers 0 et que $\displaystyle\sum\limits_{n\in\N^*}a_n^2$ diverge.
		\item On note $S_n=\displaystyle\sum\limits_{k=1}^na_n^2$. Montrer que $\displaystyle\lim\limits_{n\to+\infty}\int_{S_{n-1}}^{S_n}t^2=1$.
		\item En déduire que $a_n\unfty{\sim}\displaystyle\frac{1}{\sqrt[3]{3n}}$
	\end{enumerate}
	
	\section{Critère spécial des série alternées \etoile{1}}
	\textcolor{blue}{\hyperref[sec:critere-special-des-series-alternees]{[Corrigé]}}\\
	\label{Critère spécial des séries alternées}
	Soit $(a_n)_{n\in \N}$ une suite réelle positive de limite nulle.\\
	Peut-on affirmer que $\displaystyle\sum\limits_{n\in \N}(-1)^na_n$ converge ? Justifier.
	
	\section{Calcul d'une somme de série (1) \xens{3}}
	\textcolor{blue}{\hyperref[sec:calcul-dune-somme-de-serie-1-etoile3]{[Corrigé]}}\\
	\label{Calcul d'une somme de série 1}
	On pose $\forall n \in \N^*,\ u_n=\displaystyle\sum\limits_{k=1}^nk^2.$ Calculer  $\displaystyle\sum\limits_{n=1}^{+\infty}\frac{1}{u_n}$.
	
	\section{Calcul d'une somme de série (2) \ccinp{1}}
	\textcolor{blue}{\hyperref[sec:calcul-dune-somme-de-serie-2-etoile1]{[Corrigé]}}\\
	\label{Calcul d'une somme de série 2}
	On pose $\forall n\in \N^*,\ u_n=\displaystyle\sum\limits_{k=1}^n\frac{1}{n+k}$. Déterminer la limite de $(u_n)_{n\in \N^*}$.
	
	\section{Calcul d'une somme de série (3) \centraleponts{3}}
	\label{Calcul d'une somme de série 3}
	\textcolor{blue}{\hyperref[sec:calcul-dune-somme-de-serie-3-etoile3]{[Corrigé]}}\\
	On pose pour tout $n\in \N^*,\ u_n=\displaystyle\sum\limits_{k=1}^n\frac{\ln(k)}{k}-\frac{1}{2}\ln(n)^2$.
	\begin{enumerate}[leftmargin=*]
		\item Montrer que $(u_n)_{n\in \N^*}$ converge.
		\item Calculer la somme $\displaystyle\sum\limits_{n=1}^{+\infty}\frac{(-1)^n\ln(n)}{n}$.
	\end{enumerate}
	
	\section{Problème de Bâle}
	\label{Problème de Bâle}
	\textcolor{blue}{\hyperref[sec:probleme-de-bale]{[Corrigé]}}\\
	On cherche à calculer la somme des $\frac{1}{n^2}$. On va noter \[\zeta(2)=\sum_{n=1}^{+\infty}\frac{1}{n^2}\]
	\subsection{Lemme de Riemann-Lebesgue}
	\begin{enumerate}[leftmargin=*]
		\item Soient $(a,b)\in \R^2$ tel que $a<b$ et $f$ une fonction de classe $\mathcal C^1$ sur $[a,b]$ à valeurs dans $\R$. On pose pour $\lambda\in \R$,
		$$I(\lambda)=\int_a^bf(t)\cos(\lambda t)dt\quad \text{et}\quad J(\lambda)=\int_a^bf(t)\sin(\lambda t)dt$$
		Montrer que $\lim\limits_{\lambda\to +\infty}I(\lambda)=\lim\limits_{\lambda\to +\infty}J(\lambda)=0$.
		\item Déterminer deux réels $u$ et $v$ tels que pour tout $n\in \N^*$ :
		$$\int_0^\pi(ux+vx^2)\cos(nx)dx=\frac{1}{n^2}$$
		\item Soit $n\in\N^*$.  Montrer que pour tout $x\in]0,\pi]$.
		\[\sum_{k=1}^{n}\cos(kx)=\frac{\sin\left(\left(n+\frac{1}{2}\right)x\right)}{2\sin\left(\frac{x}{2}\right)}-\frac{1}{2}\]
		\item Montrer que la fonction $\varphi:x\in ]0,\pi]\mapsto\displaystyle\frac{x}{\sin\left(\frac{x}{2}\right)}$ est prolongeable en une fonction de classe $\mathcal C^1$ sur $[0,\pi]$.
		\item En déduire que $\zeta(2)=\displaystyle\frac{\pi^2}{6}$.
		\item Exprimer la somme de la série $\displaystyle\sum_{n\in \N^*}\frac{1}{(2n-1)^2}$ en fonction de $\zeta(2)$ et en déduire sa valeur.
		\item En adaptant les réels de la question 2, justifier la convergence et calculer les sommes des séries $\displaystyle\sum_{n\in \N^*}\frac{(-1)^{n-1}}{n^2}$.
	\end{enumerate}
	\subsection{Série de fonctions \ccinp{3}}
	Pour tout $m\in \N^*$ on pose $f_m:\theta \in ]-\pi,\pi[ \displaystyle\longmapsto\frac{\sin((2m+1)\theta)}{\sin^{2m+1}(\theta)}$
	\begin{enumerate}
		\item Démontrer que $f_m$ est une fonction polynomiale de $ \operatorname{cotan}^2(\theta) $
		\item En déduire que $\zeta(2)=\displaystyle\frac{\pi^2}{6}$
	\end{enumerate}
	\subsection{Série entière \ccinp{3}}
	En utilisant le développement en série entière de $\arcsin$ et en intégrant termes à termes, démontrer que $\zeta(2)=\displaystyle\frac{\pi^2}{6}$
	
	\section{Nombre moyen de diviseurs d'un entier \xens{4}}
	\label{Nombre moyen de diviseurs d'un entier}
	\textcolor{blue}{\hyperref[sec:nombre-moyen-de-diviseurs-dun-entier-etoile4]{[Corrigé]}}\\
	Pour tout $n \in \N^*$, on note $\tau(n)$ le nombre de diviseurs positifs de $n$ et pour tout $x \geq 1$, on pose F$(x)=\displaystyle\sum\limits_{1\leq n \leq x} \tau(n)$.
	\begin{enumerate}
		\item Déterminer un équivalent en $+\infty$ de F.
		\item Démontrer que F$(x)\uxfty{=}x\ln x+(2\gamma-1)x+\bigO{\sqrt x}$
	\end{enumerate}
	\underline{Indication:} on pourra remarquer que $\tau(n)=\displaystyle\sum\limits_{d|n}1$ où la somme porte sur les diviseurs positifs de $n$.
	
	\section{Théorème de réarrangement de Riemann \xens{5}}
	\label{Théorème de réarrangement de Riemann}
	\textcolor{blue}{\hyperref[sec:theoreme-de-rearrangement-de-riemann-etoile5]{[Corrigé]}}\\
	Soient $\displaystyle\sum\limits_{n\in \N} a_n$ une série semi-convergente et $\alpha \in \R$.
	\\Démontrer qu'il existe une permutation $\sigma$ de $\N$ telle que $\displaystyle\sum\limits_{n=0}^{+\infty}a_{\sigma(n)}=\alpha$.
	
	\section{Moyennes arithmétique, géométrique et harmonique \ccinp{1}}
	\label{Moyennes arithémtique, géométrique et harmonique}
	\textcolor{blue}{\hyperref[sec:moyennes-arithmetique-geometrique-et-harmonique-etoile1]{[Corrigé]}}\\
	Soit $(a_i)_{1\leq i\leq n}$ des réels strictement positifs. On pose $A_n=\displaystyle\frac{1}{n}\sum\limits_{k=1}^n a_k$, $G_n=\displaystyle\sqrt[n]{\prod\limits_{k=1}^n a_k}$ et $H_n=\displaystyle\frac{n}{\displaystyle\sum\limits_{k=1}^n \frac{1}{a_k}}$\\
	Démontrer que $H_n \leq G_n \leq A_n$.
	
	\section{Inégalité de Carleman \centraleponts{3}}
	\label{Inégalité de Carleman}
	\textcolor{blue}{\hyperref[sec:inegalite-de-carleman]{[Corrigé]}}\\
	Soit $a_n \in (\R_+)^{\N^*}$ telle que $\displaystyle\sum\limits_{n\in \N^*} a_n$ converge.
	\\\\Démontrer que $\displaystyle\sum\limits_{n=1}^{+\infty}\sqrt[n]{\prod\limits_{k=1}^{n} a_k} \leq e\sum\limits_{n=1}^{+\infty} a_n$.
	\\ \underline{Indication:} On utilisera le résultat de l'exercice précédent et la formule de Stirling.
	
	\newpage
\chapter{Intégrale}
	\section{Règle de Bioche \etoile{1}}
	\textcolor{blue}{\hyperref[Règle de Bioche corrigé]{[Corrigé]}}\\
	\label{bioche}
	\label{Règle de Bioche}
	Calculer:
	\begin{enumerate}
		\item $\displaystyle\int_0^\pi\frac{\sin(t)}{4-\cos(t)^2}dt$ en posant $u=\cos(t)$;
		\item $\displaystyle\int_{\pi/2}^x\frac{dt}{\sin(t)}$ pour tout $x\in]0,\pi[$ en posant $u=\cos(t)$;
		\item $\displaystyle\int_{-\pi/4}^{\pi/4} \frac{dt}{\cos(t)^3}$ en posant $u=\sin(t)$.
		\item $\displaystyle\int_0^{\pi/2}\frac{dt}{\sin(t)+\cos(t)}$ en posant $u=\displaystyle\tan\left(\frac{t}{2}\right)$
	\end{enumerate}
	
	\section{Intégrale de Wallis \ccinp{2}}
	\textcolor{blue}{\hyperref[Intégrale de Wallis corrigé]{[Corrigé]}}\\
	\label{wallis}
	\label{Intégrale de Wallis}
	$\forall n \in \N$, on pose $W_n=\displaystyle\int_0^{\pi/2}\sin^n(x)dx$.
	\begin{enumerate}
		\item Donner un équivalent simple de $W_n$
		\item Trouver une expression de $W_{2n}$ et $W_{2n+1}$ à l'aide de factorielles.
	\end{enumerate}
	
	\section{Formule de Stirling \ccinp{2}}
	\textcolor{blue}{\hyperref[Formule de Stirling corrgié]{[Corrigé]}}\\
	\label{stirling}
	\label{Formule de Stirling}
	On pose pour tout $n\in\N^*$, $\displaystyle u_n=\frac{n^ne^n\sqrt{n}}{n!}$.
	\begin{enumerate}
		\item Pour tout $n\in\N^*$, on pose $v_n=\ln(u_n)$. Montrer que : \(v_n=\underset{n\to+\infty}{\mathcal{O}}\left(\frac{1}{n^2}\right)\)
		\item En déduire que $u_n$ converge vers un certain $\ell\in\R^*_+$.
		\item Montrer que \(\displaystyle\ell=\frac{1}{\sqrt{2\pi}}\) et en déduire que un équivalent de $n!$.
	\end{enumerate}
	
	\section{Intégrale de Gauss}
	\textcolor{blue}{\hyperref[Intégrale de Gauss corrigé]{[Corrigé]}}
	\label{gauss}
	\label{Intégrale de Gauss}
	\subsection{Wallis \ccinp{3}}
	En utilisant les intégrales de Wallis et la concavité du $\ln$, démontrer que $\displaystyle\int_0^{+\infty} e^{-t^2}dt=\frac{\sqrt{\pi}}{2}$
	\subsection{Intégrales auxiliaires \telecom{3}}
	On pose $\forall n \in \N^{*}$ , $I_n=\displaystyle\int_0^1 \frac{1}{(1+t^2)^n}dt$ et $K_n=\displaystyle\int_0^{+\infty} \frac{1}{(1+t^2)^n}dt$
	\begin{enumerate}
		\item Démontrer que $K_n \unfty{\sim} I_n$ et que $\forall n \in \N^*$, $ K_n=K_{n+1}+\displaystyle\frac{K_n}{2n}$.
		\item En déduire à l'aide du théorème de convergence dominée que $\displaystyle\int_0^{+\infty} e^{-t^2}dt=\frac{\sqrt{\pi}}{2}$
	\end{enumerate}
	
	\subsection{Equivalent du reste \telecom{2}}
	
	A l'aide d'une IPP, trouver un équivalent de $\displaystyle\int_x^{+\infty}e^{\frac{-x^2}{2}}dx$ en $+\infty$.
	
	\section{Intégrale de Fresnel \centraleponts{3}}
	\textcolor{blue}{\hyperref[Intégrale de Fresnel corrigé]{[Corrigé]}}\\
		\label{fresnel}
		\label{Intégrale de Fresnel}
	\begin{enumerate}[leftmargin=*]
		\item Justifier que $I:x\mapsto\displaystyle\int_0^{+\infty}\frac{e^{-(t^2+i)x^2}}{t^2+i}dt$ est $\mathcal C^1$ sur $\R^*_+$ et calculer sa dérivée.
		\item Calculer l'intégrale de Fresnel : $\displaystyle\int_0^{+\infty}e^{-it^2}dt$.\\
		On admettra le résultat sur l'intégrale de Gauss $\displaystyle\int_0^{+\infty}e^{-t^2}dt=\frac{\sqrt{\pi}}{2}$.
	\end{enumerate}
	
	\section{Intégrale de Dirichlet}
	\textcolor{blue}{\hyperref[Intégrale de Dirichlet corrigé]{[Corrigé]}}\\
	\label{dirichlet}
	\label{Intégrale de Dirichlet}
	On pose $I=\displaystyle\int_0^{+\infty} \frac{\sin(t)}{t}dt$.
	
	\subsection{Semi-convergence \ccinp{2}}
	Démontrer que l'intégrale est semi-convergente.
	
	\subsection{Une autre expression \ccinp{2}}
	Montrer que $I=\displaystyle\int_0^{+\infty}\frac{\sin^2(t)}{t^2}dt$.
	
	\subsection{Premier calcul \ccinp{2}}
	On pose pour tout $n \in \N$ , $u_n=\displaystyle\int_0^{\pi/2} \frac{\sin((2n+1)t)}{\sin(t)}dt$ et $v_n=\displaystyle\int_0^{\pi/2} \frac{\sin((2n+1)t)}{t}dt$.
	\begin{enumerate}
		\item Démontrer que $(u_n)_{n\in \N}$ est constante et égale à $\displaystyle\frac{\pi}{2}$.
		\item En utilisant le lemme de Riemann-Lebesgue, démontrer que $\lim\limits_{n\to+\infty} v_n-u_n=0$.
		\item En déduire que $I=\displaystyle\frac{\pi}{2}$.
	\end{enumerate}
	
	\subsection{Second calcul \ccinp{3}}
	On pose $F:x\longmapsto \displaystyle\int_0^{+\infty} e^{xt}\times \frac{\sin(t)}{t}dt$.
	\begin{enumerate}
		\item Démontrer que $\forall x \in \R^*_+,\ F'(x)=-\displaystyle\frac{1}{1+x^2}$.
		\item En déduire que $I=\displaystyle\frac{\pi}{2}$.
	\end{enumerate}
	\underline{Remarque:} Il s'agit d'un cas particulier de la méthode de Feynman.
	
	\section{Intégrale du reste de l'intégrale de Dirichlet \telecom{3}}
	\textcolor{blue}{\hyperref[Intégrale du reste de l'intégrale de Dirichlet corrigé]{[Corrigé]}}\\
	\label{restedirichlet}
	\label{Intégrale du reste de l'intégrale de Dirichlet}
	Justifier l'existence et calculer l'intégrale $I=\displaystyle\int_0^{+\infty}\left(\int_x^{+\infty}\frac{\sin t}{t}dt\ \right)dx$.
	
	\section{Intégrale d'Euler \ccinp{2}}
	\textcolor{blue}{\hyperref[Intégrale d'Euler corrigé]{[Corrigé]}}\\
	\label{euler_1}
	\label{Intégrale d'Euler}
	On pose $I=\displaystyle\int_0^{\pi/2}\ln(\sin t)dt$ et $J=\displaystyle\int_0^{\pi/2}\ln(\cos t)dt$.
	\begin{enumerate}
		\item Montrer que $I=J$.
		\item Exprimer $I+J$ en fonction de $I$.
		\item En déduire la valeur de $I$.
	\end{enumerate}
	
	\section{Fonction intégrale \centraleponts{3}}
	\textcolor{blue}{\hyperref[Fonction intégrale corrigé]{[Corrigé]}}\\
	\label{fonction_intégrale}
	\label{Fonction intégrale}
	Soit $I:x\mapsto\displaystyle\int_{0}^{+\infty} \frac{\ln(t)}{x^2+t^2}dt$. Justifier que $I$ est définie sur $\R^*_+$ et déterminer $\sup\limits_{x>0}I(x)$.
	
	\section{Intégrales de Bertrand}
	\textcolor{blue}{\hyperref[Intégrale de Bertrand corrigé]{[Corrigé]}}\\
	\label{intbertrand}
	\label{Intégrales de BErtrand}
	\begin{enumerate}[leftmargin=*]
		\item Pour quelles valeurs des réels $\alpha$ et $\beta$ l'intégrale $\displaystyle\int_e^{+\infty}\frac{dt}{t^\alpha(\ln t)^\beta}$ converge ?
		\item Même question pour $\displaystyle\int_0^{e^{-1}}\frac{dt}{t^\alpha(\ln t)^\beta}$.
	\end{enumerate}
	
	\section{Intégrabilité des cosinus de polynôme}
	\textcolor{blue}{\hyperref[Intégrabilité des cosinus de polynômes corrigé]{[Corrigé]}}\\
	\label{Intégrabilité des cosinus de polynôme}
	Soit $P\in \R[X]$ de degré supérieur ou égal à $2$.
	\begin{enumerate}
		\item Déterminer la nature de l'intégrale $I=\displaystyle\int_0^{+\infty}\cos(P(x))dx$.
		\item Déterminer la nature de l'intégrale $J=\displaystyle\int_0^{+\infty}|\cos(P(x))|dx$.
		\item Déterminer le signe de $I$ dans le cas $P=X^2$.
	\end{enumerate}
	
	\section{Nature d'une intégrale (1) \telecom{2}}
	\textcolor{blue}{\hyperref[Nature d'une intégrale (1) corrigé]{[Corrigé]}}\\
	\label{Nature d'une intégrale (1)}
	Pour quelles valeurs du réel $\alpha$ l'intégrale $\displaystyle\int_0^1\frac{dt}{\arccos(t)^\alpha}$ converge-t-elle ?
	
	\section{Nature d'une intégrale (2)}
	\textcolor{blue}{\hyperref[Nature d'une intégrale (2) corrigé]{[Corrigé]}}\\
	\label{Nature d'une intégrale (2)}
	Pour quelles valeurs du réel $\alpha$ l'intégrale $\displaystyle\int_0^{+\infty}\frac{\sin t}{t^\alpha}dt$ converge ?
	
	\section{Divergence grossière}
	\textcolor{blue}{\hyperref[Divergence grossière corrigé]{[Corrigé]}}\\
	\label{divergencegrossière}
	\label{Divergence grossière}
	\begin{enumerate}[leftmargin=*]
		\item Soit $f$ une application continue par morceaux de $\R_+$ dans $\R$ admettant une limite $\ell$ en $+\infty$ et telle que l'intégrale $\displaystyle\int_0^{+\infty}f(t)dt$ converge. Montrer que $\ell=0$.
		\item Soit $f$ une application uniformément continue de $\R_+$ dans $\R$ telle que l'intégrale $\displaystyle\int_0^{+\infty}f(t)dt$ converge. Montrer que $\lim\limits_{+\infty}f=0$.
	\end{enumerate}
	
	\section{Espace $L^2$ et dérivation}
	\textcolor{blue}{\hyperref[sec:espace-L2-et-derivation]{[Corrigé]}}\\
	\label{L2}
	\label{Espace L^2 et  dérivation}
	Soit $f:\R\to \R$ de classe $\mathcal C^2$ telle que $f$ et $f''$ soit de carré intégrable sur $\R$.
	\begin{enumerate}
		\item Montrer que $f'$ est également de carré intégrable sur $\R$.
		\item Montrer que $\displaystyle\left(\int_\R f'^2\right)^2\leq \left(\int_\R f^2\right)\left(\int_\R f''^2\right)$.
	\end{enumerate}
	
	\section{Intégrale de Frullani \centraleponts{3}}
	\textcolor{blue}{\hyperref[sec:integrale-de-frullani]{[Corrigé]}}\\
	\label{frullani}
	\label{Intégrale de Frullani}
	Soit $f:[0,+\infty[ \to \R$ une fonction continue telle que l'intégrale $\displaystyle\int_0^{+\infty} \frac{f(t)}{t}dt$ converge et soient $a,b$ deux réels strictement positifs.
	\\Démontrer que $\displaystyle\int_0^{+\infty} \frac{f(at)-f(bt)}{t}dt = f(0)\ln\left(\displaystyle\frac{b}{a}\right)$.
	
	\section{Calcul d'une intégrale (1) \etoile{3}}
	\textcolor{blue}{\hyperref[sec:calcul-dune-integrale-1-etoile3]{[Corrigé]}}\\
	\label{calculintégrale1}
	\label{Calcul d'une intégrale 1}
	Justifier l'existence et calculer pour tout entier $n\geq 2,\ I_n=\displaystyle\int_0^{+\infty}\frac{dt}{(t+1)\dots(t+n)}$.
	
	\section{Calcul d'une intégrale (2) \telecom{2}}
	\textcolor{blue}{\hyperref[sec:calcul-dune-integrale-2-etoile2]{[Corrigé]}}\\
	\label{calculintégrale2}
	\label{Calcul d'une intégrale 2}
	Justifier l'existence et calculer $I=\displaystyle\int_0^1x\left\lfloor\frac{1}{x}\right\rfloor dx$.
	
	\section{Calcul d'une intégrale (3) \etoile{3}}
	\textcolor{blue}{\hyperref[sec:calcul-dune-integrale-3]{[Corrigé]}}\\
	\label{calculintégrale3}
	\label{Calcul d'une intégrale 3}
	Justifier l'existence et calculer $I=\displaystyle\int_{-\infty}^{+\infty}\frac{dx}{1+x^6}$.
	
	\section{Calcul d'une intégrale (4) \etoile{3}}
	\textcolor{blue}{\hyperref[sec:calcul-dune-integrale-4]{[Corrigé]}}\\
	\label{calculintégrale4}
	\label{Calcul d'une intégrale 4}
	Soit $a>0$.\\
	Justifier l'existence et calculer $I=\displaystyle\int_0^{+\infty}\frac{\arctan(ax)-\arctan(x/a)}{1+x^2}dx$.
	

	\section{Permutation Série-intégrale (1)}
	\textcolor{blue}{\hyperref[sec:permutation-serie-integrale-1]{[Corrigé]}}\\
	\label{ccinpmp2024}
	\label{Permutation Série-Intégrale 1}
	\begin{enumerate}
		\item Montrer que $\displaystyle I=\int_0^{+\infty}e^{-x}\cos(\sqrt{x})dx$ converge.
		\item Montrer que $\displaystyle I=\sum_{n=0}^{+\infty}\frac{(-1)^nn!}{(2n)!}$
	\end{enumerate}
	
	\section{Permutation série-intégrale (2)}
	\textcolor{blue}{\hyperref[sec:permutation-serie-integrale-2]{[Corrigé]}}\\
	\label{Permutation série-intégrale 2}
	Calculer l'intégrale $\displaystyle\int_0^{+\infty}\frac{\ln(1+t)}{t\sqrt{1+t}}dt$ à l'aide d'une permutation série-intégrale.
	
	\section{Fonction d'écart logarithmique intégral \etoile{2}}
	\textcolor{blue}{\hyperref[sec:fonction-decart-logarithmique-integral-etoile2]{[Corrigé]}}\\
	\label{logint}
	\label{Fonction d'écart logarithmique intégral}
	On considère la fonction d'écart logarithmique intégral, qui est l'application définie par: $ \forall 2 \geq x,\ \operatorname{Li}(x)=\displaystyle\int_2^{x} \frac{dt}{\ln(t)}$
	\\Déterminer un développement asymptotique de $\operatorname{Li}(x)$ à tout ordre.\\
	On donnera une expression en fonction de la somme $\displaystyle\sum\limits_{k=0}^n\frac{k!}{(\ln x)^k}$.
	
	\section{Intégrale de Bernoulli \centraleponts{3}}
	\textcolor{blue}{\hyperref[sec:integrale-de-bernoulli]{[Corrigé]}}\\
	\label{intégralebernoulli}
	\label{Intégrale de Bernoulli}
	Démontrer que $\displaystyle\int_0^1\frac{dx}{x^x}=\sum_{n=1}^{+\infty}\frac{1}{n^n}$.
	
	\section{Lemme de Riemann-Lebesgue : cas des fonctions $\mathcal{C}^1$ \ccinp{1}}
	\textcolor{blue}{\hyperref[sec:lemme-de-riemann-lebesgue--cas-des-fonctions-mathcalc1-etoile1]{[Corrigé]}}\\
	\label{riemannlebesgue}
	\label{Lemme de Riemann-Lebesgue : cas des fonction C1}
	On considère un segment $[a,b]$ de $\R$ et $\phi\in \mathcal{C}^1([a,b],\C)$.\\
	Montrer que $\lim\limits_{\lambda\to +\infty}\displaystyle\int_a^b\phi(t)e^{i\lambda t}dt=0$.
	
	\section{Intégrale de Poisson (1) \etoile{2}}
	\textcolor{blue}{\hyperref[sec:integrale-de-poisson-1-etoile2]{[Corrigé]}}\\
	\label{intpoisson1}
	\label{Intégrale de Poisson 1}
	Pour tout $\rho \in \R\setminus\{-1,1\}$, on pose $I(\rho)=\displaystyle\int_0^\pi \ln(1-2\cos(\theta)\rho+\rho^2)d\theta$\\
	Montrer en passant par des sommes de Riemann que $I(\rho)=\begin{cases}
		0 & \mbox{si} \ \rho \in ]-1,1[\\
		2\pi \ln(|\rho|) & \mbox{si} \ \rho \in \R\setminus[-1,1]
	\end{cases}$
	
	\section{Intégrale de Poisson (2) \etoile{3}}
	\textcolor{blue}{\hyperref[sec:integrale-de-poisson-2-etoile3]{[Corrigé]}}\\
	\label{intpoisson2}
	\label{Intégrale de Poisson 2}
	Pour tout $\rho \in \R\setminus\{-1,1\}$, on pose $I(\rho)=\displaystyle\int_0^\pi \ln(1-2\cos(\theta)\rho+\rho^2)d\theta$
	\begin{enumerate}[leftmargin=*]
		\item Montrer que $\forall \rho\in \R^*\setminus\{-1,1\},\ I(\rho)-I\left(\displaystyle\frac{1}{\rho}\right)=2\pi\ln(|\rho|)$.
		\item Démontrer que $\forall \rho\in \R\setminus\{-1,1\},\ \forall n \in \N$, $I(\rho)=\displaystyle\frac{1}{2^n}I\left(\rho^{2^n}\right)$.
		\item En déduire que $I(\rho)=\begin{cases}
			0 & \mbox{si} \ \rho \in ]-1,1[\\
			2\pi \ln(|\rho|) & \mbox{si} \ \rho \in \R\setminus[-1,1]
		\end{cases}$
	\end{enumerate}
	
	\section{Mines-Ponts MP 2024 (Chaïma Prime)}
	\textcolor{blue}{\hyperref[sec:mines-ponts-mp-2024-chaima-prime]{[Corrigé]}}\\
	\label{chaima}
	\label{Mines-Ponts MP 2024}
	On pose pour $n\in\N^*$: $$h_n:x\in \R_+^*\mapsto\int_0^{+\infty}\frac{dt}{(t^2+x^4)^n}$$
	\begin{enumerate}
		\item Montrer que $h_n$ est dérivable sur $\R^*_+$ et que $$\forall x\in\R^*_+,\ h_n'(x)=-4nx^3h_{n+1}(x)$$
		\item Montrer qu'il existe une suite $(a_n)_{n\in\N^*}$ telle que $$\forall n\in\N^*,\forall x\in\R^*_+,\ h_n(x)=a_nx^{2-4n}$$
		\item Déterminer $h_n$ pour tout $n\in\N^*$.
	\end{enumerate}
	
	\section{Une suite d'intégrales (1)}
	\textcolor{blue}{\hyperref[sec:une-suite-dintegrales-1]{[Corrigé]}}\\
	\label{suiteintégrale1}
	\label{Une suite d'intégrales 1}
	On pose pour tout $n\in \N$, $I_n=\displaystyle\int_0^1(t\ln t)^ndt$. Montrer l'existence de $I_n$ et calculer sa valeur pour tout $n\in \N$.
	
	\section{Une suite d'intégrales (2)}
	\textcolor{blue}{\hyperref[sec:une-suite-dintegrales-2]{[Corrigé]}}\\
	\label{suiteintégrale2}
	\label{Une suite d'intégrales 2}
	On pose pour tout $n\in\N$, $\displaystyle u_n=\int_0^1\frac{dx}{1+x^n}$
	\begin{enumerate}
		\item Montrer que $(u_n)$ converge et donner sa limite.
		\item A l'aide d'une intégration par parties, donner un développement asymptotique à deux termes de $u_n$.
	\end{enumerate}
	
	\section{Une suite d'intégrales (3)}
	\textcolor{blue}{\hyperref[sec:une-suite-dintegrales-3]{[Corrigé]}}\\
	\label{suiteintégrale3}
	\label{Une suite d'intégrles 3}
	Soit $n\in \N$. On pose :
	$$I_n=\int_0^1\frac{x^{2n}}{1+x^n}dx\quad\text{et}\quad J_n=\int_0^1\frac{x^{2n+1}}{1+x^n}dx$$
	\begin{enumerate}
		\item Justifier l'existence de $I_n$ et $J_n$ et calculer les limite de $(I_n)_{n\in \N}$ et $(J_n)_{n\in \N}$.
		\item Montrer que $|I_n-J_n|\leq \displaystyle\frac{1}{4n^2}$.
		\item Calculer $J_n$.
		\item En déduire un équivalent de $I_n$.
	\end{enumerate}
	
	
	\section{Nombre d'Apery}
	\textcolor{blue}{\hyperref[sec:nombre-dapery]{[Corrigé]}}\\
	\label{Apery}
	\label{Nombre d'Arery}
	On définit une suite $(u_n)$ de fonctions en posant :$$\forall n\geq 2,\; \forall t\in]0,1],\; u_n(t)=\frac{t^{n-1}\ln(t)}{n}$$
	\begin{enumerate}
		\item Calculer $\normep{\infty}{u_n}$.
		\item Montrer que la fonction $\displaystyle f:t\mapsto\frac{\ln(t)\ln(1-t)}{t}$ est intégrable sur $]0,1[$.
		\item En déduire que $\displaystyle\int_0^1f(t)dt=\sum_{k=1}^{+\infty}\frac{1}{k^3}$
	\end{enumerate}
	
	\section{Comportement asymptotique (1)}
	\textcolor{blue}{\hyperref[sec:comportement-asymptotique-1]{[Corrigé]}}\\
	\label{comportementasymp1}
	\label{Comportement asymptotique 1}
	Soit $f\in \mathcal C^1(\R_+,\R^*_+)$ telle que $\displaystyle\frac{f'(x)}{f(x)}\uxfty\sim\frac{2}{x}$.\\
	Montrer que $\displaystyle\int_0^xf(t)dt\uxfty\sim\frac{xf(x)}{3}$.
	
	\section{Comportement asymptotique (2)}
	\textcolor{blue}{\hyperref[sec:comportement-asymptotique-2]{[Corrigé]}}\\
	\label{comportementasymp2}
	\label{Comportement asymptotique 2}
	Soit $f\in \mathcal C^0(\R_+,\R_+)$ décroissante.\\
	Montrer que si $f$ est intégrable sur $\R_+$ alors $\uxfty\lim xf(x)=0$. La réciproque est-elle vraie ?
	
	\section{Théorème de d'Alembert-Gauss (1) \etoile{2}}
	\textcolor{blue}{\hyperref[sec:theoreme-de-dalembert-gauss-1-etoile2]{[Corrigé]}}\\
	\label{alembertgauss1}
	\label{Théorème de d'Alembert-Gauss 1}
	Le but de cet exercice est de démontrer le théorème de d'Alembert-Gauss. On suppose par l'absurde qu'il existe un polynôme $P\in \C[X]$ non constant qui ne possède aucune racine complexe. On pose pour tout $r\geq 0$ :
	$$F(r)=\displaystyle\int_0^{2\pi}\frac{d\theta}{P(re^{i\theta})}$$
	\begin{enumerate}
		\item Montrer que $F$ est de classe $\mathcal C^1$ sur $\R_+$.
		\item Montrer que $F$ est constante sur $\R_+$.
		\item Conclure.
	\end{enumerate}
	
	\section{Fonction Gamma d'Euler\ccinp{2}}
	\textcolor{blue}{\hyperref[sec:fonction-gamma-deuler]{[Corrigé]}}\\
	\label{Fonction Gamma d'Euler}
	On pose, lorsque cela est définie, $\Gamma(x)=\displaystyle\int_0^{+\infty} t^{x-1}e^{-t}dt$.
	\begin{enumerate}
		\item Déterminer le domaine de définition de $\Gamma$.
		\item Démontrer que $\forall x\in \text{dom}(\Gamma),\ \Gamma(x+1)=x\Gamma(x)$ et en déduire que $\forall n \in \N,\ \Gamma(n+1)=n!$.
		\item Déterminer un équivalent simple en $0^+$ de $\Gamma$.
		\item Démontrer que $\Gamma$ est $\mathcal C^{\infty}$ sur son domaine de définition.
		\item Démontrer que $\Gamma$ est convexe sur $\R_+^*$.
		\item Démontrer que $\Gamma$ est log-convexe sur $\R^*_+$.
	\end{enumerate}
	
	\subsection{Point critique et limite en $+\infty$ \centraleponts{3}}
	\begin{enumerate}[leftmargin=*]
		\item Montrer que $\Gamma$ admet un minimum sur $\R^*_+$ et qu'il est atteint en un unique point.
		\item Déterminer la limite de $\Gamma$ en $+\infty$.
	\end{enumerate}
	
	\subsection{Valeur en les demi-entiers \ccinp{2}}
	Exprimer $\Gamma\left(n+\displaystyle\frac{1}{2}\right)$ en fonction de $n\in \N$.\\
	On donne $\displaystyle\int_{-\infty}^{+\infty}e^{-t^2}dt=\sqrt\pi$.
	
	\subsection{Théorème de Bohr-Mollerup \centraleponts{4}}
	\label{Bohr-Mollerup}
	Démontrer que $\Gamma$ est l'unique fonction qui vérifie:
	\begin{itemize}
		\item $\forall x \in \R_+^*,\ f(x+1)=xf(x)$;
		\item $f(1)=1$;
		\item $f$ est log-convexe (c'est à dire $\ln f$ est convexe) sur $]0,+\infty[$.
	\end{itemize}
	
	\subsection{Formules de Gauss et de Weierstrass}
	\label{Formules de Gauss et de Weierstrass}
	\begin{enumerate}
		\item Démontrer que $\forall x \in \R^*_+$,
		$$\Gamma(x)=\unfty\lim\frac{n^x n!}{x(x+1)\cdots(x+n)}=\frac{1}{x}\prod_{n=1}^{+\infty}\frac{\left(1+\frac{1}{n}\right)^x}{1+\frac{x}{n}}=\frac{e^{-\gamma x}}{x}\prod_{n=1}^{+\infty}\frac{e^{\frac{x}{n}}}{1+\frac{x}{n}}$$
		\item Vérifier que $\Gamma$ est de classe $\mathcal C^1$ sur $\R^*_+$ et calculer $\Gamma'(1)$ en utilisant la formule du produit ci-dessus.
		\item En déduire la valeur de l'intégrale :
		$$\int_0^{+\infty}\ln(t)e^{-t}dt$$
	\end{enumerate}
	
	\subsection{Lien entre les gamma d'Euler \centraleponts{3}}
	\label{Lien entre les gamma d'Euler}
	On utilisera les résultats sur la fonction gamma sans les redémontrer.
	\begin{enumerate}
		\item Montrer que $\displaystyle\lim_{n\to+\infty}\int_0^n\ln(t)\left(1-\frac{t}{n}\right)^ndt=\Gamma'(1)$.
		\item En déduire que $\Gamma'(1)=-\gamma$. On rappelle que $\gamma=\displaystyle\lim_{n\to+\infty}\sum_{k=1}^n\frac{1}{k}-\ln(n)$.
	\end{enumerate}
	
	\subsection{Formule de duplication de Legendre}
	\label{Formule de duplication}
	Montrer la formule de duplication de $\Gamma$ :
	$$\forall x\in \R^*_+,\ \Gamma(x)\Gamma\left(x+\frac{1}{2}\right)=2^{1-2x}\sqrt\pi\Gamma(2x)$$
	\begin{itemize}
		\item A l'aide de la formule du produit \ref{Formules de Gauss et de Weierstrass};
		\item A l'aide du théorème de Bohr-Mollerup \ref{Bohr-Mollerup}.
	\end{itemize}
	
	\subsection{Intégrale de Raabe}
	Montrer en utilisant la formule de duplication que pour tout $a\geq0$ on a :
	$$\int_a^{a+1}\ln(\Gamma(x))dx=a\ln a-a+\frac{\ln(2\pi)}{2}$$
	
	\subsection{Généralisation de la formule de Stirling}
	Montrer que \[\Gamma(x+1)\underset{x\to+\infty}{\sim}\sqrt{2\pi x}\left(\frac{x}{e}\right)^x\]
	A reformuler pour que ce soit accessible à tous
	
	\section{Fonction Bêta d'Euler\ccinp{2}}
	\textcolor{blue}{\hyperref[sec:fonction-beta-deuler]{[Corrigé]}}\\
	\label{Fonction Bêta d'Euler}
	On pose $ B : (x,y) \mapsto \displaystyle\int_0^1 t^{x-1}(1-t)^{y-1}dt$.
	\begin{enumerate}
		\item Déterminer le domaine de définition de $B$
		\item Démontrer que $\forall (x,y) \in \text{dom}(B),\ B(x,y)=B(y,x)$
		\item Démontrer que $\forall (x,y) \in \text{dom}(B),\ B(x+1,y)=\displaystyle\frac{x}{x+y}B(x,y)$
		\item Déterminer une expression de $B(n,p)$ pour $n,p\in \N^*$.
	\end{enumerate}
	
	\subsection{Lien avec une intégrale d'Euler}
	\label{Lien avec une intégrale d'Euler}
	On pose $I=\displaystyle\int_0^{\pi/2}\ln(\sin \theta)d\theta$.
	\begin{enumerate}
		\item Montrer que $B$ est de classe $\mathcal C^1$ sur $\left(\R^*_+\right)^2$ et exprimer ses dérivées partielles sous forme d'intégrales.
		\item Exprimer $I$ à l'aide une dérivée partielle de $B$.
	\end{enumerate}
	
	\subsection{Lien entre $\Gamma$ et B}
	\begin{enumerate}[leftmargin=*]
		\item Démontrer que $\forall (x,y)\in (\R^*_+)^2,\ B(x,y)=\displaystyle\frac{\Gamma(x)\Gamma(y)}{\Gamma(x+y)}$.\\
		\textit{Indication : On pourra utiliser le théorème de Bohr-Mollerup. \ref{Bohr-Mollerup}}
		\item En déduire un calcul de l'intégrale de Gauss $\displaystyle\int_{-\infty}^{+\infty}e^{-t^2}dt$.
		\item En déduire que $B$ est de classe $\mathcal C^1$ sur son domaine de définition et exprimer ses dérivées partielles en fonction de $\Gamma$ et de sa dérivée.
		\item En utilisant \ref{Intégrale d'Euler}, \ref{Lien avec une intégrale d'Euler} et \ref{Lien entre les gamma d'Euler}, calculer $\Gamma'\left(\displaystyle\frac{1}{2}\right)$.
	\end{enumerate}
	
	\section{Inégalité intégrale-dérivée}
	\textcolor{blue}{\hyperref[sec:inegalite-integrale-derivee-etoile1]{[Corrigé]}}\\
	\label{inegaliteintder}
	\label{Inégalité intégrale-dérivée}
	Soit $f:[a,b]\longmapsto \R $ une fonction de classe $\mathcal{C}^1$ telle que $f(a)=f(b)=0$.
	\\Démontrer que  $\displaystyle\left|\int_a^b f(t)dt \right|\leq \frac{(b-a)^2}{4}\normep{\infty}{f'}$.
	
	\section{Majoration de l'erreur dans la méthode des trapèzes \ccinp{2}}
	\textcolor{blue}{\hyperref[sec:majoration-de-lerreur-dans-la-methode-des-trapezes]{[Corrigé]}}\\
	\label{trapèze}
	\label{Majoration de l'erreur dans la méthode des trapèzes}
	Soit $f \in \mathcal{C}^2([a,b],\R)$. Montrer que : $$\left| \int_a^b f(t)dt-\frac{(b-a)}{2}(f(a)+f(b))\right| \leq \frac{(b-a)^3}{12}\left\|f''\right\|_\infty$$
	
	\section{Inégalité de Young \etoile{2}}
	\textcolor{blue}{\hyperref[sec:inegalite-de-young-etoile2]{[Corrigé]}}\\
	\label{young}
	\label{Inégalité de Young}
	Soient $c>0$ et $f:[0,c] \to \R$ une fonction de classe $\mathcal C^1$, strictement croissante sur $[0,c]$ et telle que $f(0)=0$.
	\\Démontrer que $\forall a\in [0,c],\ \forall b\in [0,f(c)],\ \displaystyle\int_0^a f(t)dt +\int_0^b f^{-1}(t)dt\geq ab$.
	\\Quand est-ce qu'il y a égalité ?
	\\ \underline{Remarque:} Il s'agit du cas général de $\displaystyle\frac{u^p}{p}+\displaystyle\frac{v^q}{q} \geq uv$ utilisée pour démontrer l'inégalité de Hölder.
	
	\section{Transformée de Laplace \centraleponts{4}}
	\textcolor{blue}{\hyperref[sec:transformee-de-laplace]{[Corrigé]}}\\
	\label{laplace}
	\label{Transformée de Laplace}
	Soit $f$ une fonction continue par morceaux sur $\R_+^*$. On suppose qu'il existe $p\in\R$ tel que $t\longmapsto f(t)e^{-pt}$ soit intégrable sur $\R^*_+$ et on pose: $\alpha=\inf \{p\in\R,t \mapsto f(t)e^{-pt} \in L^1(\R^*_+,\R)\}$
	\\Pour $p\in\R$, on pose $F(p)=\displaystyle\int_0^{+\infty} f(t)e^{-pt}dt$ lorsque cela est possible.
	\begin{enumerate}[leftmargin=*]
		\item Justifier que F est définie sur $]\alpha,+\infty[$
		\item \textit{\underline{Théorème de la valeur initiale}} : On suppose que $\lim\limits_{0^+} f=l\in\R$. Montrer que $\lim\limits_{p \to +\infty} pF(p)=l$
		\item \textit{\underline{Théorème de la valeur finale}} : On suppose que $\lim\limits_{+\infty}f=l\in\R$. Montrer que $\lim\limits_{p\to 0^+} pF(p)=l$
	\end{enumerate}
	
	\section{Théorème des résidus (Version faible) (HP)\etoile{3}}
	\textcolor{blue}{\hyperref[sec:theoreme-des-residus-version-faible]{[Corrigé]}}\\
	\label{residus}
	\label{Théorème des résidus (Version faible)}
	On considère une fraction rationnelle $R$ à coefficients complexes, intégrable sur $\R$. On note $\mathcal H^+=\{z\in\C, \text{Im}(z)>0\}$ et $a_1 , \dots ,a_n$ la liste des pôles distincts de $R$. Pour tout $k\in\crblanc{1}{n}$, on note $\text{Res}_R(a_k)$ le coefficient de $\displaystyle\frac{1}{X-a_k}$ dans l'écriture de $R$ en éléments simples.
	\begin{enumerate}
		\item Montrer que $\displaystyle\sum_{k=1}^n\text{Res}_R(a_k)=0$.
		\item Montrer que $\displaystyle \int_{-\infty}^{+\infty}R(t)dt=2i\pi\sum_{a_k\in\mathcal{H}^+}\text{Res}_R(a_k)$.
	\end{enumerate}
	
	
	
	\newpage
\chapter{Fonctions réelles}
	\section{Formule de Leibniz \ccinp{1}}
	\textcolor{blue}{\hyperref[sec:formule-de-leibniz-etoile1]{[Corrigé]}}\\
	\label{leibniz}
	\label{Formule de Leibniz}
	Enoncer et démontrer la formule de Leibniz.
	
	\section{Fonction discontinue en tout point \etoile{1}}
	\textcolor{blue}{\hyperref[sec:fonction-discontinue-en-tout-point-etoile1]{[Corrigé]}}\\
	\label{discontinuetoutpoint}
	\label{Fonction discontinue en tout point}
	Donner un exemple de fonction définie sur $\R$ mais continue en aucun point de $\R$.
	
	\section{Fonction nulle part dérivable \etoile{3}}
	\textcolor{blue}{\hyperref[sec:fonction-nulle-part-derivable]{[Corrigé]}}\\
	\label{nullepartdérivable}
	\label{FOnction nulle part dérivable}
	Donner un exemple de fonction continue sur $\R$ mais dérivable en aucun point de $\R$.
	
	\section{Théorème de Rolle}
	\label{Théorème de Rolle}
	\textcolor{blue}{\hyperref[sec:theoreme-de-rolle]{[Corrigé]}}\\
	Soit $f:[a,b]\to\R$ dérivable $n$ fois.
	\begin{enumerate}
		\item On suppose que $f$ s'annule en $(n+1)$ points distincts de $[a,b]$.\\
		Démontrer qu'il existe $c\in]a,b[$ tel que $f^{(n)}(c)=0$.
		\item On suppose que $f(a)=f'(a)=\dots=f^{(n-1)}(a)=f(b)=0$.\\
		Démontrer que qu'il existe $c\in]a,b[$ tel que $f^{(n)}(c)=0$.
	\end{enumerate}
	\section{Dérivée symétrique \ccinp{1}}
	\textcolor{blue}{\hyperref[sec:derivee-symetrique-etoile1]{[Corrigé]}}\\
	\label{deriveesymetrique}
	\label{Dérivée symétrique}
	On dit qu'une fonction $f:\R\to\R$ admet une \textit{dérivée symétrique} en $a\in\R$ lorsque le rapport $\displaystyle\frac{f(a+h)-f(a-h)}{2h}$ admet une limite finie lorsque $h$ tend vers $0$.
	\begin{enumerate}
		\item Prouver la dérivabilité en $a$ est une condition suffisante de dérivabilité symétrique en $a$.
		\item Est-ce une condition nécessaire ?
	\end{enumerate}
	
	\section{Fonction de Pringsheim \etoile{2}}
	\textcolor{blue}{\hyperref[sec:fonction-de-pringsheim-etoile2]{[Corrigé]}}\\
	\label{fpringsheim}
	\label{FOnction de Pringsheim}
	Reconnaître la fonction définie sur $\R$ par $f(x)=\lim\limits_{n\to+\infty} \lim\limits_{m\to+\infty} |\cos(n!\pi x)|^m$.
	
	\section{$f\circ f=\Id_{\R_+}$ \etoile{2}}
	\textcolor{blue}{\hyperref[sec:fcirc-fidr-etoile2]{[Corrigé]}}\\
	\label{fof=I}
	Soit $f:\R_+\to\R_+$ une application continue telle que $f\circ f=\Id_{\R_+}$. Déterminer $f$.
	
	\section{Point fixe d'une fonction continue et décroissante sur $\R$ \etoile{1}}
	\textcolor{blue}{\hyperref[sec:point-fixe-dune-fonction-continue-et-decroissante-sur-r-etoile1]{[Corrigé]}}\\
	\label{pfcd}
	\label{Point fixe d'une fonction continue et décroissante sur R}
	Soit $f$ une fonction continue et décroissante sur $\R$. Montrer que $f$ admet un unique point fixe.
	
	\section{Un théorème du point fixe (1) \etoile{1}}
	\textcolor{blue}{\hyperref[sec:un-theoreme-du-point-fixe-1-etoile1]{[Corrigé]}}\\
	\label{theopointfixe1}
	\label{Un théorème du point fixe 1}
	Soit $f:[0,1]\to [0,1]$ continue. Montrer que $f$ admet un point fixe.
	
	\section{Un théorème du point fixe (2) \etoile{2}}
	\textcolor{blue}{\hyperref[sec:un-theoreme-du-point-fixe-2-etoile2]{[Corrigé]}}\\
	\label{theopointfixe2}
	\label{Un théorème du point fixe 2}
	Soit $f$ une fonction  continue sur un segment $I=[a,b]$ telle que $I\subset f(I)$.
	\begin{enumerate}
		\item Montrer que $f$ prend les valeurs $a$ et $b$ sur $I$.
		\item Montrer que $f$ admet un point fixe.
	\end{enumerate}
	
	\section{Point fixe de $f\circ f$ \etoile{1}}
	\textcolor{blue}{\hyperref[sec:point-fixe-de-fcirc-f-etoile1]{[Corrigé]}}\\
	\label{pointfixe fof}
	\label{Point fixe de fof}
	Soit $f:\R\to\R$ continue telle que $f \circ f$ admet un point fixe. $f$ admet-elle un point fixe ?
	
	\section{Point fixe de $f\circ g$ et $g\circ f$ \etoile{2}}
	\textcolor{blue}{\hyperref[sec:point-fixe-de-fcirc-g-et-gcirc-f-etoile2]{[Corrigé]}}\\
	\label{pointfixecommute}
	\label{Point fixe de fog et gof}
	Soit $f$ et $g$ deux fonctions continues sur $\R$ telles que $f\circ g$ est strictement décroissante.
	\begin{enumerate}[leftmargin=*]
		\item Montrer que $f\circ g$ admet un unique point fixe.
		\item Montrer que $g\circ f$ admet un unique point fixe.
	\end{enumerate}
	
	\section{Racine carrée de cos \etoile{3}}
	\textcolor{blue}{\hyperref[sec:racine-carree-de-cos-etoile3]{[Corrigé]}}\\
	\label{sqrtcos}
	\label{Racine carrée de cos}
	\begin{enumerate}[leftmargin=*]
		\item Montrer que $\cos$ admet un unique point fixe sur $\R$.
		\item Existe-t-il une fonction dérivable $f$ de $\R$ dans $\R$ telle que $f\circ f=\cos$ ?
		\item Même question si $f$ est simplement continue.
	\end{enumerate}
	
	\section{Trigonométrie \etoile{1}}
	\textcolor{blue}{\hyperref[sec:trigonometrie-etoile1]{[Corrigé]}}\\
	\label{trigo}
	\label{Trigonométrie}
	Démontrer les identités suivantes :
	\begin{enumerate}
		\item $\forall x\in [-1,1],\ \cos(\arcsin(x))=\sin(\arccos(x))=\sqrt{1-x^2}$.
		\item $\forall x\in]-1,1[,\ \arcsin(x)=\arctan\left(\displaystyle\frac{x}{\sqrt{1-x^2}}\right)$.
		\item $\forall x\in\R^*,\ \arctan(x) +\arctan\left(\displaystyle\frac{1}{x}\right)=\operatorname{sgn}(x)\displaystyle\frac{\pi}{2}$.
		\item $\forall x\in[-1,1], \ \arcsin(x)+\arccos(x)=\displaystyle\frac{\pi}{2}$.
		\item \textit{Formule de Machin:} Prouver l'égalité suivante, $\displaystyle 4\arctan\left(\frac{1}{5}\right)-\arctan\left(\frac{1}{239}\right)=\frac{\pi}{4}$.
	\end{enumerate}
	
	\section{Règle de l'Hôpital \etoile{2}}
	\textcolor{blue}{\hyperref[sec:regle-de-lhopital]{[Corrigé]}}\\
	\label{hopital}
	\label{Règle de l'Hôpital}
	Soient $(a,b)\in\R^2$ tel que $a<b$, $f$ et $g$ deux fonctions de $[a,b]$ dans $\R$ continues sur $[a,b]$ et dérivables sur $]a,b[$.
	\begin{enumerate}
		\item Montrer qu'il existe $c\in]a,b[$ tel que $$g'(c)(f(b)-f(a))=f'(c)(g(b)-g(a)).$$
		\item Soient $I$ un intervalle de $\R$, $x_0\in I$, $f$ et $g$ définies et continues sur $I$, dérivables sur $I\setminus\{x_0\}$ telles que pour tout $x\in I\setminus\{x_0\}$, $g'(x)\ne0$ et telles que $\displaystyle\lim_{x\to x_0}\frac{f'(x)}{g'(x)}=\ell\in\R\cup\{\pm\infty\}$.
		\\Montrer que le rapport $\displaystyle\frac{f(x)-f(x_0)}{g(x)-g(x_0)}$ tend vers $\ell$ quand $x$ tend vers $x_0$. (Règle de l'Hôpital)
		\item Retrouver, en utilisant la règle de l'Hôpital, les développement limités suivants en $0$:
		\begin{itemize}
			\item $\sin(x)\uxzero=x+\smallo{x}$
			\item $\displaystyle\cos(x)\uxzero=1-\frac{1}{2}x^2+\smallo{x^2}$
			\item $\displaystyle\sin(x)\uxzero=x-\frac{1}{6}x^3+\smallo{x^3}$
		\end{itemize}
	\end{enumerate}
	
	\section{Théorème de Darboux \etoile{3}}
	\textcolor{blue}{\hyperref[sec:theoreme-de-darboux]{[Corrigé]}}\\
	\label{darboux}
	\label{Théorème de Darboux}
	Démontrer que pour toute fonction réelle $f$ dérivable sur un intervalle $I$, $f'(I)$ est un intervalle.
	
	\subsection{Réciproque du TVI \etoile{1}}
	\label{recipTVI}
	La réciproque du théorème des valeurs intermédiaires est-elle vrai ?
	
	\subsection{Fonction non primitivable \etoile{1}}
	\label{nonprimitivable}
	Donner un exemple de fonction qui n'admet pas de primitive.
	
	\subsection{Condition suffisante pour être de classe $\mathcal C^1$ \etoile{3}}
	\label{csclassec1}
	Soit $I$ un intervalle de $\R$ et $f:I\to \R$ convexe et dérivable sur $I$. Montrer que $f$ est de classe $\mathcal C^1$ sur $I$.
	
	\section{Dérivée et inverse confondu \etoile{3}}
	\textcolor{blue}{\hyperref[sec:derivee-et-inverse-confondu]{[Corrigé]}}\\
	\label{dérivinv}
	\label{Dérivée et inverse confondu}
	On note $E$ l'ensemble des fonctions de classe $\mathcal{C}^1$ bijectives de $]0,+\infty[$ dans $]0,+\infty[$ telles que $f'=f^{-1}$.
	\begin{enumerate}
		\item Trouver un élément de $E$ de la forme $x\mapsto\alpha x^{\beta}$ avec $\alpha , \beta \in \R$.
		\item Si $f\in E$, déterminer la limite en 0 de $f$ et de $f^{-1}$.
		\item Montrer que si $f\in E$, alors $f$ est un $\mathcal{C}^{\infty}$ difféomorphisme de $]0,+\infty[$ dans $]0,+\infty[$.
		\item Montrer que toute fonction $f\in E$ admet un unique point fixe.
		\item Soit $f$ et $g$ deux éléments de $E$. Montrer que $f$ et $g$ admettent le même point fixe.
	\end{enumerate}
	
	\section{Fonction croissante et convexe sur $\R$ \etoile{1}}
	\textcolor{blue}{\hyperref[sec:fonction-croissante-et-convexe-sur-r-etoile1]{[Corrigé]}}\\
	\label{croissanteconvexe}
	\label{FOnction croissante et convexe sur R}
	Soit $f$ une fonction réelle croissante et convexe sur $\R$ non constante.
	\begin{enumerate}
		\item On suppose que $f$ est dérivable sur $\R$. Montrer que $\lim\limits_{+\infty}f=+\infty$.
		\item Montrer le même résultat sans l'hypothèse de dérivabilité.
	\end{enumerate}
	
	
	\section{Convexité des fonctions continues sur un intervalle \etoile{4}}
	\textcolor{blue}{\hyperref[sec:convexite-des-fonctions-continues-sur-un-intervalle-etoile4]{[Corrigé]}}\\
	\label{convexitecontinue}
	\label{Convexité des fonctions continue sur un intervalle}
	Démontrer qu'une fonction réelle $f$ continue sur un intervalle $I$ est convexe sur $I$ si et seulement si
	$$\forall (x,y)\in I^2,\ \displaystyle f\left(\frac{x+y}{2}\right)\leq \frac{f(x)+f(y)}{2}$$
	On pourra penser à faire une récurrence de Cauchy (cf. \ref{Récurrence de Cauchy}).
	
	\section{Convexe sur un ouvert $\implies$ continue \etoile{3}}
	\textcolor{blue}{\hyperref[sec:convexe-sur-un-ouvert-implies-continue-etoile3]{[Corrigé]}}\\
	\label{convexeouvert}
	\label{Convexe sur un ouvert implique continue}
	Soit $f$ une fonction réelle convexe sur un intervalle ouvert $I$.
	\begin{enumerate}
		\item Montrer que $f$ est continue sur $I$.
		\item Le résultat est-il encore vrai pour un intervalle qui n'est pas ouvert ?
		\item Démontrer que l'ensemble des points de $I$ où $f$ n'est pas dérivable est au plus dénombrable (on pourra penser au théorème de Froda cf. \ref{Théorème de Froda}).
	\end{enumerate}
	
	\section{Fonctions logarithmiquement convexes \etoile{3}}
	\textcolor{blue}{\hyperref[sec:fonctions-logarithmiquement-convexes-etoile3]{[Corrigé]}}\\
	\label{logconvexe}
	\label{Fonctions logarithmiquement convexes}
	On dit qu'une fonction réelle $f$ à valeurs dans $]0,+\infty[$ est logarithmiquement convexe si la fonction $\ln\circ f$ est convexe.
	Soit $I$ un intervalle de $\R$ et $f:I\to\R_+^*$ une application.
	\begin{enumerate}
		\item Montrer que si $f$ est log-convexe, alors $f$ est convexe. La réciproque est-elle vraie ?
		\item Montrer que $f$ est log-convexe si et seulement si $f^\alpha$ est convexe quel que soit $\alpha>0$.
		\item Montrer que $f$ est log-convexe si et seulement si l'application 
		$\fonction{\varphi_c}{I}{\R_+^*}{x}{f(x)c^x}$ est convexe quel que soit $c>0$.
		\item Montrer que si $f$ et $g$ sont deux applications de $I$ dans $\R_+^*$ log-convexes alors $f+g$ et $f\times g$ le sont également.
	\end{enumerate}
	
	\section{Etude d'une fonction définie implicitement \etoile{2}}
	\textcolor{blue}{\hyperref[sec:etude-dune-fonction-definie-implicitement]{[Corrigé]}}\\
	\label{fdi}
	\label{Etude d'une fonction définie implicitement}
	Soit une application continue $g:\R\to\R$ telle que $\forall x\in\R$, $g^2(x)=g\circ g(x)=2g(x)-x$.
	\begin{enumerate}
		\item Montrer que $g$ est une bijection croissante de $\R$ dans $\R$.
		\item Déterminer la forme de $g$. \\\textit{Indication: on pourra s'intéresser à la fonction $h=g-Id_\R$.}
	\end{enumerate}
	
	\section{Inégalités de Kolmogorov \etoile{4}}
	\textcolor{blue}{\hyperref[sec:inegalite-de-kolmogorov-etoile4]{[Corrigé]}}\\
	\label{Kolmogorov}
	\label{Inégalités de Kolmogorov}
	Soient $f\in \mathcal C^n(\R,\C)$ et un entier $n\geq2$ On note $\forall k \in\crblanc{0}{n}$, $M_k=\sup\limits_{x\in\R} |f^{(k)}(x)|$.\\
	On suppose que $M_0$ et $M_n$ sont finis.\\
	Le but de cet exercice est de démontrer que $\forall k\in \crblanc{1}{n},\ M_k \leq 2^{\frac{k(n-k)}{2}}M_0^{1-\frac{k}{n}}M_n^{\frac{k}{n}}$.\\
	\begin{enumerate}[leftmargin=*]
		\item Que peut-on dire si l'un des $M_k$ est nul ?\\
		Dans la suite on considérera que $\forall k\in \crblanc{0}{n},\ M_k>0$.
		\item
		\begin{enumerate}[label=\alph*.]
			\item On fixe $x\in \R$ ainsi que $h_1,\dots,h_{n-1}$ des réels strictement positifs. Montrer qu'il existe $H>0$ tel que,
			$$\forall i\in \crblanc{1}{n},\ \left|f(x)+h_if'(x)+\cdots+\frac{h_i^{n-1}}{(n-1)!}f^{(n-1)}(x)\right|\leq 2M_0+\frac{H^nM_n}{n!}$$
			\item En déduire que les $M_k$ sont finis.\\
			\textit{Indication : On pourra traduire les inégalités à l'aide de matrices}
		\end{enumerate}
		\item
		\begin{enumerate}[label=\alph*.]
			\item Soit $h>0$. Montrer que $M_1\leq \displaystyle\frac{M_2h}{2}+\frac{M_0}{h}$.
			\item En déduire que $M_1\leq \sqrt{2M_0M_2}$.
		\end{enumerate}
		\item
		\begin{enumerate}[label=\alph*.]
			\item Soit $(u_n)_{n\in \N^*}$ une suite croissante. Soient $n\geq 2$ et $k\in \crblanc{1}{n-1}$.\\
			Montrer que $\displaystyle\frac{1}{k}\sum_{i=0}^ku_i\leq \frac{1}{n-k}\sum_{i=k+1}^nu_i$.
			\item On pose pour $k\in \crblanc{0}{n},\ x_k=\displaystyle\ln(M_k)-\frac{\ln 2}{2}k(n-k)$.\\
			Montrer que $\forall k\in \crblanc{1}{n-1},\ 2x_k\leq x_{k-1}+x_{k+1}$.
			\item Conclure.
		\end{enumerate}
	\end{enumerate}
	
	\section{Lemme de Croft \etoile{2}}
	\textcolor{blue}{\hyperref[sec:lemme-de-croft-etoile2]{[Corrigé]}}\\
	\label{croft}
	\label{Lemme de Croft}
	Soit $f: \R_+\longmapsto \R$ uniformément continue sur $\R_+$ telle que pour tout $x>0$, la suite $(f(nx))_{n\in\N}$ tend vers $0$.
	\\ Montrer que $\lim\limits_{x\to +\infty} f(x)=0$.
	
	\section{Inégalité intégrale de Jensen \etoile{1}}
	\textcolor{blue}{\hyperref[sec:inegalite-integrale-de-jensen-etoile1]{[Corrigé]}}\\
	\label{jensenint}
	\label{Inéglaité intégrale de Jensen}
	Soit $f:[a,b]\to\R$ une fonction continue par morceaux à valeurs dans un intervalle $J$. Soit $\varphi$ une fonction continue et convexe sur $J$. Démontrer que: $$\varphi\left(\frac{1}{b-a}\int_a^bf(t)dt\right)\leq\frac{1}{b-a}\int_a^b\varphi\circ f(t)dt$$
	\\ On pourra passer par des sommes de Riemann.
	
	\newpage
\chapter{Polynômes}
	\section{Théorème de d'Alembert-Gauss (2) \etoile{3}}
	\textcolor{blue}{\hyperref[sec:theoreme-de-dalembert-gauss-2]{[Corrigé]}}\\
	\label{alembertgauss2}
	\label{Théorème de d'Alembert-Gauss 2}
	Soit $P=\displaystyle\sum\limits_{k=0}^na_kX^k\in\C[X]$ de degré $n\geq 1$. Notons $\P=\left\{|P(z)|,z\in\C\right\}$.
	\begin{enumerate}
		\item Justifier que $\P$ admet une borne inférieure notée $\alpha$.
		\item Soit $r>0$.\\
		Montrer que pour tout nombre complexe $z$ de module $r$, $|P(z)|\geq|a_p|r^n-\displaystyle\sum\limits_{k=0}^{n-1} |a_k|r^k$
		\item En déduire que $\lim\limits_{|z|\to+\infty}|P(z)|=+\infty$.
		\item
		\begin{enumerate}[label=\alph*.]
			\item Montrer qu'il existe une suite $(u_n)\in \C^\N$ bornée telle que $\lim\limits_{n\to+\infty}|P(u_n)|=\alpha$
			\item Montrer qu'il existe $z_0\in \C$ tel que $|P(z_0)|=\alpha$.
		\end{enumerate}
		\item On suppose que $\alpha>0$. On considère alors le polynôme $Q=\displaystyle\frac{P(X+z_0)}{P(z_0)}$
		\begin{enumerate}[label=\alph*.]
			\item Montrer que $\inf\limits_{z\in\C}{|Q(z)|}=|Q(0)|=1$.
			\item Montrer qu'il existe $p\in\crblanc{1}{n}$ et $b_p\ne0,b_{p+1},\dots,b_n\in \C$ tels que: $$Q=\displaystyle\sum\limits_{k=p+1}^n b_kX^k+b_pX^p+1$$
			\item On pose $b_p=\rho e^{i\theta}$ avec $\rho<0$ et $\theta\in\R$. Montrer qu'il existe $r_0>0$ tel que $$\forall r\in ]0,r_0], \ |Q(re^{i\theta/p})|-1<0$$
		\end{enumerate}
		\item Conclure.
	\end{enumerate}
	
	\section{\underline{Bernoulli} \ccinp{2}}
	\textcolor{blue}{\hyperref[sec:Bernoulli]{[Corrigé]}}\\
	\label{Bernoulli}
	\begin{enumerate}[leftmargin=*]
		\item Définition :
		\begin{enumerate}[label=\alph*.]
			\item Soit $P\in\R[X]$. Montrer qu'il existe un unique $Q\in\R[X]$ tel que $Q'=P$ et $\displaystyle\int_0^1 Q(x)dx=0$.
			\item En déduire qu'il existe une unique suite de polynômes réels $(B_n)_{n\in \N}$ vérifiant :
			$$B_0=1\ ; \ \forall n \geq 1, \ B_n'=nB_{n-1} \ ; \ \forall n \geq 1, \ \int_0^1 B_n(x)dx=0$$
			\item Calculer $B_1$ et $B_2$.
			\item Soit $n\in \N$. Quel est le degré de $B_n$.
		\end{enumerate}
		On appelle $(B_n)_{n\in \N}$ la suite des polynômes de Bernoulli. Pour tout $n\geq 0$, on pose $b_n=B_n(0)$. \\La suite de réels $(b_n)$ est appelée suite des nombres de Bernoulli.
		\item Propriétés :
		\begin{enumerate}[label=\alph*.]
			\item Montrer que pour tout $n\geq 2,\ B_n(0)=B_n(1)$.
			\item Montrer que pour tout entier positif $n,\ B_n=(-1)^nB_n(1-X)$. En déduire que $B_{2n+1}(0)=B_{2n+1}(1)=0$.
			\item A l'aide de la formule de Taylor, montrer que pour tout $n\in\N,\ B_n=\displaystyle\sum\limits_{k=0}^n \binom{n}{k}b_{n-k}X^k$.
			\item En déduire que: $\forall n\in\N,\ b_{2n+2}=\displaystyle\sum\limits_{k=0}^{2n+2}\binom{2p+2}{k}b_k$. \\Puis que $\forall n \in\N^*,\ b_{2n}=\displaystyle-\displaystyle\frac{1}{(n+1)(2n+1)}\displaystyle\sum\limits_{k=0}^{2n-2}\binom{2n+2}{k}b_k$    
		\end{enumerate}
	\end{enumerate}
	
	\section{\underline{Lagrange} \ccinp{1}}
	\textcolor{blue}{\hyperref[sec:Lagrange]{[Corrigé]}}\\
	\label{Lagrange}
	Soient $n$ un entier naturel non nul et $(x_1,x_2,\dots, x_n)\in \K^n$
	\begin{enumerate}[leftmargin=*]
		\item Démontrer que l'application $\fonction{\Psi}{\K_{n-1}[X]}{\K^n}{P}{(P(x_1),P(x_2),\dots,P(x_n))}$ est un isomorphisme.
		\item Montrer qu'il existe $n$ polynômes $L_1,\dots, L_n$ de $\K_{n-1}[X]$ tels que, pour tout polynôme $P\in\K_{n-1}[X]$ on ait :
		$$P=\sum\limits_{k=1}^n P(x_k)L_k$$
	\end{enumerate}
	
	\section{\underline{Tchebychev} \ccinp{2}}
	\textcolor{blue}{\hyperref[sec:Tchebychev]{[Corrigé]}}\\
	\label{Tchebychev}
	On note $E$ l'espace vectoriel des fonctions continues de $[-1,1]$ dans $\R$.
	\begin{enumerate}[leftmargin=*]
		\item Existence et unicité
		\begin{enumerate}[label=\alph*.]
			\item Démontrer qu'il existe un polynôme $T_n$ à coefficients réels de degré inférieur ou égal à $n$ vérifiant la propriété suivante:
			$$ \forall \theta\in\R,\ T_n(\cos(\theta))=\cos(n\theta)$$
			\\(On pourra remarquer que $\cos(n\theta)$ est la partie réelle de $(\cos(\theta)+i\sin(\theta))^n$.) 
			\item Démontrer qu'un tel polynôme est unique.
		\end{enumerate}
		\item Montrer que $\forall x\in[-1,1],\ T_{n+2}(x)=2xT_{n+1}(x)-T_n(x)$
		\item Quel est le degré de $T_n$ ? Quel est son coefficient dominant ?
		\item Montrer que $T_n$ est à coefficients entiers, et que si $n$ est impair alors son coefficient constant est nul.
		\item Racines et extremum :
		\begin{enumerate}[label=\alph*.]
			\item Montrer que, pour tout $x\in[-1,1], \ T_n(x)=2^{n-1}\displaystyle\prod_{k=0}^{n-1}(x-\cos(\theta_k))$ où $\theta_k=\dfrac{(2k+1)\pi}{2n}$
			\item On pose, pour $k\in\crblanc{0}{n}$, $c_k=\cos\left(\dfrac{k\pi}{n}\right)$. Calculer $\normep{\infty}{T_n}=\sup\limits_{x\in[-1,1]}|T_n(x)|$ puis prouver que $|T_n(c_k)|=\normep{\infty}{T_n}$ pour tout $k\in\crblanc{0}{n}$
		\end{enumerate}
		\item Orthogonalité :
		\begin{enumerate}[label=\alph*.]
			\item Montrer que, pour toutes fonctions $f,g$ dans $E$, l'application $t\mapsto \displaystyle\frac{f(t)g(t)}{\sqrt{1-t^2}}$ est intégrable sur $]-1,1[$.
			\item Pour $f,g$ éléments de $E$, on pose $\langle f,g \rangle =\displaystyle\int_{-1}^1\frac{f(t)g(t)}{\sqrt{1-t^2}} dt$. Justifier que ceci définit un produit scalaire sur $E$.
			\item Calculer $\langle T_n,T_m \rangle$ pour tous $n,m\in \N$. 
		\end{enumerate}
	\end{enumerate}
	
	\subsection{Angles rationnels dont le cosinus est rationnel \etoile{3}}
	Soit $\alpha\in \pi\Q$.
	\begin{enumerate}
		\item On suppose que $\alpha\in \displaystyle\frac{\pi}{2}\Z$. Que dire de $\cos(\alpha)$ ?\\
		On suppose dans la suite que $\alpha\notin\displaystyle\frac{\pi}{2}\Z$ et on écrit $\alpha=\displaystyle\pi\frac{p}{q}$ avec $p\wedge q=1$ et $q>2$. On suppose de plus que $\cos(\alpha)=\displaystyle\frac{a}{b}\in \Q$ avec $a\wedge b=1$ et $b>0$.
		\item On suppose $q$ impair.
		\begin{enumerate}[label=\alph*.]
			\item Montrer que $\cos(\alpha)$ est de la forme $\displaystyle\frac{\varepsilon}{2^r}$ avec $\varepsilon\in \{-1,1\}$ et $r\in \N$.
			\item Conclure quand aux valeurs possibles de $\cos(\alpha)$.
		\end{enumerate}
		\item On suppose que $q$ est pair.\\
		En distinguant deux cas suivant si $q$ est multiple de $4$ ou pas, conclure quand aux valeurs possibles de $\cos(\alpha)$.
		\item Synthétiser.
		\item Que peut-on dire des valeurs de $\alpha$ pour lesquelles $\sin(\alpha)$ est rationnel ?
		\item Déterminer les valeurs de $\alpha$ pour lesquelles $\tan(\alpha)$ est rationnel.
	\end{enumerate}
	
	\subsection{Triangle à angles rationnels dont tous les côtés ont une longueur rationnelle \etoile{2}}
	On se place dans le plan $\R^2$ munit de sa structure euclidienne canonique et d'un repère orthonormé. Caractériser les triangles non plats dont les angles exprimés en degrés sont rationnels et tous les côtés ont une longueur rationnelle.
	
	\subsection{Triangles dont les sommets sont à coordonnées rationnelles \etoile{2}}
	On se place dans le plan $\R^2$ munit de sa structure euclidienne canonique et d'un repère orthonormé. Caractériser les triangles non plats dont les sommets ont des coordonnées rationnelles.
	
	\section{\underline{Hilbert} \ccinp{2}}
	\textcolor{blue}{\hyperref[sec:Hilbert]{[Corrigé]}}\\
	\label{Hilbert}
	On pose pour tout $k\in\N^*,H_k=\displaystyle\frac{1}{k!}\prod\limits_{j=0}^{k-1}(X-j)$ et $H_0=1$. On pose également pour tout $P\in\C[X], \ \Delta(P)=P(X+1)-P(X)$
	\begin{enumerate}[leftmargin=*]
		\item Montrer que $(H_k)_{0\leq k\leq n}$ est une base de $\R_n[X]$.
		\item Calculer $\Delta(H_0)$ et, pour tout $k\in\crblanc{1}{n}$, exprimer $\Delta(H_k)$ à l'aide de $H_{k-1}$.
		\item Montrer que, pour tous $k,l \in\crblanc{0}{n}, \Delta^k(H_k)(0)=
		\begin{cases}
			1 & \mbox{si } k=l\\
			0 & \mbox{sinon}
		\end{cases}$
		\item Montrer que, pour tout $P\in\C_n[X]$, $P=\displaystyle\sum\limits_{k=0}^n(\Delta^k(P))(0)H_k$
		\item Calculer $H_n(k)$ pour $k\in \Z$.\\
		On distinguera trois cas : $k\in\crblanc{0}{n-1}$, $k\geq n$ et $k<0$.
		\item En déduire que $H_n(\Z)\subset\Z$.
		\item Montrer que $P\in\C_n[X]$ est à valeurs entières sur les entiers si et seulement si ses coordonnées dans la base $(H_k)_{0\leq k\leq n}$ sont entières.  
	\end{enumerate}
	
	\section{\underline{Laguerre} \centraleponts{3}}
	\textcolor{blue}{\hyperref[sec:Laguerre]{[Corrigé]}}\\
	\label{Laguerre}
	On pose, pour tout entier naturel $n$ et pour tout réel $x$, $h_n(x)=x^ne^{-x}$ et $L_n(x)=\displaystyle\frac{e^x}{n!}h_n^{(n)}(x)$.
	\begin{enumerate}[leftmargin=*]
		\item Montrer que, pour tout entier $n$, $L_n$ est une fonction polynomiale. Préciser son degré et son coefficient dominant.
		\item Pour tous, $P,Q\in\R[X]$ on pose $\langle P,Q \rangle = \displaystyle\int_0^{+\infty}P(x)Q(x)e^{-x}dx$.\\Démontrer que $\proscal{\cdot}{\cdot}$ est bien définie et est un produit scalaire sur $\R[X]$
		\item Calculer, pour tout $n\in\N$, $\proscal{L_0}{X^n}$.
		\item Montrer que pour tout $k\in\crblanc{0}{n}$ il existe $Q_k\in\R[X]$ tel que pour tout $x\in\R$ on ait :
		$$h_n^{(k)}(x)=x^{n-k}e^{-x}Q_k(x)$$
		\item Etablir que : $\forall n\in\N, \ \forall P\in\R[X], \forall p\in\crblanc{0}{n}, \langle L_n,P \rangle=\displaystyle\frac{(-1)^p}{n!}\int_0^{+\infty}h_n^{(n-p)}(x)P^{(p)}(x)dx.$
		\item En déduire que $(L_n)$ est une famille orthonormée de $(\R[X],\proscal{\cdot}{\cdot})$.
	\end{enumerate}
	
	\section{\underline{Legendre} \ccinp{2}}
	\textcolor{blue}{\hyperref[sec:Legendre]{[Corrigé]}}\\
	\label{Legendre}
	Pour tout $n\in\N$, on note $Q_n=(X^2-1)^n$ et $P_n=\displaystyle\frac{1}{2^nn!}Q_n^{(n)}$. On pourra confondre polynôme et fonction polynomiale associée.
	\begin{enumerate}[leftmargin=*]
		\item Calculer $P_0$,$P_1$,$P_2$ et $P_3$.
		\item Quel est le degré de $P_n$?
		\item Montrer que $P_n$ a la parité de $n$. En déduire $P_n(0)$ pour $n$ impair et $P_n'(0)$ pour $n$ pair.
		\item Calculer $P_n(0)$ pour $n$ pair et $P_n'(0)$ pour $n$ impair. On exprimera les résultats à l'aide de factorielles.
		\item Vérifier que $\forall  n\in\N,\ (X^2-1)Q_n'=2nXQ_n$.\\
		En déduire que $\forall n \in\N,\ (X^2-1)P_n''+2XP_n'=n(n+1)P_n$.
		\item Montrer que pour tout $k\in\crblanc{0}{n-1},\ Q_n^{(k)}(-1)=Q_n^{(k)}(1)=0$.
		\item En appliquant le théorème de Rolle et à l'aide d'une récurrence, montrer que $P_n$ admet exactement $n$ racines réelles distinctes dans $]-1,1[$.
	\end{enumerate}
	
	\section{\underline{Hermite} \centraleponts{3}}
	\textcolor{blue}{\hyperref[sec:Hermite]{[Corrigé]}}\\
	\label{Hermite}
	On définit le $n$-ième polynôme d'Hermite par: $$\forall x\in \R,\ H_n(x)=(-1)^n e^{\frac{x^2}{2}}\frac{d^n}{dx^n}\left(e^{-\frac{x^2}{2}}\right)$$
	On définit aussi le produit scalaire suivant sur $\R[X]$: $$\langle P,Q \rangle=\int_{-\infty}^{+\infty}P(t)Q(t)e^{-\frac{t^2}{2}}dt$$
	\begin{enumerate}
		\item Montrer que $\proscal{\cdot}{\cdot}$ est bien un produit scalaire.
		\item Soient $m,n \in\N$. Montrer que si $n\ne m$ alors $\langle H_n,H_m\rangle=0$.
		\item Soit $n\in\N$. Calculer $\langle H_n,H_n\rangle$.
		\item Montrer qu'on a la relation de récurrence d'ordre 2 suivante : $$\forall x\in\R,\ H_{n+1}(x)=xH_n(x)-nH_{n-1}(x)$$
		\item Montrer que $H_n$ vérifie l'équation différentielle suivante : $$\forall x\in\R,\ H_n''(x)-xH_n'(x)+nH_n(x)=0$$
	\end{enumerate}
	
	\section{\underline{Bernstein} \centraleponts{3}}
	\textcolor{blue}{\hyperref[sec:Bernstein]{[Corrigé]}}\\
	\label{Bernstein}
	On note $I=[0,1]$ et $\mathcal C$ l'espace vectoriel des fonctions continues de $I$ dans $\C$. \\ On note, pour toute fonction $f\in\mathcal C$ et $n\in\N^*$: $$\fonction{B_n(f)}{I}{\C}{x}{\displaystyle\sum_{k=0}^{n}f\left(\frac{k}{n}\right)b_k^n(x)} \ \text{avec} \ b_k^n(x)=\binom{n}{k}x^k(1-x)^{n-k}$$
	\begin{enumerate}
		\item Calculer explicitement l'expression $\displaystyle\sum_{k=0}^n\left( \frac{k}{n}-x\right)b_k^n(x)$, puis en déduire que: $$\forall\mu>0, \ \forall x\in I, \ \displaystyle\sum\limits_{\substack{0\leq k\leq n\\|\frac{k}{n}-x|\geq \mu}}{b_n^k(x)} \leq \frac{1}{n\mu^2}$$
		\item \textit{Théorème de Bernstein}: Pour tout $f\in\mathcal C$, montrer que la suite de fonctions $(B_n(f))$ converge uniformément vers $f$ sur $[0,1]$. En déduire le théorème de Weierstrass.
	\end{enumerate}
	
	\section{\underline{Polynômes cyclotomiques} \xens{3}}
	\textcolor{blue}{\hyperref[sec:polynomes-cyclotomiques]{[Corrigé]}}\\
	\label{Polynômes cyclotomiques}
	Pour un entier $n$ supérieur ou égal à 1, on dit qu'une racine $n$-ième de l'unité $z$ est primitive si $z^d\ne 1$ pour tout entier $d$ tel que $1\leq d<n$. On note $\p_n$ l'ensemble des racines primitives $n$-ième de l'unité. On a donc $\p_1=\{1\}$.
	\\On définit $\Phi\in\C[X]$ par : $$\Phi_n=\displaystyle\prod\limits_{z\in\p_n} (X-z)$$
	\begin{enumerate}[leftmargin=*]
		\item Montrer que pour tout $n\geq1$, on a: $$X^n-1=\displaystyle\prod\limits_{d|n}\Phi_d$$
		\item Montrer que si $p$ est un nombre premier et $k\geq1$ est un entier, alors $$\Phi_{p^k}=X^{(p-1)p^{k-1}}+X^{(p-2)p^{k-1}}+\dots+X^{p^{k-1}}+1$$
		\item Calculer $\Phi_n$ pour $n\in\crblanc{1}{6}$.\\
		On fixe $n\geq2$ pour toute la suite de cette partie.
		\item \begin{enumerate}[label=\alph*.]
			\item Calculer $\Phi_n(0)$.
			\item Calculer $\Phi_n(1)$ en fonction de la décomposition en facteurs premiers de $n$.
		\end{enumerate}
		\item \begin{enumerate}[label=\alph*.]
			\item Soient $A$ et $B$ deux polynômes à coefficient entiers avec $B$ unitaire.
			\\On suppose qu'il existe un polynôme $C$ tel que $A=BC$. A l'aide d'un calcul de division euclidienne, établir que $C$ est à coefficients entiers.
			\item En déduire que $\Phi_n\in\Z[X]$. 
		\end{enumerate}
	\end{enumerate}
	
	\section{Suite de polynômes définis par récurrence}
	\textcolor{blue}{\hyperref[sec:suite-de-polynomes-definis-par-recurrence]{[Corrigé]}}\\
	\label{Suite de polynômes définis par récurrence}
	Soit $\displaystyle f:x\mapsto\begin{cases}
		e^{-\frac{1}{x^2}} &\text{si}\;x\ne0\\
		0 &\text{sinon}
	\end{cases}$.
	\begin{enumerate}
		\item Montrer que pour tout $n\in\N$, il existe un polynôme $P_n$ tel que $f^{(n)}(x)=x^{-3}P_n(x)f(x)$ pour tout $x\ne0$ et donner le degré de $P_n$.
		\item Montrer que $f$ est prolongeable par continuité en une fonction de classe $\mathcal C^\infty$ sur $\R$.
		\item Montrer que pour tout $n\in\N$, $P_n$ a toutes ses racines réelles.
	\end{enumerate}
	
	\section{Equation polynomiale (1)}
	\label{Equation polynomiale (1)}
	\textcolor{blue}{\hyperref[sec:équation-polynomiale-(1)]{[Corrigé]}}\\
	Trouver les polynômes $P\in \R[X]$ tels que $(X^2-X)P''(X)=6P(X)$.
	
	\section{Equation polynomiale (2)}
	\label{Equation polynomiale (2)}
	\textcolor{blue}{\hyperref[sec:équation-polynomiale-(2)]{[Corrigé]}}\\
	Trouver les polynômes $P\in \R[X]$ tels que $P(X^2)=(X^3+1)P(X)$.
	
	\section{Equation polynomiale (3)}
	\label{Equation polynomiale (3)}
	\textcolor{blue}{\hyperref[sec:équation-polynomiale-(3)]{[Corrigé]}}\\
	Trouver les polynômes $P\in \C[X]$ tels que $P(X^2)=P(X+1)^2$.
	
	\section{Equation polynomiale (4)}
	\label{Equation polynomiale (4)}
	\textcolor{blue}{\hyperref[sec:équation-polynomiale-(4)]{[Corrigé]}}\\
	On cherche à déterminer les polynômes $P\in \R[X]$ solutions de l'équation $(*) : P(X^2)=P(X+1)P(X)$.
	\begin{enumerate}
		\item Déterminer les polynômes constants solutions de $(*)$.
		\item Soit $P\in \R[X]$ non constant solution de $(*)$ et soit $\lambda$ une racine complexe de $P$.\\
		Montrer que $\lambda\in \{0,1\}$ ou $|\lambda|=|\lambda-1|=1$.
		\item Tracer dans python l'ensemble des $\lambda\in \C$ vérifiant $|\lambda|=|\lambda-1|=1$.
		\item En déduire l'ensemble des solutions de $(*)$.
	\end{enumerate}
	
	\section{Equation polynomiale (5)}
	\label{Equation polynomiale (5)}
	\textcolor{blue}{\hyperref[sec:équation-polynomiale-(5)]{[Corrigé]}}\\
	Trouver les polynômes $P\in \C[X]$ tels que $P(X^2)=P(X+1)P(X-1)$.\\
	On pourra considérer une racine de $P$ de module maximal.
	
	\section{Equation de Shapiro}
	\label{Equation de Shapiro}
	\textcolor{blue}{\hyperref[sec:équation-de-shapiro]{[Corrigé]}}\\
	Trouver les polynômes $P\in \R[X]$ tels que $P(X)P(X+1)=P(X^2+X+1)$.
	
	\section{Degré d'une différence \telecom{1}}
	\label{Degré d'une différence}
	\textcolor{blue}{\hyperref[sec:degré-d'une-différence]{[Corrigé]}}\\
	Soient $P\ne Q\in \R[X]$ de degrés $n\geq 0$. Montrer que $P^3-Q^3$ est au moins de degré $2n$.
	
	\section{Théorème de la racine rationnelle \telecom{2}}
	\textcolor{blue}{\hyperref[sec:theoreme-de-la-racine-rationnelle]{[Corrigé]}}\\
	\label{Théorème de la racine rationnelle}
	Soit $P=\displaystyle\sum_{k=0}^na_kX^k$ de degré $n\geq 1$ un polynôme à coefficients entiers.\\
	Montrer que si $P$ admet une racine rationnelle irréductible $\displaystyle\frac{p}{q}$ alors $p|a_0$ et $q|a_n$.
	
	\section{Critère d'Eisenstein \etoile{3}}
	\textcolor{blue}{\hyperref[sec:critere-deisenstein-etoile3]{[Corrigé]}}\\
	\label{Eisenstein}
	\label{Critère d'Eisenstein}
	Soit $A(X)=X^n+\displaystyle\sum_{k=0}^{n-1}a_kX^k$ un polynôme à coefficients entiers. On suppose qu'il existe un nombre premier $p$ tel que $p^2\nmid a_0$ et $\forall i\in \crblanc{0}{n-1},\ p|a_i$.\\
	Pour $P\in \Z[X]$ on note $c(P)$ le $\pgcd$ de ses coefficients. l'entier $c(P)$ est appelé \textit{contenu} de $P$.
	\begin{enumerate}
		\item Soient $P$ et $Q$ deux polynômes unitaires à coefficients entiers.
		\begin{enumerate}[label=\alph*.]
			\item Montrer que $c(PQ)=c(P)c(Q)$.
			\item En déduire que le produit de deux polynômes à coefficients rationnels est à coefficients entiers si et seulement si les deux facteurs sont à coefficients entiers.
		\end{enumerate}
		\item Montrer que $A$ est irréductible dans $\Q[X]$.
	\end{enumerate}
	
	\subsection{Irréductibilité des polynômes cyclotomiques d'indices premiers \etoile{2}}
	Soit $p$ un nombre premier. On pose $\Phi_p(X)=\displaystyle\sum_{k=0}^{p-1}X^k$.\\
	En considérant $\Psi_p=\Phi_p(X+1)$, montrer que $\Phi_p$ est irréductible dans $\Q[X]$.
	
	\subsection{Dimension de $\R$ en tant que $\Q$-espace vectoriel \etoile{3}}
	Soient $n\geq 1$ un entier, $a_0,\dots,a_n$ des entiers et $p$ un nombre premier vérifiant le critère d'Eisenstein. On pose $P=X^{n+1}+\displaystyle\sum_{k=0}^na_kX^k$ et on note $\alpha$ une racine complexe de $P$. On note enfin $\fonction{f_\alpha}{\Q[X]}{\C}{Q}{Q(\alpha)}$.
	\begin{enumerate}
		\item Donner la structure de $\Ker(f_\alpha)$ et montrer qu'il est engendré par un unique polynôme unitaire que l'on précisera.
		\item Montrer que la famille $(1,\alpha,\dots,\alpha^n)$ est libre dans $\Q$.
		\item En déduire la dimension de $\R$ en tant que $\Q$-espace vectoriel.
	\end{enumerate}
	
	\section{Points critiques des polynômes de Hilbert \centraleponts{3}}
	\textcolor{blue}{\hyperref[sec:points-critiques-des-polynômes-de-hilbert]{[Corrigé]}}\\
	\label{Points critiques des polynômes de Hilbert}
	Soient $n$ un entier supérieur ou égal à deux et $P_n=\displaystyle\prod\limits_{k=0}^n(X-k)$.
	\begin{enumerate}
		\item En considérant $F_n=\displaystyle\frac{P_n'}{P_n}$, Montrer que $P_n'$ admet une unique racine $x_n$ sur $]0,1[$.
		\item Montrer que $(x_n)_{n\geq 2}$ converge vers $0$.
		\item Montrer que $x_n\unfty{\sim}\displaystyle\frac{1}{\ln n}$.
	\end{enumerate}
	
	\section{Zéros du sinus tronqué}
	\textcolor{blue}{\hyperref[sec:zeros-du-sinus-tronqué]{[Corrigé]}}\\
	\label{Zéros du sinus tronqué}
	On pose pour tout $n\in \N,\ P_n=\displaystyle\sum_{k=0}^n\frac{(-1)^kX^{2k+1}}{(2k+1)!}$.\\
	Montrer que le nombre $c_n$ de racines réelles de $P_n$ (comptées avec multiplicité) vérifie $c_n\unfty\sim\displaystyle\frac{4n}{e\pi}$.
	
	\section{Exponentielle tronquée \ccinp{1}}
	\textcolor{blue}{\hyperref[sec:exponentielle-tronquée]{[Corrigé]}}\\
	\label{Exponentielle tronquée}
	Soit $n\in \N^*$. Montrer que le polynôme $P=\displaystyle\sum_{k=0}^n\frac{X^k}{k!}$ est scindé à racine simples.
	
	\section{Les fonctions localement polynomiales sont polynomiales \centraleponts{2}}
	\textcolor{blue}{\hyperref[sec:les-fonctions-localement-polynomiales-sont-polynomiales]{[Corrigé]}}\\
	\label{Les fonctions localement polynomiales sont polynomiales}
	Soit $f:\R\to\R$ une fonction \textit{localement polynomiale} c'est-à-dire vérifiant :
	$$\forall a\in \R,\ \exists\varepsilon>0,\ \exists P\in \R[X],\ \forall x\in ]a-\varepsilon,a+\varepsilon[,\ f(x)=P(x)$$
	Montrer que $f$ est une fonction polynomiale.
	
	\section{Intégrales de polynômes \telecom{1}}
	\textcolor{blue}{\hyperref[sec:integrales-de-polynomes-etoile1]{[Corrigé]}}\\
	\label{Intégrales de polynômes}
	Soient $a\leq b$ deux réels et $x_0,\dots,x_n$ une subdivision de $[a,b]$.\\
	Montrer qu'il existe des réels $\lambda_0,\dots,\lambda_n$ tels que :
	$$\forall P\in \K[X],\ \int_a^bP(x)dx=\sum_{i=0}^n\lambda_iP(x_i)$$
	
	\section{Théorème de Gauss-Lucas \centraleponts{2}}
	\textcolor{blue}{\hyperref[sec:theoreme-de-gauss-lucas-etoile2]{[Corrigé]}}\\
	\label{Théorème de Gauss-Lucas}
	Pour tout $P\in \C[X]$, on note $R_P$ l'ensemble des racines de $P$. Soit $P=\Lambda\displaystyle\prod\limits_{k=1}^r{(X-z_k)^{n_k}} \in\C[X]$ non constant avec $R_P=\{z_k,\ k\in\crblanc{1}{r}\}$.
	\begin{enumerate}
		\item Montrer que les racines de $P'$ sont incluses dans l'enveloppe convexe de $R_P$: $$\text{Conv}(R_P)=\left\{\displaystyle\sum\limits_{k=1}^r{\lambda_kz_k}\ |\ (\lambda_1,\dots,\lambda_r)\in \ (\R_+)^r,\displaystyle\sum\limits_{k=1}^r{\lambda_k}=1\right\}$$
		\item On suppose que $P$ est à racines réelles. Que peut-on dire ?
	\end{enumerate}
	
	\subsection{Une application \etoile{3}}
	On reprend les notations précédentes.\\
	On pourra utiliser, sans avoir à le démontrer, que l'enveloppe convexe d'une partie $A$ de $\C$ est la plus petite partie convexe de $\C$ contenant $A$.
	\begin{enumerate}
		\item Montrer qu'il existe une sous partie $R_{P,\min}$ de $R_P$ minimale pour l'inclusion telle que Conv$(R_P)=\text{Conv}(R_{P,\min})$ puis que Conv$(R_{P})\setminus R_{P,\min}$ est convexe.\\
		\item Démontrer que si $P''|P$, alors les racines de $P$ sont alignées.
		\item La réciproque est-elle vraie ?
	\end{enumerate}
	
	\section{Graphe d'un polynôme \telecom{2}}
	\textcolor{blue}{\hyperref[sec:graphe-d'un-polynôme]{[Corrigé]}}\\
	\label{Graphe d'un polynôme}
	Soit $P$ un polynôme de degré $n\geq 2$. Montrer que le graphe de $P$ a au plus $n$ points alignés.
	
	\section{Polynômes qui commutent avec cosinus \centraleponts{3}}
	\textcolor{blue}{\hyperref[sec:polynomes-qui-commutent-avec-cosinus-etoile3]{[Corrigé]}}\\
	\label{Polynômes qui commutent avec cosinus}
	Soit $P\in \R[X]$ tel que $\forall x\in \R,\ P(\cos(x))=\cos(P(x))$.
	\begin{enumerate}
		\item Déterminer $P$ s'il est constant.
		\item Déterminer $P$ si $\deg(P)=1$.
		\item Déterminer toutes les solutions.
	\end{enumerate}
	
	\section{Relation trigonométrique polynomiale \etoile{3}}
	\textcolor{blue}{\hyperref[sec:relation-trigonometrique-polynomiale-etoile3]{[Corrigé]}}\\
	\label{relationtrigopoly}
	\label{Relation trigonométrique polynomiale}
	Déterminer l'ensemble des polynômes $P\in \R[X]$ tels que
	$$\forall t\in \R,\ P(\cos t)+P(\sin t)=1$$
	
	\section{Division euclidienne (1) \ccinp{2}}
	\textcolor{blue}{\hyperref[sec:division-euclidienne-(1)]{[Corrigé]}}\\
	\label{Division euclidienne (1)}
	Déterminer le reste dans la division euclidienne de $X^{42}+X^{1729}+X^{11\, 111}$ par $X^2+X+1$.
	
	\section{Division euclidienne (2) \ccinp{1}}
	\textcolor{blue}{\hyperref[sec:division-euclidienne-(2)]{[Corrigé]}}\\
	\label{Division euclidienne (2)}
	Soit $n\in\N$. Déterminer le reste dans la division euclidienne de $(\cos\theta+X\sin(\theta))^n$ par $X^2+1$.
	
	\section{Fonctions trigonométriques polynomiale ? \ccinp{1}}
	\textcolor{blue}{\hyperref[sec:fonctions-trigonométriques-polynomiales-?]{[Corrigé]}}\\
	\label{Fonctions trigonométriques polynomiales ?}
	\begin{enumerate}[leftmargin=*]
		\item Montrer que $\cos$ n'est pas une fonction polynomiale.
		\item Montrer que $\tan$ n'est pas une fonction polynomiale.
	\end{enumerate}
	
	\section{Logarithme rationnel ? \telecom{2}}
	\textcolor{blue}{\hyperref[sec:logarithme-rationnel-?]{[Corrigé]}}\\
	\label{Logarithme rationnel ?}
	Existe-il une fraction rationnelle $R\in\K(X)$ telle que $R'(X)=\displaystyle\frac{1}{X}$.
	
	\section{Une fraction rationnelle \etoile{1}}
	\textcolor{blue}{\hyperref[sec:une-fraction-rationnelle]{[Corrigé]}}\\
	\label{fractionrationnelle}
	\label{Une fraction rationnelle}
	Décomposer en éléments simples sur $\C(X)$ la fraction rationnelle $F(X)=\displaystyle\frac{1}{X^n(1-X)^n}$.
	
	\section{Dérivé d'un polynôme scindé sur $\R$ \centraleponts{3}}
	\textcolor{blue}{\hyperref[sec:dérivé-d'un-polynôme-scindé-sur-R]{[Corrigé]}}\\
	\label{Dérivé d'un polynôme scindé sur R}
	Soit $P$ un polynôme de degré supérieur ou égal à $2$ scindé sur $\R$.
	\begin{enumerate}
		\item Montrer que $P'$ l'est aussi.
		\item On fixe $\alpha\in \R$. Montrer que $P'+\alpha P$ l'est aussi.
	\end{enumerate}
	
	\section{Une condition nécessaire pour qu'un polynôme soit scindé sur $\R$ \centraleponts{3}}
	\textcolor{blue}{\hyperref[sec:une-condition-nécessaire-pour-qu'un-polynôme-soit-scindé-sur-R]{[Corrigé]}}\\
	\label{Une condition nécessaire pour qu'un polynôme soit scindé sur R}
	Soit $P=\displaystyle\sum\limits_{k=0}^n{a_kX^k}$ scindé sur $\R$.
	\begin{enumerate}
		\item Montrer que $\forall x\in \R,\ P''(x)P(x)-(P'(x))^2\leq 0$.
		\item Montrer que $P',\dots ,P^{(n-1)}$ sont scindés sur $\R$.
		\item Démontrer que $\forall k\in \crblanc{1}{n-1},\ a_k^2\leq a_{k-1}a_{k+1}$.
	\end{enumerate}
	
	\section{Une condition nécessaire pour qu'un polynôme soit dissocié sur $\R$ \telecom{2}}
	\textcolor{blue}{\hyperref[sec:une-condition-nécessaire-pour-qu'un-polynôme-soit-dissocié-sur-R]{[Corrigé]}}\\
	\label{Une condition nécessaire pour qu'un polynôme soit dissocié sur R}
	Soit $P=\displaystyle\sum_{k=0}^na_kX^k$ de degré $n\geq 2$ scindé à racines simples sur $\R$.
	\begin{enumerate}
		\item Montrer que $P'$ est scindé à racines simples sur $\R$.
		\item Montrer que $\forall k\in \crblanc{0}{n-1},\ a_k^2+a_{k+1}^2>0$.
	\end{enumerate}
	
	\section{Suite de polynômes scindés sur $\R$ \xens{3}}
	\textcolor{blue}{\hyperref[sec:suite-de-polynômes-scindés-sur-R]{[Corrigé]}}\\
	\label{Suite de polynômes scindés sur R}
	Soit $(P_n)_{n\in \N}\in \R_n[X]^\N$ une suite de polynômes unitaires scindés sur $\R$ convergeant simplement vers un polynôme $P$ sur $\C$. Montrer que $P$ est scindé sur $\R$.
	
	\section{Borne de Cauchy \telecom{2}}
	\textcolor{blue}{\hyperref[sec:borne-de-cauchy]{[Corrigé]}}\\
	\label{Borne de Cauchy}
	Soient $n\in \N^*$ et $P=X^n+\displaystyle\sum_{k=0}^{n-1}a_kX^k\in \C[X]$.\\
	Montrer que pour toute racine $z$ de $P$ on a $|z|\leq 1+\max\limits_{0\leq k\leq n-1}|a_k|$.
	
	\section{Théorème d'Eneström-Kakeya \centraleponts{3}}
	\textcolor{blue}{\hyperref[sec:théorème-d'eneström-kakeya]{[Corrigé]}}\\
	\label{Théorème d'Eneström-Kakeya}
	Soit $P=\displaystyle\sum_{k=0}^na_kX^k\in \R[X]$ tel que $\forall k\in \crblanc{0}{n},\ a_k>0$.
	\begin{enumerate}
		\item On suppose $a_0\leq a_1\leq\cdots\leq a_n$. Montrer que les racines de $P$ sont toutes de module au plus $1$.\\
		On pourra considérer le polynôme $Q=(X-1)P$.
		\item Montrer qu'en général les racines de $P$ sont comprises dans la couronne
		$$C(r,R)=\{z\in \C\ |\ r\leq |z|\leq R\}$$
		où $r$ et $R$ sont respectivement le minimum et le maximum de $\left(\dfrac{a_k}{a_{k+1}}\right)_{0\leq k\leq n-1}$.
	\end{enumerate}
	
	\section{Perturbations de polynômes}
	\textcolor{blue}{\hyperref[sec:pertubation-de-polynômes]{[Corrigé]}}\\
	\label{Pertubations de polynômes}
	Montrer pour tout $n\in \N^*$, il existe $(a_0,\dots,a_n)\in (\R^*_+)^n$ tel que $\forall (\varepsilon_0,\dots,\varepsilon_n)\in \{-1,1\}^n$, le polynôme
	$$P=\sum_{k=0}^na_k\varepsilon_kX^k$$
	soit scindé sur $\R$.
	
	\section{Polynômes à coefficients dans $\{-1,0,1\}$}
	On note $S$ l'ensemble des polynômes à coefficients dans $\{-1,0,1\}$ et $R$ l'ensemble des racines réelles des polynômes non nuls de $S$.
	
	\subsection{Polynômes scindés}
	\textcolor{blue}{\hyperref[sec:polynômes-scindés]{[Corrigé]}}\\
	\label{Polynômes scindés}
	Déterminer les polynômes unitaires de $S$ qui sont scindés sur $\R$.
	
	\subsection{Ensemble des racines (1)}
	\textcolor{blue}{\hyperref[sec:ensemble-des-racines-(1)]{[Corrigé]}}\\
	\label{Ensemble des racines (1)}
	Montrer que $R$ est une partie dénombrable de $\left[-2,-\dfrac{1}{2}\right]\cup\{0\}\cup\left[\dfrac{1}{2},2\right]$.
	
	\subsection{Ensemble des racines (2)}
	\textcolor{blue}{\hyperref[sec:ensemble-des-racines-(2)]{[Corrigé]}}\\
	\label{Ensemble des racines (2)}
	Montrer que $R$ est dense dans $\left[-2,-\dfrac{1}{2}\right]\cup\{0\}\cup\left[\dfrac{1}{2},2\right]$.\\
	On pourra construire pour $\alpha\in \left[\dfrac{1}{2},1\right]$ une partie $I$ de $\N^*$ telle que $\displaystyle\sum_{n\in I}\alpha^n=1$.
	
	\section{Théorème de Bernstein \centraleponts{4}}
	\textcolor{blue}{\hyperref[sec:theoreme-de-bernstein]{[Corrigé]}}\\
	\label{Théorème de Bernstein}
	Soient $n\in \N$ et $P\in \C_n[X]$. Pour tout $\lambda\in \C$ on pose $Q_\lambda(X)=\dfrac{P(\lambda X)-P(\lambda)}{X-1}$. On fixe $\lambda\in \C$.
	\begin{enumerate}
		\item En décomposant la fraction rationnelle $\displaystyle\frac{Q_\lambda(X)}{X^n+1}$ en éléments simples, montrer qu'en notant $\zeta_1,\dots,\zeta_n$ les racines de $X^n+1$ on a :
		$$\lambda P'(\lambda)=\displaystyle\frac{2}{n}\sum_{k=1}^n\frac{\zeta_kP(\zeta_k\lambda)}{(\zeta_k-1)^2}-\dfrac{2}{n}P(\lambda)\sum_{k=1}^n\frac{\zeta_k}{(\zeta_k-1)^2}$$
		\item En déduire l'égalité :
		$$XP'(X)=\displaystyle\frac{n}{2}P(X)+\frac{2}{n}\sum_{k=1}^n\frac{\zeta_kP(\zeta_kX)}{(\zeta_k-1)^2}$$
		On pourra appliquer le résultat de la question 2 a un polynôme bien choisi.
		\item En déduire que $\sup\limits_{z\in \U}|P'(z)|\leq n\sum\limits_{z\in \U}|P(z)|$.
	\end{enumerate}
	
	\section{Etude d'un polynôme défini implicitement}
	\textcolor{blue}{\hyperref[sec:etude-dun-polynome-defini-implicitement]{[Corrigé]}}\\
	\label{etudepolyimplicite}
	\label{Etude d'un polynôme défini implicitement}
	\begin{enumerate}
		\item Soit $n\in \N^*$. Montrer qu'il existe un unique polynôme $A_n\in \C[X]$ tel que $\displaystyle A_n\left(X+\frac{1}{X}\right)=X^n+\frac{1}{X^n}$.
		\item Déterminer les racines de $A_n$.
		\item Décomposer $\displaystyle\frac{1}{A_n}$ en éléments simples.
	\end{enumerate}
	
	\section{P'|P \telecom{1}}
	\textcolor{blue}{\hyperref[sec:P'|P]{[Corrigé]}}\\
	\label{P'|P}
	Déterminer les polynômes $P\in \C[X]$ tels que $P'$ divise $P$.
	
	\section{Polynôme positif (1) \centraleponts{3}}
	\textcolor{blue}{\hyperref[sec:polynôme-positif-(1)]{[Corrigé]}}\\
	\label{Polynôme positif (1)}
	Soit $P\in \R[X]$ de degré $n\in \N^*$ tel que $\forall x\in \R,\ P(x)\geq 0$. On pose $Q=\displaystyle\sum_{k=0}^nP^{(k)}$.
	\begin{enumerate}
		\item Montrer que $\lim\limits_{|x|\to +\infty}Q(x)=+\infty$.
		\item En déduire que $Q$ admet un minimum sur $\R$.
		\item En déduire que $\forall x\in \R,\ Q(x)\geq 0$.
	\end{enumerate}
	
	\section{Théorème de Pythagore polynomial \centraleponts{3}}
	\textcolor{blue}{\hyperref[sec:théorème-de-pythagore-polynomial]{[Corrigé]}}\\
	\label{Théorème de Pythagore polynomial}
	Soit $P\in\R[X]$ non constant tel que $P(x)\geq0$ pour tout réel $x$.
	\begin{enumerate}
		\item Montrer que le coefficient dominant de $P$ est positif et que les racines réelles de $P$ sont de multiplicité paire.
		\item Montrer qu'il existe un polynôme $C\in\C[X]$ tel que $P=C\overline{C}$.
		\item En déduire qu'il existe $A$ et $B$ dans $\R[X]$ tels que $P=A^2+B^2$.
	\end{enumerate}
	
	\section{Polynômes à valeurs carrées}
	\textcolor{blue}{\hyperref[sec:polynomes-à-valeurs-carrées]{[Corrigé]}}\\
	\label{Polynômes à valeurs carrées}
	Soit $P\in \R[X]$ tel que $\forall n\in \N,\ \exists m\in \N,\ P(n)=m^2$. On souhaite montrer qu'il existe un polynôme $Q\in \R[X]$ tel que $P=Q^2$.
	\begin{enumerate}
		\item Soient $a\in \R$ et $f\in \mathcal C^{\infty}(]a,+\infty[,\R)$. On définit $\fonction{\Delta(f)}{]a,+\infty[}{\R}{x}{f(x+1)-f(x)}$. Montrer que :
		$$\forall n\in \N^*,\ \forall x>a,\ \exists \theta\in [0,n],\ \Delta^n(f)(x)=f^{(n)}(x+\theta)$$
		\item Conclure en appliquant la question 1 à $x\mapsto \sqrt{P(x)}$.
	\end{enumerate}
	
	\section{Polynômes réciproques \ccinp{2}}
	\textcolor{blue}{\hyperref[sec:polynomes-reciproques-etoile2]{[Corrigé]}}\\
	\label{Polynômes réciproques}
	On dit qu'un polynôme $P\in\C[X]$ de degré $n$ est réciproque s'il s'écrit $P=a_nX^n+\dots+a_0$ avec $a_k=a_{n-k}$ pour tout $k\in\crblanc{0}{n}$.
	\begin{enumerate}
		\item Soit $P\in\C[X]$ de degré $n$. Démontrer que $P$ est réciproque si et seulement $P(X)=X^nP\left(\displaystyle\frac{1}{X}\right)$.
		\item Montrer qu'un produit de polynômes réciproques est réciproque.
		\item On suppose que $P$ et $Q$ sont réciproques et que $Q|P$. Démontrer que $\displaystyle\frac{P}{Q}$ est réciproque.
		\item Soit $P=\displaystyle\sum\limits_{k=0}^n{a_kX^k}\in\C[X],\ a_n\ne 0$, un polynôme réciproque.
		\begin{enumerate}[label=\alph*.]
			\item Démontrer que si $\alpha$ est une racine de $P$, alors $\alpha\ne0$ et $\alpha^{-1}$ est une racine de $P$.
			\item Démontrer que si 1 est une racine de $P$, alors sa multiplicité est supérieure ou égale à 2.
			\item Démontrer que si le degré de $P$ est impair, alors $-1$ est une racine de $P$.
			\item Démontrer que si $P$ est de degré pair et si $-1$ est une racine de $P$, alors sa multiplicité est supérieure ou égale à $2$.
		\end{enumerate}
		\item Démontrer que tout polynôme réciproque de $\C[X]$ de degré $2n$ se factorise en $P=a_{2n}(X^2+b_1X+1)\dots(X^2+b_nX+1)$.
		\\Que peut-on dire si le degré de $P$ est impair ?
	\end{enumerate}
	
	\section{Polynômes surjectifs \etoile{5}}
	\textcolor{blue}{\hyperref[sec:polynomes-surjectifs-etoile5]{[Corrigé]}}\\
	\label{polysurj}
	\label{Polynômes surjectifs}
	Déterminer les polynômes $P\in \C[X]$ vérifiant :
	\begin{enumerate}
		\item $P(\C)=\C$
		\item $P(\U)=\U$
		\item $P(\R)=\R$
		\item $P(\Q)=\Q$
		\item $P(\R\backslash\Q)=\R\backslash\Q$
		\item $P(\Z)=\Z$
	\end{enumerate}
	
	\section{Résultant et discriminant \ccinp{2}}
	\textcolor{blue}{\hyperref[sec:resultant-et-discriminant-etoile2]{[Corrigé]}}\\
	\label{Résultant}
	\label{Résultant et discriminant}
	Soit $(m,n)\in(\N^*)^2$. Soient $P=\displaystyle\sum\limits_{k=0}^{n}a_kX^k\in\K_n[X]$ et $Q=\displaystyle\sum\limits_{k=0}^{m}b_kX^k\in\K_m[X]$ deux polynômes.
	\\ On pose le résultant de $P$ et $Q$: $$\operatorname{Res}(P,Q)= 
	\begin{vmatrix}
		a_0 & 0&\dots &\dots &0 &b_0 &0  &\dots &0\\
		a_1 & a_0 &\ddots&\ddots &\vdots &b_1  &b_0 &\ddots &\vdots\\
		\vdots &a_1 &\ddots & \ddots &\vdots &\vdots &b_1 &\ddots &0\\
		a_n & \vdots &\ddots &\ddots &0&\vdots &  &\ddots &b_0\\
		0 &a_n & &\ddots &a_0 &b_m &  & &b_1 \\
		\vdots &\ddots  &\ddots & &a_1 &0 &\ddots  & &\vdots\\
		\vdots & &\ddots &\ddots &\vdots &\vdots &\ddots &\ddots &\vdots\\
		0 &\dots &\dots&0 &a_n &0 &\dots &0 &b_m \\
	\end{vmatrix}$$
	$\hspace{67mm}\hspace{2mm}\underbrace{\rule{38mm}{0pt}}_m \underbrace{\rule{30mm}{0pt}}_n$
	\\Le résultant des polynômes $P$ et $Q$ est défini comme le déterminant d'une matrice de taille $n+m$, appelée matrice de Sylvester et notée $\operatorname{Syl}(P,Q)$.
	\\On note $\B_c$ la base canonique de $\K_{n+m-1}[X]$.
	\begin{enumerate}
		\item Montrer que $\B=((1,0),(X,0),\dots,(X^{m-1},0),(0,1),(0,X),\dots, (0,X^{n-1}))$ est une base de $\K_{m-1}[X]\times\K_{n-1}[X]$
		\item On pose l'application $\fonction{\varphi}{\K_{m-1}[X]\times\K_{n-1}[X]}{\K_{n+m-1}[X]}{(U,V)}{PU+QV}$
		\\Montrer que $\varphi$ est une application linéaire. 
		\item Expliciter sa matrice $M$ relativement aux bases $\B$ et $\B_c$
		\item Montrer que $P\land Q=1\iff\operatorname{Res}(P,Q)\ne 0$.
	\end{enumerate}
	On pose $\Delta(P)=\displaystyle\frac{(-1)^\frac{n(n-1)}{2}}{a_n}\operatorname{Res}(P,P')$ appelé discriminant de $P$.
	\begin{enumerate}[resume]
		\item On suppose ici que P est de degré 2 et on pose $P=aX^2+bX+c$. Calculer $\Delta(P).$
		\item On suppose ici que $\K=\C$ et par conséquent que $P\in\C[X]$. Montrer que $P$ est scindé à racines simples si et seulement $\Delta(P)\ne 0$
	\end{enumerate}
	
	\section{Théorème de Liouville : Fermat pour les polynômes \xens{4}}
	\textcolor{blue}{\hyperref[sec:theoreme-de-liouville--fermat-pour-les-polynomes]{[Corrigé]}}\\
	\label{Théorème de Liouville : Fermat pour les polynômes}
	Soit $n$ un entier supérieur ou égal à $3$. On souhaite montrer que si $(P,Q,R)\in \C[X]^3$ tel que $P^n+Q^n=R^n$ alors $P,Q,R$ sont égaux à une constante multiplicative près. On se donne $(P,Q,R)$ un tel triplet.
	\begin{enumerate}
		\item Montrer que l'on peut se ramener à $\tilde P,\tilde Q,\tilde R$ premiers entre eux deux à deux.
	\end{enumerate} 
	Dorénavant on supposera $P,Q,R$ premiers entre eux deux à deux et on cherche à montrer que $P,Q,R$ sont constants.
	\begin{enumerate}[resume]
		\item On note $\zeta_1,\dots,\zeta_n$ les racines de $X^n+1$ et pour $i\in \crblanc{1}{n},\ T_i=P-\zeta_iQ$.\\
		Montrer que $\forall i\in \crblanc{1}{n},\exists H_i\in \C[X],\ T_i=H_i^n$.\\
		\item Conclure.
	\end{enumerate}
	
	\newpage
\chapter{Espace vectoriels normés}
	\section{Suite de Cauchy \etoile{2}}
	\textcolor{blue}{\hyperref[sec:suite-de-cauchy-etoile-2]{[Corrigé]}}\\
	\label{Suite de Cauchy}
	Soit $(E,\norme{.})$ un espace vectoriel normé.\\
	On dit qu'une suite $(u_n)\in E^\N$ est de Cauchy lorsqu'elle vérifie :
	$$\forall \varepsilon>0,\ \exists N\in \N,\ \forall p,q\in \llbracket N;+\infty\llbracket,\ ||u_p-u_q||\leq \varepsilon$$
	\\Démontrer que toute suite convergente est une suite de Cauchy puis démontrer qu'en dimension finie il y a équivalence.
	
	\section{Théorème de Fréchet-Von Neumann-Jordan}
	\textcolor{blue}{\hyperref[sec:theoreme-de-frechet-von-neumann]{[Corrigé]}}\\
	\label{Théorème de Fréchet-Von Neumann-Jordan}
	Soit $(E,\norme{.})$ un espace vectoriel normé.\\
	Montrer que $\norme{.}$ est une norme euclidienne si et seulement si elle vérifie l'identité du parallélogramme :
	$$\forall x,y\in E,\ \norme{x-y}^2+\norme{x+y}^2=2\left(\norme{x}^2+\norme{y}^2\right)$$
	
	\section{Une norme non euclidienne}
	\textcolor{blue}{\hyperref[sec:une-norme-non-euclidienne]{[Corrigé]}}\\
	\label{Une norme non euclidienne}
	Soient $n\in \N^*$ et $\alpha_0,\dots,\alpha_n$ des réels distincts. \\
	Montrer que l'application $N$ définie sur $\R_n[X]$ par $\forall P\in \R_n[X],\ N(P)=\sum_{k=0}^n|P(\alpha_k)|$ est une norme non euclidienne.
	
	\section{Norme invariante par similitude}
	\textcolor{blue}{\hyperref[sec:norme-invariante-par-similitude]{[Corrigé]}}\\
	\label{Norme invariante par similitude}
	Soit $E=\M_n(\K)$ et $\norme{.}$ une norme sur $E$ telle que : $$\forall A\in\M_n(\K), \; \forall P\in \text{GL}_n(\K), \; \norme{P^{-1}AP}=\norme{A}$$
	\begin{enumerate}
		\item Montrer que, pour tout $(A,B)\in\M_n(\K)^2$, $\norme{AB}=\norme{BA}$. On pensera à utiliser la densité de $\text{GL}_n(\K)$.
		\item En déduire une contradiction.
	\end{enumerate}
	
	\section{Equivalence des normes dans un espace vectoriel normé de dimension finie}
	\textcolor{blue}{\hyperref[sec:equivalence-des-normes-dans-un-espace-vectoriel-norme-de-dimension-finie]{[Corrigé]}}\\
	\label{Equivalence des normes dans un espace vectoriel normée de dimension finie}
	Soient $E$ un $\K$-espace vectoriel de dimension finie et $(e_1,\dots,e_n)$ une base de $E$. Fixons une norme $N$ sur $E$.\\
	On définit l'application $\fonction{N_0}{E}{\R_+}{x=\displaystyle\sum_{i=1}^nx_ie_i}{\sup\limits_{1\leq i\leq n}{|x_i|}}$.
	\begin{enumerate}
		\item Montrer que $N_0$ définie une norme sur $E$.
		\item Trouver une constante $\beta>0$ tel que $\forall x\in E,\ N(x)\leq \beta N_0(x)$
		\item On définit $\fonction{T}{(\K^n,\normep{\infty}{.})}{(E,N_0)}{(x_1,\dots,x_n)}{\displaystyle\sum_{i=1}^nx_ie_i}$.
		\begin{enumerate}[label=\alph*.]
			\item Montrer que $T$ est continue.
			\item En déduire que $S_{N_0}=\{x\in E,\ N_0(x)=1\}$ est une partie compacte de $(E,N_0)$.
			\item Déterminer une constante $\alpha>0$ telle que $\forall x\in \K^n,\ N(x)\geq \alpha N_0(x)$.
		\end{enumerate}
		\item Conclure que toutes les normes de $E$ sont équivalentes.
	\end{enumerate}
	
	\section{Normes non équivalentes}
	\textcolor{blue}{\hyperref[sec:normes-non-equivalentes]{[Corrigé]}}\\
	\label{Normes non équivalentes}
	Donner un exemple de deux normes non équivalentes sur un espace vectoriel normé.
	
	\section{Normes semblables à la norme uniforme sur $\K[X]$}
	\textcolor{blue}{\hyperref[sec:normes-semblables-a-la-norme-uniforme-sur-kx]{[Corrigé]}}\\
	\label{Normes semblables à la norme uniforme sur KX}
	On pose pour $A\subset \K$ et $P\in \K[X]$, $N_A(P)=\sup\limits_{x\in A}|P(x)|$.\\
	Trouver une condition nécessaire et suffisante pour que $N_A$ soit une norme sur $\K[X]$.
	
	\section{Comparaisons de deux normes sur $\K_n[X]$}
	\textcolor{blue}{\hyperref[sec:comparaison-de-deux-normes-sur-knx]{[Corrigé]}}\\
	\label{Comparaison de deux normes sur KnX}
	Soit $n\in \N$. Pour $P\in \K_n[X]$ on pose $\normep{1}{P}=\displaystyle\int_0^1|P(t)|dt$ et $\norme{P}=\displaystyle\sum_{k=0}^n|P(k)|$.
	\begin{enumerate}
		\item Montrer que $\normep{1}{.}$ et $\norme{.}$ sont des normes de $\K_n[X]$.
		\item Trouver une constante $C_n>0$ telle que $\forall P\in \K_n[X],\ \normep{1}{P}\leq C_n\norme{P}$.
		\item $\normep{1}{.}$ et $\norme{.}$ sont-elles équivalentes ?
	\end{enumerate}
	
	\section{Comparaisons de normes usuelles sur $\mathcal C^0([a,b],\K)$}
	\textcolor{blue}{\hyperref[sec:comparaison-de-normes-usuelles-sur-mathcalc0abk]{[Corrigé]}}\\
	\label{Comparaisons de normes usuelles sur C0}
	Soient $a\leq b$ deux réels. On note $E=\mathcal C^0([a,b],\K)$. Pour $f\in E$ on définit :
	$$\normep{\infty}{f}=\sup\limits_{a\leq t\leq b}|f(t)|\quad\quad \normep{1}{f}=\int_a^b|f(t)|dt\quad\quad \normep{2}{f}=\sqrt{\int_a^b|f(t)|^2dt}$$
	\begin{enumerate}
		\item Montrer que $\normep{\infty}{.},\ \normep{1}{.}$ et $\normep{2}{.}$ sont des normes sur $E$.
		\item Soit $f\in E$. Montrer que
		$$\normep{1}{f}\leq (b-a)\normep{\infty}{f}\quad\quad \normep{2}{f}\leq \sqrt{b-a}\normep{\infty}{f}\quad\quad \normep{1}{f}\leq \sqrt{b-a}\normep{2}{f}$$
		\item Montrer que ces trois normes ne sont pas équivalentes.
	\end{enumerate}
	
	\section{Normes $p$}
	\textcolor{blue}{\hyperref[sec:normes-p]{[Corrigé]}}\\
	\label{Normes p}
	Pour $x=(x_1,\dots,x_n)\in\K^n$ et $p\geq1$, on pose $\displaystyle\normep{p}{x}=\left(\sum_{i=1}^n|x_i|^p\right)^\frac{1}{p}$.
	
	\subsection{Inégalités de Hölder et Minkowski}
	Soient $p$ et $q$ deux nombres réels strictement positifs tels que $\displaystyle\frac{1}{p}+\frac{1}{q}=1$.
	\begin{enumerate}
		\item Prouver l'inégalité de Young, $$\displaystyle \forall(u,v)\in(\R_+^*)^2,\ uv\leq\frac{u^p}{p}+\frac{v^q}{q}.$$
		\item \textit{Inégalité de Hölder}\\Soient $x_1,\dots,x_n$ et $y_1,\dots,y_n$ des réels strictement positifs. Prouver l'inégalité de Hölder, $$\sum_{k=1}^nx_ky_k\leq\left(\sum_{k=1}^nx_k^p\right)^\frac{1}{p}\left(\sum_{k=1}^ny_k^q\right)^\frac{1}{q}.$$
		\item \textit{Inégalité de Minkowski}\\Soient $p\geq 1$, $x_1,\dots,x_n$ et $y_1,\dots,y_n$ des réels strictement positifs. Prouvez l'inégalité de Minkowski, $$\left(\sum_{k=1}^n(x_k+y_k)^p\right)^\frac{1}{p}\leq\left(\sum_{k=1}^nx_k^p\right)^\frac{1}{p}+\left(\sum_{k=1}^ny_k^p\right)^\frac{1}{p}$$
		\item En déduire que $\normep{p}{.}$ est une norme sur $\K^n$.
	\end{enumerate}
	
	\subsection{Equivalence des normes $p$ et $q$}
	\begin{enumerate}[leftmargin=*]
		\item Soit $p\geq 1$. Montrer que $\normep{\infty}{.}$ et $\normep{p}{.}$ sont équivalentes.
		\item Soit $1\leq p\leq q<+\infty$. Montrer que $\forall x\in \K^n,\ \normep{q}{x}\leq \normep{p}{x}\leq n^{\frac{1}{p}-\frac{1}{q}}\normep{q}{x}$.
	\end{enumerate}
	
	\subsection{Norme infinie}
	On définit la norme infini $\normep{\infty}{.}$ par $\forall x=(x_1,\dots,x_n)\in \K^n,\ \normep{\infty}{x}=\max\limits_{1\leq i\leq n}|x_i|$.\\
	Montrer que $\forall x\in \K^n,\ \normep{\infty}{x}=\lim\limits_{p\to+\infty}\normep{p}{x}$.
	
	\section{Normes de Sobolev}
	\textcolor{blue}{\hyperref[sec:normes-de-sobolev]{[Corrigé]}}\\
	\label{Normes de Sobolev}
	Soit $E=\mathcal{C}^n([a,b],\R)$ et $F=\mathcal{C}^{n-1}([a,b],\R)$.\\
	On définit la n-ième norme de Sobolev sur $E$ par : \[S_n(f)=\sum_{i=0}^{n}\normep{2}{f^{(i)}}\]
	\begin{enumerate}
		\item Montrer qu'il s'agit bien d'une norme.
		\item Montrer que la dérivation \[\fonction{D}{E}{F}{f}{f'}\] est continue sur $(E,S_n)$.
		\item Généralisation : \\Soient $(E,N_E)$ et $(F,N_F)$ deux espaces vectoriels normés et soit $T:E\to F$ linéaire\\
		La fonction \[\fonction{N_T}{E}{\R_+}{x}{N_E(x)+N_F(T(x))}\]
		est une norme rendant $T$ continue.
	\end{enumerate}
	
	\section{Norme duale}
	\textcolor{blue}{\hyperref[sec:norme-duale]{[Corrigé]}}\\
	\label{Norme duale}
	Soit $(E,\langle\cdot,\cdot\rangle)$ un espace euclidien et $N$ une norme sur $E$ (qui n'est pas forcément la norme associée au produit scalaire). On note $S$ la sphère unité pour la norme $N$ i.e $S=\{x\in E,\ N(x)=1\}$ et on pose pour tout $x\in E$,
	$$N^*(x)=\sup_{y\in S}|\langle x,y\rangle|$$
	\begin{enumerate}
		\item Montrer que l'application est bien définie sur $E$.
		\item Montrer que $N^*$ est une norme sur $E$.
		\item On suppose que $E=\R^n$.\\
		Déterminer $N^*$ lorsque $N$ est la norme $\normep{2}{.},\ \normep{\infty}{.}$ ou $\normep{1}{.}$.
	\end{enumerate}
	
	\section{Norme à partir d'une famille libre}
	\textcolor{blue}{\hyperref[sec:norme-a-partir-dune-famille-libre]{[Corrigé]}}\\
	\label{Norme à partir d'une famille libre}
	Soit $E$ un $\R$-espace vectoriel muni d'une norme $\norme{.}$. On se donne $(x_1,\dots x_n)\in E^n$. 
	\\Montrer que l'application $\displaystyle \fonction{N}{\R^n}{\R_+}{(\lambda_1,\dots,\lambda_n)}{\displaystyle\norme{\sum_{k=1}^n\lambda_kx_k}}$ est une norme sur $\R^n$ si et seulement si $(x_1,\dots,x_n)$ est une famille libre.
	
	\section{Quelques normes matricielles}
	\textcolor{blue}{\hyperref[sec:quelques-normes-matricielles]{[Corrigé]}}\\
	\label{Quelques normes matricielles}
	Pour $A\in\M_{n,p}(\R)$, on pose: \begin{align*}
		&N_1(A)=\max_{1\leq i\leq n}\sum_{j=1}^n|A_{i,j}|  &N_2(A)=\max_{1\leq j\leq n}\sum_{i=1}^n|A_{i,j}|\\
		&N_3(A)=\sqrt{\sum_{i=1}^n\sum_{j=1}^pA_{i,j}^2}  &N_4(A)=\sqrt{\max Sp(A^\top A)}
	\end{align*}
	\begin{enumerate}
		\item Montrer que $N_1$,$N_2$,$N_3$ et $N_4$ sont des normes sur $\M_{n,p}(\R)$.
		\item Montrer que si $n=p$, ce sont des normes d'algèbre sur $\M_n(\R)$.
	\end{enumerate}
	
	\section{Caractérisation des sous-espaces de dimension finie de $\mathcal C^0([0,1],\K)$}
	\textcolor{blue}{\hyperref[sec:caracterisation-des-sous-espaces-de-dimension-finie-de-mathcalc001k]{[Corrigé]}}\\
	\label{Caractérisation des sous-espaces de dimension finie de C0}
	On note $E=\mathcal C^0([0,1],\K)$. Pour $f\in E$ on pose $\normep{\infty}{f}=\sup\limits_{[0,1]}|f|$ et $\normep{2}{f}=\displaystyle\left(\int_{[0,1]}f^2\right)^{1/2}$.
	\begin{enumerate}
		\item Montrer qu'il existe $b>0$ tel que $\forall f\in E,\ \normep{2}{f}\leq b\normep{\infty}{f}$.
		\item Soit $V$ un sous-espace vectoriel de $E$ de dimension finie. Montrer qu'il existe $c>0$ tel que $\forall f\in V,\ \normep{\infty}{f}\leq c\normep{2}{f}$.
		\item Soit $V$ un sous-espace vectoriel de $E$. On suppose qu'il existe un entier $n\in \N^*$ tel que $\forall f\in V,\ \normep{\infty}{f}\leq n\normep{2}{f}$.\\
		Montrer que $V$ est de dimension finie et que $\dim V\leq n^2$.
	\end{enumerate}
	
	\section{Distance}
	\textcolor{blue}{\hyperref[sec:distance]{[Corrigé]}}\\
	\label{Distance}
	Soit $A$ un ensemble.
	On appelle distance sur $A$ toute application $d:A^2\to \R_+$ qui vérifie les axiomes :
	\begin{itemize}
		\item De symétrie : $\forall (x,y)\in A^2,\ d(x,y)=d(y,x)$;
		\item De séparation : $\forall (x,y)\in A^2,\ d(x,y)=0\iff x=y$;
		\item D'inégalité triangulaire : $\forall (x,y,z)\in A^3,\ d(x,y)\leq d(x,z)+d(z,y)$.
	\end{itemize}
	\begin{enumerate}[leftmargin=*]
		\item Soit $(E\norme{.})$ un espace vectoriel normé. montrer que $\fonction{d}{E^2}{\R_+}{(x,y)}{\norme{x-y}}$ est une distance sur $E$.
		\item Pour $(x,y)\in \R^2$ on pose $d(x,y)=\arctan|x-y|$. Montrer que $d$ est une distance sur $\R$ et qu'elle ne peut pas s'exprimer comme la distance de la question précédente.
	\end{enumerate}
	
	\section{Distance à une partie}
	\textcolor{blue}{\hyperref[sec:distance-a-une-partie]{[Corrigé]}}\\
	\label{Distance à une partie}
	Soit $A$ une partie non vide d'un espace vectoriel normé $E$. On pose pour tout $x,y\in E^2,\ d(x,y)=\norme{x-y}$ et $d(x,A)=\inf\limits_{a\in A}d(x,a)$. Montrer que
	$$\forall (x,y)\in E^2,\ |d(x,A)-d(y,A)|\leq d(x,y)$$
	
	\section{Distance d'un élément à une partie (1)}
	\textcolor{blue}{\hyperref[sec:distance-dun-element-a-une-partie-1]{[Corrigé]}}\\
	\label{Distance d'un élément à une partie 1}
	On considère $E$ l'espace des suites réelles bornées que l'on munit de la norme uniforme. Calculer la distance de $u=((-1)^n)_{n\in \N}$ à l'ensemble des suites convergentes.
	
	\section{Distance d'un élément à une partie (2)}
	\textcolor{blue}{\hyperref[sec:distance-dun-element-a-une-partie-2]{[Corrigé]}}\\
	\label{Distance d'un élément à une partie 2}
	On munit $\M_n(\R)$ de son produit scalaire canonique.
	\begin{enumerate}
		\item Montrer que $\M_n(\R)=\mathcal S_n(\R)\oplus\mathcal A_n(\R)$.
		\item Montrer que $\mathcal S_n(\R)=(\mathcal A_n(\R))^\perp$.
		\item Soit $M=\begin{pmatrix}
			1&2&3\\4&5&6\\7&8&9
		\end{pmatrix}$. Quelle est la distance de $M$ à $\mathcal S_n(\R)$ ?
	\end{enumerate}
	
	\section{Passage par les matrices orthogonales}
	\textcolor{blue}{\hyperref[sec:passage-par-les-matrices-orthogonales]{[Corrigé]}}\\
	\label{Passage par les matrices orthogonales}
	Pour $X\in\M_{n,1}(\R)$, on pose $\displaystyle N(X)=\max_{A\in\O_n(\R)}\normep{\infty}{AX}$.
	\begin{enumerate}
		\item Montrer que $N$ est une norme sur $\M_{n,1}(\R)$.
		\item Vérifier que : $\forall X\in \M_{n,1}(\R),\forall A \in \O_n(\R),\quad N(AX)=N(X)$.
		\item Montrer que $N=\normep{2}{.}$ la norme euclidienne canonique de $\M_{n,1}(\R)$.
	\end{enumerate}
	
	\section{Diamètre d'une partie bornée}
	\textcolor{blue}{\hyperref[sec:diametre-dune-partie-bornee]{[Corrigé]}}\\
	\label{Diamètre d'une partie bornée}
	Lorsque $A$ est une partie bornée non vide d'un espace vectoriel normé $(E,N)$, on définit le \textit{diamètre} de $A$ défini par : $$\delta(A)=\sup_{(x,y)\in A^2} N(y-x).$$
	\begin{enumerate}
		\item Justifier l'existence du diamètre.
	\end{enumerate}
	Soient $A$ et $B$ deux parties bornées et non vides de $E$.
	\begin{enumerate}[resume]
		\item Etablir que $A\subset B \Rightarrow \delta(A)\leq\delta(B)$.
		\item On suppose de plus $A\cap B\ne \emptyset$. Montrer que $\delta(A\cup B)\leq\delta(A)+\delta(B)$
		\item Montrer que dans le cas général, $\delta(A\cup B)\leq \delta(A)+\delta(B)+d(A,B)$ où $d(A,B)=\inf\limits_{(a,b)\in A\times B}N(a-b)$.
	\end{enumerate}
	
	\section{Détermination d'une borne inférieure}
	\textcolor{blue}{\hyperref[sec:determination-dune-borne-inferieure]{[Corrigé]}}\\
	\label{Détermination d'une borne inférieure}
	On note $E=\left\{f\in\mathcal{C}^1([0,1],\K),\;f(0)=0 \; \text{et} \; f(1)=1\right\}$.\\
	Déterminer $$\inf_{f\in E}\int_0^1|f'(x)-f(x)|dx$$
	
	\section{Normes usuelles sur $\mathcal C^1([0,1],\K)$}
	\textcolor{blue}{\hyperref[sec:normes-usuelles-sur-mathcalc101k]{[Corrigé]}}\\
	\label{Normes usuelles sur C1}
	Soit $E=\mathcal C^1([0,1],\K)$. On pose pour tout $f\in E$ : 
	\begin{itemize}[leftmargin=*]
		\item $\displaystyle\normep{1}{f}=\int_0^1|f(x)|dx$ ;
		\item $N_1(f)=\normep{1}{f}+\normep{1}{f'}$ ;
		\item $N_2(f)=|f(0)|+\normep{1}{f'}$.
	\end{itemize}
	\begin{enumerate}
		\item Montrer que $N_1$ et $N_2$ sont des normes sur $E$.
		\item $N_1$ et $N_2$ sont-elles équivalentes ?
	\end{enumerate}
	
	\section{Intersection des boules unités subordonnées d'un espace vectoriel normé de dimension finie}
	\textcolor{blue}{\hyperref[sec:intersection-des-boules-unites-subordonnees-dun-espace-vectoriel-norme-de-dimension-finie]{[Corrigé]}}\\
	\label{Intersection des boules unités subordonnées d'un espace vectoriel normé de dimension finie}
	On note $\mathcal N$ l'ensemble des normes de $\M_n(\C)$ subordonnées à une norme de $\C^n$. Pour toute norme $N\in \mathcal N$ on note $B_N$ la boule unité fermée de $(E,N)$, $B_N=\{x\in E,\ N(x)\leq 1\}$.\\
	Déterminer $B=\displaystyle\bigcap_{N\in \mathcal N}B_N$.
	
	\section{Modes de convergence}
	\textcolor{blue}{\hyperref[sec:modes-de-convergence]{[Corrigé]}}\\
	\label{Modes de convergence}
	Soit $E$ un espace préhilbertien réel muni de son produit scalaire $\langle\cdot,\cdot\rangle$. On note $\norme{.}$ la norme associée.
	\\On dit qu'une suite $(x_n)\in E^\N$ \textit{converge fortement} vers $x\in E$ si $\displaystyle\lim_{n\to+\infty}\norme{x_n-x}=0$ et que $(x_n)$ \textit{converge faiblement} vers $x$ si pour tout $y\in E$, $\displaystyle\lim_{n\to+\infty}\langle x_n-x,y\rangle=0$.
	\begin{enumerate}
		\item
		\begin{enumerate}[label=\alph*.]
			\item Montrer que si $(x_n)$ converge faiblement, sa limite est unique.
			\item Montrer que la convergence forte implique la convergence faible.
		\end{enumerate}
		\item Montrer que $(x_n)$ converge fortement vers $x$ si et seulement si $(x_n)$ converge faiblement vers $x$ et $\displaystyle\lim_{n\to+\infty}\norme{x_n}=\norme{x}$
		\item Montrer que, en dimension finie, ces deux modes de convergence sont équivalents.
		\item Donner un contre-exemple en dimension infinie.
	\end{enumerate}
	
	\section{Moyenne des itérés et projection sur l'espace des invariants d'une application linéaire contractante}
	\textcolor{blue}{\hyperref[sec:moyenne-des-iteres-et-projection-sur-lespace-des-invariants-dune-application-lineaire-contractante]{[Corrigé]}}\\
	\label{Moyenne des itérés et projection sur l'espace des invariants d'une application linéaire contractante}
	Soit $E$ un espace vectoriel normé de dimension finie. Soit $u\in \mathcal L(E)$ tel que $\forall x\in E,\ \norme{u(x)}\leq \norme{x}$.
	\begin{enumerate}
		\item Montrer que $E=\Ker(\Id_E-u)\oplus\text{Im}(\Id_E-u)$.
		\item Soit $x\in E$. Pour $n\in \N^*$, on pose $x_n=\displaystyle\frac{1}{n}\sum_{k=0}^{n-1}u^k(x)$. Montrer que $(x_n)_{n\in \N^*}$ converge vers la projection de $x$ sur $\Ker(\Id_E-u)$ parallèlement à Im$(\Id_E-u)$.
	\end{enumerate}
	
	\section{Matrice de projecteur}
	\textcolor{blue}{\hyperref[sec:matrice-de-projecteur]{[Corrigé]}}\\
	\label{Matrice de projecteur}
	Soit $A\in \M_p(\R)$ telle que la suite $(A^n)_{n\in \N}$ converge vers une matrice $L$. Montrer que $L$ est une matrice de projecteur.
	
	\section{Matrice de rotation}
	\textcolor{blue}{\hyperref[sec:matrice-de-rotation]{[Corrigé]}}\\
	\label{Matrice de rotation}
	Soit $a\in \R$. Pour $n\in \N^*$, on pose $A_n=
	\begin{pmatrix}
		1&\displaystyle-\frac{a}{n}\\
		\displaystyle\frac{a}{n}&1
	\end{pmatrix}$.\\
	Montrer que $\unfty\lim A_n^n=
	\begin{pmatrix}
		\cos a&-\sin a\\
		\sin a&\cos a
	\end{pmatrix}$.
	
	\section{Applications contractantes}
	\textcolor{blue}{\hyperref[sec:applications-contractantes]{[Corrigé]}}\\
	\label{Application contractantes}
	Soient $E$ un espace vectoriel normé de dimension finie, $k\in [0,1[$ et $f:E\to E$ $k$-lipschitzienne. Soit $(u_n)\in E^\N$ telle que $\forall n\in \N,\ u_{n+1}=f(u_n)$.\\
	Montrer que $(u_n)_{n\in \N}$ converge.\\
	\textit{\underline{Indication :} on pourra considérer la série $\displaystyle\sum_{n\in \N}u_{n+1}-u_n$.}
	
	\section{Une série vectorielle}
	\textcolor{blue}{\hyperref[sec:une-serie-vectorielle]{[Corrigé]}}\\
	\label{Une série vectorielle}
	Soient $E$ un espace vectoriel normé de dimension finie et $(u_n)\in E^\N$ telle que $\displaystyle\sum_{n\in \N}u_n$ converge absolument.\\
	Pour tout $n\in \N$, on pose $v_n=\displaystyle\frac{1}{2^n}\sum_{k=0}^n2^ku_k$.\\
	Montrer que la série $\displaystyle\sum_{n\in \N}v_n$ converge absolument et calculer sa somme.
	
	\section{Polytopes réguliers d'un espace vectoriel euclidien}
	\textcolor{blue}{\hyperref[sec:polytopes-reguliers-dun-espace-vectoriel-euclidien]{[Corrigé]}}\\
	\label{Polytopes réguliers d'un espace vectoriel euclidien}
	On note $E$ un espace euclidien de dimension $n\in\N^*$. On note $\langle\cdot,\cdot\rangle$ le produit scalaire et $\norme{.}$ la norme associée.
	\begin{enumerate}
		\item Montrer que si $H$ est un hyperplan de $E$, alors il existe $a$ dans $E$ tel que $H=\left(\vect(a)\right)^\perp$.
		\item Dans cette question uniquement, on prend $E=\R^2$ et $\langle\cdot,\cdot\rangle$ désigne le produit scalaire canonique. On pose $e=(0,1)$.
		\\Trouver $f,g$ dans $E$ tels que $\norme{f}=\norme{g}=1$ et le triangle (dont les sommets sont) $e$,$f$,$g$ est équilatéral.
		\\Prouver (à permutation près) l'unicité de cette solution.
		\item On revient à $E$ euclidien de dimension $n$.
		\begin{enumerate}[label=\alph*.]
			\item On suppose que $x_1,\dots,x_{n+1}$ sont des vecteurs unitaires de $E$ tels que : $$\exists \alpha\in\R_-^*,\quad\forall(i,j)\in\crblanc{1}{n+1}^2, \left(i\neq j\Longrightarrow \langle x_i,x_j\rangle=\alpha\right)$$
			\item Expliquer comment trouver dans $E$ une famille de $n+1$ vecteurs vérifiant les conditions précédentes.
		\end{enumerate}
		
	\end{enumerate}
	\newpage
\chapter{Suites et séries de fonctions}
	
	\section{Etude d'une suite de fonctions (1)}
	\textcolor{blue}{\hyperref[sec:etude-dune-suite-de-fonctions-1]{[Corrigé]}}\\
	\label{Etude d'une suite de fonctions 1}
	Soit $(P_n)$ la suite de fonctions définie sur $[0,1]$ par:
	\begin{itemize}[leftmargin=*]
		\item $P_0(x)=0$
		\item $\forall n\in \N,\ P_{n+1}=P_n(x)+\frac{1}{2}(x-P_n(x)^2)$
	\end{itemize}
	\begin{enumerate}[leftmargin=*]
		\item Montrer que pour tout $x\in[0,1], 0\leq P_n(x) \leq \sqrt{x}$.
		\item Montrer que pour tout $x\in[0,1], 0\leq \sqrt{x}-P_n(x)\leq \sqrt{x}\left(1-\displaystyle\frac{\sqrt{x}}{2}\right)^n$
		\item En déduire que la suite $(P_n)$ converge uniformément sur $[0,1]$ vers la fonction $x\mapsto\sqrt{x}$.
	\end{enumerate}
	
	\section{Etude d'une suite de fonctions (2)}
	\textcolor{blue}{\hyperref[sec:etude-dune-suite-de-fonction-2]{[Corrigé]}}\\
	\label{Etude d'une suite de fonctions 2}
	On définit la suite de fonctions $(g_n)$ de $[0,1]$ dans $\R$ par $g_0=1$ et: 
	\\$$\forall n\in\N, \ \forall x\in[0,1], g_{n+1}(x)=\displaystyle\int_0^xg_n(1-t)dt$$
	\begin{enumerate}[leftmargin=*]
		\item Montrer que pour tout $n\in\N, \ g_n$ est bornée et que, $\forall n\in\N^*$, $\normep{\infty}{g_{n+1}}\leq\displaystyle\frac{1}{2}\normep{\infty}{g_{n-1}}$
		\item On pose $G:x\mapsto\displaystyle\sum\limits_{n=0}^{+\infty}g_n(x)$
		\\Montrer que $G$ est bien définie sur $[0,1]$ et déterminer une équation différentielle vérifiée par $G$.
		\item En déduire l'expression de $G$.
	\end{enumerate}
	
	\section{Etude d'une suite de fonctions (3)}
	\textcolor{blue}{\hyperref[sec:etude-dune-suite-de-fonctions-3]{[Corrigé]}}\\
	\label{Etude d'une suite de fonctions 3}
	Soit $f_n:x\mapsto n\cos(x)^n\sin(x)$. Etudier la convergence simple et uniforme de la suite de fonctions $(f_n)_{n\in \N}$ sur $\R$.
	
	\section{Etude d'une suite de fonctions (4)}
	\textcolor{blue}{\hyperref[sec:etude-dune-suite-de-fonctions-4]{[Corrigé]}}\\
	\label{Etude d'une suite de focntions 4}
	Soit $f_n:x\mapsto \sin(x)^n\cos x$. Etudier la convergence simple et uniforme de la suite de fonctions $(f_n)_{n\in \N}$ sur $\R$.
	
	\section{Etude d'une suite de fonctions (5)}
	\textcolor{blue}{\hyperref[sec:etude-dune-suite-de-fonction-5]{[Corrigé]}}\\
	\label{Etude d'une suite de fonctions 5}
	Soit $f_n:x\mapsto \displaystyle\frac{\sin(nx)}{n\sqrt x}$. Etudier la convergence simple et uniforme de la suite de fonctions $(f_n)_{n\in \N}$ sur $\R^*_+$.
	
	\section{Etude d'une suite de fonctions (6)}
	\textcolor{blue}{\hyperref[sec:etude-dune-suite-de-fonction-6]{[Corrigé]}}\\
	\label{Etude d'une suite de fonctions 6}
	Soit $f_n:x\mapsto e^{\frac{n-1}{n}x}$. Etudier la convergence simple et uniforme de la suite de fonctions $(f_n)_{n\in \N}$ sur $\R$, puis sur $]-\infty,a]$ pour $a\in \R$.
	
	\section{Etude d'une suite de fonctions (7)}
	\textcolor{blue}{\hyperref[sec:etude-dune-suite-de-fonction-7]{[Corrigé]}}\\
	\label{Etude d'une suite de fonctions 7}
	Pour tout réel $x$ et tout entier naturel $n$ non nul, on pose $P_n(x)=\displaystyle\prod\limits_{k=1}^{n} \text{ch}\left( \frac{x}{k}\right)$
	\begin{enumerate}[leftmargin=*]
		\item Déterminer l'ensemble $I$ des réels $x$ pour lesquels la suite $(P_n(x))_{n\in \N^*}$ converge.\\ On pourra utiliser la suite $(\ln(P_n(x)))_{n\in \N^*}$.
		\\ Pour $x\in I$ on note $\varphi(x)$ la limite de la suite $(P_n(x))$.
		\item Etudier la parité et la monotonie de la fonction $\varphi$.
		\item Démontrer que la fonction $\varphi$ est continue sur $I$.
		\item En étudiant $\displaystyle\int_{\R} \frac{1}{\text{ch}}$, montrer que $\displaystyle\frac{1}{\varphi}$ est intégrable sur $\R$.
	\end{enumerate}
	
	\section{Développement de la cotangente (1)}
	\textcolor{blue}{\hyperref[sec:developpement-de-la-cotangente-(1)]{[Corrigé]}}\\
	\label{Développement de la cotangente (1)}
	On pose pour $n\in \N$ et $x\in \R\setminus\Z$, $f_n(x)=\displaystyle\sum_{k=-n}^n\frac{1}{x-k}$.
	\begin{enumerate}
		\item Montrer que la suite de fonction $(f_n)_{n\in \N}$ converge simplement vers une fonction $f$.
		\item Montrer que la fonction $g$ définie par $\forall x\in \R\setminus\Z,\ g(x)=\pi\cotan(\pi x)-f(x)$ se prolonge en une fonction continue sur $\R$ et $1$-périodique, qu'on continuera d'appeler $g$.
		\item Donner une expression pour tout $x\in \R$ de $g(x)$ en fonction de $\displaystyle g\left(\frac{x}{2}\right)$ et $\displaystyle g\left(\frac{x+1}{2}\right)$.
		\item En déduire en utilisant la $1$-périodicité de $g$ qu'elle est nulle sur $\R$.
	\end{enumerate}
	
	\section{Etude d'une fonction définie par une série alternée (1)}
	\textcolor{blue}{\hyperref[sec:etude-dune-fonction-definie-par-une-serie-alternee-1]{[Corrigé]}}\\
	\label{Etude d'une fonction définie par une série alternée 1}
	Pour $t>0$, on pose: $$S(t)=\sum_{n=0}^{+\infty}\frac{(-1)^n}{1+nt}$$
	\begin{enumerate}
		\item Justifier que $S$ est définie et continue sur $]0,+\infty[$.
		\item Etablir la limite de $S$ en $+\infty$.
		\item Etablir que $S$ est de classe $\mathcal{C}^1$ sur $]0,+\infty[$
	\end{enumerate}
	
	\section{Etude d'une fonction définie par une série alternée (2)}
	\textcolor{blue}{\hyperref[sec:etude-dune-fonction-definie-par-une-serie-alternee-2]{[Corrigé]}}\\
	\label{Etude d'une fonction définie par une série alternée 2}
	Pour $x>0$, on pose $$S(x)=\sum_{n=0}^{+\infty}\frac{(-1)^n}{n+x}$$
	\begin{enumerate}
		\item Justifier que $S$ est définie et de classe $\mathcal{C}^1$ sur $\R^*_+$.
		\item Préciser le sens de variation de $S$.
		\item Etablir : $\displaystyle \forall x>0, \; S(x+1)+S(x)=\frac{1}{x}$.
		\item Donner un équivalent de $S$ en 0.
		\item Donner un équivalent de $S$ en $+\infty$.
		\item Montrer que pour $x>0$, $$F(x)=\int_0^1\frac{t^{x-1}}{1+t}dt$$
	\end{enumerate}
	
	\section{Convergence vers une dérivée}
	\textcolor{blue}{\hyperref[sec:convergence-vers-une-derivee]{[Corrigé]}}\\
	\label{Convergence vers une dérivée}
	Soit $f:\R\to\R$ une fonction deux fois dérivable de dérivée seconde bornée.
	\\Montrer que la suite des fonctions $$g_n:x\mapsto n\left(f\left(x+\frac{1}{n}\right)-f(x)\right)$$ converge uniformément vers $f'$ sur $\R$.
	
	\section{Limite ponctuelle et uniforme d'une suite de fonctions}
	\textcolor{blue}{\hyperref[sec:limite-ponctuelle-et-uniforme-dune-suite-de-fonctions]{[Corrigé]}}\\
	\label{Limite ponctuelle et uniforme d'une suite de fonctions}
	On suppose qu'une suite de fonctions $(f_n)$ de $[a,b]$ vers $\R$ converge uniformément vers $f:[a,b]\to\R$ continue et on considère une suite $(x_n)$ d'éléments de $[a,b]$ convergeant vers $x$.
	\\ Montrer que $$f_n(x_n)\unfty{\longrightarrow} f(x)$$
	
	\section{Convergence des suites de polynômes}
	\textcolor{blue}{\hyperref[sec:convergence-des-suites-de-polynomes]{[Corrigé]}}\\
	\label{Convergence des suites de polynômes}
	Soient $d\in\N$ et $(P_n)_{n\in \N}$ une suite de polynômes de $\R_d[X]$. Montrer que les propositions suivantes sont équivalentes:
	\begin{enumerate}[label=(\roman*)]
		\item $(P_n) \ \text{converge dans} \ \R_d[X].$
		\item $(P_n) \ \text{converge simplement sur}\ [0,1].$
		\item $(P_n) \ \text{converge uniformément sur}\ [0,1].$
	\end{enumerate}
	
	\section{Un théorème de Weierstrass sur $\R$ ?}
	\textcolor{blue}{\hyperref[sec:un-theoreme-de-weierstrass-sur-r-]{[Corrigé]}}\\
	\label{Un théorème de Weierstrass sur R}
	Soit $f\in \mathcal{C}^0(\R,\C)$ limite uniforme sur $\R$ d'une suite de fonctions polynomiales. Démontrer que $f$ est une fonction polynomiale.
	
	\section{Approximation paire}
	\textcolor{blue}{\hyperref[sec:approximation-paire]{[Corrigé]}}\\
	\label{Approximation paire}
	Soit $S$ un segment de $\R_+$. Montrer que toute fonction $f:S\to \R$ continue est limite uniforme d'une suite de polynômes pairs.
	
	\section{Approximation croissante}
	\textcolor{blue}{\hyperref[sec:approximation-croissante]{[Corrigé]}}\\
	\label{Approximation croissante}
	Montrer que toute fonction réelle croissante sur un segment s'approche uniformément sur ce segment par des polynômes croissants sur ce même segment.
	
	\section{Interversion Série-Intégrale}
	\textcolor{blue}{\hyperref[sec:interversion-serie-integrale]{[Corrigé]}}\\
	\label{Interversion Série-Intégrale}
	Pour $x\in]-1,1[$, on pose $F(x)=\displaystyle\frac{1}{2\pi}\int_{-\pi}^{\pi}\frac{1}{1-x\cos(t)}dt$
	\begin{enumerate}[leftmargin=*]
		\item Etablir que pour tout $x\in]-1,1[, \ F(x)=\displaystyle\sum\limits_{n=0}^{+\infty}\frac{1}{4^n}\binom{n}{2n}x^{2n}$
		\item Montrer que $\forall x\in]-1,1[, \displaystyle\frac{1}{\sqrt{1-x^2}}=\displaystyle\sum\limits_{n=0}^{+\infty}\frac{1}{4^n}\binom{n}{2n}x^{2n}$
		\item $\displaystyle\sum\limits_{n=0}^{+\infty}\frac{3}{(2n+1)4^{2n}}\binom{2n}{n}=\pi$
	\end{enumerate}
	
	\section{Série de fonction matricielle}
	\textcolor{blue}{\hyperref[sec:serie-de-fonction-matricielle]{[Corrigé]}}\\
	\label{Série de fonction matricielle}
	On munit $\M_n(\R)$ d'une norme d'algèbre $\norme{.}$.
	\\Soient $A\in\M_n(\R)$ non nulle et $I=]-\alpha,\alpha[$ avec $\alpha=\displaystyle\frac{1}{\norme{A}}$. Pour tout $t\in I$, on pose $f(t)=\displaystyle\sum\limits_{k=0}^{+\infty}(tA)^k$
	\begin{enumerate}[leftmargin=*, noitemsep]
		\item Montrer que $f$ est bien définie sur $I$ et que $\forall t\in I,\ f(t)=(I_n-tA)^{-1}$.
		\item Justifier que $f$ est de classe $\mathcal C^1$ sur $I$ et que $\forall t\in I,\ f'(t)=A(f(t))^2$. % Y a un problème non ? A(f(t)) ça veut rien dire je crois
	\end{enumerate}
	
	\section{Fonction $\zeta$ de Riemann}
	\textcolor{blue}{\hyperref[sec:fonction-zeta-de-riemann]{[Corrigé]}}\\
	\label{Fonction zeta de Riemann}
	On pose $\zeta(x)=\displaystyle\sum\limits_{n=1}^{+\infty}\frac{1}{n^x}$ et pour tout $n\in\N^* f_n:x\mapsto\displaystyle\frac{1}{n^x}$
	\\On pose également $\eta(x)=\displaystyle\sum\limits_{n=1}^{+\infty}\frac{(-1)^{n-1}}{n^x}$ 
	\begin{enumerate}[leftmargin=*,noitemsep]
		\item Donner le domaine de définition $D_{\zeta}$ de $\zeta$.
		\item Démontrer que $\sum f_n$ ne converge pas normalement sur $D_{\zeta}$ mais qu'elle converge normalement sur $[a,+\infty[ $ pour tout $a>1$.
		\item Montrer que $\zeta$ est continue sur $D_{\zeta}$.
		\item Trouver un équivalent simple de $\zeta$ en $1^+$ et donner la limite de $\zeta$ en $+\infty$.
		\item Montrer que la série $\sum\limits_{n\geq1}(-1)^{n-1}f_n$ converge uniformément sur $[a,+\infty[$. pour tout $a>0$.
		\item Montrer que $\eta$ est continue sur $\R_+^*$.
		\item Montrer que $\eta(x)=1-\displaystyle \frac{1}{2^x}+ \underset{x\to +\infty}{o}\left(\displaystyle\frac{1}{2^x}\right)$
		\item Montrer que: $\forall x\in]1,+\infty[, \zeta(x)-\eta(x)=2^{1-x}\zeta(x)$. En déduire un développement asymptotique de $\zeta$ à l'ordre 2 en $+\infty$.
		\item Montrer que $\zeta$ est $C^{\infty}$ sur $D_{\zeta}$. En déduire le sens de variation et la convexité de $\zeta$ sur $D_{\zeta}$.
	\end{enumerate}
	
	\section{Expression de suites sous forme de séries}
	\textcolor{blue}{\hyperref[sec:expression-de-suites-sous-forme-de-series]{[Corrigé]}}\\
	\label{Expression de suites sous forme de séries}
	\begin{enumerate}[leftmargin=*]
		\item Soit $\displaystyle\sum a_n$ une série complexe absolument convergence. On suppose que pour tout $k\in\N^*, \ \displaystyle\sum\limits_{n=0}^{+\infty}a_n^k=0$.\\
		Montrer que la suite $(a_n)$ est nulle.
		\item Existe-t-il une suite $(a_n)$ telle que $\forall k\in\N^*, \ \displaystyle\sum\limits_{n=0}^{+\infty}a_n^k=k$?
		\item Existe-t-il une suite $(a_n)$ telle que $\forall k\in\N^*, \ \displaystyle\sum\limits_{n=0}^{+\infty}a_n^k=\frac{1}{k^2}$?
	\end{enumerate}
	
	\section{Etude d'une série de fonctions}
	\textcolor{blue}{\hyperref[sec:etude-dune-serie-de-fonctions]{[Corrigé]}}\\
	\label{Etude d'une série de fonctions}
	Soit $(a_n)_{n\geq1}$ une suite décroissante de limite nulle. On pose $f_n:x\mapsto\sin(nx)$
	\begin{enumerate}[leftmargin=*, noitemsep]
		\item Montrer que la série $\displaystyle\sum\limits_{n\geq1}a_nf_n$ converge simplement.
		\item Montrer que la série $\displaystyle\sum\limits_{n\geq1}a_nf_n$ converge uniformément sur $\R$ si et seulement si la suite $(na_n)$ converge vers $0$.
	\end{enumerate}
	
	\section{Théorème de Dini \etoile{4}}
	\textcolor{blue}{\hyperref[sec:theoreme-de-dini-etoile4]{[Corrigé]}}\\
	\label{Théorème de Dini}
	\begin{enumerate}[leftmargin=*]
		\item Soit $(f_n)_{n\in \N}$ une suite croissante de fonctions réelles continues sur un segment $[a,b]$ de $\R$. Montrer que si $(f_n)_{n\in \N}$ converge simplement vers une fonction $f$ continue sur $[a,b]$, alors la convergence est uniforme.
		\item Soit $(f_n)_{n\in \N}$ une suite de fonctions réelles croissantes et continues sur un segment $[a,b]$ de $\R$. Montrer que si $(f_n)_{n\in \N}$ converge simplement vers une fonction $f$ continue sur $[a,b]$, alors la converge est uniforme.
	\end{enumerate}
	
	\section{Suite de fonction lipschitzienne \etoile{3}}
	\textcolor{blue}{\hyperref[sec:suite-de-fonction-lipschitzienne-etoile3]{[Corrigé]}}\\
	\label{Suite de fonction lipschitzienne}
	Soit $(f_n)_{n\in \N}$ une suite de fonctions réelles $L$-lipschitziennes convergeant simplement vers une fonction $f$ sur un segment $[a,b]$ de $\R$.
	\begin{enumerate}
		\item Montrer que $f$ est $L$-lipschitzienne.
		\item Montrer que la convergence est uniforme.
	\end{enumerate}
	
	\section{Phénomène de Runge}
	\textcolor{blue}{\hyperref[sec:phenomene-de-runge]{[Corrigé]}}\\
	\label{Phénomène de Runge}
	Soit $\alpha>0$ et $f_{\alpha}$ la fonction $f_{\alpha}:x\in[-1,1]\mapsto\displaystyle\frac{1}{x^2+\alpha^2}$
	\\Soit $n\in\N^*$. On considère les $2n$ points équirépartis dans $[-1,1]$ définis par $a_k=\displaystyle\frac{2k+1}{2n}$ pour $-n\leq k \leq n-1$. On note $P_n$ le polynôme d'interpolation de Lagrange de degré $<2n$ déterminé par les conditions $P_n(a_k)=f_\alpha(a_k)$ pour $-n\leq k \leq n-1$.
	\begin{enumerate}[leftmargin=*]
		\item Montrer $f_\alpha(x)-P_n(x)=\displaystyle\frac{1}{x^2+\alpha^2}\frac{\omega_n(x)}{\omega(\alpha i)}$ avec $\omega_n(x)=\displaystyle\prod\limits_{k=-n}^n(x-a_k)$
		\item En déduire le premier terme du développement asymptotique de $\log(|f_\alpha(1)-P_n(1)|)$ quand $n$ tend vers l'infini.
		\item Montrer que si $\alpha>0$ est suffisamment petit, la suite de fonctions $(P_n)$ ne converge pas uniformément vers $f_\alpha$.
	\end{enumerate}
	\textit{\underline{Remarque:} On vient de démontrer que l'augmentation du nombre de points d'interpolation n'est pas nécessairement une bonne stratégie d'approximation. Pour approcher une fonction avec des polynômes, on peut préférer utiliser des splines par exemple (polynômes par morceaux). Dans ce cas, pour améliorer l'approximation, on augmente le nombre de morceaux et non le degré des polynômes.}
	
	\section{Théorème de Weierstrass}
	\textcolor{blue}{\hyperref[sec:theoreme-de-weierstrass]{[Corrigé]}}\\
	\label{Théorème de Weierstrass}
	On note $E$ l'espace vectoriel des fonctions continues de $\R$ dans $\C$ et nulles en dehors d'un compact. On muni $E$ de la loi de convolution $*$ en définissant, pour tout $(f,g)\in E^2$ la convolée: $$f*g:x\mapsto\int_{-\infty}^{+\infty}f(x-t)g(t)dt$$
	\begin{enumerate}[leftmargin=*]
		\newcounter{saveenum}
		\item 
		\begin{enumerate}
			\item Montrer que la loi * est commutative et distributive sur l'addition.
			\item\underline{\textit{Séquence de Dirac}} On appelle séquence de Dirac toute suite $(\chi_n)$ de fonctions positives de $E$ vérifiant:
			$$\forall n\in\N, \int_{-\infty}^{+\infty} \chi_n(t)dt=1 \ \text{et} \ \forall \alpha>0, \lim_{n\to+\infty }\int_{|t|\geq\alpha}\chi_n(t)dt=0$$
		\end{enumerate} 
		\setcounter{saveenum}{\value{enumi}}
	\end{enumerate}
	
	Soit $(\chi_n)$ une telle suite et soit $f\in E$. Montrer que la suite de fonctions $(f*\chi_n)$ converge uniformément vers $f$ sur $\R$.
	\begin{enumerate}[leftmargin=*]
		\setcounter{enumi}{\value{saveenum}}
		\item Pour tout $n\in\N$, on pose: $$a_n=\int_{-1}^1(1-t^2)^ndt \ \text{et} \ p_n:t\in\R\mapsto\begin{cases}\frac{(1-t^2)^n}{a_n} & \mbox{si } |t|\leq1\\0 & \mbox{sinon}\end{cases}$$
		\begin{enumerate}
			\item Montrer que $(p_n)$ est une séquence de Dirac.
			\item Soit $f\in E$, nulle en dehors de $I=\displaystyle\left[-\frac{1}{2},\frac{1}{2}\right]$. Pour tout $n\in\N$, montrer que $f*p_n$ est une fonction polynomiale. Conclure.
			\item En déduire le théorème de Weierstrass: si $I$ est un segment de $\R$ et si $f:I\mapsto\C$ est continue, alors $f$ est limite uniforme sur $I$ d'une suite de fonctions polynomiale.
		\end{enumerate}
		\item \underline{Application:}
		\begin{enumerate}   
			\item Soit $f:[0,1]\mapsto\C$ une fonction continue, telle que pour tout $n\in\N, \displaystyle\int_0^1f(t)t^ndt=0$. 
			\\Montrer que $f$ est la fonction nulle.
			\item Soit $f:\R^+\mapsto\C$ une fonction continue telle que l'intégrale $\displaystyle\int_0^{+\infty}f(t)dt$ existe. \\Montrer que pour tout $n\in\N^*$, l'intégrale $I_n=\displaystyle\int_0^{+\infty}f(t)e^{-nt}dt$ existe. \\Si $\forall n\in\N, \ I_n=0$, montrer que $f$ est la fonction nulle.
		\end{enumerate}
	\end{enumerate}
	
	\section{Théorème de Chudnovsky \etoile{4}}
		\textcolor{blue}{\hyperref[sec:theoreme-de-chudnovsky-etoile4]{[Corrigé]}}\\
	\label{Théorème de Chudnovsky}
	On se donne deux réels $a,b$ tels que $0<a\leq b<1$. Le but de cet exercice est de démontrer que toute fonction continue sur $[a,b]$ est limite uniforme sur $[a,b]$ d'une suite de fonctions polynomiales à coefficients entiers. On munit $\mathcal C([a,b],\R)$ de sa norme uniforme.
	\begin{enumerate}
		\item Montrer que l'ensemble des nombres dyadiques $\mathcal D=\left\{\displaystyle\frac{p}{2^q},\ (p,q)\in \Z\times\N\right\}$ est dense dans $\R$.
		\item On pose $\fonction{\varphi}{\R}{\R}{x}{2x(1-x)}$ et pour $n\in \N$ on définit $\varphi_n=\varphi\overset{n}{\overbrace{\circ\dots\circ}}\varphi$. Par convention $\varphi_0=\varphi$.
		\begin{enumerate}[label=\alph*.]
			\item Montrer que $(\varphi_n)_{n\in \N}$ converge simplement vers la fonction constante égale à $\displaystyle\frac{1}{2}$ sur $[a,b]$.
			\item Montrer que $(\varphi_n)_{n\in \N}$ converge uniformément vers la fonction constante égale à $\displaystyle\frac{1}{2}$ sur $[a,b]$.
		\end{enumerate}
		\item On note $\mathcal Z$ l'ensemble des limites uniformes de suites de fonctions polynomiales à coefficients entiers:
		$$\mathcal Z=\{f\in \R^{[a,b]},\ \exists (P_n)\in \Z[X]^\N,\ \unfty{\lim}\normep{\infty}{x\mapsto f(x)-P_n(x)}=0\}$$
		Montrer que $\mathcal Z$ est stable par somme et par produit.
		\item Conclure.
		\item Le résultat est-il encore vrai pour $a\leq b$ des réels quelconques ? Que peut-on dire pour des fonctions à valeurs dans $\C$ ?
	\end{enumerate}
	
	\section{Théorème de sélection de Helly}
	\textcolor{blue}{\hyperref[sec:theoreme-de-selection-de-helly]{[Corrigé]}}\\
	\label{Théorème de sélection de Helly}
	Soit $(f_n)_{n\in \N}$ une suite de fonctions croissantes d'un intervalle ouvert $I$ dans $\R$ telle que, pour tout $x\in I$, la suite $(f_n(x))_{n\in \N}$ est bornée. Démontrer qu'il existe une sous-suite $(f_{\varphi(n)})_{n\in \N}$ et une fonction croissante $f:I \to\R$, telle que cette sous-suite converge simplement vers $f$.
	%https://agreg-maths.fr/uploads/versions/842/Theoreme_de_selection_de_Helly.pdf
	%https://les-mathematiques.net/vanilla/discussion/363714/principe-dextraction-diagonale
	

\chapter{Série entière}
\section{Lemme d'Abel}
\label{Lemme d'Abel}
\textcolor{blue}{\hyperref[sec:lemme-dabel]{[Corrigé]}}\\
Enoncé et démontrer le lemme d'Abel

\section{Fonction non développable en série entière}
\label{Fonction non développable en série entière}
\textcolor{blue}{\hyperref[sec:fonction-non-developpable-en-serie-entiere]{[Corrigé]}}\\
On pose pour tout $x\in\R^*$, $f(x)=\exp\left(-\displaystyle\frac{1}{x^2}\right)$ et $f(0)=0$.
\begin{enumerate}
	\item Montrer que $f$ est continue sur $\R$.
	\item Montrer que $f$ est de classe $\mathcal{C}^\infty$ sur $\R$ et calculer pour tout $n\in\N$, $f^{(n)}(0)$.
	\item En déduire que $f$ n'est pas développable en série entière.
\end{enumerate}

\section{CCINP MP 2019}
\label{CCINP MP 2019}
\textcolor{blue}{\hyperref[sec:ccinp-mp-2019]{[Corrigé]}}\\
On pose $S(x)=\displaystyle\sum_{n=0}^{+\infty}\binom{2n}{n}x^n$
\begin{enumerate}
	\item Déterminer le rayon de convergence de la série $\displaystyle\sum\binom{2n}{n}x^n$. On note $R$ le rayon de convergence de cette série.
	\item Pour tout $x\in]-R,R[$, prouver la relation $(1-4x)S'(x)-2S(x)=0$.
	\item En déduire une expression de $S'(x)$.
\end{enumerate}

\section{Série entière de terme général binomial}
\label{Série entière de terme général binomial}
\textcolor{blue}{\hyperref[sec:serie-entiere-de-terme-general-binomial]{[Corrigé]}}\\
Soient $p\in\N$ et $\displaystyle f(x)=\sum_{n=0}^{+\infty}\binom{n+p}{p}x^n$
\begin{enumerate}
	\item Déterminer le rayon de convergence de la série entière définissant cette fonction.
	\item Calculer $f(x)$ en étudiant $(1-x)f'(x)$.
\end{enumerate}

\section{Formule de Cauchy}
\label{Formule de Cauchy}
\textcolor{blue}{\hyperref[sec:formule-de-cauchy]{[Corrigé]}}\\
Soit $\displaystyle\sum_{n\in \N} a_nz^n$ une série entière de rayon de convergence $R>0$. On pose $f(z)=\displaystyle\sum\limits_{n=0}^{+\infty}a_nz^n$
\\Soit $r\in [0,R[$ Montrer que $a_nr^n=\displaystyle\frac{1}{2\pi}\int_0^{2\pi}f(re^{i\theta})e^{-in\theta}d\theta$

\section{Principe des zéros isolés}
\label{Principe des zéros isolés}
\textcolor{blue}{\hyperref[sec:principe-des-zeros-isoles]{[Corrigé]}}\\
Soit $f$ la somme de la série entière $\displaystyle\sum_{n\in \N} a_nz^n$ sur son disque de convergence. Montrer que s'il existe une suite $(z_p)_{p\in \N}$ de nombres complexes non nuls tendant vers $0$ telle que pour tout $p\in \N , f(z_p)=0$, alors pour tout $n \in \N, a_n=0$.

\section{Produit de Hadamard}
\label{Produit de Hadamard}
\textcolor{blue}{\hyperref[sec:produit-de-hadamard]{[Corrigé]}}\\
\begin{enumerate}[leftmargin=*]
	\item Soit $\displaystyle\sum_{n\in \N} a_nz^n$ une série entière de rayon de convergence $R>0$ telle que $a_n>0$ pour tout $n\in \N$. Discuter en fonction du paramètres $\alpha\in\R$ le rayon de convergence $R'$ de la série entière $\displaystyle\sum_{n\in \N} a_n^\alpha z^n$
	\item Soient $\displaystyle\sum_{n\in \N} a_nz^n$ et $\displaystyle\sum_{n\in \N} b_nz^n$ deux séries entières de rayon respectifs $R$ et $R'$. Que dire du rayon de convergence $R''$ de la série entière $\displaystyle\sum_{n\in \N} a_nb_nz^n$.
\end{enumerate}

\section{Théorème de Liouville}
\label{Théorème de Liouville}
\textcolor{blue}{\hyperref[sec:theoreme-de-liouville]{[Corrigé]}}\\
Soit $\displaystyle\sum_{n\in \N} a_nz^n$ une série entière dont le rayon de convergence est infini. Soit $f:\C\mapsto\C$ la somme de cette série entière.
\begin{enumerate}[leftmargin=*]
	\item Si la fonction entière $f$ est bornée sur $\C$, montrer que $f$ est constante.
	\item Plus généralement, s'il existe un polynôme $P$ à coefficients positifs tel que $\forall z\in\C, |f(z)|\leq P(|z|)$, montrer que $f$ est un polynôme.
\end{enumerate}

\section{Inverse d'une série entière}
\label{Inverse d'une série entière}
\textcolor{blue}{\hyperref[sec:inverse-dune-serie-entiere]{[Corrigé]}}\\
Soit $1+\displaystyle\sum_{n\geq1}a_nz^n$ une série entière de rayon de convergence non nul, et $S$ la somme de cette série sur son disque de convergence. Montrer que $\displaystyle\frac{1}{S}$ est développable en série entière autour de l'origine.
\section{Equivalent de séries entières}
\label{Equivalent de séries entières}
\textcolor{blue}{\hyperref[sec:equivalent-de-series-entieres]{[Corrigé]}}\\
Soient $(a_n)\in \R^\N$ et $(b_n)\in \left(\R_+\right)^\N$ telles que le rayon de convergence de la série entière $\displaystyle\sum_{n\in \N}b_nx^n$ vaut $1$, $\displaystyle\sum_{n\in \N}b_n$ diverge, la suite $\displaystyle\left(\frac{a_n}{b_n}\right)_{n\in \N}$ est définie à partir d'un certain rang et converge vers un réel $\ell$.
\begin{enumerate}
	\item Montrer que
	$$\sum_{n=0}^{+\infty}b_nx^n\underset{x\to 1^-}\longrightarrow+\infty$$
	\item Montrer que
	$$\frac{\displaystyle\sum_{n=0}^{+\infty}a_nx^n}{\displaystyle\sum_{n=0}^{+\infty}b_nx^n}\underset{x\to 1^-}{\longrightarrow}\ell$$
\end{enumerate}

\section{Théorème de d'Alembert-Gauss}
\label{Théorème de d'Alembert-Gauss}
\textcolor{blue}{\hyperref[sec:theoreme-de-dalembert-gauss]{[Corrigé]}}\\
A l'aide du théorème de Liouville \ref{Théorème de Liouville} et de \ref{Inverse d'une série entière}, démontrer le théorème de d'Alembert-Gauss.

\section{Développement de fraction rationnelle autour de 0}
\label{Développement de fraction rationnelle autour de 0}
\textcolor{blue}{\hyperref[sec:developpement-de-fraction-rationnelle-autour-de-0]{[Corrigé]}}\\
\begin{enumerate}[leftmargin=*]
	\item Soient $P$ et $Q$ deux polynômes à coefficients dans $\C$ tels que $Q(0)\ne 0$. On pose, pour $z$ non racine de $Q$, $f(z)=\displaystyle\frac{P(z)}{Q(z)}$.\\
	Montrer que $f$ est développable en série entière au voisinage de $0$ et que les coefficients de son développement vérifient une relation de récurrence linéaire à coefficients constants. En outre, préciser le rayon de convergence.
	\item Réciproquement, on se donne une suite $(u_n)\in \C^\N$ vérifiant une relation de récurrence linéaire à coefficients constants. Montrer que la série entière $\displaystyle\sum_{n\in \N}u_nz^n$ a un rayon de convergence $R$ non nul et qu'il existe deux polynômes $P,Q\in \C[X]$ avec $Q(0)\ne 0$ tels que pour tout $z\in \C$, si $|z|>R$ alors $\displaystyle\sum_{n=0}^{+\infty}u_nz^n=\frac{P(z)}{Q(z)}$.
\end{enumerate}

\section{Fonction quasi-polynomiale}
\label{FOnction quasi-polynomiale}
\textcolor{blue}{\hyperref[sec:fonction-quasi-polynomiale]{[Corrigé]}}\\
Une fonction $P:\Z\to \C$ est dite quasi-polynomiale s'il existe $k\in \N$ et $k+1$ fonctions périodiques $c_0,\dots,c_k\in \C^\Z$ telles que $\forall n\in \Z,\ P(n)=\displaystyle\sum_{i=0}^kc_i(n)n^i$. Si la fonction $c_k$ n'est pas nulle, on dira que le degré de la fonction $P$ est $k$ et que $c_k$ est son coefficient dominant.
\begin{enumerate}
	\item Montrer que l'ensemble des fonctions quasi-polynomiales forme une $\C$-algèbre.
	\item Montrer que si $P,Q\in \C^\Z$ sont deux fonctions quasi-polynomiales qui coïncident sur $\N$ alors elles sont égales.
\end{enumerate}
Dans la suite, on dira que $P:\N\to \C$ est quasi-polynomiale si c'est la restriction à $\N$ d'une fonction quasi-polynomiale (qui est bien définie uniquement d'après la question précédente). 
\begin{enumerate}[resume]
	\item Montrer que $P:\Z\to\C$ est quasi-polynomiale si et seulement s'il existe un entier $m\in \N^*$ et $m$ polynômes $P_0,\dots,P_m\in \C[X]$ tels que pour tout $j\in \crblanc{0}{m-1}$ on ait : $\forall n\in \Z,\ n\equiv j[m]\implies P(n)=P_j(n)$.
\end{enumerate}

\subsection{Série génératrice d'une fonction quasi-polynomiale}
\label{Série génératrice d'une fonction quasi-polynomiale}
Soit $P$ une fonction quasi-polynomiale. Montrer que le rayon de convergence de la série $\displaystyle\sum_{n\in \N}P(n)x^n$ est supérieur ou égal à $1$.


\subsection{Partitions d'un entier}

\label{Partitions d'un entier}
Soient $k\geq 2$ un entier et $a_1,\dots,a_k\in \N^*$ que l'on suppose premier entre eux dans leur ensemble. On définit une fonction $P:\N\to \C$ en posant pour tout $n\in \N$:
$$P(n)=\Card\left(\left\{(n_1,\dots,n_k)\in \N^k,\ \sum_{i=1}^ka_ix_i=n\right\}\right)$$
On définit ensuite la série entière $F(x)=\displaystyle\sum_{n=0}^{+\infty}P(n)x^n$.
\begin{enumerate}
	\item Montrer que le rayon de convergence de $F$ est supérieur ou égal à $1$.
	\item Prouver l'égalité $F(x)=\displaystyle\prod_{i=1}^k\frac{1}{1-x^{a_i}}$ pour $x\in ]-1,1[$.
	\item Soient $\omega$ une racine de l'unité et $p\in \N^*$. On note $f:x\mapsto \displaystyle\frac{1}{(1-\omega x)^p}$ et $f(x)=\displaystyle\sum_{n=0}^{+\infty}R(n)x^n$ son développement en série entière. Montrer que $R$ est une fonction quasi-polynomiale, puis déterminer son degré et son coefficient dominant.
	\item En déduire que $P$ est quasi-polynomiale et déterminer son coefficient dominant.
\end{enumerate}

\section{Théorème de réalisation de Borel}
\label{Théorème de réalisation de Borel}
\textcolor{blue}{\hyperref[sec:theoreme-de-realisation-de-borel]{[Corrigé]}}\\
Soit $(a_n)_{n\in \N}$ une suite complexe quelconque.
\\Soit $\varphi:\R\mapsto\R$ une application de classe $\mathcal C^\infty$ telle que $\varphi(x)=1$ pour $x\in[-1,1]$ et $\varphi(x)=0$ pour $|x|\geq2$. On pose $\varphi_n=x^n\varphi(x)$, on note $M_n$ un majorant de $|\varphi'|,|\varphi''|,\dots,|\varphi^{(n-1)}|$ sur $\R$, et on choisit une suite réelle $(\lambda_n)_{n\in \N}$ vérifiant $\lambda_n\geq1$ pour tout $n\in\N$, tendant vers $+\infty$, et telle que $\displaystyle\sum\limits_{n\in \N}\frac{|a_n|M_n}{\lambda_n}$ converge.
\\Montrer que la fonction $f:x\mapsto\displaystyle\sum\limits_{n=0}^{+\infty}a_nx^n\varphi(\lambda_nx)$ est bien définie, de classe $C^{\infty}$ sur $\R$ et vérifie $\displaystyle\frac{f^{(n)}(0)}{n!}=a_n$ pour tout $n\in\N$.
\\ \textit{\underline{Remarque:} On vient de montrer que pour suite $(a_n)_{n\in \N}$ de nombres complexes, il existe une fonction $f:\R\mapsto\C$ de classe $\mathcal C^\infty$ telle que, pour tout entier $n\in\N$, $f^n(0)=a_n$.}

\section{Série de Lambert}
\label{Série de Lambert}

\textcolor{blue}{\hyperref[sec:serie-de-lambert]{[Corrigé]}}\\
Soient $\alpha\in \N^*$ et $x\in [0,1[$.
\begin{enumerate}
	\item Montrer que la série $\displaystyle\sum_{n\in \N^*}\frac{n^\alpha x^n}{1-x^n}$ converge.
	\item Donner un équivalent, lorsque $x\to 1^-$, de sa somme $\varphi(x)=\displaystyle\sum_{n=1}^{+\infty}\frac{n^\alpha x^n}{1-x^n}$ sous la forme de la somme d'une série double.\\
	\textit{\underline{Indication :} On pourra considérer le développement en série entière de $\displaystyle\frac{\varphi(x)}{1-x}$.}
\end{enumerate}

\section{Somme de Goldbach}
\label{Somme de Goldbach}
\textcolor{blue}{\hyperref[sec:somme-de-goldbach]{[Corrigé]}}\\
Soit $R=\{m^n,\ (m,n)\in {\llbracket 2;+\infty\llbracket}^2\}$. Calculer la somme :
$$\sum_{r\in R}\frac{1}{r-1}$$

\section{Une somme avec l'indicatrice d'Euler}
\label{Une somme avec l'indicatrice d'Euler}
\textcolor{blue}{\hyperref[sec:une-somme-avec-lindicatrice-deuler]{[Corrigé]}}\\
On note $\varphi$ l'indicatrice d'Euler et on fixe $a>1$. Calculer la somme :
$$\sum_{n=1}^{+\infty}\frac{\varphi(n)}{a^n-1}$$
% J'ai l'impression que les deux exos ci-dessus se font à grands coups de séries entières mais je suis pas sûr je les ai pas encore fait.

\section{Coefficients définies par des intégrales}
\label{Coefficients définies par des intégrales}
\textcolor{blue}{\hyperref[sec:coefficients-definies-par-des-integrales]{[Corrigé]}}\\
On note $\displaystyle a_n=\int_0^1\frac{dt}{(2+t^2)^{n+1}}$ pour $n\in\N$.
\begin{enumerate}
	\item Donner le rayon de convergence de la série entière $\displaystyle\sum_{n\in \N}a_nx^n$.
	\item Calculer la somme de cette série entière sur son domaine de convergence.
\end{enumerate}

\section{Détermination des coefficients d'un développement en série entière}
\label{Détermination des coefficients d'un développement en série entière}
\textcolor{blue}{\hyperref[sec:determination-des-coefficients-dun-developpement-en-serie-entiere]{[Corrigé]}}\\
Soit $f:x\in]-1,1[\mapsto \displaystyle\frac{\arcsin(x)}{\sqrt{1-x^2}}$
\begin{enumerate}[leftmargin=*]
	\item Justifier que $f$ est développable en série entière.
	\item Montrer que $f$ vérifie une équation différentielle d'ordre un.
	\item En déduire le développement en série entière. \\En déduire que pour tout $n\in\N, \displaystyle\sum\limits_{k=0}^{n}\frac{1}{2k+1}\binom{2k}{k}\binom{2n-2k}{n-k}=\frac{2^n(n!)^2}{(2n+1)!}$
\end{enumerate}

\section{Série génératrice du nombre de points à coordonnées entières dans un quart de disque}
\label{Série génératrice du nombre de points à coordonnées entières dans un quart de disque}
\textcolor{blue}{\hyperref[sec:serie-generatrice-du-nombre-de-points-a-coordonnees-entieres-dans-un-quart-de-disque]{[Corrigé]}}\\
On note $p_n = \Card\{(a,b)\in \N^2 \mid a^2+b^2\leq n\}$


\begin{enumerate}
	\item Déterminer le rayon de convergence $R$ de la série entière $\displaystyle\sum_{n\in \N}p_nx^n$.
	\item Démontrer que $\forall x\in ]-R,R[,\ \displaystyle\sum_{n=0}^{+\infty}p_nx^n=\frac{1}{1-x}\left(\sum_{n=0}^{+\infty}x^{n^2}\right)^2$.
\end{enumerate}

\subsection{Nombres de points à coordonnées entières dans un disque}
\label{Nombre de points à coordonnées entières dans un disque}
On munit $\R^2$ de sa norme euclidienne canonique $\norme{.}$. Pour $x\in \R_+$ on définit les ensembles $C(x)=\{u\in \Z^2,\ \norme u\leq x\}$ et $C_+(x)=C(x)\cap\N^2$.
\begin{enumerate}
	\item Ecrire un programme python qui calcule $N_+(x)$.
	\item Montrer que $\forall x\in \R_+,\ 4N_+(x)-N(x)-4\lfloor x\rfloor=3$.
	\item Montrer que $\forall n\in \N,\ N_+(n)=\displaystyle\sum_{k=0}^n\left\lfloor\sqrt{n^2-k^2}\right\rfloor+1$.
	\item Déterminer un équivalent de $N(x)$ lorsque $x\to+\infty$.
\end{enumerate}

\subsection{Prolongement du problème}
\begin{enumerate}
	\item Déduire de \ref{Série génératrice du nombre de points à coordonnées entières dans un quart de disque} et \ref{Nombre de points à coordonnées entières dans un disque} un équivalent en $1^-$ de $\displaystyle\sum_{n=0}^{+\infty}x^{n^2}$.
	\item Montrer à l'aide d'une comparaison série intégrale que $$\displaystyle\sum_{n=0}^{+\infty}x^{n^2}\underset{x\to 1^-}{\sim}\frac{1}{\sqrt{x-1}}\int_0^{+\infty}e^{-t^2}dt$$
	\item En déduire la valeur de l'intégrale $\displaystyle\int_{-\infty}^{+\infty}e^{-t^2}dt$.
\end{enumerate} 

\section{Nombre d'involution}
\label{Nombre d'involution}
\textcolor{blue}{\hyperref[sec:nombre-dinvolution]{[Corrigé]}}\\
On rappelle qu'une involution d'un ensemble $E$ est une application $f:E \mapsto E$ telle que $f\circ f=\Id_E$. On note $I_n$ le nombre d'involution de $\crblanc{1}{n}$. On convient que $I_0=1$.
\begin{enumerate}[leftmargin=*]
	\item Montrer que pour tout entier $n\geq 2$, $I_n=I_{n-1}+(n-1)I_{n-2}$
	\item Montrer que le rayon de convergence de la série entière $\displaystyle\sum \frac{I_n}{n!}x^n$ est supérieur ou égal à 1. On note $S(x)$ sa somme.
	\item Montrer que: $\forall x\in]-1,1[, S'(x)=(1+x)S(x)$
	\item En déduire une expression de $S(x)$ puis de $I_n$.
\end{enumerate}

% Cet exo est vraiment hors programme... même le G m'a dit qu'il devrait l'enlever du td.
% \section{Ens MP 2011}
% Soit $\K$ un corps fini et $\mathcal P$ l'ensemble des polynômes irréductibles unitaires de $\K[X].$ \\On pose $\zeta(t)=\displaystyle\prod\limits_{P\in\mathcal{P}}\frac{1}{1-t^{deg(P)}}$.
% \begin{enumerate}
	%     \item Montrer que $\zeta$ est défini sur un intervalle du type $[0,t_0[$.
	%     \item Montrer que $\zeta$ est développable en série entière au voisinage à droite de 0 et déterminer son développement.
	% \end{enumerate}

\section{Théorème d'Abel}
\label{Théorème d'Abel}
\textcolor{blue}{\hyperref[sec:theoreme-dabel]{[Corrigé]}}\\
Soit  $\sum\limits a_nz^n$ une série entière de rayon de convergence $R\geq 1$ et de somme $f$. On note pour $\theta_0 \in [0,\displaystyle\frac{\pi}{2}[$, $$\Delta_{\theta_0}=\{z\in\C; |z|<1 \text{ et }\exists \rho>0,\exists\theta\in[-\theta_0,\theta_0],\ z=1-\rho e^{i\theta}\}$$ 
\begin{enumerate}[leftmargin=*]
	\item Démontrer (Abel) pour $R>1$.
\end{enumerate}
A partir de maintenant, on suppose que $R=1$ et que $\sum a_n$ converge, et on se donne un $\theta_0 \in [0,\displaystyle\frac{\pi}{2}[$
\begin{enumerate}[resume, leftmargin=*]
	\item Démontrer que pour tous $N\in\N^*$ et $z\in\C , |z|<1$, on a: $$\displaystyle\sum\limits_{n=0}^N a_nz^n -S_N=(z-1)\displaystyle\sum\limits_{n=0}^{N-1} R_nz^n -R_N(z^N-1)$$
	\item En déduire que pour tout $z\in\C, |z|<1$, on a: $$f(z)-S=(z-1)\displaystyle\sum\limits_{n=0}^{+\infty} R_nz^n$$
	\item Soit $\varepsilon>0$. Démontrer qu'il existe $N_0\in\N$ tel que pour tout $z\in\C, |z|<1$: $$|f(z)-S|\leq |z-1|\sum_{n=0}^{N_0}|R_N|+\varepsilon\frac{|z-1|}{1-|z|}$$
	\item Démontrer qu'il existe $\rho(\theta)>0$ tel que pour tout $z\in\Delta_{\theta_0}$ de la forme $z=1-\rho e^{i\theta}$ avec $0<\rho\leq \rho(\theta_0)$, on a:
	$$\frac{|z-1|}{1-|z|}\leq\frac{2}{\cos(\theta_0)}$$
	\item En déduire le théorème d'Abel.
\end{enumerate}
\underline{Application:} Démontrer que $\displaystyle\sum\limits_{n=0}^{+\infty} \frac{(-1)^n}{2n-1}=\frac{\pi}{4}$ et $\displaystyle\sum\limits_{n=1}^{+\infty} \frac{(-1)^{n-1}}{n}=\ln(2)$

\section{Théorèmes taubériens d'Abel}
\textcolor{blue}{\hyperref[sec:theoremes-tauberiens-dabel]{[Corrigé]}}\\
\label{Théorème taubériens d'Abel}
On pose pour tout $n\in\N$, $S_n=\displaystyle\sum_{k=0}^n a_k$. 
\\Si la série est convergente, on note $S$ sa somme définie par: $S=\unfty{\lim}S_n$ \\et $(R_n)$ la suite des restes définie par: $\forall n\in\N$, $R_n=S-S_n$
\\On s'intéresse aux réciproques partielles du théorème d'Abel.
\\
\\Exhiber une série entière $\displaystyle\sum_{n\in \N} a_nz^n$ de rayon de convergence $1$ et de somme $f$ telle que $f(z)$ converge quand $z\underset{|z|<1}{\longrightarrow}1$ et telle que la série $\displaystyle\sum_{n\in \N} a_n$ ne converge pas.

\subsection{Cas des séries à coefficients positifs}
Démontrer que :
$$\left(\lim_{\substack{x\to1^-\\x\in \R}}f(x)=S \; \text{et} \; \forall n\in \N,\ a_n\geq 0\right)\Longrightarrow\left(\sum_{n\in \N} a_n \; \text{converge et } \sum_{n=0}^{+\infty}a_n=S\right)$$

\subsection{Théorème taubérien faible}
Soit $\displaystyle\sum_{n\in \N} a_nz^n$ une série entière de rayon de convergence $1$ et de somme $f$. Soit $S\in\C$. 
\\Le but de cette question est de démontrer que: $$\left(\lim_{\substack{x\to1^-\\x\in \R}}f(x)=S \; \text{et} \; a_n\unfty{=}\smallo{\frac{1}{n}}\right)\Longrightarrow\left(\sum_{n\in \N} a_n \; \text{converge et } \sum_{n=0}^{+ \infty}a_n=S\right)$$
On suppose que $\lim\limits_{\substack{x\to1^-\\x\in \R}}f(x)=S$ et que $a_n\unfty{=}\displaystyle\smallo{\frac{1}{n}}$.
\begin{enumerate}
	\item Démontrer que pour tous $n\in\N^*$ et $x\in]0,1[$, on a:
	$$|S_n-f(x)|\leq(1-x)\sum_{k=1}^nk|a_k|+\frac{\sup\limits_{k>n}(k|a_k|)}{n(1-x)}$$
	\item En déduire le théorème taubérien faible. On pourra poser $x=x_n=1-\displaystyle\frac{1}{n}$ pour $n\in\N^*$.
\end{enumerate}

\subsection{Théorème taubérien fort}
Soit $\displaystyle\sum_{n\in \N} a_nz^n$ une série entière de rayon de convergence $1$ et de somme $f$. Soit $S\in\C$. 
\\Le but de cette question est de démontrer que: $$\left(\lim_{\substack{x\to1^-\\x\in \R}}f(x)=S \; \text{et} \; a_n\unfty{=}\bigO{\frac{1}{n}}\right)\Longrightarrow\left(\sum_{n\in \N} a_n \; \text{converge et } \sum_{n=0}^{+ \infty}a_n=S\right)$$
\begin{enumerate}
	\item Démontrer que, sans perte de généralité, on peut supposer que $S=0$.
\end{enumerate}
On suppose désormais que $\lim\limits_{\substack{x\to1^-\\x\in \R}}f(x)=0$ et que $a_n\unfty{=}\displaystyle\bigO{\frac{1}{n}}$.
\begin{enumerate}[resume]
	\item On définit $\Theta$ de la manière suivante: $$\Theta=\left\{\theta:[0,1]\to\R\; ;\;\forall x\in[0,1]\; ; \; \sum_{n\geq0}a_n\theta(x^n) \; \text{converge et }\lim_{x\to1^-}\sum_{n=0}^{\infty}a_n\theta(x_n)=0\right\}$$
	Démontrer que $\Theta$ est un espace vectoriel sur $\R$.
	\item Soit $P\in\R[X]$ tel que $P(0)=0$. Démontrer que  $P\in\Theta$.
	\item Démontrer que: $$\forall P\in\R[X], \lim_{\substack{x\to1^-\\x\in \R}}(1-x)\sum_{n=0}^{+\infty}x^nP(x^n)=\int_0^1P(t)dt$$
\end{enumerate}
On définit la fonction $g:\R\to\R$ par: $g(x)=\begin{cases}
	1 &\text{si }x\in\left[\displaystyle\frac{1}{2},1\right]\\
	0 &\text{sinon}
\end{cases}$
\begin{enumerate}[resume]
	\item Démontrer que pour établir le théorème taubérien fort, il suffit de démontrer que $g\in\Theta$.
	\item Soit $$h(x)=\begin{cases}
		-1 &\text{si } x=0,\\
		\frac{g(x)-x}{x(1-x)} &\text{si } x\in]0,1[,\\
		1 &\text{si }x=1
	\end{cases}$$
	Etant donné $\varepsilon>0$, démontrer qu'il existe $s_1,s_2\in\mathcal{C}^0([0,1])$ vérifiant: $$s_1\leq h\leq s_2 \;\text{et}\; \int_0^1(s_2(t)-s_1(t))dt\leq\varepsilon$$
	\\Représenter graphiquement $h$ et deux telles fonctions $s_1,s_2$.
\end{enumerate}
A partir de maintenant, $\varepsilon>0$, $s_1$ et $s_2$ sont fixés.
\begin{enumerate}[resume]
	\item Démontrer qu'il existe $T_1,T_2\in\R[X]$ tels que:
	$$\sup_{x\in[0,1]}|T_1(x)-s_1(x)|\leq \varepsilon \quad \text{et}\quad \sup_{x\in[0,1]}|T_2(x)-s_2(x)|$$
\end{enumerate}
On pose, pour tout $x\in[0,1]$,
$$P_1(x)=x+x(1-x)(T_1(x)-\varepsilon) ,\; P_2(x)=x+x(1-x)(T_2(x)-\varepsilon),\; \text{et }Q(x)=\displaystyle\frac{P_2(x)-P_1(x)}{x(1-x)}$$
\begin{enumerate}[resume]
	\item $P_1(0)=P_2(0)=0$, $P_1(1)=P_2(1)=0$, $P_1\leq g\leq P_2$ et $0\leq\displaystyle\int_0^1Q(x)dx\leq5\varepsilon$.
	\item Démontrer qu'il existe $M>0$ tel que pour tout $x\in]0,1[$, $$\left| \sum_{n=0}^{+\infty}a_ng(x^n)-\sum_{n=0}^{+\infty}a_nP_1(x^n)\right|\leq M(1-x)\sum_{n=0}^{+\infty}x^nQ(x^n)$$
	\item Conclure.
\end{enumerate}





\newpage
\chapter{Topologie}
\section{Normes d'opérateur \ccinp{1}}
\textcolor{blue}{\hyperref[sec:normes-doperateur]{[Corrigé]}}\\
\label{Normes d'opérateur}
Soit $A\in\M_{n,p}(\R)$.
\begin{enumerate}[leftmargin=*]
	\item On suppose que $\M_{p,1}(\R)$ et $\M_{n,1}(\R)$ sont munis de leurs normes uniformes respectives. \\Montrer que: $${\mid\mid\mid A\mid\mid\mid}_\infty=\max\limits_{1\leq i \leq n} \sum\limits_{j=1}^p |A_{i,j}|$$
	\item On suppose que $\M_{p,1}(\R)$ et $\M_{n,1}(\R)$ sont munis de leurs normes 1 respectives. \\Montrer que: $${\mid\mid\mid A\mid\mid\mid}_1=\max\limits_{1\leq j \leq p} \sum\limits_{i=1}^n |A_{i,j}|$$
	\item On suppose que $\M_{p,1}(\R)$ et $\M_{n,1}(\R)$ sont munis de leurs normes 2 respectives. \\Montrer que:$${\mid\mid\mid A\mid\mid\mid}_2=\sqrt{\max \operatorname{Sp}(A^\top A)}$$
\end{enumerate}

\section{$\Z$ est fermé \etoile{1}}
\label{Z est fermé}
\textcolor{blue}{\hyperref[sec:z-est-ferme-etoile1]{[Corrigé]}}\\
Montrer que $\Z$ est fermé.

\section{Orthogonalité et topologie \ccinp{2}}
\label{Orthogonalité et topologie}
\textcolor{blue}{\hyperref[sec:orthogonalite-et-topologie]{[Corrigé]}}\\
Soit $F$ un sous-espace vectoriel d'un espace préhilbertien réel $E$ que l'on munit de sa norme euclidienne.
\begin{enumerate}
	\item Montrer que pour tout $y\in E, \ \varphi_y:x\in E \mapsto \langle x,y\rangle$ est continue.
	\item Montrer que $F^{\bot}$ est un fermé dans $E$.
	\item Montrer que de manière général, $\overline{F}\subset(F^{\bot})^{\bot}$
\end{enumerate}

\section{Ensemble des valeurs d'adhérence d'une suite \centraleponts{3}}
\label{Ensemble des valeurs d'adhérence d'une suite}
\textcolor{blue}{\hyperref[sec:ensemble-des-valeurs-dadherence-dune-suite]{[Corrigé]}}\\
Soit $(u_n)_{n\in \N}$ une suite à valeurs dans un espace vectoriel normé $E$. On note $V$ l'ensemble des valeurs d'adhérence de $(u_n)_{n\in \N}$.\\
Montrer que $V=\displaystyle\bigcap\limits_{n\in \N}{\overline{\{u_k,\ k\geq n\}}}$ et en déduire que $V$ est fermé.

\subsection{Une application \etoile{4}}
\label{Une application}
\textcolor{blue}{\hyperref[sec:une-application]{[Corrigé]}}\\
\begin{enumerate}
	\item Soit $z\in \U$. Montrer que $1$ est une valeur d'adhérence de la suite $(z^n)_{n\in \N}$.
	\item Soit $\begin{pmatrix}z_1\\\vdots\\z_m\end{pmatrix}\in \U^m$. Montrer que $\begin{pmatrix}1\\\vdots\\1\end{pmatrix}$ est une valeur d'adhérence de la suite $\begin{pmatrix}z_1^n\\\vdots\\z_m^n\end{pmatrix}_{n\in \N}$.
	\item Que peut-on dire de complexes $a_1,\dots,a_n$ tels que $\displaystyle\sum_{k=1}^na_k^m$ converge pour $m\to\infty$ ?
\end{enumerate}

\section{Ensemble des suites convergents vers 0 \centraleponts{2}}
\label{Ensemble des suites convergents vers 0}
\textcolor{blue}{\hyperref[sec:ensemble-des-suites-convergents-vers-0]{[Corrigé]}}\\
On note $\ell^\infty$ l'ensemble des suites bornées de $\K^\N$ que l'on munit de la norme $\normep{\infty}{\cdot}$.\\
Montrer que l'ensemble des suites convergeant vers $0$ est un fermé de $\ell^\infty$.

\subsection{Ensemble des suites convergentes \etoile{3} (HP)}
\label{Ensemble des suites convergentes}
\textcolor{blue}{\hyperref[sec:ensemble-des-suites-convergentes]{[Corrigé]}}\\
Montrer que l'ensemble des suites convergentes est un fermé de $\ell^\infty$.\\
On pourra utiliser l'exercice \ref{Suite de Cauchy}.

\section{Calcul d'une adhérence \xens{3}}
\label{Calcul d'adhérence}
\textcolor{blue}{\hyperref[Calcul d'adhérence corrigé]{[Corrigé]}}\\
Quelle est l'adhérence de $E=\left\{\dfrac{1}{p}+\dfrac{1}{q},\ (p,q)\in (\N^*)^2\right\}$ ?

\section{Partie ouverte et fermée simultanément \centraleponts{3}}
\label{Partie ouverte et fermée simultanément}
\textcolor{blue}{\hyperref[sec:partie-ouverte-et-fermee-simultanement]{[Corrigé]}}\\
Montrer que les seules parties à la fois ouvertes et fermées d'un espace vectoriel normé $E$ sont $\varnothing$ et $E$.

\section{Opérations sur les adhérences/intérieurs}
\label{Opérations sur les adhérences/intérieurs}
\textcolor{blue}{\hyperref[Opérations sur les adhérences/intérieurs corrigé]{[Corrigé]}}\\
Soit $E$ un espace vectoriel normé et soit $A,B$ deux parties de $E$.
\begin{enumerate}
	\item Montrer que $\overline{A\cup B}=\overline A\cup \overline B$ et $\widering{A\cap B}=\ring A\cap\ring B$.
	\item Montrer que $\overline{A\cap B}\subset \overline A\cap\overline B$ et $\ring A\cup\ring B\subset \widering{A\cup B}$.\\
	Montrer qu'il n'y a pas égalité en général.
\end{enumerate}

\section{Les sept espaces de Kuratowski \etoile{3}}
\label{Les sept espaces de Kuratowski}
\textcolor{blue}{\hyperref[sec:les-sept-espaces-de-kuratowski]{[Corrigé]}}\\
Trouver une partie $A$ de $\R$ telles que les sept ensembles suivants soient tous distincts :
$$A,\ring A,\overline A,\overline{\ring A},\ring{\overline A},\ring{\overline{\ring A}},\overline{\ring{\overline A}}$$

\section{Intérieur d'un sous-espace \telecom{2}}
\label{Intérieur d'un sev}
\textcolor{blue}{\hyperref[sec:interieur-dun-sev]{[Corrigé]}}\\
Soit $F$ un sous-espace vectoriel d'un espace vectoriel normé $E$.
\begin{enumerate}
	\item Montrer que si $F$ est ouvert, alors $F=E$.
	\item Montrer que si $F\ne E$, alors $\overset{\circ}{F}=\varnothing$.
\end{enumerate}

\section{Adhérence d'un sous-espace \centraleponts{3}}
\label{Adhérence d'un sev}
\textcolor{blue}{\hyperref[sec:adherence-dun-sev]{[Corrigé]}}\\
Soit $E$ un espace vectoriel normée.
\begin{enumerate}
	\item Soit $F$ un sous-espace vectoriel de $E$. Montrer que $\overline F$ est encore un sous-espace vectoriel.
	\item Soit $F$ un sous-espace vectoriel de dimension finie de $E$. Montrer que $F$ est fermé dans $E$.
	\item Soit $H$ un hyperplan de $E$. Montrer que $H$ est fermé ou dense dans $E$.
\end{enumerate}

\section{Graphe fermé \centraleponts{3}}
\label{Graphe fermé}
\textcolor{blue}{\hyperref[sec:graphe-ferme]{[Corrigé]}}\\
Soit $f$ une fonction réelle. On note $G=\{(x,y)\in \R^2,\ y=f(x)\}$ le graphe de $f$.
\begin{enumerate}
	\item Montrer que si $f$ est continue alors $G$ est fermé.
	\item Montrer que si $f$ est bornée et $G$ est fermé alors $f$ est continue.
	\item Montrer que ce n'est plus vrai si on ne suppose plus $f$ bornée.
\end{enumerate}

\section{Application linéaire continue \centraleponts{2}}
\label{Application linéaire continue}
\textcolor{blue}{\hyperref[sec:application-lineaire-continue]{[Corrigé]}}\\
On considère les espaces vectoriels normés $E=(\mathcal C^0([0,1],\R),\normep{\infty}{.})$ et $F=(\mathcal C^0([0,1],\R),\normep{1}{.})$ avec $\forall f\in \mathcal C^0([0,1],\R)$ :
$$\normep{\infty}{f}=\sup\limits_{[0,1]}f\quad\text{et}\quad \normep{1}{f}=\int_0^1|f|$$
\begin{enumerate}
	\item Trouver une forme linéaire continue sur $F$ et pas sur $E$.
	\item Peut-on trouver une forme linéaire continue sur $E$ et pas sur $F$ ?
\end{enumerate}

\section{Application linéaire non continue \centraleponts{2}}
\label{Application linéaire non continue}
\textcolor{blue}{\hyperref[sec:application-lineaire-non-continue]{[Corrigé]}}\\
On note $E=\mathcal C^\infty(\R,\R)$. Existe-il une application linéaire sur $E$ continue pour aucune norme ?

\section{Polynômes réels de degré $n$ scindés à racines simples sur $\R$ \xens{4}}
\label{Polynômes réels de degré n scindés à racines simples sur R}
\textcolor{blue}{\hyperref[sec:polynomes-reels-de-degre-n-scindes-a-racines-simples-sur-r-etoile4]{[Corrigé]}}\\
On note $A$ l'ensemble des polynômes à coefficients réels de degré $n$ scindé à racines simples sur $\R$.
\begin{enumerate}
	\item Montrer que $A$ est ouvert dans $\R_n[X]$.
	\item Déterminer l'adhérence de $A$.
\end{enumerate}

\section{Lemme de Riemann-Lebesgue \centraleponts{3}}
\label{Lemme de Riemann-Lebesgue}
\textcolor{blue}{\hyperref[sec:lemme-de-riemann-lebesgue-etoile3]{[Corrigé]}}\\
On considère un segment $[a,b]$ de $\R$, $(E,||.||)$ un espace vectoriel normé de dimension finie et $\phi:[a,b]\to E$.
\\Démontrer que $\lim\limits_{\lambda \to+\infty} \displaystyle\int_a^b e^{i\lambda t}\phi(t)dt=0$ quand
\begin{itemize}
	\item $\phi$ est une fonction en escalier sur $[a,b]$;
	\item $\phi$ est une fonction continue par morceaux sur $[a,b]$;
	\item $\phi$ est une fonction continue par morceaux et intégrable sur $\R$ avec $a=-\infty$ et $b=+\infty$.
\end{itemize}

\section{Borel-Lebesgue (HP)}
\label{Borel-Lebesgue}
\textcolor{blue}{\hyperref[sec:borel-lebesgue]{[Corrigé]}}\\
Soit $E$ un espace vectoriel normé dont on note $\mathcal T$ l'ensemble des ouverts. On dit qu'une partie $K$ de $E$ est compacte au sens de Borel-Lebesgue lorsque :
$$\forall (O_i)_{i\in I}\subset \mathcal T,\ K\subset \bigcup_{i\in I}O_i\implies \exists p\in \N,\ \exists i_1,\dots,i_p\in I,\ K\subset \bigcup_{j=1}^pO_{i_j}$$
Autrement dit, de tout recouvrement de $K$ composé d'ouverts, on peut extraire un sous-recouvrement fini.\\
Montrer qu'une partie de $E$ est compacte au sens de Borel-Lebesgue si et seulement si elle l'est au sens de Bolzano-Weierstrass (définition par l'existence d'une valeur d'adhérence).\\\\

\section{Parties compactes d'un espace vectoriel normé de dimension finie \etoile{2}}
\label{Parties compactes d'un espace vectoriel normé de dimension finie}
\textcolor{blue}{\hyperref[sec:parties-compactes-dun-espace-vectoriel-norme-de-dimension-finie]{[Corrigé]}}\\
Soit $E$ un $\K$-espace vectoriel normé.
\begin{enumerate}
	\item Montrer que les parties compactes de $E$ sont fermées.
	\item Montrer qu'une partie fermée de $E$ incluse dans une partie compacte est compacte.
	\item Montrer qu'un produit cartésien d'un nombre fini de compact de $E$ est compact de $E$.
	\item Justifier que les segments de $\R$ sont compacts.
	\item On suppose que $E$ est de dimension finie. Démontrer que les parties compactes de $E$ sont exactement les parties fermées bornées de $E$.
\end{enumerate}

\section{Somme de sous-espaces \centraleponts{3}}
\label{Somme de sous-espaces}
\textcolor{blue}{\hyperref[sec:somme-de-sous-espaces]{[Corrigé]}}\\
\begin{enumerate}[leftmargin=*]
	\item Montrer que la somme de deux compacts est compacte.
	\item Montrer que la somme d'un compact et d'un fermé est fermé.
	\item Que peut-on dire de la somme de deux fermés ?
\end{enumerate}

\section{Un théorème du point fixe \centraleponts{3}}
\label{Théorème du point fixe}
\textcolor{blue}{\hyperref[Théorème du point fixe corrigé]{[Corrigé]}}\\
Soit $K$ un compact d'un espace vectoriel. Soit $f:K\to K$ une application vérifiant
$$\forall x,y\in K,\ x\ne y\implies \norme{f(x)-f(y)}<\norme{x-y}$$
\begin{enumerate}
	\item Montrer que $f$ admet un unique point fixe $a$.
	\item Soit $x_0\in K$. Montrer que la suite des itérés $(f^n(x_0))_{n\in \N}$ converge vers $a$.
	\item Donner un contre-exemple en ne supposant plus $K$ compact.
\end{enumerate}

\section{Théorème de Heine \etoile{2}}
\label{Théorème de Heine}
\textcolor{blue}{\hyperref[sec:theoreme-de-heine]{[Corrigé]}}\\
Démontrer qu'une fonction continue sur un compact est uniformément continue sur ce compact.

\section{Lemme des compacts emboîtés \telecom{1}}
\label{Lemme des compacts emboités}
\textcolor{blue}{\hyperref[sec:lemme-des-compacts-emboites-etoile1]{[Corrigé]}}\\
Soient $E$ un espace-vectoriel normé et $(K_n)_{n\in \N}$ une suite décroissante de compacts non vides de $E$.\\
Montrer que $K=\displaystyle\bigcap\limits_{n\in \N} K_n$ est non vide.

\section{Théorème de Baire \xens{5} (HP)}
\label{Théorème de Baire}
\textcolor{blue}{\hyperref[sec:theoreme-de-baire-etoile5]{[Corrigé]}}\\
Soit $(E,||.||)$ un espace de Banach, c'est à dire un espace vectoriel normée complet, ou encore dans lequel toute suite de Cauchy \ref{Suite de Cauchy} converge.
\begin{enumerate}
	\item Démontrer qu'une intersection dénombrable d'ouverts denses dans $E$ est dense dans $E$.
	\item Montrer que cette propriété est équivalente à ce qu'une réunion dénombrable de fermés d'intérieurs vide soit d'intérieur vide.
\end{enumerate}

\subsection{$\R$ n'est pas dénombrable \etoile{2} (HP)}
Démontrer, à l'aide du théorème de Baire, que $\R$ n'est pas dénombrable.

\subsection{Base d'un espace de Banach \etoile{3} (HP)}
Montrer qu'un espace de Banach ne peut pas admettre de base dénombrable.

\subsection{Densité des fonctions nulle part dérivables (2) \etoile{4} (HP)}
On souhaite montrer que l'ensemble $A$ des fonctions continues mais nulle part dérivables sur $[0,1]$ est dense dans l'ensemble $E$ des fonctions continues sur $[0,1]$ pour la norme uniforme.\\
Pour cela on pose, pour tout $n\in \N$, $F_n=\{f\in E,\ \exists x\in I,\ \forall y\in I,\ |f(x)-f(y)|\leq n|x-y|\}$.
\begin{enumerate}
	\item Montrer que $A^c\subset \displaystyle\bigcup\limits_{n\in \N}F_n$.
	\item Montrer que les $F_n$ sont fermés.
	\item Soient $f\in F_n$ et $\varepsilon>0$.\\
	Pour $N\in \N^*$ et on pose $g_N$ la fonction périodique, de période $\displaystyle\frac{1}{N}$ défini par :
	$$g_N(x)=\begin{cases}
		\displaystyle\frac{\varepsilon N}{2}x&\mbox{ si }x\in [0,\frac{1}{2N}]\\
		\displaystyle\frac{\varepsilon}{2}-\frac{\varepsilon N}{2}x&\mbox{ si }x\in ]\frac{1}{2N},\frac{1}{N}]
	\end{cases}$$
	Montrer que pour une fonction $P$ et un certain $N$ bien choisis la fonction $g=P+g_N$ appartient à $F_n^c\cap B(f,\varepsilon)$.
	\item Conclure.
\end{enumerate}

\subsection{Caractérisation des endomorphismes nilpotents d'un espace de Banach \etoile{2} (HP)}
\begin{enumerate}[leftmargin=*]
	\item Soit $E$ un espace de Banach. Soit $f\in \mathcal L_c(E)$ tel que,
	$$\forall x\in E,\ \exists n_x\in \N^*,\ f^{n_x}(x)=0$$
	Montrer que $f$ est nilpotent.
	\item Donner un contre exemple dans $\R[X]$.
\end{enumerate}

\subsection{Lemme de Croft (2) \etoile{4} (HP)}
Soit $f:\R^*_+\to\R$ une application telle que
$$\forall x>0,\ \unfty\lim f(nx)=0$$
\begin{enumerate}
	\item On suppose $f$ uniformément continue. Montrer que $\uxfty\lim f(x)=0$.
	\item On suppose seulement $f$ continue. Montrer à l'aide du théorème de Baire qu'on a toujours $\uxfty\lim f(x)=0$.
	\item Le résultat est-t-il vrai sans hypothèse supplémentaire sur $f$ ?
\end{enumerate}

\subsection{Caractérisation des polynômes réels \etoile{5} (HP)}
Soit $f\in \mathcal C^\infty(\R,\R)$ telle que $\forall x\in \R,\ \exists n\in \N,\ f^{(n)}(x)=0$. Le but de cet exercice est de montrer que $f$ est polynomiale. On note pour $n\in \N,\ F_n=\{x\in \R,\ f^{(n)}(x)=0\}$. On note aussi $\Omega=\displaystyle\bigcup_{n\in \N} \ring F_n$ et $\Phi=\R\setminus\Omega$. Enfin, on suppose que $\Phi$ n'est pas vide. On admettra que $\R$ est complet (cf. \ref{Suite de Cauchy}).
\begin{enumerate}
	\item Montrer qu'il existe $N\in \N$ tel que $\ring F_N\ne \emptyset$.
	\item Soit $I$ un intervalle ouvert non vide de $F_N$.
	\begin{enumerate}[label=\alph*.]
		\item Soit $x\in I$. Montrer que $\forall k\geq N,\ x\in F_k$.
		\item En déduire que $f$ est polynomiale sur $I$.
	\end{enumerate}
	\item Soit $J$ une composante connexe par arcs de $\Omega$ et $x_0\in J$.
	\begin{enumerate}[label=\alph*.]
		\item Montrer l'existence d'un intervalle ouvert et non vide $I$ et d'un polynôme $P$ tels que : $$\exists n\in \N,\ I\subset F_n\ \land\ \forall y\in I,\ f(y)=P(y)$$
		On pose dans la suite $A=\{x\geq x_0\ |\ \forall y\in [x_0,x],\ f(y)=P(y)\}$.
		\item Justifier que $A$ est un sous-ensemble non vide de $\ring J$. On note $s$ sa borne supérieure.
		\item Montrer par l'absurde que $s\notin \Omega$ et en déduire que $s=\sup J$.
		\item En déduire que $f$ est polynomiale sur $\ring J$.
	\end{enumerate}
	\item 
	\begin{enumerate}[label=\alph*.]
		\item On dit qu'un point de $x\in \Phi$ est \textit{isolé} lorsque, $\exists \varepsilon>0,\ ]x-\varepsilon,x+\varepsilon[\ \cap\ \Phi=\{x\}$.\\
		Montrer que $\Phi$ n'a pas de point isolé.
		\item Montrer que $\Phi$ est complet.
		\item En déduire que l'on peut trouver un intervalle $I$ ouvert qui vérifie :
		$$(\exists n_0\in \N,\ I\cap \Phi\subset F_{n_0})\ \land\ I\cap \Phi\ne \emptyset$$
		On pourra commencer par écrire $\Phi=\displaystyle\bigcup_{n\in \N}(\Phi\cap F_n)$.
		\item On se donne $x\in I\cap \Phi$. Montrer qu'il existe une suite de $I\cap \Phi$ qui converge, puis justifier que cette suite peut être prise croissante.
		\item Montrer que $\forall n\geq n_0,\ x\in F_n$.
		\item Soit $J=[u,v]$ une composante connexe par arcs de $I\cap \Omega$. Montrer que $u\in I\cap \Phi$ ou $v\in I\cap \Phi$ et en déduire que $J\subset F_{n_0}$.
		\item En déduire que $I\subset \Omega$.
	\end{enumerate}
	\item Conclure.
\end{enumerate}

\subsection{Un raffinement \etoile{1} (HP)}
\begin{enumerate}[leftmargin=*]
	\item Expliquer comment adapter la démonstration précédente pour montrer le résultat suivant :\\
	Si $f\in \mathcal C^\infty(\R,\R)$ et si $D$ est une partie au plus dénombrable qui vérifie
	$$\forall x\in \R,\ \exists n\in \N,\ f^{(n)}(x)\in D$$
	alors $f$ est polynomiale.
	\item En déduire que si $f\in \mathcal C^\infty(\R,\R)$ n'est pas polynomiale alors il existe un réel en lequel toutes les dérivées successives de $f$ sont irrationnelles.
\end{enumerate}

\section{Volume d'une (hyper)boule \xens{4} (HP)}
\label{Volume d'une (hyper)boule}
\textcolor{blue}{\hyperref[sec:volume-dune-hyperboule-etoile3]{[Corrigé]}}\\
Soit $R\in\R^*_+$.
\\Pour tout $n\in\N^*$. On pose $\B_n(R)=\left\{(x_1,x_2,\dots,x_n)\in \R^n \ | \ x_1^2+x_2^2+\dots+x_n^2\leq R^2\right\}$
\begin{enumerate}
	\item Calculer le volume de $\B_n(R)$ : $V_n(R)=\displaystyle\idotsint_{(x_1,\dots,x_n)\in \B_n(R)}dx_1\dots dx_n$.
	\item Déterminer la limite de $V_n(R)$. Quelle interprétation peut-on en faire ? Est-ce surprenant ?
\end{enumerate}

\section{Partie fermée bornée non compacte \centraleponts{3}}
\label{Partie fermée bornée non compacte}
\textcolor{blue}{\hyperref[sec:partie-fermee-bornee-non-compacte-etoile3]{[Corrigé]}}\\
Donner un exemple de partie fermée bornée non compacte d'un espace vectoriel normé.

\section{Théorème de compacité de Riesz \centraleponts{4}}
\label{Théorème de compacité de Riesz}
\textcolor{blue}{\hyperref[sec:theoreme-de-compacite-de-riesz-etoile4]{[Corrigé]}}\\
Soit $(E,\norme{.})$ un $K$-espace vectoriel normé.
\begin{enumerate}[leftmargin=*]
	\item Soit $F$ un sous-espace vectoriel fermé de $E$ tel que $F\ne E$.
	\begin{enumerate}[label=\alph*.]
		\item Soit $x\in E\setminus F$. Justifier que $\delta=d(x,F)>0$.
		\item Justifier qu'il existe $v\in F$ tel que $0<\norme{x-v}\leq 2\delta$.
		\item On pose $u=\displaystyle\frac{x-v}{\norme{x-v}}$. Justifier que $d(u,F)\geq \displaystyle\frac{1}{2}$.
	\end{enumerate}
	\item On note $B$ la boule unité fermée de $E$ i.e. $B=\{x\in E,\ \norme{x}\leq1\}$. Montrer que si $E$ n'est pas de dimension finie, alors $B$ n'est pas compacte.
\end{enumerate}

\section{Sphère et boule unité \centraleponts{3}}
\label{Sphère et boule unité}
\textcolor{blue}{\hyperref[sec:sphere-et-boule-unite-etoile3]{[Corrigé]}}\\
Soit $(E,||.||)$ un espace vectoriel normé. On note $B$ la boule unité fermée de $E$ et $S$ la sphère unité de $E$.\\
Montrer que $B$ est compacte si et seulement si $S$ est compacte.

\section{Principe du maximum pour les polynômes \xens{3}}
\label{Principe du maximum pour les polynômes}
\textcolor{blue}{\hyperref[sec:principe-du-maximum-pour-les-polynomes]{[Corrigé]}}\\
Soit $P\in \C[X]$. On note $B=\{z\in \C,\ |z|\leq 1\}\text{ et }S=\{z\in \C,\ |z|=1\}$.\\\\
Montrer que $\max\limits_{z\in B}{|P(z)|}=\max\limits_{z\in S}{|P(z)|}$.

\section{Applications $1$-lipschitzienne surjective sur un compact \centraleponts{4}}
\label{Applications 1-lipschitzienne sujective sur un compact}
\textcolor{blue}{\hyperref[sec:applications-1-lipschitzienne-surjective-sur-un-compact]{[Corrigé]}}\\
Soient $E$ un espace vectoriel normé, $K$ un compact de $E$ et $g:K\to K$ une application $1$-lipschitzienne. On cherche à montrer que $g$ est surjective si et seulement si c'est une isométrie (i.e $\forall x,y\in E,\ ||g(x)-g(y)||=||u(x)-u(y)||$).
\begin{enumerate}[leftmargin=*]
	\item On suppose $g$ surjective. On considère $x,y\in K$ ainsi que $x_n,y_n$ des antécédents par $g^n$ de $x$ et $y$ respectivement. On note $(x',y')$ une valeur d'adhérence de $(x_n,y_n)_{n\in \N}$. Montrer que $x-y$ est une valeur d'adhérence de $(g^n(x')-g^n(y'))_{n\in \N}$.
	\item Montrer que $||g^n(x')-g^n(y')||\unfty{\longrightarrow}||x-y||$. En déduire que $g$ est une isométrie de $E$.
	\item On suppose maintenant que $g$ est une isométrie de $E$. Montrer que $g$ est surjective. Donner un contre-exemple lorsque $K$ est seulement borné.
\end{enumerate}

\section{Une isométrie conserve les milieux \centraleponts{4}}
\label{Une isométrie conserve les milieux}
\textcolor{blue}{\hyperref[sec:une-isometrie-conserve-les-milieux]{[Corrigé]}}\\
Soit $E$ un $\R$-espace vectoriel normé de dimension finie.
\begin{enumerate}[leftmargin=*]
	\item Pour $K$ un compact non vide on pose $\delta(K)=\sup\limits_{(x,y)\in K^2}{||x-y||}$. Montrer que $\delta(K)$ est bien défini. La borne supérieure est-elle atteinte ?
	\item Pour $a\in E$, on note $\mathcal{S}_a$ l'ensemble des compacts $K$ de $E$ symétriques par rapport à $a$ (i.e $\forall x\in K,\ 2a-x\in K$). \\
	Pour $B\subset E$ compacte, on pose
	$$T(B)=\left\{x\in B\ |\ \forall y\in B,\ ||x-y||\leq\displaystyle\frac{1}{2}\delta(K)\right\}$$
	Montrer que $T$ induit une application de $\mathcal{S}_a$ dans $\mathcal{S}_a$.
	\item Soit $B_0\in \mathcal{S}_a$. On pose pour $n\in \N,\ B_{n+1}=T(B_n)$. Déterminer $\displaystyle\bigcap\limits_{n\in \N}B_n$.
	\item En déduire que toute isométrie de $E$ conserve les milieux.\\
	\textit{Remarque : une isométrie de $E$ est une application $u:E\to E$ telle que $\forall (x,y)\in E^2,\ ||u(x)-u(y)||=||x-y||$.}
\end{enumerate}

\section{Fonctions coercives \centraleponts{3}}
\label{Fonctions coercives}
\textcolor{blue}{\hyperref[sec:fonctions-coercives]{[Corrigé]}}\\
Soient $(E,\norme{.})$ un espace vectoriel normé de dimension finie et $f:E\to \R$ continue.\\
Montrer que $\lim\limits_{\norme{x}\to +\infty}f(x)=+\infty$ si et seulement si l'image réciproque par $f$ de tout compact de $\R$ est un compact de $E$.

\section{Homéomorphisme de compacts \centraleponts{3}}
\label{Homéomorphisme de compacts}
\textcolor{blue}{\hyperref[sec:homeomorphisme-de-compacts]{[Corrigé]}}\\
Soient $E$ et $F$ deux espaces vectoriels normés, $K$ un compact de $E$ et $L$ une partie de $F$. Soit $f:K\to L$ bijective et continue. Montrer que $f^{-1}$ est continue.

\section{Distance à un fermé}
\label{Distance à un fermé}
\textcolor{blue}{\hyperref[sec:distance-a-un-ferme]{[Corrigé]}}\\
Soient $X$ une partie fermée, non vide d'un espace vectoriel normé $(E,\norme{.})$ et $a\in E$.
Montrer que la distance de $a$ à $X$, $d(a,X)=\inf\limits_{x\in X}{\norme{a-x}}$ est atteinte.

\section{Diamètre et frontière}
\label{Diamètre et frontière}
\textcolor{blue}{\hyperref[sec:diametre-et-frontiere]{[Corrigé]}}\\
Soit $(E,\norme{.})$ un espace vectoriel normé. Pour $A$ une partie bornée de $E$ on définit le \textit{diamètre} de $A$ : $\delta(A)=\sup\limits_{(x,y)\in A^2}\norme{x-y}$.\\
Montrer que pour toute partie bornée $A$ de $E$ on a :
$$\delta(A)=\delta(\Fr(A))$$

\section{Frontière \ccinp{2}}
\label{Frontière}
\textcolor{blue}{\hyperref[sec:frontiere]{[Corrigé]}}\\
Soient $E$ un espace vectoriel normé et $F$ une partie fermée de $E$.\\
Montrer que $\Fr(\Fr(F))=\Fr(F)$.

\section{Projeté sur un convexe compact \centraleponts{3}}
\label{Projeté convexe}
\textcolor{blue}{\hyperref[sec:projete-sur-un-convexe-compact]{[Corrigé]}}\\
Soit $(E,\proscal{.}{.})$ un espace euclidien. Soient $H$ une partie convexe et compacte de $E$ et soit $x\in E$. On note
$$d(x,H)=\inf\limits_{h\in H}{||x-h||}.$$
Soient $h,h'\in H$. On pose $q:t\in [0,1]\longmapsto ||x-th-(1-t)h'||^2$.
\begin{enumerate}[leftmargin=*]
	\item Montrer qu'il existe un unique élément $h_0\in H$ tel que $d(x,H)=||x-h_0||$.\\
	\item Montrer que $h_0$ est caractérisé par la condition : $\forall y\in H,\ \langle x-h_0,y-h_0\rangle\leq 0$.
\end{enumerate}
\textit{Le vecteur $h_0$ est appelé projeté de $x$ sur $H$}.

\section{Convexité de l'adhérence et de l'intérieur \centraleponts{3}}
\label{Convexité de l'adhérence et de l'intérieur}
\textcolor{blue}{\hyperref[sec:convexite-de-ladherence-et-de-linterieur]{[Corrigé]}}\\
Soit $A$ une partie convexe d'un espace vectoriel normé $E$. Montrer que $\overline A$ et $\ring A$ sont convexes.

\section{Fonctions positivement homogènes}
\label{FOnctions positivement homogènes}
\textcolor{blue}{\hyperref[sec:fonctions-positivement-homogenes]{[Corrigé]}}\\
Soit $E$ un $\R$-espace vectoriel. Une application $f:E\to\R$ est dite positivement homogène de degré $\alpha$ (avec $\alpha$>0) quand: $$\forall x\in E, \ \forall \lambda\in\R_+, \ f(\lambda x)=\lambda^{\alpha}f(x)$$
\\On appelle semi-norme sur $E$ une application $N: E\to\R_+^*$ qui vérifie les axiomes définissant une norme hormis la séparation. On s'intéresse ici aux fonctions positivement homogènes de degré 1.
\begin{enumerate}[leftmargin=*]
	\item Soit $f:E\to\R$ une fonction homogène de degré 1.
	\begin{enumerate}
		\item Montrer que $f$ est convexe si et seulement si $\forall(x,y)\in E^2$, $f(x+y)\leq f(x)+f(y)$
		\item Si f est à valeurs positives, montrer que $f$ est convexe sur $E$ si et seulement si l'ensemble $C=\{x\in E | f(x)\leq 1\}$ est convexe.
		\item Si f est convexe, à valeurs positives et paire, montrer que f est une semi norme.
		\item On suppose ici que $E$ est de dimension finie. Soit $\Omega$ un ouvert borné non vide de $E$. Montrer qu'il existe une norme $N$ sur $E$ telle que $\Omega=B_N(0,1)=\{x\in E,\ N(x)<1\}$ si et seulement si $\Omega$ est convexe et admet $0$ comme centre de symétrie.
	\end{enumerate}
	\item (Etude de normes particulières) Soit un réel $\alpha \geq 1$. Montrer, sans utiliser l'inégalité de Minkowski, que l'application $$\fonction{N_\alpha}{\R^n}{\R^+}{(x_1,\dots, x_n)}{(|x_1|^\alpha + \dots +|x_n|^\alpha)}$$ définit une norme sur $\R^n$.
\end{enumerate}

\section{Enveloppe convexe}
\label{Enveloppe convexe}
\textcolor{blue}{\hyperref[sec:enveloppe-convexe]{[Corrigé]}}\\
Soit $E$ un espace euclidien.
\begin{enumerate}[leftmargin=*]
	\item Montrer que si $A$ et $B$ sont deux parties convexes de $E$ alors $A\cap B$ est une partie convexe de $E$.\\
	Pour $A\subset E$, on définit l'enveloppe convexe de $A$, Conv$(A)$, comme la plus petite partie convexe de $E$ contenant $A$, c'est à dire l'intersection de tous les convexes de $E$ contenant $A$.
	\item On dit que $x\in E$ est combinaison convexe de $x_1,\dots,x_p\in E$ lorsqu'il existe des réels positifs $\lambda_1,\dots,\lambda_p$ tels que $x=\displaystyle\sum\limits_{k=1}^p{\lambda_kx_k}$ et $\displaystyle\sum\limits_{k=1}^p{\lambda_k}=1$.\\
	Montrer que Conv$(A)$ est constitué des combinaisons convexes d'éléments de $A$.
\end{enumerate}

\section{Théorème de Carathéodory \centraleponts{3}}
\label{Théorème de Carathéodory}
\textcolor{blue}{\hyperref[sec:theoreme-de-caratheodory]{[Corrigé]}}\\
Soit $E$ un espace vectoriel de dimension $n$. Soit $A\subset E$. On souhaite montrer que l'enveloppe convexe de $A$ (\ref{Enveloppe convexe}) est constitué des combinaisons convexes d'au plus $n+1$ éléments de $A$.\\
Soit $x=\displaystyle\sum\limits_{k=1}^p{\lambda_kx_k}$ une combinaison convexe de $x_1,\dots,x_p\in A$ avec $p\geq n+2$.
\begin{enumerate}[leftmargin=*]
	\item En considérant la famille $(x_2-x_1,\dots,x_p-x_1)$, montrer qu'il existe $p$ réels non tous nuls $\mu_1,\dots,\mu_p$ tels que
	$$\displaystyle\sum\limits_{k=1}^p{\mu_kx_k}=0\text{   et   }\displaystyle\sum\limits_{k=1}^p{\mu_k}=0$$
	\item Conclure.
\end{enumerate}

\subsection{Enveloppe convexe d'une partie compacte \centraleponts{2}}
\label{Enveloppe convexe d'une partie compacte}
\textcolor{blue}{\hyperref[sec-enveloppe-convexe-d'une-partie-compacte]{[Corrigé]}}
En déduire que l'enveloppe convexe d'une partie compacte est compacte.

\section{Théorème de Krein-Milman}
\label{Théorème de Krein-Milman}
\textcolor{blue}{\hyperref[sec:theoreme-de-krein-milman]{[Corrigé]}}\\
% Correction ici : https://mickael-nahon.fr/wp-content/uploads/2020/08/Enveloppe_convexe_et_points_extr_maux.pdf
Soit $E$ un espace euclidien.\\
Pour $C$ une partie convexe de $E$ on dit que $x\in C$ est un point extrémal de $C$ si $C\setminus \{x\}$ est convexe, autrement dit, si $x$ appartient à un segment de $C$ alors $x$ est une borne du segment : $x\in [a,b]\subset C\implies (x=a\text{ ou }x=b)$. On note Ext($C$) l'ensemble des points extrémaux de $C$.\\
Soit $C$ un convexe compact de $E$.\\
On pourra librement utiliser dans cet exercice le théorème de projection sur un convexe compact \ref{Projeté convexe}.
\begin{enumerate}
	\item Soit $x\in \operatorname{Fr}(C)$. Montrer qu'il existe une forme linéaire non nulle $\varphi$ et $a\in E$ tels que $C\subset \varphi^{-1}(]-\infty,a])$. On note $H=\varphi^{-1}(a)$.
	\item Montrer que Ext$(C)\cap H=\text{Ext}(C\cap H)$.
	\item Montrer que $C=\text{Conv}(\text{Ext}(C))$.
\end{enumerate}

\section{Epigraphe \ccinp{1}}
\label{Epigraphe}
\textcolor{blue}{\hyperref[sec:epigraphe]{[Corrigé]}}\\
Soit $f$ une fonction réelle. On note $E=\{(x,y)\in \R^2,\ y\geq f(x)\}$ l'épigraphe de $f$.\\
Montrer que $f$ est convexe si et seulement si $E$ est convexe.

\section{Partie convexe et dense de $\R^n$ \xens{4}}
\label{Partie convexe et dense de R^n}
\textcolor{blue}{\hyperref[sec:partie-convexe-et-dense-de-rn]{[Corrigé]}}\\
Soit $A$ une partie convexe et dense de $\R^n$. Montrer que $A=\R^n$.

\section{Partie convexe et ouverte de $\R^n$ \xens{4}}
\label{Partie convexe et ouverte de R^n}
\textcolor{blue}{\hyperref[sec:partie-convexe-et-ouverte-de-rn]{[Corrigé]}}\\
\begin{enumerate}[leftmargin=*]
	\item Soit $A$ une partie convexe et ouverte de $\R^2$. Montrer que le complémentaire de $A$ contient une droite vectorielle.
	\item Soit $A$ une partie convexe et ouverte de $\R^n$, $n\geq 2$. Montrer que le complémentaire de $A$ contient une droite vectorielle.
\end{enumerate}

\section{Connexité de l'espace \etoile{2}}
\label{Connexité de l'espace}
\textcolor{blue}{\hyperref[sec:connexité-de-l'espace]{[Corrigé]}}\\
\begin{enumerate}[leftmargin=*]
	\item Déterminer les composantes connexes par arcs de $\R^*$.
	\item Montrer que $\U$ privé d'un point est connexe par arcs. $\U$ privé de deux points est-t-il connexe par arcs ? En déduire les parties connexes par arcs de $\U$.
	\item Montrer que $\C$ privé d'un nombre fini de points est connexe par arcs.
	\item Montrer que $\R^3$ privé d'un nombre fini de droites est connexe par arcs.
\end{enumerate}

\section{Complémentaire d'un hyperplan \centraleponts{3}}
\label{Complémentaire d'un hyperplan}
\textcolor{blue}{\hyperref[sec:complementaire-dun-hyperplan]{[Corrigé]}}\\
Soit $E$ un $\R$-espace vectoriel de dimension $n$ finie.
\begin{enumerate}
	\item Soit $H$ un hyperplan de $E$. Montrer que $E\backslash H$ n'est pas connexe par arcs. Quelles sont ses composantes connexes par arcs ?
	\item Soit $F$ un sous-espace vectoriel de $E$ de dimension $d\leq n-2$. $E\backslash F$ est-t-il connexe par arcs ?
	\item Reprendre la question 1 avec $E$ un $\C$-espace vectoriel.
\end{enumerate}

\section{Composantes connexes par arcs du complémentaire de la réunion de plusieurs hyperplans \xens{5}}
\label{Composantes connexes par arcs du complémentaire de la réunion de plusieurs hyperplans}
\textcolor{blue}{\hyperref[sec:composantes-connexes-par-arcs-du-complementaire-de-la-reunion-de-plusieurs-hyperplans]{[Corrigé]}}\\
Soient $n,r\in \N^*$.
\begin{enumerate}[leftmargin=*]
	\item
	\begin{enumerate}[label=\alph*.]
		\item Soit $(f_1,\dots,f_r)$ une famille libre de $(\R^n)^*$.
		Quel est le nombre de composantes connexes par arcs de $\R^n\setminus \displaystyle\bigcup\limits_{i=1}^r{\ker f_i}$ ?
		\item Même question en remplaçant $\R$ par $\C$.
	\end{enumerate}
	\item Soient $H_1,\dots,H_r$ des hyperplans affines de $\R^n$. Quel est le nombre maximal de composantes connexes par arcs de $\R^n\setminus \displaystyle\bigcup\limits_{i=1}^r{H_i}$ ?
\end{enumerate}

\section{Sphères d'un $\R$-espace vectoriel \centraleponts{3}}
\label{Sphères d'un R espace vectoriel}
\textcolor{blue}{\hyperref[sec:spheres-dun-r-espace-vectoriel]{[Corrigé]}}\\
Soit $E$ un $\R$-espace vectoriel de dimension supérieure ou égale à $2$.
\begin{enumerate}[leftmargin=*]
	\item Montrer que la sphère unité $S$ de $E$ est connexe par arcs.
	\item En déduire que toutes les sphères de $E$ sont connexes par arcs.
\end{enumerate}

\section{Théorème du passage à la douane \centraleponts{3}}
\label{Théorème du passage à la douane}
\textcolor{blue}{\hyperref[sec:theoreme-du-passage-a-la-douane]{[Corrigé]}}\\
Soit $E$ un $\R$-espace vectoriel normé, montrer que toute partie connexe par arcs qui rencontre une partie $A$ et son complémentaire rencontre forcément la frontière de $A$.

\section{Condition nécessaire de la connexité par arc \etoile{1}}
\label{Condition nécessaire de la connexité par arc}
\textcolor{blue}{\hyperref[sec:condition-necessaire-de-la-connexite-par-arc]{[Corrigé]}}\\
Soit $C$ un connexe par arcs.
\\ Montrer que toute application $f:C\to\{0,1\}$ continue est constante.

\section{Entre un ensemble et son adhérence}
\label{Entre un ensemble et son aadhérence}
\textcolor{blue}{\hyperref[sec:entre-un-ensemble-et-son-adherence]{[Corrigé]}}\\
Soient $E$ un $\R$-espace vectoriel normé, $C$ une partie convexe de $E$ et $D\subset E$ telles que $C\subset D\subset \overline{C}$.\\
Montrer que $D$ est connexe par arcs.

\section{Continuité d'applications matricielles}
\label{Continuité d'applicaiton matricielles}
\textcolor{blue}{\hyperref[sec:continuite-dapplications-matricielles]{[Corrigé]}}\\
Montrer les propositions suivantes :
\begin{enumerate}
	\item $f:M\in \M_n(\K)\mapsto M^\top$ est continue.
	\item $g:(A,B)\in \M_n(\K)^2\mapsto AB$ est continue.
	\item $h:M\in \M_n(\K)\mapsto M^\top M$ est continue.
	\item $\det:M\in \M_n(\K)\mapsto \det M$ est continue.
	\item $\operatorname{Com}:M\in \M_n(\K)\mapsto \operatorname{Com}(M)$ est continue.
	\item $\text{inv}:M\in \text{GL}_n(\K)\mapsto M^{-1}$ est continue.
	\item $\Pi:M\in \M_n(\K)\mapsto \pi_M$ n'est pas continue.
\end{enumerate}

\section{Points de continuité du polynôme minimal}
\label{Points de continuité du polynôme minimal}
\textcolor{blue}{\hyperref[sec:points-de-continuite-du-polynome-minimal]{[Corrigé]}}\\
Déterminer l'ensemble des points de continuité de l'application $\Pi:M\in \M_n(\K)\mapsto \pi_M$.

\section{Exponentielle matricielle et topologie}
\label{Exponentielle matricielle et topologie}
\textcolor{blue}{\hyperref[sec:exponentielle-matricielle-et-topologie]{[Corrigé]}}\\
Soit $M\in \M_n(\K)$. Montrer que exp($M$) est un polynôme en $M$.

\section{Lemme du déterminant}
\label{Lemme du déterminant}
\textcolor{blue}{\hyperref[sec:lemme-du-determinant]{[Corrigé]}}\\
\begin{enumerate}[leftmargin=*]
	\item Montrer que $\forall (U,V)\in \M_{n,1}(\K)^2,\  \det{(I_n+UV^\top)}=1+V^\top U$
	\item Montrer que $\forall M\in \M_n(\K),\forall (U,V)\in \M_{n,1}(\K)^2,\ \det{(M+UV^\top)}=\det{(M)}+V^\top\text{Com}(M)^\top U$
\end{enumerate}

\section{Matrice de déterminant $1$ \etoile{3}}
\label{Matrice de déterminant 1}
\textcolor{blue}{\hyperref[sec:matrice-de-determinant-1-etoile3]{[Corrigé]}}\\
On pose SL$_n(\K)=\{M\in\M_n(\K)|\det(M)=1\}$ (appelé groupe spécial linéaire).\\
Montrer que: 
\begin{enumerate}
	\item SL$_n(\K)$ est un groupe.
	\item SL$_n(\K)$ est fermé.
	\item SL$_n(\K)$ n'est pas borné.
	\item SL$_n(\K)$ est d'intérieur vide.
	\item SL$_n(\K)$ est connexe par arcs.\\
	\textit{On admettra que} SL$_n(\K)$ \textit{est engendré par l'ensemble des matrices de transvection.}
\end{enumerate}

\section{Ensembles de matrices de rang fixé}
\label{Ensembles de matroces de rang fixé}
\textcolor{blue}{\hyperref[sec:ensembles-de-matrices-de-rang-fixe]{[Corrigé]}}\\
Soit $(p,r)\in \N^*\times \N$. On pose
$$A_r=\{M\in\M_{n,p}(\K),\ \rg(M)=r\}$$
$$B_r=\{M\in\M_{n,p}(\K),\ \rg(M)\leq r\}$$
$$C_r=\{M\in\M_{n,p}(\K),\ \rg(M)\geq r\}$$
Les ensembles $A_r,B_r,C_r$ sont-ils ouverts ? Fermés ?\\
Déterminer leurs adhérence et leurs intérieur.

\section{Densité des matrices inversibles \etoile{3}}
\label{Densité des matrices inversibles}
\textcolor{blue}{\hyperref[sec:densite-des-matrices-inversibles-etoile3]{[Corrigé]}}\\
\begin{enumerate}[leftmargin=*]
	\item Montrer que GL$_n(\K)$ est dense dans $\M_n(\K)$.
	\item Montrer que $\forall (A,B)\in \M_n(\K)^2,\ \chi_{AB}=\chi_{BA}$.
	\item Montrer que $\forall (A,B)\in \M_n(\K)^2,\ \chi_{\operatorname{exp}(AB)}=\chi_{\operatorname{exp}(BA)}$.
\end{enumerate}

\section{Comatrice et topologie}
\label{Comatrice et toplogie}
\textcolor{blue}{\hyperref[sec:comatrice-et-topologie]{[Corrigé]}}\\
Soit $A\in \M_n(\K)$. Montrer que la transposée de la comatrice de $A$ est un polynôme en $A$.

\section{Groupe orthogonal \etoile{1}}
\label{Groupe orthogonal}
\textcolor{blue}{\hyperref[sec:groupe-orthogonal-etoile1]{[Corrigé]}}\\
Montrer que $\O_n(\R)$ est un sous-groupe compact de GL$_n(\R)$. Est-il connexe par arcs ?

\section{Groupe (spécial) unitaire \etoile{3}}
\label{Groupe (spécial) unitaire}
\textcolor{blue}{\hyperref[sec:groupe-special-unitaire-etoile3]{[Corrigé]}}\\
On note pour $M\in \M_n(\C),\ \overline{M}=\left(\overline{M_{ij}}\right)_{1\leq i,j\leq n}$ la matrice dont les coefficients sont les conjugués de ceux de $M$ et on pose $U_n(\C)=\left\{M\in\M_n(\C) \ | \ \overline{M}^\top M=I_n\right\}$ ainsi que $SU_n(\C)=\{M\in U_n(\C) \ | \ \det(M)=1\}$.
\begin{enumerate}
	\item Montrer que $U_n(\C)$ et $SU_n(\C)$ sont deux sous-groupes compacts d'intérieurs vides de GL$_n(\C)$.
	\item \begin{enumerate}[label=\alph*.]
		\item Démontrer que toute matrice de $U_n(\C)$ peut s'écrire sous la forme,
		$$P\text{diag}(e^{i\theta_1},\dots,e^{i\theta_n})P^{-1}$$
		avec $P\in U_n(\C)$ et $\theta_1,\dots,\theta_n$ des réels.\\
		\item Montrer que $U_n(\C)$ et $SU_n(\C)$ sont connexes par arcs.
	\end{enumerate}
\end{enumerate}

\section{Partie compacte et stable par produit de GL$_n(\K)$ \etoile{3}}
\label{Partie compacte et stable par produit de GLn(K)}
\textcolor{blue}{\hyperref[sec:partie-compacte-et-stable-par-produit-de-glnk-etoile3]{[Corrigé]}}\\
Montrer que toute partie non vide, compacte et stable par produit de GL$_n(\K)$ est un sous-groupe de GL$_n(\K)$.

\section{Intérieur des matrices diagonalisables \etoile{5}}
\label{Intérieur des matrices diagonalisables}
\textcolor{blue}{\hyperref[sec:interieur-des-matrices-diagonalisable-etoile5]{[Corrigé]}}\\
On note $\mathcal{D}_n(\K)$ l'ensemble des matrices de $\M_n(\K)$ diagonalisables ainsi que $\B_n(\K)=\{M\in\M_n(\K),\ \text{Card}(\operatorname{Sp}(M))=n\}$.\\
\begin{enumerate}
	\item Montrer que $\widering{\mathcal{D}_n(\R)}=\B_n(\R)$
	\item Montrer que $\widering{\mathcal{D}_n(\C)}=\B_n(\C)$
\end{enumerate}

\section{Adhérence des matrices diagonalisables \etoile{3}}
\label{Adhérence des matrices diagonalisables}
\textcolor{blue}{\hyperref[sec:adherence-des-matrices-diagonalisables-etoile3]{[Corrigé]}}\\
On note $\mathcal{D}_n(\K) \text{ (resp. } \mathcal{T}_n(\K))$ l'ensemble des matrices diagonalisables (resp. trigonalisables) de $\M_n(\K)$.
\begin{enumerate}[leftmargin=*]
	\item Montrer que $\mathcal{D}_n(\C)$ est dense dans $\M_n(\C)$.
	\item \begin{enumerate}[label=\alph*.]
		\item Soient $d\in \N$ et $P\in \R[X]$ unitaire de degré $d$. Montrer que $P$ est scindé dans $\R[X]$ si et seulement si $$\forall z\in \C,\ |P(z)|\geq |\text{Im}(z)|^d$$
		\item En déduire que $\overline{\mathcal{D}_n(\R)}=\mathcal{T}_n(\R)$
	\end{enumerate}
\end{enumerate}

\section{Une preuve de Cayley-Hamilton (1) \etoile{3}}
\label{Une preuve de Cayley-Hamilton (1)}
\textcolor{blue}{\hyperref[sec:une-preuve-de-cayley-hamilton-1-etoile2]{[Corrigé]}}\\
\begin{enumerate}[leftmargin=*]
	\item Soit $A\in \M_n(\C)$ diagonalisable. Montrer que $\chi_A(A)=0$.
	\item Montrer que $\forall A\in \M_n(\C),\ \chi_A(A)=0$.
\end{enumerate}

\section{Dimension du commutant d'une matrice}
\label{Dimension du commutant d'une matrice}
\textcolor{blue}{\hyperref[sec:dimension-du-commutant-dune-matrice]{[Corrigé]}}\\
Soit $M\in \M_n(\C)$. On note $\mathcal C(M)=\{A\in \M_n(\C),\ AM=MA\}$.
\begin{enumerate}
	\item Déterminer la dimension de $\mathcal C(M)$ lorsque $M$ est une matrice diagonale dont tous les coefficients diagonaux sont distincts.
	\item Soit $r\in \crblanc{0}{n}$. Montrer que $B_r=\{A\in \M_n(\C),\ \rg(A)\leq r\}$ est fermé.
	\item En déduire que $\dim\mathcal C(M)\geq n$.
\end{enumerate}

\section{Topologie et réduction}
\label{Topologie et réduction}
\textcolor{blue}{\hyperref[sec:topologie-et-reduction]{[Corrigé]}}\\
Pour tout $M\in\M_n(\K)$, on désigne sa classe de similitude sur $\K$ par: $$S_{\K}(M)=\left\{PMP^{-1}\in\M_n(\K) \ | \ P\in \text{GL}_n(\K)\right\}$$
\\ Soit $M\in\M_n(\K)$.
\begin{enumerate}
	\item Montrer que $S_\K(M)$ est une partie bornée de $\M(\K)$ si et seulement si $M$ est une matrice scalaire (de la forme $\alpha I_n$ avec $\alpha\in \K$).
	\item Montrer que l'ensemble $S_\K(M)$ est une partie fermée de $\M_n(\K)$ si et seulement la matrice $M$ est diagonalisable.
	\item Montrer que $M$ est nilpotente si et seulement si la matrice nulle est un point adhérent à $S_\K(M)$.
\end{enumerate}

\section{Groupe spécial orthogonal et connexité}
\label{Groupe spécial orthogonal et connexité}
\textcolor{blue}{\hyperref[sec:groupe-special-orthogonal-et-connexite]{[Corrigé]}}\\
\begin{enumerate}[leftmargin=*]
	\item $\O_n(\R)$ est-il connexe par arcs ?
	\item Montrer que SO$_2(\R)$ est connexe par arcs.
	\item Montrer que SO$_n(\R)$ est connexe par arcs.
\end{enumerate}

\section{Matrices inversibles et connexité}
\label{Matrices inversibles et connexité}
\textcolor{blue}{\hyperref[sec:matrices-inversibles-et-connexite]{[Corrigé]}}\\
\begin{enumerate}[leftmargin=*]
	\item GL$_n(\R)$ est-il connexe par arc ?
	\item \begin{enumerate}[label=\alph*.]
		\item Soit $(A,B)\in \text{GL}_n(\C)^2$. On pose $d:z\in \C \mapsto \operatorname{det}((1-z)A+zB)$\\
		Montrer que $V=\{z\in \C,\ d(z)\ne 0\}$ est connexe par arcs.
		\item En déduire que GL$_n(\C)$ est connexe par arcs.
	\end{enumerate}
\end{enumerate}

\section{Matrices nilpotentes et connexité}
\label{Matrices nilpotentes et connexité}
\textcolor{blue}{\hyperref[sec:matrices-nilpotentes-et-connexite]{[Corrigé]}}\\
L'ensemble des matrices nilpotentes de $\M_n(\R)$ est-il convexe ? Connexe par arcs ? Et si on enlève $0_n$ ?

\section{Raffinement sur les disques de Gershgorin}
\label{Raffinament sur les disques de Gershgorin}
\textcolor{blue}{\hyperref[sec:raffinement-sur-les-disques-de-gershgorin]{[Corrigé]}}\\
Soit $A\in \M_n(\C)$. Pour $i\in \crblanc{1}{n}$ on note $R_i=\sum\limits_{j\ne i}{|a_{ij}|}$ et $\mathcal{D}_i=D(a_{ii},R_i)$ le disque \underline{fermé} de centre $a_{ii}$ et de rayon $R_i$.
\begin{enumerate}
	\item \begin{enumerate}[label=\alph*.]
		\item Montrer que $\text{Sp}(A)\subset \mathcal{D}=\displaystyle\bigcup\limits_{i=1}^{n}{\mathcal{D}_i}$.
		\item Pour  $j\in \crblanc{1}{n}$ on note $T_j=\sum\limits_{i\ne j}{|a_{ij}|}$ et $\mathcal{D}_j^*=D(a_{jj},T_j)$ et $\mathcal{D}^*=\displaystyle\bigcup\limits_{j=1}^{n}{\mathcal{D}^*_j}$.\\
		Montrer que $\text{Sp}(A)\subset \mathcal{D}\cap \mathcal{D}^*$.
	\end{enumerate}
	\item On note $\mathcal{D}=\displaystyle\bigsqcup\limits_{k=1}^p{C_k}$ la décomposition en composantes connexes par arcs de $\mathcal{D}$.
	\begin{enumerate}[label=\alph*.]
		\item Montrer que chacune des composantes connexes par arcs de $\mathcal{D}$ est réunion d'un certain nombre des disques de Gershgorin $\mathcal{D}_i$.\\
		En déduire que les composantes connexes par arcs de $\mathcal{D}$ sont à la fois ouvertes dans $\mathcal{D}$ et fermées dans $\C$.\\
		On note dans la suite $n_k$ le nombre de disques de Gershgorin inclus dans $C_k$.
		\item On souhaite montrer pour toute matrice $A$ la proposition $\mathcal P(A):"\text{Il y a exactement $n_k$ valeurs propres de $A$ dans $C_k$}"$. Pour cela on fixe $A\in \M_n(\C)$ et on pose pour $t\in [0,1],\ A(t)=(a_{ij}(t))_{1\leq i,j\leq n}$ où $\forall i\in \crblanc{1}{n},\ a_{ii}(t)=a_{ii}$ et $\forall i,j\in \crblanc{1}{n}, i\ne j\implies a_{ij}(t)=ta_{ij}$, ainsi que $I$ l'ensemble des $t\in [0,1]$ tels que $\mathcal P(A(t))$.\\\\
		Montrer que $I$ est non vide puis montrer $\mathcal P(A)$.
		\item \underline{Application}: Montrer que si les disques de Gershgorin de $A\in \M_n(\C)$ sont deux à deux disjoints, alors $A$ est diagonalisable.
	\end{enumerate}
\end{enumerate}

\section{Matrices stochastiques et bistochastiques}
\label{Matrices stochastiques et bistochatiques}
\label{Matrices stochastiques}
\textcolor{blue}{\hyperref[sec:matrices-stochastiques-et-bistochastiques]{[Corrigé]}}\\
\begin{enumerate}[leftmargin=*]
	\item Montrer que $\mathcal S_{n,p}=\{M\in \M_{n,p}(\R^+)\ |\ \forall j\in \crblanc{1}{p},\displaystyle\sum\limits_{i=1}^n{M_{ij}}=1\}$ l'ensemble des matrices stochastiques est une partie convexe et compacte de $\M_{n,p}(\R)$. Montrer que $\forall (A,B)\in \mathcal S_{n,p}\times\mathcal S_{p,q},\ AB\in \mathcal S_{n,q}$.
	\item Montrer que $\B_n=\{M\in \M_n(\R^+)\ |\ \forall j\in \crblanc{1}{n},\displaystyle\sum\limits_{i=1}^n{M_{ij}}=\displaystyle\sum\limits_{i=1}^n{M_{ji}}=1\}$ l'ensemble des matrices bistochastiques est une partie convexe et compacte de $\M_n(\R)$.
\end{enumerate}

\section{Théorème de Birkhoff-Von Neumann \etoile{4}}
\label{Théorème de Birkhoff-Von Neumann}
\textcolor{blue}{\hyperref[sec:theoreme-de-birkhoff-von-neumann-etoile4]{[Corrigé]}}\\
On note $\mathcal P_n$ l'ensemble des matrices de permutation d'ordre $n$ (\ref{Matrices de permutation}) et $\B_n$ l'ensemble des matrices bistochastiques d'ordre $n$ (\ref{Matrices stochastiques}). Pour $A\subset \M_n(\R)$, Conv($A$) désigne l'enveloppe convexe de $A$ (\ref{Enveloppe convexe}). On souhaite montrer que $\B_n=\text{Conv}(\mathcal P_n)$.
\begin{enumerate}[leftmargin=*]
	\item Montrer que $\B_n\supset \text{Conv}(\mathcal P_n)$.
	\item Pour l'inclusion réciproque, on raisonne par récurrence sur le nombre de coefficients différents de $0$ des matrices bistochastiques en jeu.
	\begin{enumerate}[label=\alph*.]
		\item Soit $B\in \B_n$ ayant exactement $n$ coefficients non nuls. Montrer que $B\in \text{Conv}(\mathcal P_n)$.
		\item On fixe un entier $n^2\geq m>n$ et on suppose que toute matrice $M\in \B_n$ ayant moins de $m-1$ coefficients non nuls appartient à l'enveloppe convexe de $\mathcal{P}_n$. Soit $B\in \B_n$ ayant exactement $m$ coefficients non nuls. On note pour $i\in \crblanc{1}{n},\ A_i=\{j\in \crblanc{1}{n},\ B_{ij}\ne 0\}$.\\
		A l'aide du théorème de Hall (Tome Algèbre), déterminer une matrice de permutation $P_\sigma$ et un réel positif $\lambda$ tels que $B_0=\displaystyle\frac{1}{1-\lambda}(B-\lambda P_\sigma)$ soit une matrice bistochastique ayant au moins un coefficient nul de plus que $B$.
	\end{enumerate}
	\item Conclure.
\end{enumerate}

\subsection{Points extrémaux des matrices bistochastiques}
On note $\mathcal{P}_n$ l'ensemble des matrices de permutation d'ordre $n$ (Tome Algèbre) et $\B_n$ l'ensemble des matrices bistochastiques d'ordre $n$ (\ref{Matrices stochastiques}).
\begin{enumerate}[leftmargin=*]
	\item Montrer que $\B_n$ est convexe et compact.
	\item Montrer que Ext$(\B_n)=\mathcal{P}_n$.
\end{enumerate}

\subsection{Points extrémaux des matrices orthogonales}









\newpage
\chapter{Fonctions à valeurs vectorielles}
Dans toute cette section, $n$ désigne un entier naturel non nul.\\

\section{Point fixe de l'exponentielle complexe}
\textcolor{blue}{\hyperref[sec:point-fixe-de-lexponentielle-complexe]{[Corrigé]}}\\
\label{Point fixe de l'exponentielle complexe}
Le but de cet exercice est de montrer l'existence de points fixes de l'exponentielle complexe, c'est à dire qu'il existe $z\in \C$ tel que $e^z=z$.
\begin{enumerate}
	\item L'exponentielle a-t-elle des points fixes sur $\R$ ?
	\item Pour $x\in \displaystyle\left]0,\frac{\pi}{2}\right[$ on pose, $$f(x)=\exp\left(\frac{x}{\tan x}\right)-\frac{x}{\sin x}$$
	Déterminer les limites de $f$ en $0$ et en $\displaystyle\frac{\pi}{2}$.
	\item En déduire qu'il existe $b\in \displaystyle\left]0,\frac{\pi}{2}\right[$ tel que $f(b)=0$.
	\item On pose $a=\displaystyle\frac{b}{\tan b}$ et $z=a+ib$. Montrer que $e^z=z$.
\end{enumerate}

\section{Théorème du relèvement}
\textcolor{blue}{\hyperref[sec:theoreme-du-relevement]{[Corrigé]}}\\
\label{Théorème du relèvement}
Soient $I$ un intervalle de $\R$, $f:I\to \C$ une fonction de classe $\mathcal C^n$ et $t_0\in I$. Soit aussi $\theta_0$ un argument de $f(t_0)$.
\begin{enumerate}
	\item Montrer qu'il existe une unique fonction $\theta:I\to \R$ de classe $\mathcal C^n$ telle que $\forall t\in I,\ f(t)=|f(t)|e^{2i\pi\theta(t)}$.\\
	On dit que $\theta$ est un \textit{argument} de $f$.
	\item Supposons que $I=[a,b]$ avec $a<b$ et $f(a)=f(b)$. On définit $N_\theta(f)=\theta(b)-\theta(a)$ où $\theta$ est un argument de $f$. Montrer que $N_\theta(f)$ est indépendant de $f$.\\
	On appelle cette quantité le \textit{nombre de tours} de $f$.
	\item Démontrer qu'il n'existe aucune fonction continue $L:\C^*\to \C$ telle que $\exp\circ L=\Id_{\C^*}$.\\
	On pourra montrer par exemple que si il en existe une, alors $t\mapsto\displaystyle\frac{1}{2i\pi}L(e^{2i\pi t})$ est un argument de $t\mapsto e^{2i\pi t}$.
\end{enumerate}

\section{Equation fonctionnelle de l'exponentielle matricielle \etoile{3}}
\textcolor{blue}{\hyperref[sec:equation-fonctionnelle-de-lexponentielle-matricielle-etoile3]{[Corrigé]}}\\
\label{Equation fonctionnelle de l'exponentielle matricielle}
Soit $\varphi:\R\to \M_n(\K)$ une application telle que $\forall (s,t)\in \R^2,\ \varphi(s+t)=\varphi(s)\varphi(t)$.
\begin{enumerate}
	\item On suppose que $\varphi$ est dérivable en $0$. Déterminer $\varphi$.
	\item On suppose que $\varphi$ est continue en $0$ et que $\varphi(\R)\subset \text{GL}_n(\K)$. Déterminer $\varphi$.
\end{enumerate}

\section{Formule de Trotter-Kato \etoile{2}}
\textcolor{blue}{\hyperref[sec:formule-de-trotter-kato-etoile2]{[Corrigé]}}\\
\label{Formule de Trotter-Kato}
Soient $A$ et $B$ deux matrices de $\M_n(\K)$ que l'on munit d'une norme sous-multiplicative $\norme{.}$. Pour tout $k$ entier naturel non nul, on pose : $$X_k=\exp\left(\frac{A}{k}\right)\exp\left(\frac{B}{k}\right) \qquad \text{et} \qquad Y_k=\exp\left(\frac{A+B}{k}\right)$$
\begin{enumerate}
	\item Prouver les majoration: $$\forall k\in\N^*, \quad \norme{X_k}\leq\exp\left(\frac{\norme{A}+\norme{B}}{k}\right) \quad \text{et} \quad \norme{Y_k}\leq\exp\left(\frac{\norme{A}+\norme{B}}{k}\right)$$
\end{enumerate}
On introduit la fonction $\fonction{h}{\R}{\M_n(\K)}{t}{e^{tA}e^{tB}-e^{t(A+B)}}$.
\begin{enumerate}[resume]
	\item Montrer que $X_k-Y_k\ukfty{=}\bigO{\displaystyle\frac{1}{k^2}}$
	\item Vérifier la relation $X_k^k-Y_k^k=\displaystyle\sum_{i=0}^{k-1}X_k^i(X_k-Y_k)Y_k^{k-i-1}$.
	\item En déduire que $\displaystyle\ukfty{\lim}\left(\exp\left(\frac{A}{k}\right)\exp\left(\frac{B}{k}\right)\right)^k=\exp(A+B)$.
\end{enumerate}

\section{Série entière de matrice \etoile{2}}
\textcolor{blue}{\hyperref[sec:serie-entiere-de-matrice-etoile2]{[Corrigé]}}\\
\label{Série entière de matrice}
Soit $A\in\M_n(\K)$.
\\On définit $\cos(A)=\displaystyle\sum\limits_{n=0}^{+\infty} \frac{(-1)^n}{(2n)!}A^{2n}$ et $\sin(A)=\displaystyle\sum\limits_{n=0}^{+\infty} \frac{(-1)^n}{(2n+1)!}A^{2n+1}$.
\\\\Montrer que $\cos(A)^2+\sin(A)^2=I_n$.

\section{Expression d'un projecteur}
\textcolor{blue}{\hyperref[sec:expression-dun-projecteur]{[Corrigé]}}\\
\label{Expression d'un projecteur}
Soit $A\in \mathcal S_n^{++}(\R)$. Justifier l'existence et calculer :
$$\int_0^{+\infty}A\cdot(A^2+x^2I_n)^{-1}dx$$

\section{\underline{Une preuve analytique de Cayley-Hamilton} \centraleponts{3}}
\textcolor{blue}{\hyperref[sec:une-preuve-analytique-de-cayley-hamilton]{[Corrigé]}}\\
\label{Une preuve analytique de Cayley-Hamilton}
On munit $\M_n(\C)$ d'une norme d'algèbre $\norme{.}$ et on se donne $A\in \M_n(\C)$.
\begin{enumerate}
	\item On suppose que $\norme{A}<1$. Montrer que $I_n-A$ est inversible et que $(I_n-A)^{-1}=\displaystyle\sum_{k=0}^{+\infty}A^k$.
	\item Soit $k\in \N$. Montrer que pour $r\in \R$ assez grand, l'intégrale
	$$I_k(r)=\frac{1}{2\pi}\int_{-\pi}^{\pi}\left(re^{i\theta}\right)^{k+1}\left(re^{i\theta}I_n-A\right)^{-1}d\theta$$
	est définie et que $I_k(r)=A^k$.
	\item Justifier que
	$$\chi_A(A)=\frac{1}{2\pi}\int_{-\pi}^{\pi}re^{i\theta}\Com(re^{i\theta}I_n-A)^\top d\theta$$
	\item En déduire le théorème de Cayley-Hamilton.
\end{enumerate}

\section{Exemple de fonction lipschitzienne}
\label{Exemple de fonction lipschitzienne}
\textcolor{blue}{\hyperref[sec:exemple-de-fonctions-lipschitzienne]{[Corrigé]}}\\
Soit $(E,\norme{})$ un espace vectoriel réel normé.\\
On pose :\[\fonction{f}{E}{E}{x}{\frac{x}{\max\{1,\norme{x}\}}}\]
\begin{enumerate}
	\item Montrer que $f$ est $2$-lipschitzienne.
	\item Montrer que si $\norme{.}$ est euclidienne alors $f$ est $1$-lipschitzienne.
\end{enumerate}

\section{Condition de continuité sur un espace vectoriel normé}
\label{Condition de continuité sur un espace vecoriel normé}
\textcolor{blue}{\hyperref[sec:condition-de-continuite-sur-un-espace-vectoriel-norme]{[Corrigé]}}\\
Soient $E$ et $F$ deux espaces vectoriels réels normés.\\
On note $\normep{E}{.}$ (respectivement $\normep{F}{.}$) la norme sur $E$.\\
Démontrer que si $f$ est application linéaire de $E$ dans $F$, alors les propriétés suivantes sont deux à deux équivalentes :\\
\begin{itemize}
	\item $f$ est continue sur $E$,
	\item $f$ est continue en $O$,
	\item il existe $k>0$ tel que pour tout $x\in E$, $\normep{F}{f(x)}\geq k\normep{E}{x}$.
\end{itemize}
\section{Application linéaire (2)}
\label{Application linéaire 2}
\textcolor{blue}{\hyperref[sec:application-lineaire-2]{[Corrigé]}}\\
Soient $E$ un espace vectoriel de dimension finie et $f:\R\to E$ dérivable en $0$ telle que :\[\forall x\in\R, f(2x)=2f(x)\]
Montrer que $f$ est linéaire.
\section{Mouvement à force centrale}
\label{Mouvement à force centrale}
\textcolor{blue}{\hyperref[sec:mouvement-a-force-centrale]{[Corrigé]}}\\
Soit $I$ un intervalle de $R$ et $f:I\to\R^3$ de classe $\mathcal{C}^2$ tel que pour tout $t\in I$, $f(t)$ et $f''(t)$ soient colinéaires. On suppose de plus qu'il existe $t_0\in I$ tel que $(f(t_0),f'(t_0))$ est libre.
\begin{enumerate}
	\item Montrer que $f$ est à valeurs dans un plan vectoriel de $\R^3$. On pourra utiliser le produit vectoriel.
	\item Montrer que l'aire orientée du triangle porté par les vecteurs $f(t)$ et $f'(t)$.
\end{enumerate}
\section{Dérivée d'un produit de deux matrices}
\label{Dérivée d'un produit de deux matrices}
\textcolor{blue}{\hyperref[sec:derivee-dun-produit-de-deux-matrices]{[Corrigé]}}\\
Soit $M:\R\to\M_n(\R),t\mapsto M(t)$ une fonction dérivable.
\begin{enumerate}
	\item Démontrer que la fonction $\fonction{\varphi}{\R}{\M_n(\R)}{t}{M(t)M(t)^\top}$ est dérivable.
	\item On suppose que pour tout $t\in\R$, la matrice $M(t)$ est orthogonale.\\
	Démontrer que, pour tout $t\in\R$, $M'(t)M(t)^\top$ est antisymétrique.
\end{enumerate}
\section{Inégalité des accroissements finis pour un espace euclidien}
\label{Inégalité des accroissements finis pour un espace euclidien}
\textcolor{blue}{\hyperref[sec:inegalite-des-accroissements-finis-pour-un-espace-euclidien]{[Corrigé]}}\\
Soit $E$ un espace vectoriel euclidien et $f:[a,b]\to E$ continue sur $[a,b]$ et dérivable sur $]a,b[$.
En considérant $\varphi(t)=\langle f(b)-f(a),f(t)\rangle$, démontrer qu'il existe $c\in]a,b[$ tel que \[\norme{ f(b)-f(a)}\leq (b-a)\norme{f'(c)}\]
\newpage
\chapter{Equations différentielles}
\section{Equations différentielles du premier ordre}
\textcolor{blue}{\hyperref[sec:equations-differentielles-du-premier-ordre]{[Corrigé]}}\\
\label{Equations différentielles du premier ordre}
Résoudre ces équations différentielles:
\begin{enumerate}
	\item $y'+y=x$ sur $\R$;
	\item $y'+\operatorname{th}(t)y=\sh(t)$ sur $\R$;
	\item $y'+2xy=e^{x-x^2}$ , y(0)=0, sur $\R$;
	\item $|x(x-1)|y'-y=x^2$ sur $\R$;
	\item $y'+\cotan(t)y=\cos^2(t)$ sur $]0,\pi[$.
\end{enumerate}

\section{Equations différentielles du second ordre}
\textcolor{blue}{\hyperref[sec:equations-differentielles-du-second-ordre]{[Corrigé]}}\\
\label{Equations différentielles du second ordre}
Résoudre ces équations différentielles
\begin{enumerate}
	\item $y''-2y'-3y=t^2e^t$ sur $\R$;
	\item $y''-2y'+2y=e^{-t}\cos(t)$ sur $\R$;
	\item $y''+\lambda y=0$ sur $\R$, pour tout $\lambda\in\R$;
	\item $y''-(1-i)y'-2(1+i)y=0$ sur $\C$ avec $y(0)=y'(0)=1$.
\end{enumerate}

\section{Une équation quasi-différentielle}
\textcolor{blue}{\hyperref[Une équation quasi-différentielle corrigé]{[Corrigé]}}\\
\label{Une équation quasi-différentielle}
Déterminer l'ensemble des fonctions $f\in \mathcal C^1(\R,\C)$ telles que $\forall x\in \R,\ f'(x)=f(-x)$.

\section{Problèmes de raccordement}
\textcolor{blue}{\hyperref[sec:problemes-de-raccordement]{[Corrigé]}}\\
\label{Problème de raccordement}
Résoudre sur $\R$ l'équation différentielle: $xy'-y=x$.

\section{Suite d'équations différentielles}
\textcolor{blue}{\hyperref[sec:suite-dequations-differentielles]{[Corrigé]}}\\
\label{Suite d'équations différentielles}
Soit $\alpha\in\R$.
\begin{enumerate}
	\item Résoudre sur $\R_+^*$ l'équation différentielle $xy'-\alpha y =0$. Déterminer l'unique solution $f$ vérifiant $f(1)=1$.
	\item Résoudre sur $\R_+^*$ l'équation différentielle $xy'-\alpha y =f$. Déterminer l'unique solution vérifiant $g(1)=0$.
	\item On définit par récurrence une suite de fonctions $(u_n)$ sur $\R_+^*$ de la manière suivante:
	\begin{itemize}
		\item $u_0=f$,
		\item pour tout $n\in\N$, $u_{n+1}$ est l'unique solution de l'équation différentielle $xy'-\alpha y=u_n$ sur $\R^*_+$ valant $0$ en $1$.
	\end{itemize}
	Déterminer par récurrence $u_n$ pour tout $n\in\N$.
	%Je sais pas pourquoi l'exo doit se faire par récurrence alors qu'on peut juste vérifier que ce que l'on pense fonctionne.
	% Bah alors enlève par récurrence je trouve ça mieux aussi, Monsieur Esteve.
\end{enumerate}

\section{Equation de Bernoulli (1)}
\textcolor{blue}{\hyperref[sec:equation-de-bernoulli-1]{[Corrigé]}}\\
\label{Equation de Bernoulli 1}
On souhaite résoudre l'équation $$(E):x^2y''+3xy'+y=\frac{1}{x^2}$$ sur l'intervalle $I=]0,+\infty[$.
\begin{enumerate}
	\item Soient $y:I\to\R$ deux fois dérivable  et $Y:\R\to\R$ définie par $Y(t)=y(e^t)$.
	\begin{enumerate}[label=\alph*]
		\item Calculer les dérivées $y$,$y'$ et $y''$ en fonction de $Y$,$Y'$ et $Y''$
		\item En déduire que $y$ est solution de $(E)$ si et seulement si $Y$ est solution d'une équation différentielle linéaire du deuxième ordre à coefficients constants $(E')$ que l'on précisera.
	\end{enumerate}
	\item Résoudre $(E')$ sur $\R$.
	\item En déduire les solutions de $(E')$.
	\item En déduire les solutions de $(E)$ sur $I$.
	\item Déterminer l'unique solution $y$ de $(E)$ sur $I$ telle que $y(1)=y'(1)=0$
\end{enumerate}

\section{Equation de Bernoulli (2)}
\textcolor{blue}{\hyperref[sec:equation-de-bernoulli-2]{[Corrigé]}}\\
\label{Equation de Bernoulli (2)}
Soient I=$]1,+\infty[$, $$(E): -t^2y'+ty=y^2$$
\begin{enumerate}
	\item Soit $y$ une fonction ne s'annulant par sur $I$. Prouver que $y$ est solution de $(E)$ si et seulement si $z=\displaystyle\frac{1}{y}$ est solution sur $I$ d'une équation différentielle $(E')$ linéaire d'ordre un.
	\item Résoudre $(E')$ sur $I$.
	\item En déduire les solutions de $(E)$ ne s'annulant pas sur l'intervalle $I$.
\end{enumerate}

\section{Etude asymptotique des solutions d'une équation différentielle \centraleponts{4}}
\textcolor{blue}{\hyperref[sec:etude-asymptotique-des-solutions-dune-equation-differentielle-etoile4]{[Corrigé]}}\\
\label{Etude asymptotique des solution d'une équation différentielle}
\begin{enumerate}[leftmargin=*]
	\item Soient $a \in \C$ tel que $\Re(a)>0$ et f une fonction de classe $\mathcal{C}^1$ sur $\R_+$, à valeurs dans $\C$ telle que $\lim\limits_{+\infty} f'+af=0$. Montrer que $\lim\limits_{+\infty} f=0$.
	\item Soit $f\in \mathcal{C}^2(\R_+,\C)$ telle que $\lim\limits_{+\infty}f''+f'+f=0$. Montrer que $\lim\limits_{+\infty} f=0$.
	\item Démontrer que : pour tout $P \in \C[X]$ dont les racines sont toutes de parties réelles strictement négatives, si f est une fonction de classe $\mathcal{C}^n$ sur $\R_+$ à valeurs dans $\C$ avec $n=\deg(P)$ telle que $\lim\limits_{+\infty} P(D)(f)=0$, alors $\lim\limits_{+\infty}f=0$. \\ ($D$ représente l'opérateur de dérivation)
\end{enumerate}

\section{Inéquation différentielle}
\textcolor{blue}{\hyperref[sec:inequation-differentielle]{[Corrigé]}}\\
\label{Inéquation différentielle}
Soit $f$ une application de classe $\mathcal{C}^2$ de $\R$ dans $\R$ telle que $f''+f\geq0$. Montrer que: $$\forall x\in\R,\quad f(x)+f(x+\pi)\geq0$$

\section{Solution $2\pi$-périodique d'une équation différentielle}
\textcolor{blue}{\hyperref[sec:solution-2pi-periodique-dune-equation-differentielle]{[Corrigé]}}\\
\label{Solution 2pi-périodique d'une équation différentielle}
Soit $f$ une fonction $2\pi$-périodique de classe $\mathcal{C}^2$. Montrer que l'équation différentielle $y''+y=f$ admet des solutions $2\pi$-périodiques si et seulement si $$\int_0^{2\pi}f(t)\cos(t)dt=\int_0^{2\pi}f(t)\sin(t)dt=0$$

\section{Superposition de solutions}
\textcolor{blue}{\hyperref[sec:superposition-de-solutions]{[Corrigé]}}\\
\label{Superposition de solutions}
\begin{enumerate}[leftmargin=*]
	\item Soit $n\in\N$. Résoudre l'équation différentielle $y''+y=\cos(nt)$.
	\item Soit $a_n$ une série absolument convergente. Résoudre l'équation différentielle $$y''+y=\sum_{n=0}^{+\infty}a_n\cos(nt)$$
\end{enumerate}

\section{Fonction de Bessel}
\textcolor{blue}{\hyperref[sec:fonction-de-bessel]{[Corrigé]}}\\
\label{FOnction de Bessel}
On considère l'équation de Bessel, $(E):xy''+y'+xy=0$.
\begin{enumerate}
	\item Montrer que la fonction $\fonction{J_0}{\R}{\R}{x}{\displaystyle\frac{1}{\pi} \int_0^\pi \cos(x\sin(\theta)) d\theta}$ est solution de $(E)$ (sur $\R$ ?).
	\item Montrer qu'il existe une unique solution $f_0$ de l'équation $(E)$ qui est développable en série entière, définie sur tout $\R$ et telle que $f_0(0)=1$.
	\item Soit $f:]0,a[\to\R$ une solution de l'équation $(E)$. \\Montrer que $(f,f_0)$ est libre si et seulement la fonction $f$ n'est pas bornée au voisinage de $0$.
	\item En déduire que $\forall x\in\R, \quad \displaystyle\int_0^\pi \cos(x\sin(\theta)) d\theta=\sum_{n=0}^{+\infty}\frac{(-1)^n}{4^n(n!)^2}x^n$.
\end{enumerate}

\section{Développement de la cotangente (2)}
\textcolor{blue}{\hyperref[sec:developpement-de-la-cotangente-2]{[Corrigé]}}\\
	\label{Développement de la cotangente 2}
On pose pour $n\in \N$ et $x\in \R\setminus\Z$, $f_n(x)=\displaystyle\sum_{k=-n}^n\frac{1}{x-k}$.
\begin{enumerate}
	\item Montrer que la suite de fonction $(f_n)_{n\in \N}$ converge vers une fonction $f$ de classe $\mathcal C^1$ sur $\R\setminus\Z$ et donner une expression de $f'$ sous forme d'une série de fonctions.
	\item Trouver une équation différentielle vérifiée par $f$.
	\item En déduire que $\forall x\in \R,\ f(x)=\pi\cotan(\pi x)$.
\end{enumerate}

\section{Wronskien}
\textcolor{blue}{\hyperref[sec:wronskien]{[Corrigé]}}\\
\label{Wronskien}
\begin{enumerate}[leftmargin=*]
	\item
	Soient $I$ un intervalle de $\R$ et deux applications $p$ et $q$ de $I$ dans $\C$ continues. On considère deux solutions $u$ et $v$ de l'équation différentielle $(E): y''+py'+qy=0.$ 
	\\Calculer le wronskien de $u$ et $v$ en fonction de sa valeur en un point $a$ et $I$.
	\item On veut étendre ce résultat aux systèmes linéaires. Soient $I$ un intervalle de $\R$ et $A:I\to\M_n(\C)$ une fonction continue. On considère $f_1,\dots,f_n$ $n$ solutions sur $I$ de l'équation différentielle $(S):Y'=AY$.
	\\Calculer le wronskien de $f_1,\dots,f_n$ en fonction de sa valeur en un point $a$ de $I$.
\end{enumerate}

\section{Utilité du wronskien}
\textcolor{blue}{\hyperref[sec:utilite-du-wronskien]{[Corrigé]}}\\
\label{Utilité du wronskien}
Soient $q$ une fonction continue et intégrable sur $\R_+$. On considère l'équation différentielle $(E):y''+qy=0$.
\begin{enumerate}
	\item Soit $f$ une solution bornée de $(E)$ sur $\R_+$. Montrer que $f'$ admet une limite en $+\infty$ puis déterminer la valeur de cette limite.
	\item Soient $f$ et $g$ deux solutions bornées de $(E)$ sur $\R_+$. Etudier le wronskien $W=fg'-f'g$ des solutions $f$ et $g$.
	\\En déduire que $f$ et $g$ sont liées. Que peut-on en conclure ?
\end{enumerate}

\section{Principe d'entrelacement des zéros de Sturm}
\textcolor{blue}{\hyperref[sec:principe-dentrelacement-des-zeros-de-sturm]{[Corrigé]}}\\
\label{Principe d'entrelacement des zéros de Sturm}
\begin{enumerate}[leftmargin=*]
	\item Soient $p$ et $q$ deux fonctions continues sur $\R$ telles que $p\leq q$ sur $\R$. Soient $u$ et $v$ deux fonctions de classe $\mathcal{C}^2$ telles que $u''+pu=0$ et $v''+qv=0$. On suppose que $u$ s'annule en des réels $a$ et $b$ avec $a<b$ mais qu'elle n s'annule pas sur $]a,b[$.
	\begin{enumerate}[label=\alph*.]
		\item On pose le \textit{pseudo-wronskien} $W=u'v-uv'$. Déterminer $W'$.
		\item En déduire que $v$ s'annule sur $[a,b]$.
	\end{enumerate}
	\item Application. Soient $r$ une fonction continue sur $\R$, f de classe $\mathcal{C^2}$ sur $\R$ telle que $f''+rf=0$ et $M\in\R^*_+$.
	\begin{enumerate}[label=\alph*]
		\item On suppose $r\geq M^2$. Montrer que tout intervalle fermé de longueur $\displaystyle\frac{\pi}{M}$ contient au moins un zéro de $f$.
		\item On suppose $r\leq M^2$. On suppose que $f$ s'annule en des réels $a$ et $b$ tels que $a<b$ mais qu'elle ne s'annule pas sur $]a,b[$.\\
		Montrer que $b-a\geq\displaystyle\frac{\pi}{M}$.
	\end{enumerate}
\end{enumerate}

\section{Solution qui s'annule}
\textcolor{blue}{\hyperref[sec:solution-qui-sannule]{[Corrigé]}}\\
\label{Solution qui s'annule}
Soit $p:\R\to\R_+$ une fonction continue non identiquement nulle. On se propose de démontrer que toutes les solutions de l'équation différentielle $y''+py=0$ s'annulent. Pour cela, on raisonne par l'absurde et on suppose que $f$ est une solution ne s'annulant pas.
\begin{enumerate}
	\item Justifier que $f$ est de signe constant.
\end{enumerate}
On supposera que $f>0$ quitte à changer $f$ en $-f$.
\begin{enumerate}[resume]
	\item Justifier que $f$ est concave.
	\item En déduire que $f$ est constante sur $\R$.
	\item Conclure.
\end{enumerate}

\section{Solution qui s'annule une infinité de fois}
\label{Solution qui s'annule une infinité de fois}
\textcolor{blue}{\hyperref[sec:solution-qui-sannule-une-infinite-de-fois]{[Corrigé]}}\\
Soient $p$ une application continue périodique non identiquement nulle de $\R$ dans $\R_+$ et $f$ une solution de l'équation différentielle $y''+qy=0$. 
\\Montrer que $f$ s'annule une infinité de fois sur $\R_+$.

\section{Lemme de Grönwall}
\textcolor{blue}{\hyperref[sec:lemme-de-gronwall]{[Corrigé]}}\\
\label{Lemme de Gröwall}
\begin{enumerate}[leftmargin=*]
	\item Soient $\varphi,\psi$ et $y$ trois fonctions continues sur un segment $[a,b]$, à valeurs positives et vérifiant l'inégalité: $$\forall t\in[a,b],\quad y(x)\leq \psi(x)+\int_a^x y(t)\varphi(t)dt$$
	\\Montrer que: $$\forall x\in[a,b], \quad y(x)\leq\psi(x)+\int_a^x\psi(t)\varphi(t)\exp\left(\int_t^x\varphi(u)du\right)dt$$
	\item Quelle inégalité obtient-on lorsque $\psi$ est une fonction constante égal à $c\in\R_+$.
\end{enumerate}

\subsection{Application du lemme de Grönwall}
Soit $q:\R_+\to\R$ une fonction de classe $\mathcal{C}^1$, strictement positive et croissante.
\\Montrer que que toutes les solutions de l'équation différentielle $(E):y''+qy=0$ sont bornées sur $\R_+$.

\section{Théorème de Floquet}
\textcolor{blue}{\hyperref[sec:theoreme-de-floquet]{[Corrigé]}}\\
\label{Théorème de Floquet}
On considère un système différentielle sur $\C^n$, $(E):Y'=AY$ où $A:\R\to\M_n(\C)$ est une fonction continue et $T$-périodique.
\begin{enumerate}
	\item Montrer que $(E)$ admet une solution $V$ non nulle telle que: $$\exists \lambda\in\C,\forall t\in\R, \quad V(t+T)=\lambda V(t).$$
	\item On considère $n$ solutions $V_1,\dots,V_n$ de $(E)$ linéairement indépendantes. En notant $M(t)$ la matrice carrée dont les vecteurs colonnes sont $V_1,\dots,V_n$, montrer que : $$\exists C\in \text{GL}_n(\C),\forall t\in\R,\quad M(t+T)=M(t)C$$ 
\end{enumerate}

\section{Méthode de Lagrange (1)}
\textcolor{blue}{\hyperref[sec:methode-de-lagrange-1]{[Corrigé]}}\\
\label{Méthode de Lagrange 1}
On étudie l'équation différentielle suivante sur $]0,+\infty[$,$$(E):xy''+3y'-4x^3y=0$$
\begin{enumerate}
	\item Chercher une solution $\varphi$ développable en série entière au voisinage de $0$ et non nulle.
	\item Terminer de résoudre l'équation par le changement de fonction inconnue $y(x)=\varphi(x)z(x)$.
\end{enumerate}

\section{Méthode de Lagrange (2)}
\textcolor{blue}{\hyperref[sec:methode-de-lagrange-2]{[Corrigé]}}\\
\label{Méthode de Lagrange 2}
On fixe un entier $n\geq 2$ et on introduit l'équation différentielle sur $]1,+\infty[$,
$$(E_n):x(x-1)y''+(1-2x)y'+n(n-1)y=0$$
\begin{enumerate}
	\item Chercher une solution $\varphi$ de $(E_n)$ développable en série entière en $0$.
	\item Résoudre $(E_n)$ en effectuant le changement de fonction inconnue $y(x)=\varphi(x)z(x)$.
	\item Déterminer les polynômes $P\in \C[X]$ qui vérifient $P''|P$.
\end{enumerate}

\section{Equation différentielle matricielle non linéaire}
\label{Equation différentielle matricielle non linéaire}
\textcolor{blue}{\hyperref[sec:equation-differentielle-matricielle-non-lineaire]{[Corrigé]}}\\
Soit $A_0\in\mathcal S_n(\R)$ à spectre dans $\R_-$.
\\Dans $\M_n(\R)$, on considère le système différentiel $(E):\begin{cases}
	A'(t)=A(t)^2 \\
	A(0)=A_0
\end{cases}$.\\
Montrer que la solution $t\mapsto A(t)$ tend vers une limite finie en $+\infty$, à préciser.

\section{Système dynamique}
\textcolor{blue}{\hyperref[sec:systeme-dynamique]{[Corrigé]}}\\
\label{Système dynamique}
Soit $n\in \N^*$. Soient $A:\R\to\M_n(\R)$ de classe $\mathcal C^1$ et $B:\R\to \M_n(\R)$ vérifiant :
$$\forall t\in \R,\ A'(t)=A(t)B(t)-B(t)A(t)$$
\begin{enumerate}
	\item On suppose que $B$ est constante égale à $B_0$.\\
	Montrer que $\chi_{A(t)}$ est indépendant de $t$.
	\item Montrer que $\chi_{A(t)}$ est indépendant de $t$.
\end{enumerate}

\section{Solutions de norme constante \etoile{3}}
\textcolor{blue}{\hyperref[sec:solutions-de-norme-constante-etoile3]{[Corrigé]}}\\
\label{Solutions de norme constante}
On munit $\M_n(\R)$ de sa structure euclidienne canonique et on se donne $A\in \M_n(\R)$. Montrer que les solutions de l'équation différentielle $X'=AX,\ X\in \M_{n,1}(\R)$ sont toutes de norme constante si et seulement si $A$ est antisymétrique.

\section{Exponentielles de matrices qui commutent \etoile{2}}
\textcolor{blue}{\hyperref[sec:exponentielles-de-matrices-qui-commutent-etoile2]{[Corrigé]}}\\
\label{Exponentielles de matrices qui commutent}
Soient $A$ et $B$ deux matrices de $\M_n(\K)$ qui commutent. \\
On définit les applications $\fonction{f_A}{\R}{\M_n(\K)}{t}{e^{tA}}$ et $\fonction{g}{\R}{\M_n(\K)}{t}{e^{t(A+B)}e^{-tB}}$
\begin{enumerate}
	\item Montrer que l'application $f_A$ et l'application $g$ sont solutions d'un même problème de Cauchy. En déduire une démonstration de la relation: $$\forall t\in\R, \quad e^{t(A+B)}=e^{tA}e^{tB}$$
	\item Réciproquement, montrer que si $\forall t\in\R, \quad e^{t(A+B)}=e^{tA}e^{tB}$ alors $A$ et $B$ commutent.
\end{enumerate}

\section{Lemme de Hochshild}
\textcolor{blue}{\hyperref[sec:lemme-de-hochshild]{[Corrigé]}}\\
\label{Lemme de Hochsild}
On note $E=\mathcal C^\infty(\R,\R)$ et pour tout $f\in E,\ V_f=\Vect(x\mapsto f(x+a),\ a\in \R)$.\\
Déterminer les fonctions $f\in E$ telles que $V_f$ soit de dimension finie.

\newpage
\chapter{Calcul Différentiel}
\section{Calcul de dérivées partielles}
\textcolor{blue}{\hyperref[sec:calcul-de-derivees-partielles-1]{[Corrigé]}}\\
\label{Calcul de dérivées partielles 1}
Soit $f$ une application de classe $\mathcal{C}^1$ sur $\R^2$. Calculer les dérivées partielles des fonctions suivantes en fonction des dérivées partielles de $f$.
\begin{itemize}
	\item $g(x,y)=f(y,x)$
	\item $g(x)=f(x,x)$
	\item $g(x,y)=f(y,f(x,x))$
	\item $g(x)=f(x,f(x,x))$
\end{itemize}

\section{Existence de dérivées partielles}
\label{Existence de dérivées partielles}
Etudier l'existence de dérivées partielles pour les fonctions suivantes.
\begin{itemize}
	\item $f(x,y)=\max(|x|,|y|)$
	\item $f(x,y)=|x|+|y|$
	\item $f(x,y)=\begin{cases}
		\displaystyle\frac{\sin(x^2)+\sin(y^2)}{\sqrt{x^2+y^2}}&\mbox{si }(x,y)\ne(0,0)\\
		\ \ \ \ \ \ \ \ \ \ \ 0&\mbox{si } (x,y)=(0,0)
	\end{cases}$
\end{itemize}

\section{Etude d'une fonction}
\label{Etude d'une fonction}
Soit $f:\R^2\mapsto\R$ définie par $f(x,y)=\begin{cases}(x^2+y^2)\displaystyle\sin\left(\frac{1}{\sqrt{x^2+y^2}}\right) &\text{si } (x,y)\ne(0,0) \\ \ \ \ \ \ \ \ \ \ \ \ \ 0 & \text{sinon}\end{cases}$
\begin{enumerate}
	\item Etudier la continuité de $f$.
	\item \begin{enumerate}
		\item Prouver l'existence de dérivées partielles premières de $f$ sur $\R^2$.
		\item Etudier la continuité des dérivées partielles premières de $f$.
		\item La fonction $f$ est-elle de classe $\mathcal{C}^1$ sur $\R^2$? 
	\end{enumerate}
\end{enumerate}

\section{Une équation fonctionnelle \etoile{2}}
\label{Une équation fonctionnelle}
\textcolor{blue}{\hyperref[sec:une-equation-fonctionnelle-etoile2]{[Corrigé]}}\\
Le but de cet exercice est de déterminer les fonctions $f$ de classe $\mathcal{C}^2$ sur $\R$ solutions de l'équation: \begin{equation}
	\forall (x,y)\in\R^2, f(x+y)+f(x-y)=2f(x)f(y)
	\label{*}
\end{equation}
\begin{enumerate}
	\item Déterminer les solutions constantes de \eqref{*}.
	\item Soit $f$ une solution non constamment nulle de \eqref{*}.
	\begin{enumerate}
		\item Montrer que $f(0)=1$ et $f'(0)=0$.
		\item Montrer que $f$ est une fonction paire.
	\end{enumerate}
	\item Soit $f$ une fonction de classe $\mathcal{C}^2$. on considère la fonction $F$ définie sur $\R^2$ par $$\forall(x,y)\in\R^2, F(x,y)=f(x+y)+f(x-y)$$
	\begin{enumerate}
		\item Justifier que $F$ est de classe $\mathcal{C}^2$.
		\item Calculer les dérivées partielles secondes de $F$.
		\item On suppose que $f$ est une solution non constamment nulle de \eqref{*}. Des expressions des dérivées partielles de $F$, déduire que $f$ vérifie une équation différentielle de la forme $z''-\alpha z=0$.
		\item Donner les solutions de l'équation différentielle $z''-\alpha z=0$ suivant les valeurs de $\alpha$.
	\end{enumerate}
	\item Déterminer toutes les solutions de \eqref{*}.
\end{enumerate}

\section{Application linéaire}
\label{Application linéaire}
\textcolor{blue}{\hyperref[sec:application-lineaire]{[Corrigé]}}\\
Soit $f:E\mapsto F$ une fonction différentiable en 0 vérifiant $f(\lambda x)=\lambda f(x)$ pour tout $\lambda\in\R$ et tout $x\in E$.
\\ Montrer que l'application $f$ est linéaire.

\section{Opérateurs vectoriels}
\label{Opérateurs vectoriels}
\textcolor{blue}{\hyperref[sec:operateurs-vectoriels]{[Corrigé]}}\\
Pour $f=(f_1,\dots,f_n)$ un \textit{champ vectoriel} différentiable, c'est à dire une application de $\R^n$ dans $\R^n$ différentiable, on définit la \textbf{divergence} de $f$ par :
$$\operatorname{div}(f)=\sum_{i=1}^n\partial_if_i$$
Pour $f=(f_1,f_2,f_3)$ un champ vectoriel de $\R^3$ dans $\R^3$ différentiable, on définit le \textbf{rotationnel} de $f$ par :
$$\operatorname{rot}(f)=\left(\dpartial{f_z}{2}{y}-\dpartial{f_y}{2}{z},\dpartial{f_x}{2}{z}-\dpartial{f_z}{2}{x},\dpartial{f_y}{2}{x}-\dpartial{f_x}{2}{y}\right)$$
Pour $f$ une application de $\R^n$ dans $\R$ de classe $\mathcal C^2$, on définit le \textbf{laplacien} de $f$ par :
$$\Delta f=\sum_{i=1}^n\partial_i^2f$$
\begin{enumerate}
	\item  Soit $f$ une application de classe $\mathcal C^2$ de $\R^n$ dans $\R$. Montrer que
	$$\operatorname{div}(\nabla f)=\Delta f$$
	\item Soit $f$ une application de classe $\mathcal C^2$ de $\R^3$ dans $\R$. Montrer que
	$$\operatorname{rot}(\nabla f)=0$$
	\item Soit $f=(f_x,f_y,f_z)$ une application de classe $\mathcal C^2$ de $\R^3$ dans $\R^3$. Montrer que
	$$\operatorname{rot}(\operatorname{rot}f)=\nabla(\operatorname{div}f)-\Delta f_x-\Delta f_y-\Delta f_z$$
\end{enumerate}

\section{Laplacien en polaires}
\label{Laplacien en polaires}
\textcolor{blue}{\hyperref[sec:laplacien-en-polaires]{[Corrigé]}}\\
Soit $f:\R^2\mapsto\R$ de classe $\mathcal{C}^2$. On appelle \textit{laplacien} de $f$ l'application $\Delta f =\displaystyle\frac{\partial^2 f}{\partial x^2}+\frac{\partial^2 f}{\partial y^2}$.
\\Donner une expression du laplacien en coordonnées polaires.

\section{Fonction harmonique}
\label{Fonction harmoinique}
\textcolor{blue}{\hyperref[sec:fonction-harmonique]{[Corrigé]}}\\
Soit $U$ un ouvert connexe par arcs de $\R^n$. On dit qu'une fonction $f$ de classe $\mathcal{C}^2$ sur $U$ à valeurs dans $\R$ est harmonique si $\Delta f=0$ sur $U$.
\\ Montrer que si $f$ et $f^2$ sont harmoniques sur $U$, alors $f$ est constante sur $U$.

\section{Mines ponts MP 2016}
\label{Mines ponts MP 2016}
\textcolor{blue}{\hyperref[sec:mines-ponts-mp-2016]{[Corrigé]}}\\
On se donne $R\in\R_+^*$ et on définit $U=\{(x,y)\in\R^2, x^2+y^2<R^2\}$. Soit $f$ une fonction harmonique sur $U$. On définit également $$\fonction{F}{]-R,R[\times \R}{\R}{(r,\theta)}{f(r\cos(\theta),r\sin(\theta))}$$
\begin{enumerate}
	\item Trouver une relation entre les dérivées partielles de $F$ et $f$.
	\item Soit $n\in\Z$. On définit $$\fonction{\varphi_n}{]-R,R[}{\R}{r}{\displaystyle\int_0^{2\pi}F(r,\theta)e^{-in\theta}d\theta}$$
	\\Trouver une équation différentielle vérifiée par $\varphi_n$ et la résoudre. En déduire $\varphi_n$.
\end{enumerate}

\section{Différentielle de l'exponentielle matricielle}
\label{Différentielle de l'exponentielle matricielle}
\textcolor{blue}{\hyperref[sec:differentielle-de-la-norme-euclidienne]{[Corrigé]}}\\
Soit $M:\R\mapsto\M_n(\R)$ dérivable telle que pour tout $(s,t)\in\R^2$, $M(s)$ et $M(t)$ commutent.
\begin{enumerate}
	\item Justifier que $M\in\M_n(\R)$ est différentiable en 0 et calculer sa différentielle en 0.
	\item En déduire que $\varphi:t\in\R\mapsto \exp(A(t))$ est dérivable sur $\R$ et que: $$\forall t\in\R, \varphi'(t)=A'(t)\exp(A(t))=\exp(A(t))A'(t)$$
\end{enumerate}

\section{Différentielle de la norme euclidienne}
\label{Différentielle de la norme euclidienne}
\textcolor{blue}{\hyperref[sec:differentielle-de-la-norme-euclidienne]{[Corrigé]}}\\
Soit $(E,\langle\ ,\ \rangle)$ un espace euclidien. On pose $f:x\in E\mapsto\norme{x}^2$ où $\norme{.}$ désigne la norme associée à $\langle\ ,\ \rangle$.\\
Montrer que $f$ est différentiable sur $E$ et calculer la différentielle de $f$ en tout point $a\in E$.

\section{Différentielle de l'inversion matricielle}
\textcolor{blue}{\hyperref[sec:differentielle-de-linversion-matricielle]{[Corrigé]}}\\
\label{Différentielle de l'inversion matricielle}
On considère $\M_n(\R)$ muni d'une norme $\norme{.}$ sous-multiplicative.
\begin{enumerate}
	\item Soit $H\in\M_n(\R)$ telle que $\norme{H}<1$. Montrer que $I_n-H$ est inversible, d'inverse $\displaystyle\sum\limits_{n=0}^{+\infty}H^n$.
	\item Montrer que GL$_n(\R)$ est ouvert dans $\M_n(\R)$.
	\item Soit $f:M\in \text{GL}_n(\R)\mapsto M^{-1}$.
	\begin{enumerate}[label=\alph*.]
		\item Montrer que $f$ est différentiable en $I_n$ et que $df(I_n)\cdot H=-H$.
		\item Montrer que $f$ est différentiable en tout point de GL$_n(\R).$ On remarquera que $(M+H)^{-1}=(M(I_n+M^{-1}H))^{-1}$.
	\end{enumerate}
\end{enumerate}

\section{Gradient et différentielle du déterminant}
\label{Gradient et différentielle du déterminant}
\textcolor{blue}{\hyperref[sec:gradient-et-differentielle-du-determinant]{[Corrigé]}}\\
On munit $\M_n(\R)$ de son produit scalaire usuel $(A,B)\mapsto\Tr(A^\top B)$.
Déterminer le gradient et la différentielle de l'application $\det:M\in \M_n(\R)\mapsto\det(M)$.

\section{Espace tangent aux matrices orthogonales en l'identité}
\label{Espace tangent aux matrices orthogonales en l'identité}
\textcolor{blue}{\hyperref[sec:espace-tangent-aux-matrices-orthogonales-en-lidentite]{[Corrigé]}}\\
Montrer que l'ensemble des vecteurs tangents à l'ensemble des matrices orthogonales en la matrice identité $T_{I_n}(\O_n(\R))$ est l'ensemble des matrices antisymétriques réelles.

\section{Vecteur propre d'un endomorphisme auto-adjoint}
\label{Vecteur propre d'un endomorhpsime auto-adjoint}
\textcolor{blue}{\hyperref[sec:vecteur-propre-dun-endomorphisme-auto-adjoint]{[Corrigé]}}\\
Soit $f$ un endomorphisme auto-adjoint d'un espace euclidien $E$ de dimension finie non nulle.
\\ Pour tout $x\in E \setminus\{0\}$, on pose $\varphi(x)=\displaystyle\frac{\langle f(x),x \rangle}{\norme{x}^2}$
\\ On n'utilisera pas le théorème spectral dans tout cet exercice.
\begin{enumerate}
	\item Calculer le gradient de $\varphi$ en tout point de $E\setminus \{0\}$.
	\item Montrer que $x\in E\setminus \{0\}$ est un vecteur de $f$ si et seulement $\nabla \varphi(x)=0$.
	\item Montrer que $\varphi$ admet un maximum sur $E\setminus \{0\}$.
	\item En déduire que $f$ admet un vecteur propre.
\end{enumerate}

\section{Quotient de Rayleigh}
\label{Quotient de Rayleigh}
\textcolor{blue}{\hyperref[sec:quotient-de-rayleigh]{[Corrigé]}}\\
On munit $\R^n$ de sa structure euclidienne canonique.
\\ Soient $A\in\M_n(\R)$ une matrice symétrique et $f_A: \R^n\mapsto \R$ définie par $f_A(x)=x^\top Ax$.
\begin{enumerate}
	\item Calculer les dérivées partielles de $f_A$ et exprimer $\nabla f_A (x)$ en fonction de $Ax$ pour tout $x\in \R^n.$
	\item Pour $x\in\R^n$ non nul, on introduit le \textit{quotient de Rayleigh}: $R(x)=\displaystyle\frac{x^\top Ax}{x^\top x}$.
	\\Montrer que $x$ est vecteur propre de A, si et seulement si $\nabla R(x)=0$.
\end{enumerate}

\section{Différentielle du déterminant}
\label{Différentielle du déterminant}
\textcolor{blue}{\hyperref[sec:differentielle-du-determinant]{[Corrigé]}}\\
\begin{enumerate}
	\item Montrer que l'application $\det:A\mapsto \det(A)$ est différentiable sur $\M_n(\R)$.
	\item Calculer sa différentielle en commençant par évaluer ses dérivées partielles.
	\item On munit $\M_n(\R)$ du produit scalaire canonique.
	\\Déterminer le vecteur gradient de $\det$ en $A$
\end{enumerate}

\section{Equation de d'Alembert}
\label{Equation de d'Alembert}
\textcolor{blue}{\hyperref[sec:equation-de-dalembert]{[Corrigé]}}\\
Soit $c\ne0$. chercher les solutions de classe $\mathcal{C}^2$ de l'équation aux dérivées partielles suivantes: $$\frac{\partial^2f}{\partial x^2}=\frac{1}{c^2}\frac{\partial^2f}{\partial t^2}$$
à l'aide d'un changement de variable de la forme $u=x+at,v=x+bt$.

\section{Utilisation des extrema liés (1)}
\label{Utilisation des extrema liés 1}
\textcolor{blue}{\hyperref[sec:utilisation-des-extremas-lies-1]{[Corrigé]}}\\
Soit $f:(x,y)\in\R^2\mapsto xy$. Déterminer le minimum et le maximum éventuels de $f$ sur $S=\{(x,y)\in\R^2,x^2+y^2=1\}$.

\section{Utilisation des extrema liés (2)}
\label{Utilisation des extrema liés 2}
\textcolor{blue}{\hyperref[sec:utilisation-des-extremas-lies-2]{[Corrigé]}}\\
Etudier mes extrema globaux de $f:(x,y)\mapsto 2x-y$ sous la contrainte $g(x,y)=x^2+xy+y^2-1=0$.

\section{Utilisation des extrema liés (3)}
\label{Utilisation des extrema liés 3}
\textcolor{blue}{\hyperref[sec:utilisation-des-extremas-lies-3]{[Corrigé]}}\\
Montrer que pour tous les $(x,y,z)\in (\R_+)^3$ tels que $x+y+z=\displaystyle\frac{\pi}{2}$,
$$\sin(x)\sin(y)\sin(z)\leq \frac{\pi}{8}$$

\section{Sinus complexe}
\label{Sinus complexe}
\textcolor{blue}{\hyperref[sec:sinus-complexe]{[Corrigé]}}\\
On pose: $\forall z\in\C,\ \sin(z)=\displaystyle\frac{e^{iz}-e^{-iz}}{2i}$.
\begin{enumerate}
	\item Exprimer $|\sin(z)|^2$ en fonction de $\operatorname{Re}(z)$ et $\operatorname{Im}(z)$.
	\item Déterminer $\max\limits_{|z|\leq 1}|\sin(z)|$.
\end{enumerate}

\section{Entropie}
\label{Entropie}
\textcolor{blue}{\hyperref[sec:entropie]{[Corrigé]}}\\
Soit un entier $n\geq 2$. On pose $$\forall(x_1,\dots,x_n)\in(\R^*_+)^n,f(x_1,\dots,x_n)=-\sum\limits_{i=0}^n x_i\ln(x_i)$$
\\On note $$C=\left\{(x_1,\dots,x_n)\in(\R^*_+)^n,\sum\limits_{i=0}^n x_i=1\right\}$$
\begin{enumerate}
	\item Justifier que $f$ admet un maximum sur $C$.
	\item Déterminer la valeur de ce maximum et le point où il est atteint.
\end{enumerate}

\section{Fonction convexe sur $\R^n$}
\label{Fonction convexe sur R^n}
\textcolor{blue}{\hyperref[sec:fonction-convexe-sur-rn]{[Corrigé]}}\\
On considère une fonction $f:\R^n\to\R$.
\begin{enumerate}
	\item Pour tous $x,y\in\R^n$, soit $\varphi_{x,y}:\R\to\R$ la fonction définie par $$\forall t\in\R,\quad \varphi_{x,y}(t)=f(x+t(y-x))$$
	Montrer que f est convexe si seulement si pour tous $x,y\in\R^n$, la fonction $\varphi_{x,y}$ est convexe.
	\item On suppose que $f$ est différentiable sur $\R^n$. Montrer que pour tout $x,y\in\R^n$, la fonction $\varphi_{x,y}$ est dérivable, et montrer que $$\forall t\in\R, \varphi_{x,y}'(t)=\langle\nabla f(x+t(y-x)),y-x\rangle$$
	\item En déduire que si $f$ est différentiable sur $\R^n$, alors $f$ est convexe si et seulement si pour tous $x,y\in\R^n$, $$f(y)\geq f(x)+\langle \nabla f(x),y-x\rangle$$
	\item Montrer que si $f:\R^n\to\R$ est différentiable sur $R^n$, alors $f$ est convexe si et seulement pour tous $x,y\in\R^n$, $$\langle\nabla f(y)-\nabla f(x),y-x\rangle\geq 0$$
\end{enumerate}

\section{Chemin le plus court entre deux points}
\label{Chemin le plus court entre deux points}
\textcolor{blue}{\hyperref[sec:chemin-le-plus-court-entre-deux-points]{[Corrigé]}}\\
On utilisera les résultats de \ref{Fonction convexe sur R^n}.\\
Soient $a,b,\alpha,\beta \in\R$, avec $a<b$. On pose $F=\{f\in\mathcal{C}^1([a,b]), \; f(a)=\alpha, \, f(b)=\beta\}$.
\\ Montrer que $\displaystyle \min_{f\in F}\int_a^b \sqrt{1+f'(x)^2}dx$ est atteint par une unique fonction affine de $F$.


\section{Fonction homogène}
\label{Fonction homogène}
\textcolor{blue}{\hyperref[sec:fonction-homogene]{[Corrigé]}}\\
Soient $f\in\mathcal{C}^1(\R^2,\R)$ et $\alpha\in\R$. On dit que $f$ est \textit{homogène de degré} $\alpha$ si $$\forall (x,y)\in\R^2, \forall t>0, f(tx,ty)=t^{\alpha}f(x,y)$$
\begin{enumerate}
	\item Montrer que $f$ est homogène de degré $\alpha$ si et seulement si $$\forall (x,y)\in\R^2, x\frac{\partial f}{\partial x}(x,y)+y\frac{\partial f}{\partial y}(x,y)=\alpha f(x,y)$$
	\item Montrer que si $f$ est de degré $\alpha$, les dérivées partielles de $f$ sont également homogènes et préciser leurs degré.
\end{enumerate}

\section{Problème de Dirichlet et principe faible du maximum}
\label{Problème de Dirichlet et principe faible du maximum}
\textcolor{blue}{\hyperref[sec:probleme-de-dirichlet-et-principe-du-maximum]{[Corrigé]}}\\
Soient $U$ un ouvert borné non vide de $\R^n$. On note $\partial U=\overline{U}\setminus \overset{\circ}{U}$ la frontière de $U$.
On se donne une fonction $f$ à valeurs réelles continue sur $\overline{U}$ et de classe $\mathcal{C}^2$ sur $U$. On pose alors: $$\forall x\in U, \Delta f(x)=\displaystyle\sum\limits_{i=1}^n\frac{\partial^2 f}{\partial x_i^2}(x)$$
\begin{enumerate}
	\item Montrer que $f$ admet un maximum sur $\overline{U}$. On note alors $\overline{x}$ un point de $\overline{U}$ où ce maximum est atteint.
	\item On suppose que $\Delta f>0$ sur $U$. Montrer que $\overline{x}\in\partial U$.
\end{enumerate}
A partir de maintenant, on suppose $\Delta f=0$ sur $U$.
\begin{enumerate}[resume]
	\item On se donne $\varepsilon >0$ et on pose: $$\forall x\in \overline{U}, f_{\varepsilon}(x)=f(x)+\varepsilon\displaystyle\sum\limits_{i=1}^nx_i^2$$
	Montrer que $f_\varepsilon$ est continue sur $\overline{U}$ de classe $\mathcal{C}^2$ sur $U$ et que $\Delta f_{\varepsilon}>0$ sur $U$.
	\item En déduire que le maximum de $f$ sur $\overline{U}$ est atteint sur $\partial U$.
	\item Soient $f_1$ et $f_2$ deux fonctions continues sur $\overline{U}$, de classe $\mathcal{C}^2$ sur $U$ et vérifiant $\Delta f_1=\Delta f_2$ sur $U$. On supposera en outre que $f_1=f_2$ sur $\partial U$. Montrer que $f_1=f_2$ sur $U$.
\end{enumerate}

\section{La méthode des moindres carrés}
\label{La méthode des moindres carrés}
\textcolor{blue}{\hyperref[sec:la-methode-des-moindres-carres]{[Corrigé]}}\\
Etant donné un nuage de points $(x_i,y_i)_{0\leq i\leq n}$ la droite des moindres carrés (ou droite de régression linéaire) est la droite d'équation $y=mx+p$ qui minimise la quantité: $$F(m,p)=\displaystyle\sum\limits_{i=1}^n(y_i-mx_i-p)^2$$
\begin{enumerate}
	\item Démontrer que $(m,p)$ est un couple où ce minimum est atteint, alors $(m,p)$ est solution du système: $$\begin{cases}
		\sum\limits_{i=1}^n(y_i-mx_i-p)=0 & \\
		\sum\limits_{i=1}^nx_i(y_i-mx_i-p)=0 &
	\end{cases}$$
	\item On note $\overline{x}$ et $\overline{y}$ les valeurs moyennes respectives de $(x_i)$ et $(y_i)$. Démontrer que si $\displaystyle\sum\limits_{i=1}^n(x_i-\overline{x})^2\ne0$ alors il existe au plus une droite des moindres carrés, avec $$m=\frac{\displaystyle\sum\limits_{i=1}^n(x_i-\overline{x})(y_i-\overline{y})}{\sum\limits_{i=1}^n(x_i-\overline{x})^2}$$
	\item On veut démontrer prouver l'exister d'une droite des moindres carrés, toujours sous la condition $\displaystyle\sum\limits_{i=1}^n(x_i-\overline{x})^2\ne0$
	\begin{enumerate}[label=\alph*.]
		\item Pourquoi suffit-il de prouver que $\lim\limits_{\norme(m,p)\to +\infty}F(m,p)=+\infty$ ?
		\item Démontrer que $$F(m,p)=\displaystyle\sum\limits_{i=1}^n u_i^2(m,p)+v(m,p)+c$$ où $u_1,\dots,u_n,v$ sont des formes linéaires sur $\R^2$ et $c\in \R$.
		\item Démontrer que le rang de $(u_1,\dots u_n)$ est 2.
		\item On suppose que $(u_1,\dots, u_n)$ sont indépendantes. Justifier que l'on peut écrire: $$F(m,p)=u_1^2(m,p)+au_1(m,p)+u_2^2(m,p)+bu_2(m,p)+c+R(m,p)$$
		où $a,b,c \in \R$ et $R(m,p)\geq 0$.
		\item Justifier que $\norme{(m,p)}\to+\infty \Longrightarrow |u_1(m,p)|+|u_2(m,p)|\to+\infty$.
		\item Conclure.
	\end{enumerate}
\end{enumerate}

\section{Equation de la chaleur}
\label{Equation de la chaleur}
\textcolor{blue}{\hyperref[sec:equation-de-la-chaleur]{[Corrigé]}}\\
On se place dans le plan $\R^2$ dont les éléments sont notés $(x,t)$. Pour tout $T>0$, on note:
\begin{itemize}
	\item $R_T=]0,\pi[\times]0,T[$
	\item $C_T=(\{0\}\times[0,T])\cap([0,\pi]\times\{0\})\cap(\{\pi\}\times[0,T])$
	\item $\Lambda_T=]0,\pi[\times\{T\}$.
\end{itemize}
de sorte que $R_T,C_T$ et $\Lambda_T$ soient disjoints et que leur réunion soit le rectangle fermé $\overline{R_T}$.
\begin{enumerate}
	\item Soit $\varphi:[0,\pi]\to\R$ une fonction de classe $\mathcal C^1$, telle que $\varphi(0)=\varphi(\pi)=0$.
	\begin{enumerate}[label=\alph*.]
		\item Montrer l'existence d'une suite réelle $(b_n)_{n\in \N}$ telle que $\displaystyle\sum_{n\in \N}|b_n|$ converge et telle que $$\forall x\in[0,\pi], \varphi(x)=\displaystyle\sum\limits_{n=0}^{+\infty}b_n\sin(nx).$$
		\item Soit $T_0>0$. Construire une fonction $\Phi$ continue sur $\overline{R_{T_0}}$ telle que:
		\begin{enumerate}[label=(\roman*)]
			\item $\varphi$ est de classe $\mathcal C^2$ sur $R_{T_0}$ et $\displaystyle\frac{\partial^2\Phi}{\partial x^2}-\frac{\partial \Phi}{\partial t}=0$ sur $R_{T_0}$;
			\item pour tout $t\in[0,T_0]$, $\Phi(0,t)=\Phi(\pi,t)=0$
			\item pour tout $x\in [0,\pi]$, $\Phi(x,0)=\varphi(x)$.
		\end{enumerate}
		\item On veut montrer qu'il existe qu'une seule fonction $\Phi$ vérifiant (i),(ii) et (iii). Soit $f$ une fonction à valeurs réelles, continue sur $\overline{R_{T_0}}$ et de classe $\mathcal C^2$ sur $R_{T_0}$.
		\begin{enumerate}
			\item On suppose $\displaystyle\frac{\partial^2f}{\partial x^2}-\frac{\partial f}{\partial t}>0$ sur $R_{T_0}$, montrer que $f$ atteint son maximum sur $C_{T_0}$ (on pourra commencer par prouver le résultat sur $R_T$ et $C_T$ pour tout $T\in]0,T_0[$).
			\item On suppose $\displaystyle\frac{\partial^2f}{\partial x^2}-\frac{\partial f}{\partial t}\geq0$ sur $R_{T_0}$, montrer que $f$ atteint son maximum sur $C_{T_0}$.
			\item On suppose $f$ nulle sur $C_{T_0}$ et $\displaystyle\frac{\partial^2f}{\partial x^2}-\frac{\partial f}{\partial t}=0$ sur $R_{T_0}$, montrer que $f$ est nulle.
			\item En déduire que la fonction $\Phi$ construite à la question (1b) est la seule fonction vérifiant (i),(ii) et (iii).
		\end{enumerate}
	\end{enumerate}
\end{enumerate}

\newpage
\chapter{Divers}
\section{Développement décimal propre d'un réel \xens{3}}
\textcolor{blue}{\hyperref[sec:developpement-decimal-propre-dun-reel]{[Corrigé]}}\\
\label{Développement décimal propre d'un réel}
Démontrer que tout réel $x\in [0,1[$ s'écrit de manière unique $x=\displaystyle\sum_{n=1}^{+\infty}\frac{a_n}{10^n}$ avec $(a_n)_{n\in \N^*}$ une suite à valeurs dans $\crblanc{0}{9}$ qui ne stationne pas à $9$.

\subsection{Une caractérisation des rationnels \xens{3}}
Soit $x\in [0,1[$. Montrer que $x\in \Q$ si et seulement si son développement décimal propre est périodique à partir d'un certain rang.

\section{Distribution du premier chiffre des puissances de $2$ \xens{3}}
\textcolor{blue}{\hyperref[sec:distribution-du-premier-chiffre-des-puissances-de-2]{[Corrigé]}}\\
\label{Distribution du premier chiffre des puissances de 2}
Soit $i\in \crblanc{1}{9}$. On note $N_i(n)$ le nombre d'éléments de $\{2,2^2,\dots,2^n\}$ dont le premier chiffre dans l'écriture décimale est $i$. On note pour $x\in \R$, $\{x\}=x-\lfloor x\rfloor$ la partie fractionnaire de $x$.
\begin{enumerate}
	\item Montrer qu'en notant $\theta=\log_{10}(2)$, $N_i(n)$ est exactement le nombre d'entier $k\in \crblanc{1}{n}$ tels que $\{k\theta\}$ est dans $[\log_{10}(i),\log_{10}(i+1)[$.
	\item Montrer que la suite $(\{k\theta\})_{k\in \N^*}$ est dense dans $[0,1]$.
	\item En déduire qu'il existe une infinité de puissances de $2$ dont le premier chiffre est $i$.
\end{enumerate}

\section{Série de Engel}
\textcolor{blue}{\hyperref[sec:serie-de-engel]{[Corrigé]}}\\
\label{Série de Engel}
Soit $x\in ]0,1]$.
\begin{enumerate}
	\item Montrer qu'il existe une unique suite $(q_n)_{n\in \N}$ d'entiers naturels supérieurs ou égaux à $2$ telle que $x=\displaystyle\sum_{n=0}^{+\infty}\frac{1}{q_0q_1\dots q_n}$.
	\item Montrer que $x$ est rationnel si et seulement si la suite $(q_n)_{n\in \N}$ est stationnaire.
	\begin{enumerate}[label=\alph*.]
		\item En déduire que $e,\ch(1)$ et $\sh(1)$ sont irrationnels.
		\item En déduire que $e^{\sqrt 2}$, $\displaystyle\sum_{n=1}^{+\infty}\frac{1}{2^{n^2}}$ et $\sqrt[n]e$ pour $n\in \N^*$ sont irrationnels.
	\end{enumerate}
\end{enumerate}

\section{Théorème de Müntz}
\label{Théorème de Muntz}
\textcolor{blue}{\hyperref[sec:theoreme-de-muntz]{[Corrigé]}}\\
On admettra ou démontrera les résultats sur le déterminant de Gram (cf. IV-7 tome Algèbre) et sur le déterminant de Cauchy (cf. IV-8 tome Algèbre).\\
Soit $(\mathcal{C},\norme{}_2)$ l'espace des fonctions continues sur $[0,1]$, muni de la norme usuelle $\mathcal{L}^2$.\\
Soit $(\alpha_n)$ une suite strictement croissante de réels positifs.\\
Alors, on a l'équivalence :
\begin{itemize}
	\item $V:=\text{Vect}((x\mapsto x^{\alpha_n})_{n\in\N})$ est dense dans $\mathcal{C}$.
	\item La série $\displaystyle \sum\frac{1}{\alpha_n}$
\end{itemize}
\newpage
\chapter{Correction}

\section{Correction Suite et série numérique}\label{sec:correction-suite-et-serie-numerique}
	\subsection{Lemme de Césarò \etoile{2}}\label{sec:lemme-de-cesaro-etoile2}
	\textcolor{blue}{\hyperref[Lemme de Cesaro]{[Enoncé]}}\\
	Si $\ell\in \R$ alors $u_n-\ell\unfty{=}\smallo{1}$.\\
	Or $\displaystyle\sum\limits_{n\geq 0} 1$ diverge et $(1)_{n\in \N}$ est de signe constant APCR donc \[\displaystyle\sum\limits_{k=0}^n(u_k-\ell)=\displaystyle\sum\limits_{k=0}^nu_k-(n+1)\ell\unfty{=} \smallo{\displaystyle\sum\limits_{k=0}^n{1}}=\smallo{n+1}\]
	Ainsi, \[\displaystyle\frac{1}{n+1}\displaystyle\sum\limits_{k=0}^nu_k\unfty{\longrightarrow} \ell\]
	Supposons que $\ell=+\infty$.\\ Fixons $A\in \R_+^*$. $\exists n_0\in \N,\forall n>n_0,\ u_n\geq A+1$.\\
	Alors pour tout $n>n_0$, \[\displaystyle\frac{1}{n+1}\displaystyle\sum\limits_{k=0}^nu_k=\displaystyle\frac{1}{n+1}\left(\displaystyle\sum\limits_{k=0}^{n_0}u_k+\displaystyle\sum\limits_{k=n_0+1}^nu_k\right)\geq \displaystyle\frac{1}{n+1}\displaystyle\sum\limits_{k=0}^{n_0}u_k+\frac{(n-n_0)(A+1)}{n+1}\]
	Or $\displaystyle\frac{1}{n+1}\displaystyle\sum\limits_{k=0}^{n_0}u_k+\frac{(n-n_0)(A+1)}{n+1}\unfty{\longrightarrow} A+1$.\\ Donc $\exists n_1\in \N,\ \forall n>n_1,\ \displaystyle\frac{1}{n+1}\displaystyle\sum\limits_{k=0}^{n_0}u_k+\frac{(n-n_0)(A+1)}{n+1}\geq A$.\\
	Ainsi $\forall n>\max(n_0,n_1),\ \displaystyle\frac{1}{n+1}\displaystyle\sum\limits_{k=0}^nu_k\geq A$.\\ Donc $\displaystyle\frac{1}{n+1}\displaystyle\sum\limits_{k=0}^nu_k\unfty{\longrightarrow}+\infty$.\\\\
	Par le même raisonnement, si $\ell=-\infty$ alors $\displaystyle\frac{1}{n+1}\displaystyle\sum\limits_{k=0}^nu_k\unfty{\longrightarrow}-\infty$.
	
	\subsubsection{Lemme de l'escalier\etoile{1}}
	On remarque que $\displaystyle\frac{1}{n}\sum_{k=0}^{n-1}(u_{k+1}-u_k)=\frac{1}{n}(u_n-u_0)$
	\\Et d'après le lemme de Césarò: $\displaystyle\lim_{n\to+\infty}\frac{1}{n}\sum_{k=0}^{n-1}(u_{k+1}-u_k)=\ell$
	\\Ainsi: on a $\displaystyle\lim_{n\to+\infty}\frac{1}{n}(u_n-u_0)=\ell$.
	\\Par conséquent, on a bien: $u_n\sim\ell n$
	
	\subsection{Théorèmes Taubériens d'Hardy \etoile{1}}\label{sec:theoremes-tauberiens-dhardy-etoile1}
	\textcolor{blue}{\hyperref[Théorèmes Taubériens d'Hardy]{[Enoncé]}}\\
	Posons pour tout $n\in \N,\ u_n=(-1)^n$.\\
	$\forall n\in \N,\ \begin{cases}\sigma_{2n}=\displaystyle\frac{1}{2n+1}\\\sigma_{2n+1}=0\end{cases}$. Donc $\sigma_n\unfty{\longrightarrow}0$ alors que $(u_n)_{n\in \N}$ diverge.
	
	\subsubsection{Hardy Faible \etoile{2}}
	Soit $n\in \N$.\\
	$\displaystyle\sum_{k=0}^nk\varepsilon_k=\sum_{k=1}^nk(u_{k+1}-u_k)=\sum_{k=1}^n(ku_{k+1}-(k-1)u_k)-\sum_{k=1}^nu_k=nu_{n+1}-\sum_{k=1}^nu_k$.\\
	Donc $(n+1)\sigma_n-u_0=\displaystyle\sum_{k=1}^nu_k=nu_{n+1}-\sum_{k=1}^nk\varepsilon_k$ \\d'où $\forall n\geq 2,\ u_n=\displaystyle\frac{n}{n-1}\sigma_{n-1}+\frac{1}{n-1}\sum_{k=0}^{n-1}k\varepsilon_k-\frac{u_0}{n-1}$.\\
	Or, $n\varepsilon_n\unfty{=}\smallo{1}$ et $\displaystyle\sum_{n\in \N}1$ diverge donc $\displaystyle\sum_{k=0}^{n-1}k\varepsilon_k\unfty{=}\smallo{\sum_{k=0}^{n-1}1}\unfty{=}\smallo{n}$.\\
	Ainsi, $u_n\unfty{=}\ell+\smallo{1}$, c'est à dire $u_n\unfty{\longrightarrow}\ell$.
	
	\subsubsection{Hardy Fort \etoile{3}}
	\begin{enumerate}[leftmargin=*]
		\item
		\begin{align*}
			\displaystyle\sum_{k=n}^{m-1}(m-k)\varepsilon_k&=\sum_{k=n}^{m-1}(m-k)(u_{k+1}-u_k)\\
			&=\sum_{k=n}^{m-1}\left[(m-k)u_{k+1}-(m-(k-1))u_k\right]+\sum_{k=n}^{m-1}u_k\\
			&=u_m-(m-n+1)u_n+\sum_{k=n}^{m-1}u_k\\
			&=\sum_{k=n+1}^mu_k-(m-n)u_n
		\end{align*}
		\item Soit $m$ et $n$ deux entiers supérieurs que $2$.\\
		$\displaystyle\left|\frac{(m+1)\sigma_m-(n+1)\sigma_n}{m-n}-u_n\right|=\left|\frac{1}{m-n}\sum_{k=m+1}^nu_k-u_n\right|=\left|\sum_{k=n}^{m-1}\frac{m-k}{m-n}\varepsilon_k\right|\leq\sum_{k=n}^{m-1}\frac{m-k}{m-n}|\varepsilon_k|$.\\
		Or $\varepsilon_n\unfty{=}\bigO{\displaystyle\frac{1}{n}}$ donc $\exists N\in \N,\ \exists C\in \R^*_+,\ \forall n\geq N,\ |n\varepsilon_n|\leq C$.\\
		Donc $\forall n\geq N$ \[\displaystyle\left|\frac{(m+1)\sigma_m-(n+1)\sigma_n}{m-n}-u_n\right|\leq \frac{C}{m-n}\sum_{k=n}^{m-1}\frac{m-k}{k}\leq\frac{C}{m-n}\sum_{k=n}^{m-1}\frac{m-n}{k}=C\sum_{k=n}^{m-1}\frac{1}{k}\]
		Or $\forall k\geq 2$ \[\forall t\in [k-1,k],\ \displaystyle\frac{1}{k}\leq\frac{1}{t}\implies \forall k\geq 2,\ \frac{1}{k}=\int_{k-1}^k\frac{dt}{k}\leq \int_{k-1}^k\frac{dt}{t}=\ln(k)-\ln(k-1)\]
		Ainsi $\forall n\geq N, \displaystyle\left|\frac{(m+1)\sigma_m-(n+1)\sigma_n}{m-n}-u_n\right|\leq C\sum_{k=n}^{m-1}(\ln(k)-\ln(k-1))=C\ln\left(\frac{m-1}{n-1}\right)$.\\
		Par conséquent si $n\geq N$ et $m<n$ sont deux entiers,
		\begin{align*}
			|u_n-\ell|&\leq \left|u_n-\frac{(m+1)\sigma_m-(n+1)\sigma_n}{m-n}\right|+\left|\frac{(m+1)\sigma_m-(n+1)\sigma_n}{m-n}-\ell\right|\\
			&\leq C\ln\left(\frac{m-1}{n-1}\right)+\frac{m+1}{m-n}\left|\sigma_m-\frac{n+1}{m+1}\sigma_n-\frac{m-n}{m+1}\ell\right|\\
			&\leq C\ln\left(\frac{m-1}{n-1}\right)+\frac{m+1}{m-n}\left|\sigma_m-\ell+\frac{n+1}{m+1}(\ell-\sigma_n)\right|\\
			&\leq C\ln\left(\frac{m-1}{n-1}\right)+\frac{m+1}{m-n}(|\sigma_m-\ell|+|\sigma_n-\ell|)
		\end{align*}
		\item Fixons $\varepsilon>0$. Soit $\alpha>1$. On prend $m=1+\lfloor\alpha n\rfloor>\alpha n>n$ dans l'inéquation précédente :\\
		$\forall n\geq N,\ |u_n-\ell|\leq\displaystyle C\ln\left(\frac{\lfloor\alpha n\rfloor}{n-1}\right)+\frac{\lfloor\alpha n\rfloor+2}{1+\lfloor\alpha n\rfloor-n}(|\sigma_{1+\lfloor\alpha n\rfloor}-\ell|+|\sigma_n-\ell|)$.\\
		Par définition de la partie entière, $\forall n\in \N^*,\ n\alpha-1<\lfloor n\alpha\rfloor\leq n\alpha$ Donc $\lfloor n\alpha\rfloor\unfty{\sim} n\alpha$.\\
		Ainsi par composition de limite, $\displaystyle\ln\left(\frac{\lfloor n\alpha\rfloor}{n-1}\right)\unfty{\longrightarrow}\ln(\alpha)$.\\ Aussi $1+\lfloor n\alpha\rfloor\unfty{\longrightarrow}+\infty$ donc $|\sigma_{1+\lfloor n\alpha\rfloor}-\ell|\unfty\longrightarrow 0$. \\Puis, $\displaystyle\frac{\lfloor n\alpha\rfloor+2}{1+\lfloor n\alpha\rfloor-n}\unfty=\frac{\alpha n+\smallo n+2}{1+\alpha n-n+\smallo n}\unfty=\frac{\alpha n+\smallo n}{(\alpha-1)n+\smallo n}\unfty\longrightarrow \frac{\alpha}{\alpha-1}$.\\
		Donc par produit $\displaystyle\frac{\lfloor\alpha n\rfloor+2}{1+\lfloor\alpha n\rfloor-n}(|\sigma_{1+\lfloor\alpha n\rfloor}-\ell|+|\sigma_n-\ell|)\unfty\longrightarrow 0$.\\
		On sait alors qu'il existe $M\in \N$ tel que \[\forall n\geq M,\displaystyle\ln\left(\frac{\lfloor\alpha n\rfloor}{n-1}\right)\leq \ln(\alpha)+\frac{\varepsilon}{4C} \text{ et }\displaystyle\frac{\lfloor\alpha n\rfloor+2}{1+\lfloor\alpha n\rfloor-n}(|\sigma_{1+\lfloor\alpha n\rfloor}-\ell|+|\sigma_n-\ell|)\leq \frac{\varepsilon}{2}\]
		Ainsi, $\forall n\geq \max(M,N),\ |u_n-\ell|\leq \displaystyle C\left(\ln(\alpha)+\frac{\varepsilon}{4C}\right)+\frac{\varepsilon}{2}$.\\
		Enfin, on prend $\alpha=1+\displaystyle\frac{\varepsilon}{4C}>1$ et on utilise $\displaystyle\ln\left(1+\frac{\varepsilon}{4C}\right)\leq \frac{\varepsilon}{4C}$. on obtient :\\
		$$\forall n\geq \max(M,N),\ |u_n-\ell|\leq \varepsilon$$
		C'est à dire $u_n\unfty\longrightarrow \ell$.
	\end{enumerate}
	
	\subsection{Série Harmonique \etoile{3}}\label{sec:serie-harmonique-etoile3}
	\textcolor{blue}{\hyperref[Série Harmonique]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item \underline{Première méthode :} Sommation de relations de comparaisons\\
		On remarque que $\ln(n+1)-\ln(n)=\ln\left(1+\displaystyle\frac{1}{n}\right)\underset{\nfty}{\sim}\displaystyle\frac{1}{n}$. \\O $(\ln(n+1)-\ln(n))_{n\in \N^*}$ est de signe constant APCR et $\displaystyle\sum\limits_{n\in \N^*}{\ln(n+1)-\ln(n)}$ diverge puisque de même nature que la suite $(\ln n)_{n\in \N^*}$. \\
		Donc $H_n\underset{\nfty}{\sim}\ln n$.\\\\
		\underline{Seconde méthode :} Comparaison série-intégrale\\
		Soit $n\in \N^*$.
		\begin{align*}
			&\forall t\in [n,n+1],\ \frac{1}{n+1}\leq \frac{1}{t}\leq \frac{1}{n}\\
			\implies&\int_n^{n+1}\frac{dt}{n+1}=\frac{1}{n+1}\leq \int_n^{n+1}{\frac{dt}{t}}\leq \frac{1}{n}=\int_n^{n+1}{\frac{dt}{n}}\\
			\implies&\sum\limits_{k=1}^{n-1}{\frac{1}{k+1}}\leq \sum\limits_{k=1}^{n-1}{\ln(k+1)-\ln(k)}\leq\sum\limits_{k=1}^{n-1}{\frac{1}{k}}\\
			\implies&H_n-1\leq \ln n\leq H_n-\frac{1}{n}\\
			\implies&\ln n+\frac{1}{n}\leq H_n\leq \ln n+1
		\end{align*}
		Or, $\ln n+\displaystyle\frac{1}{n}\unfty{\sim} \ln n\unfty{\sim}\ln n+1$. Donc $H_n\underset{\nfty}{\sim}\ln n$.
		\item Fixons un entier $n\geq 2$.\\
		\[v_n-v_{n-1}=\displaystyle\frac{1}{n}+\ln\left(1-\displaystyle\frac{1}{n}\right)\leq \displaystyle\frac{1}{n}-\displaystyle\frac{1}{n}=0\] par l'inégalité de convexité classique du $\ln$.\\
		De plus, la comparaison série intégrale donne $v_n\in [0,1]$.\\
		$(v_n)_{n\in \N^*}$ est décroissante et minorée, d'après le théorème de la limite monotone, elle converge.\\
		On peut donc écrire $H_n\unfty{=}\gamma+\ln n+\smallo{\ln n}$ où $\gamma$ est appelée constante d'Euler.
		\item La suite $(v_n-v_{n-1})_{n\geq 2}$ est convergente et de signe constant. On peut alors penser à chercher un équivalent du reste de la série $\displaystyle\sum\limits_{n\geq 2} v_n-v_{n-1}$.\\
		On a $v_n-v_{n-1}=\displaystyle\frac{1}{n}+\ln\left(1-\displaystyle\frac{1}{n}\right)\unfty{=}\displaystyle\frac{1}{n}-\displaystyle\frac{1}{n}-\displaystyle\frac{1}{2n^2}+\smallo{\displaystyle\frac{1}{n^2}}\unfty{\sim} -\displaystyle\frac{1}{2n^2}$.\\
		Donc, \[\displaystyle\sum\limits_{k=n+1}^{+\infty}{v_k-v_{k-1}}=\gamma-v_n\unfty{\sim}\displaystyle\sum\limits_{k=n+1}^{+\infty}-{\frac{1}{2k^2}}=\displaystyle\frac{1}{2}\displaystyle\sum\limits_{k=n+1}^{+\infty}{\left(\frac{1}{k+1}-\frac{1}{k}\right)}=-\displaystyle\frac{1}{2(n+1)}\unfty{\sim}-\displaystyle\frac{1}{2n}\]
		On en déduit $v_n\unfty{=}\gamma +\displaystyle\frac{1}{2n}+\smallo{\displaystyle\frac{1}{n}}$.\\
		Et finalement,$$H_n\unfty{=}\ln n+\gamma +\displaystyle\frac{1}{2n}+\smallo{\displaystyle\frac{1}{n}}$$
		\item Sur le même principe on calcule:
		\begin{align*}
			w_n-w_{n-1}&\ \ \ =v_n-v_{n-1}+\frac{1}{2n-2}-\frac{1}{2n}\\
			&\unfty{=}-\frac{1}{2n^2}-\frac{1}{3n^3}+\smallo{\frac{1}{n^3}}+\frac{1}{2n(n-1)}\\
			&\unfty{=}\frac{1}{2n^2(n-1)}-\frac{1}{3n^3}+\smallo{\frac{1}{n^3}}\\
			&\unfty{=}\frac{2+n}{6n^3(n-1)}+\smallo{\frac{1}{n^3}}\\
			&\unfty{\sim}\frac{1}{6n^3}
		\end{align*}
		la suite $(u_n)_{n\in \N^*}=\displaystyle\left(\frac{1}{6n^3}\right)_{n\in \N^*}$ est positive et $\displaystyle\sum\limits_{n\geq 2} u_n$ converge donc par comparaison de séries convergentes,\\
		$\displaystyle\sum\limits_{k=n+1}^{+\infty} w_k-w_{k-1}=\left(\lim\limits_{k\to +\infty} w_k\right)-w_n=-w_n\unfty{\sim}\displaystyle\sum\limits_{k=n+1}^{+\infty} \frac{1}{6n^3}$.\\
		Or $\displaystyle\frac{1}{n^3}\unfty{\sim} \displaystyle\frac{n+1/2}{n^2(n+1)^2}=\displaystyle\frac{1}{2}\left(\displaystyle\frac{1}{n^2}-\displaystyle\frac{1}{(n+1)^2}\right)$ donc : \[\displaystyle\sum\limits_{k=n+1}^{+\infty} \frac{1}{6k^3}\unfty{\sim} \displaystyle\frac{1}{12}\displaystyle\sum\limits_{k=n+1}^{+\infty}\left(\frac{1}{k^2}-\frac{1}{(k+1)^2}\right)=\displaystyle\frac{1}{12(n+1)^2}\unfty{\sim}\displaystyle\frac{1}{12n^2}\]
		Ainsi, $w_n\unfty{\sim}-\displaystyle\frac{1}{12n^2}$ puis:
		$$H_n\unfty{=}\ln n+\gamma+\displaystyle\frac{1}{2n}-\displaystyle\frac{1}{12n^2}+\smallo{\displaystyle\frac{1}{n^2}}$$
		\item On écrit $H_n=\ln n+\gamma + \varepsilon_n$ avec $\varepsilon_n\unfty{\longrightarrow} 0$.\\
		Par définition de $k_n$ on a:
		$$\ln(k_n)+\gamma +\varepsilon_{k_n}\geq n\text{ et }\ln(k_n-1)+\gamma +\varepsilon_{k_n-1}<n$$
		Donc on a:
		$$e^{n-\gamma-\varepsilon_{k_n}}\leq k_n< 1+e^{n-\gamma-\varepsilon_{k_n-1}}$$
		Or $\forall n\in \N^*,\ H_n\leq n$ donc $\forall n\in \N^*,\ k_n\geq n$ d'où $k_n\unfty{\longrightarrow}+\infty$.\\
		Ainsi $k_n\unfty{\sim} e^{n-\gamma}$ d'où $\lim\limits_{\nfty}\displaystyle\frac{k_{n+1}}{k_n}=e$.
	\end{enumerate}
	
	\subsection{Suite récurrente (1) \etoile{3}}\label{sec:suite-recurrente-1-etoile3}
	\textcolor{blue}{\hyperref[Suite récurrente 1]{[Enoncé]}}\\
	\begin{enumerate}
		\item $u_1=\sin(u_0)\in [-1,1]$ et $\sin([-1,1])\subset [-1,1]$ donc $(u_n)_{n\in \N}$ est bien définie et est bornée. \\Tout d'abord, si $u_1=0$ alors $\forall n\in \N^*,\ u_n=0$.\\
		De plus $\sin(]0,1])\subset ]0,1]$ et $\sin$ est impaire on peut donc supposer, quitte à étudier $(-u_n)$, que $u_1\in ]0,1]$.\\
		$\forall x\in \R_+,\ \sin(x)\leq x\implies \forall n\in \N^*,\ u_{n+1}=\sin(u_n)\leq u_n$.\\
		$(u_n)$ est décroissante et minorée, d'après le théorème de la limite monotone, $(u_n)$ converge. Notons $L=\lim\limits_{\nfty} u_n$\\
		D'une part, $\sin$ est continue en $L$ donc $\sin(u_n)\unfty{\longrightarrow} \sin(L)$. D'autre part $(\sin(u_n))=(u_{n+1})$ est une suite extraite de $(u_n)$ donc $\sin(u_n)\unfty{\longrightarrow} L$. Par unicité de la limite, $L=\sin(L)$.\\
		Posons $f:x\mapsto x-\sin(x)$. $f$ est dérivable sur $\R$ et $\forall x\in \R,\ f'(x)=1-\cos(x)\geq 0$. De plus $f'$ ne s'annule qu'en des points isolés (pour $x\in 2\pi\Z$) donc $f$ est strictement croissante sur $\R$. $f$ étant continue et strictement monotone sur $\R$, elle est injective sur $\R$. Ainsi comme $f(L)=f(0)$, on a $L=0$.\\
		Cherchons $\alpha\in \R$ tel que $(u_{n+1}^\alpha-u_n^\alpha)$ converge en utilisant le DL de $\sin$ en $0$.\\\\
		$u_{n+1}^\alpha-u_n^\alpha\unfty{=}u_n^\alpha\left[\left(1-\displaystyle\frac{u_n^2}{6}+\smallo{u_n^2}\right)^\alpha-1\right]\unfty{=}u_n^\alpha\left[1-\alpha\displaystyle\frac{u_n^2}{6}+\smallo{u_n^2}-1\right]\unfty{=}-\displaystyle\frac{\alpha}{6}u_n^{\alpha+2}+\smallo{u_n^{\alpha+2}}$.\\
		On choisit alors $\alpha=-2$ et on a $u_{n+1}^{-2}-u_n^{-2}\unfty{\sim}\displaystyle\frac{1}{3}$. $\displaystyle\sum\limits_{n\in \N}\frac{1}{3}$ diverge et $\left(\displaystyle\frac{1}{3}\right)_{n\in \N}$ est de signe constant APCR donc $\displaystyle\sum\limits_{k=0}^{n-1}\left(u_{k+1}^{-2}-u_k^{-2}\right)=\displaystyle\frac{1}{u_n^2}-\displaystyle\frac{1}{u_0^2}\unfty{\sim}\displaystyle\frac{n}{3}=\displaystyle\sum\limits_{k=0}^{n-1}\frac{1}{3}$. Or $\displaystyle\frac{1}{u_n^2}\unfty{\longrightarrow}+\infty$ donc $\displaystyle\frac{1}{u_n^2}\unfty{\sim}\displaystyle\frac{1}{u_n^2}-\displaystyle\frac{1}{u_0^2}$.\\
		On en déduit $u_n\unfty{\sim}\displaystyle\displaystyle\sqrt\frac{3}{n}$. Si $u_1<0$ on a alors $u_n\unfty{\sim}-\displaystyle\displaystyle\sqrt\frac{3}{n}$.
		\item On reprend le calcul de $u_{n+1}^{-2}-u_n^{-2}$ en poussant le DL un ordre plus loin:
		$u_{n+1}^{-2}-u_n^{-2}\unfty{=}\displaystyle\frac{1}{3}-\displaystyle\frac{u_n^2}{60}+\smallo{u_n^2}$.\\
		Avec $u_n^2\unfty{=}\displaystyle\frac{3}{n}+\smallo{\displaystyle\frac{3}{n}},\ u_{n+1}^{-2}-u_n^{-2}\unfty{=}\displaystyle\frac{1}{3}-\displaystyle\frac{1}{20n}+\smallo{\displaystyle\frac{1}{n}}$.\\
		Donc en sommant: $\displaystyle\frac{1}{u_n^2}\unfty{=}\displaystyle\frac{n}{3}-\displaystyle\frac{1}{20}H_{n-1}+\smallo{H_{n-1}}$ où $H_{n-1}=\displaystyle\sum\limits_{k=1}^{n-1} \frac{1}{k}$ est le $n-1$-ième terme de la série harmonique.\\
		On montre classiquement que $H_{n-1}\unfty{\sim} \ln(n-1)\unfty{\sim}\ln n$ pour en déduire:
		\begin{align*}
			u_n&\unfty{=}\left(\displaystyle\frac{n}{3}-\displaystyle\frac{1}{20}\ln n+\smallo{\ln n}\right)^{-1/2}\\
			&\unfty{=}\displaystyle\displaystyle\sqrt{\frac{3}{n}}\left(1-\displaystyle\frac{3}{20}\displaystyle\frac{\ln n}{n}+\smallo{\displaystyle\frac{\ln n}{n}}\right)^{-1/2}\\
			&\unfty{=}\displaystyle\displaystyle\sqrt{\frac{3}{n}}\left(1+\displaystyle\frac{3}{40}\displaystyle\frac{\ln n}{n}+\smallo{\displaystyle\frac{\ln n}{n}}\right)\\
			&\unfty{=}\displaystyle\displaystyle\sqrt{\frac{3}{n}}+\displaystyle\frac{3\displaystyle\sqrt{3}}{40}\displaystyle\frac{\ln n}{n\displaystyle\sqrt{n}}+\smallo{\displaystyle\frac{\ln n}{n\displaystyle\sqrt{n}}}
		\end{align*}
		Si $u_1<0$ alors le même raisonnement appliqué à $(-u_n)$ donne $u_n\unfty{=}-\displaystyle\displaystyle\sqrt{\frac{3}{n}}-\displaystyle\frac{3\displaystyle\sqrt{3}}{40}\displaystyle\frac{\ln n}{n\displaystyle\sqrt{n}}+\smallo{\displaystyle\frac{\ln n}{n\displaystyle\sqrt{n}}}$.
	\end{enumerate}
	
	\subsection{Suite récurrente (2)}\label{sec:suite-recurrente-2}
	\textcolor{blue}{\hyperref[Suite récurrente 2]{[Enoncé]}}\\
	
	\subsection{Suite récurrente (3)}\label{sec:suite-recurrente-3}
	\textcolor{blue}{\hyperref[Suite récurrente 3]{[Enoncé]}}\\
	
	\subsection{Suite récurrente (4) \etoile{3}}\label{sec:suite-recurrente-4-etoile3}
	\textcolor{blue}{\hyperref[Suite récurrente 4]{[Enoncé]}}\\
	$u_0>0$ donc par récurrence immédiate, $\forall n \in \N,\ u_n>0$.\\
	On en déduit que $\forall n\in \N,\ u_{n+1}-u_n=\displaystyle\frac{1}{u_n^\alpha}>0$. Donc $(u_n)_{n\in \N}$ est croissante et elle admet alors une limite $l$ dans $\R\cup \{+\infty\}$.\\
	Fixons $n\in \N^*$. En sommant l'égalité précédente, $\displaystyle\sum\limits_{k=0}^{n-1} u_{k+1}-u_k=u_n-u_0=\displaystyle\sum\limits_{k=0}^{n-1} \frac{1}{u_k^\alpha}$.\\
	Si $(u_n)$ converge alors $u_n-u_0\unfty{\longrightarrow} l-u_0\in \R$ d'où $\displaystyle\sum\limits_{k\geq 0} \frac{1}{u_k^\alpha}$ converge. Cependant, $\displaystyle\frac{1}{u_k^\alpha}\ukfty{\longrightarrow} \displaystyle\frac{1}{l^\alpha}\ne 0$ ($+\infty$ si $l=0$) donc $\displaystyle\sum\limits_{k\geq 0} \frac{1}{u_k^\alpha}$ diverge grossièrement. Ainsi $\unfty{\lim} u_n=+\infty$.\\\\
	Soit $\beta\in \R$.
	\begin{align*}
		u_{n+1}^\beta-u_n^\beta&\ \ \ =\ \ \ u_n^\beta\left[\left(1+\displaystyle\frac{1}{u_n^{\alpha+1}}\right)^\beta-1\right]\\
		&\unfty{=}u_n^\beta\left[1+\displaystyle\frac{\beta}{u_n^{\alpha+1}}+\smallo{\displaystyle\frac{1}{u_n^{\alpha+1}}}-1\right]\\
		&\unfty{=}\beta u_n^{\beta-\alpha-1}+\smallo{u_n^{\beta-\alpha+-1}}
	\end{align*}
	On choisit $\beta=\alpha+1$ et on a alors $u_{n+1}^{\alpha+1}-u_n^{\alpha+1}\unfty{\sim}\alpha+1\ \ \ \ \ \ (\alpha+1\ne 0$ puisque $\alpha>-1)$. La série $\displaystyle\sum\limits_{n\geq 0}(\alpha+1)$ diverge et $(\alpha+1)_{n\in \N}$ est de signe constant APCR donc par sommation de relations de comparaisons,\\
	$\displaystyle\sum\limits_{k=0}^{n-1}(u_{k+1}^{\alpha+1}-u_k^{\alpha+1})=u_n^{\alpha+1}-u_0^{\alpha+1}\unfty{\sim}(\alpha+1)n=\displaystyle\sum\limits_{k=0}^{n-1}(\alpha+1)$.\\
	Or $u_n^{\alpha+1}\unfty{\longrightarrow}+\infty$ donc $u_n^{\alpha+1}-u_0^{\alpha+1}\unfty{\sim}u_n^{\alpha+1}$. D'où $u_n\unfty{\sim}((\alpha+1)n)^{1/(\alpha+1)}$.
	
	\subsection{Suite récurrente (5)}\label{sec:suite-recurrente-5}
	\textcolor{blue}{\hyperref[Suite récurrente 5]{[Enoncé]}}\\
	On sait que la fonction $x\mapsto e^{-\frac{x^2}{2}}$ est continue et positive sur $\R$. Ainsi pour tout $n\in\N$, $\displaystyle\int_{x_n}^{+\infty}e^{-\frac{x^2}{2}}dx$ est positive, ce qui montre la croissance de la suite $(x_n)$.
	Montrons, par l'absurde, que $(x_n)$ n'est pas majorée.
	D'après le théorème de Bolzano-Weierstrass, la suite $(x_n)$ admet une sous-suite convergente de limite $\ell$ telle que:$$\ell=\ell+\int_\ell^{+\infty}e^{-\frac{x^2}{2}}dx$$
	\\Cette égalité n'est vérifié pour aucune valeur $\ell\in\R$ par stricte positivité de l'intégrale.
	\\Donc, on a montré que $(x_n)$ n'est pas majorée et donc qu'elle tend vers $+\infty$.
	\\On sait également que $\displaystyle\int_x^{+\infty}e^{-\frac{x^2}{2}}dx\uxfty{\sim}\frac{e^{-x^2}}{2x}$ d'après \ref{Intégrale de Gauss}.
	\\Et donc puisque $x_n\to+\infty$, on a: $$x_{n+1}-x_n\sim\frac{e^{-x_n^2}}{2x_n}$$
	De plus, puisque $x_n\to +\infty$ et que $\int_{0}^{+\infty}e^{-\frac{t^2}{2}}dt$ converge, on en déduit que \[x_{n+1}\sim x_n\]
	On pose la fonction : \[\fonction{f}{\R}{\R}{x}{e^{x^2}}\].
	D'après le théorème des accroissements finis, il existe $c_n\in]x_n, x_{n+1}[$ tel que \[f(x_{n+1})-f(x_n)=f'(c_n)(x_{n+1}-x_n)\]
	Ainsi, \[f(x_{n+1})-f(x_n)\underset{n\to+\infty}{\sim}f'(c_n)\frac{e^{-\frac{x_n^2}{2}}}{2x_n}=\frac{c_n}{x_n}e^{\frac{c_n^2-x_n^2}{2}}\]
	et \[c_n\sim x_n \text{par encadrement}\]
	Montrons que $c_n^2-x_n^2\to 0$.\\
	\begin{align*}
		c_n^2-x_n^2&=(c_n+x_n)(c_n-x_n)\\
		&\sim 2x_n(c_n-x_n)
	\end{align*}
	Or \[0\leq 2x_n(c_n-x_n)\leq 2x_n(x_{n+1}-x_n)\sim e^{-\frac{x_n^2}{2}}\]
	Donc par encadrement, \[c_n^2-x_n^2\to 0\]
	Par conséquent, $f(x_{n+1})-f(x_n)\to 1$.\\
	D'après le lemme de l'escalier \ref{Lemme de Cesaro}, on a \[e^{x_n^2}\sim n\]
	et donc \[x_n\sim\sqrt{\ln(n)}\]
	
	\subsection{Suite récurrente (6)}\label{sec:suite-recurrente-6}
	\textcolor{blue}{\hyperref[Suite récurrente 6]{[Enoncé]}}\\
	
	
	\subsection{Suite définie implicitement (1)\etoile{2}}\label{sec:suite-definie-implicitement-1etoile2}
		\textcolor{blue}{\hyperref[Suite définie implicitment 1]{[Enoncé]}}\\
	\begin{enumerate}
		\item Soit $n\in \N^*$. Notons $f_n:x\in [0,1]\mapsto nx-\cos(x)$. $f_n$ est dérivable sur $[0,1]$ et pour tout $x\in [0,1]$,\\
		$f'_n(x)=n+\sin(x)\geq 0$ avec égalité si et seulement si $n=1$ et $x\in -\displaystyle\frac{\pi}{2} + 2\pi\Z$. Ainsi $f_n$ est strictement croissante et donc d'après le théorème de la bijection, $f_n$ est bijective de $[0,1]$ dans $[f_n(0),f_n(1)]=[-1,n-\cos(1)]\owns 0$.\\
		Donc $\exists!\ x_n\in [0,1],\ \cos(x_n)=nx_n$.
		\item $\forall n\in \N^*,\ |x_n|=\displaystyle\frac{|\cos(x_n)|}{n}\leq \displaystyle\frac{1}{n}$. Donc $x_n\unfty{\longrightarrow} 0$.
		\item $\forall n\in \N^*,\ f_{n+1}(x_n)=(n+1)x_n-\cos(x_n)=f_n(x_n)+x_n=x_n\geq 0=f_{n+1}(x_{n+1})$. De plus, il n'y a pas égalité par unicité de $x_{n+1}$. Donc comme $f_n$ est strictement croissante, $x_n>x_{n+1}$.\\
		Ainsi $(x_n)_{n\in \N^*}$ est décroissante.
		\item En passant à la limite dans l'équation définissant $x_n$, on obtient $nx_n\unfty{\longrightarrow} 1$ c'est-à-dire $x_n\unfty{\sim} \displaystyle\frac{1}{n}$.
		\item $x_n-\displaystyle\frac{1}{n}=\displaystyle\frac{\cos(x_n)-1}{n}\unfty{=}-\displaystyle\frac{x_n^2}{2n}+\smallo{\displaystyle\frac{x_n^2}{n}}\unfty{\sim}-\displaystyle\frac{x_n^2}{2n}\unfty{\sim}-\displaystyle\frac{1}{2n^2}$.
	\end{enumerate}
	
	\subsection{Suite définie implicitement (2)}\label{sec:suite-definie-implicitement-2}
		\textcolor{blue}{\hyperref[Suite définie implicitement 2]{[Enoncé]}}\\
	
	\subsection{Suite définie implicitement (3)}\label{sec:suite-definie-implicitement-3}
	\textcolor{blue}{\hyperref[Suite définie implicitement 3]{[Enoncé]}}\\	
	
	\subsection{Suite définie implicitement (4)}\label{sec:suite-definie-implicitement-4}
	\textcolor{blue}{\hyperref[Suite définie implicitement 4]{[Enoncé]}}\\	
	
	\subsection{Suite définie implicitement (5) \etoile{3}}\label{sec:suite-definie-implicitement-5-etoile3}
		\textcolor{blue}{\hyperref[Suite définie implicitement 5]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item Posons pour $n\in \N^*,\ f_n:x\in \R_+\mapsto \displaystyle\sum_{k=1}^n\frac{x^k}{k}$ et fixons $n\in \N^*$.\\
		$f_n$ est $\mathcal C^1$ sur $\R_+$ et $\forall x\in \R_+,\ f_n'(x)=\displaystyle1+\sum_{k=2}^nx^{k-1}>0$. De plus $f(0)=0$ et $\uxfty\lim f_n(x)=+\infty$ donc d'après le théorème de la bijection $f_n-1$ s'annule exactement une fois sur $\R_+$.
		\item On remarque que $f_{n+1}\geq f_n$ donc $f_{n+1}(x_n)\geq 0=f_{n+1}(x_{n+1})$. Par croissance de $f_{n+1}$ on sait alors que $x_{n+1}\leq x_n$.\\
		$(x_n)_{n\in \N^*}$ est décroissante et minorée (par $0$ par exemple), d'après le théorème de la limite monotone elle converge vers une limite $\ell$.
		\item $x_1=1$ donc $\forall n\geq 2,\ 0<x_n\leq x_2<1$.\\
		$\forall n\geq 2,\ 1=\displaystyle\sum_{k=1}^n\frac{x_n^k}{k}=\sum_{k=1}^n\int_0^{x_n}t^{k-1}dt=\int_0^{x_n}\sum_{k=1}^nt^{k-1}dt=\int_0^{x_n}\frac{1-t^n}{1-t}dt=-\ln(1-x_n)-\int_0^{x_n}\frac{t^n}{1-t}dt$.\\
		Or $\forall n\geq 2,\ \displaystyle\left|\int_0^{x_n}\frac{t^n}{1-t}dt\right|\leq \int_0^1\frac{x_2^n}{1-x_2}dt=\frac{x_2^n}{1-x_2}\unfty\longrightarrow 0$.\\\\
		Donc $\ln(1-x_n)\unfty\longrightarrow -1$ i.e $x_n\unfty\longrightarrow1-e^{-1}$.
	\end{enumerate}
	
	
	\subsection{Formule d'inversion de Pascal \etoile{2}}\label{sec:formule-dinversion-de-pascal-etoile2}
		\textcolor{blue}{\hyperref[Formule d'inversion de Pascal]{[Enoncé]}}\\
	\subsubsection{Première méthode matrice de passage \etoile{1}}
	\begin{enumerate}
		\item Les familles $\B_c$ et $\B_t$ sont deux familles à degrés échelonnés de $m+1=\dim \K_m[X]$ éléments de $\K_m[X]$. Ce sont donc des bases de $\K_m[X]$.
		\item Soit $j\in \crblanc{0}{m}$.\\
		$(X-1)^j=\displaystyle\sum\limits_{i=0}^{j} \binom{j}{i}(-1)^{j-i}X^i$ donc $\forall (i,j)\in \crblanc{0}{m}^2,\ \displaystyle\left(P_{\B_t}^{\B_c}\right)_{i+1,j+1}=\binom{j}{i}(-1)^{j-i}$\\
		Et, $X^j=(X-1+1)^j=\displaystyle\sum\limits_{i=0}^j \binom{j}{i}(X-1)^i$ donc $\forall (i,j)\in \crblanc{0}{m}^2,\ \displaystyle\left(P_{\B_c}^{\B_t}\right)_{i+1,j+1}=\binom{j}{i}$
		\item Fixons $n\in \N$ et notons $A_n=\begin{pmatrix} a_1\\\vdots\\a_n\end{pmatrix}$ et $B_n=\begin{pmatrix} b_1\\\vdots\\b_n\end{pmatrix}$.
		\begin{align*}
			\forall p\in&\crblanc{0}{n},\ b_p=\displaystyle\sum\limits_{k=0}^p\binom{p}{k}a_k\\
			\iff\ \ \ \ \ \ \ \ &B_n=P_{\B_t}^{\B_c}A_n\\
			\iff\ \ \ \ \ \ \ \ &A_n=P_{\B_c}^{\B_t}B_n\\
			\iff\  \forall p\in&\crblanc{0}{n},\ a_p=\displaystyle\sum\limits_{k=0}^p(-1)^{p-k}\binom{p}{k}b_k
		\end{align*}
	\end{enumerate}
	
	\subsubsection{Deuxième méthode : binôme de Newton \etoile{2}}
	$S$ est un endomorphisme de $\C^\N$ qui commute trivialement avec $T=\Id_{\C^\N}$.\\
	Donc $\forall n\in \N,\ ((T+S)^n(a))_0=\displaystyle\sum_{k=0}^n\binom{n}{k}(S^k\circ T^{n-k})(a))_0=\sum_{k=0}^n\binom{n}{k}(S^k(a))_0=\sum_{k=0}^n\binom{n}{k}a_k=b_n$.\\
	Et par conséquent,
	\begin{align*}
		\forall n\in \N,\ a_n&=(S^n(a))_0\\
		&=(T+S-T)^n(a))_0\\
		&=\sum_{k=0}^n\binom{n}{k}(-1)^{n-k}((T+S)^k(a))_0\\
		&=\sum_{k=0}^n\binom{n}{k}(-1)^{n-k}b_k
	\end{align*}
	
	\subsubsection{Troisième méthode : par le calcul \etoile{2}}
	\begin{enumerate}[leftmargin=*]
		\item $\displaystyle\sum_{i=0}^p(-1)^{p-i}\binom{p}{i}b_i=\sum_{i=0}^p(-1)^{p-i}\binom{p}{i}\sum_{j=0}^i\binom{i}{j}a_j=\sum_{0\leq j\leq i\leq p}(-1)^{p-i}\binom{p}{i}\binom{i}{j}a_j=\sum_{j=0}^p\sum_{i=j}^p(-1)^{p-i}\binom{p}{i}\binom{i}{j}a_j$.
		\item
		\begin{align*}
			\sum_{j=0}^p\sum_{i=j}^p(-1)^{p-i}\binom{p}{i}\binom{i}{j}a_j&=\sum_{j=0}^pa_j\sum_{i=j}^p\frac{p!}{(p-i)!}\cdot\frac{1}{(i-j)!j!}(-1)^{p-i}\\
			&=\sum_{j=0}^pa_j\sum_{i=0}^{p-j}\frac{p!}{j!}\cdot\frac{1}{i!(p-j-i)!}(-1)^{p-j-i}\\
			&=\sum_{j=0}^pa_j\frac{p!}{j!(p-j)!}\sum_{i=0}^{p-j}(-1)^{p-j-i}\frac{(p-j)!}{i!(p-j-i)!}\\
			&=\sum_{j=0}^p\binom{p}{j}a_j\sum_{i=0}^{p-j}(-1)^{p-j-i}\binom{p-j}{i}
		\end{align*}
		\item Si $p-j\ne 0$, alors $\displaystyle\sum_{i=0}^{p-j}(-1)^{p-j-i}\binom{p-j}{i}=(1-1)^{p-j}=0$. Pour $j=p$, la somme vaut $1$.\\
		Ainsi, on a montré que $\displaystyle\sum_{i=0}^p(-1)^{p-i}\binom{p}{i}b_i=\binom{p}{p}a_p=a_p$.
	\end{enumerate}
	
	\subsubsection{Dérangement \etoile{3}}
	Notons pour $k\in \crblanc{0}{n},\ A_k$ l'ensemble des permutations de $\crblanc{1}{n}$ ayant exactement $k$ points fixes. On a $\mathcal S_n=\displaystyle\bigsqcup_{k=0}^nA_k$ où $\displaystyle\bigsqcup$ représente une union disjointe.\\
	Or si $k\in \crblanc{0}{n}$, pour construire un élément de $A_k$ on choisis $k$ éléments dans $\crblanc{1}{n}$ qui reste fixe et on construit un dérangement à partir des $n-k$ éléments restant. Ainsi $\forall k\in \crblanc{0}{n},\ \Card(A_k)=\displaystyle\binom{n}{k}D_{n-k}$.\\
	On obtient alors $n!=\Card(S_n)=\displaystyle\sum_{k=0}^n\Card(A_k)=\sum_{k=0}^n\binom{n}{k}D_{n-k}=\sum_{k=0}^n\binom{n}{n-k}D_k=\sum_{k=0}^n\binom{n}{k}D_k$.\\
	D'après la formule d'inversion de Pascal on a $D_n=\displaystyle\sum_{k=0}^n(-1)^{n-k}\binom{n}{k}k!=\sum_{k=0}^n(-1)^{n-k}\frac{n!}{(n-k)!}=n!\sum_{k=0}^n\frac{(-1)^k}{k!}$.\\
	Par conséquent $\displaystyle\frac{D_n}{n!}\unfty\longrightarrow\sum_{k=0}^{+\infty}\frac{(-1)^k}{k}=\frac{1}{e}$.\\
	Le quotient $\displaystyle\frac{D_n}{n!}$ peut s'interpréter comme la probabilité d'obtenir un dérangement quand on tire au hasard une permutation dans un ensemble à $n$ éléments, en considérant qu'il y a équiprobabilité pour de toutes les issus. On a montré que cette probabilité tend vers $\displaystyle\frac{1}{e}\approx0,37$ quand on augmente le nombre d'éléments.
	
	\subsection{Théorème de Pringsheim \etoile{3}}
	\label{sec:theoreme-de-pringsheim-etoile3}
	\textcolor{blue}{\hyperref[Théorème de Pringsheim]{[Enoncé]}}\\
	On pose pour tout $n\in\N$, $S_n=\displaystyle\sum\limits_{k=0}^na_k$.
	\\On a pour tout $n\in\N$, $S_{2n}-S_n=\displaystyle\sum\limits_{k=n+1}^{2n}a_k\geq na_{2n}\geq0$ car $(a_n)_{n\geq 0}$ est décroissante.
	\\ Or comme $\displaystyle\sum\limits_{k\geq 0}a_k$ converge, on en déduit que $S_{2n}-S_n$ tend vers $0$. Donc par encadrement, on en déduit que $(2na_{2n})_{n\geq 0}$ tend vers $0$.
	\\De plus, on remarque que pour tout entier naturel $n$, $0\leq (2n+1)a_{2n+1}\leq (2n+1)a_{2n}$. On sait que $a_{2n}\unfty{\longrightarrow}0$ car $\displaystyle\sum\limits_{n\geq 0}a_n$ converge et que $2na_{2n}\unfty{\longrightarrow}0$ d'après ce qui précède. On en déduit par encadrement que $(2n+1)a_{2n+1}\unfty{\longrightarrow}0$.
	\\Finalement, $na_n\unfty{\longrightarrow}0$.
	
	\subsection{Lemme de Fekete \centraleponts{3}}
	\label{sec:lemme-de-fekete}
	\textcolor{blue}{\hyperref[Lemme de Fekete]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item Par récurrence immédiate $\forall k\in \N^*,\ u_{kn}\leq ku_n$.\\
		Donc $u_n\leq u_{qN}+u_r\leq qu_N+u_r\leq qu_N+\max\limits_{0\leq k<N}u_k$.
		\item Supposons $\left(\dfrac{u_n}{n}\right)_{n\in \N^*}$ minorée et fixons $\varepsilon>0$. Alors $\exists N\in \N^*,\ \dfrac{u_N}{N}-\ell\leq\dfrac{\varepsilon}{2}$. On note $U:=\max\limits_{0\leq k<N}u_k$.\\
		Notons $N'=\max\left(N,\left\lfloor\dfrac{2U}{\varepsilon}\right\rfloor+1\right)$. Alors si $n\geq N'$, $\displaystyle\frac{u_n}{n}-\ell\leq \frac{q}{n}u_N-\ell+\frac{U}{n}\leq \frac{qN}{n}\left(\ell+\frac{\varepsilon}{2}\right)-\ell+\frac{\varepsilon}{2}$.\\
		Or $qN=n-r\leq n$ donc $\dfrac{qN}{n}\leq 1$ d'où $\dfrac{u_n}{n}-\ell\leq \varepsilon$.\\
		Donc $\dfrac{u_n}{n}\longrightarrow\ell$.\\
		Supposons maintenant $\left(\dfrac{u_n}{n}\right)_{n\in \N^*}$ non minorée et fixons $\delta<0$. Alors $\exists N\in \N^*,\ u_n\leq \delta-1$.\\
		Alors $\forall n\geq \max(N,\lfloor U\rfloor+1),\ \displaystyle\frac{u_n}{n}\leq \frac{qN}{n}\left(\delta-1+\ell\right)-\ell+\frac{U}{n}\leq \delta-1+\ell-\ell+1=\delta$.\\
		Donc $\dfrac{u_n}{n}\unfty\longrightarrow-\infty$.
	\end{enumerate}
	
	\subsubsection{Chemins auto-évitant \etoile{3}}
	\label{Chemins auto-évitant corrigé}
	\textcolor{blue}{\hyperref[Chemins auto-évitant]{[Enoncé]}}\\
	La suite $(c_n)_{n\in \N^*}$ est clairement minorée par $1$. On remarque par croissance de $\ln$ que $\ln\mu=\inf\limits_{n\in \N^*}\dfrac{\ln c_n}{n}$. On va donc montrer que la suite $(\ln c_n)_{n\in \N^*}$ est sous-additive. Autrement dit que $(c_n)_{n\in \N^*}$ est sous-multiplicative :
	$$\forall m,n\in \N^*,\ c_{n+m}\leq c_nc_m$$
	Cette inégalité est simple à obtenir car on peut voir un chemin de longueur $n+m$ comme un chemin de longueur $n$ associé à un chemin de longueur $m$ (qui part du point d'arrivée de celui de longueur $n$).\\\\
	\textit{Remarque : On peut définir les chemins auto-évitant dans n'importe quel réseau. La constante $\mu$ s'appelle alors constante de connectivité du réseau. On ne dispose pas de valeur exacte pour cette constante en général, elle n'est en fait connu que pour le réseau hexagonal : $\mu=\sqrt{2+\sqrt 2}$. Ce résultat est dû à Hugo Duminil-Copin, médaillé Fields français et Stanislav Smirnov, médaillé Fields russe.}
	
	\subsection{Théorème de Bolzano-Weierstrass \etoile{3}}
	\label{sec:theoreme-de-bolzano-weierstrass-etoile3}
	\textcolor{blue}{\hyperref[Théorème de Bolzano-Weierstrass]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item Soit $(v_n)\in \R^\N$. On pose $A=\{n\in \N\ |\ \forall k>n,\ v_k\geq v_n\}$.\\
		Si $A$ est infini alors n'importe quelle suite extraite de $(v_n)_{n\in \N}$ à valeur dans $A$ est croissante.\\
		Et si $A$ est fini alors il existe $N\in \N$ tel que $\forall n\geq N,\ n\notin A$. Autrement dit, $\forall n\geq N,\ \exists k_n>n,\ v_{k_n}<v_n$.\\
		On définit alors $\varphi:\N\to \N$ par $\varphi(0)=N$ et $\forall n\in \N,\ \varphi(n+1)=k_{\varphi(n)}$.\\
		Par définition pour tout $n\in \N$, $\varphi(n+1)=k_{\varphi(n)}>\varphi(n)$ et $v_{\varphi(n+1)}=v_{k_{\varphi(n)}}<v_{\varphi(n)}$. Ainsi, $(v_{\varphi(n)})_{n\in \N}$ est une suite extraite de $(v_n)_{n\in \N}$ décroissante.
		\item Attention ! On ne peut pas utiliser le fait que $\{z\in \C,\ |z|\leq M\}$ est une partie compacte de $\C$ car la démonstration de ce résultat est l'objet de l'exercice !
		Posons pour tout $n\in \N,\ x_n=\text{Re}(u_n)$ et $y_n=\text{Im}(u_n)$. Notons $M\in \R_+$ tel que $\forall n\in \N,\ |u_n|\leq M$.\\
		$\forall n\in \N,\ \displaystyle|x_n|=\sqrt{x_n^2}\leq \sqrt{x_n^2+y_n^2}=|u_n|\leq M$. De même, $\forall n\in \N,\ |y_n|\leq M$.\\
		D'après le lemme des pics appliqué à $x_n$ qui est une suite réelle, il existe  $\varphi$ une application strictement croissante de $\N$ dans $\N$ telle que $(x_{\varphi(n)})_{n\in \N}$ monotone. On pose alors $\theta=\varphi\circ\psi$. $(x_{\theta(n)})_{n\in \N}$ est monotone comme suite extraite d'une suite monotone. Ensuite, encore d'après le lemme des pics il existe $\alpha:\N\to \N$ strictement croissante telle que $(y_{\theta\circ\alpha(n)})_{n\in \N}$ soit monotone. Alors en posant $\eta=\theta\circ\alpha$, $(y_{\eta(n)})_{n\in \N}$ est monotone par définition et $(x_{\eta(n)})_{n\in \N}$ est monotone en tant que suite extraite de $(x_{\theta(n)})_{n\in \N}$ qui est elle-même monotone. Etant bornées en tant que suites extraites de suites bornées, d'après le théorème de la limite monotone elles convergent.\\
		Ainsi, $(u_{\eta(n)})_{n\in \N}=(x_{\eta(n)}+iy_{\eta(n)})_{n\in \N}$ est une suite convergente extraite de $(u_n)_{n\in \N}$.\\\\
		\textit{\underline{Remarque} : Le résultat s'étend de manière similaire à tout $\R$-espace vectoriel de dimension $p$ finie (et donc à tout $\C$-espace vectoriel de dimension $p$ finie, vu comme un $\R$-espace vectoriel de dimension $2p$) normé en procédant par récurrence, soit en extrayant de la suite des premières composantes, qui est bornée, une sous-suite convergente, puis une sous-sous-suite de cette sous-suite qui fait converger la suite des secondes composantes et ainsi de suite jusqu'à la suite des $p$-ième composantes, soit en montrant que le produit cartésien d'un nombre fini de compacts est un compact.}
	\end{enumerate}
	
	\subsection{$\R$ est complet \etoile{2}}\label{sec:r-est-complet-etoile2}
		\textcolor{blue}{\hyperref[R est complet]{[Enoncé]}}\\
	Soit $(u_n)\in \R^\N$ une suite convergente. On note $l=\unfty{\lim}u_n$.\\
	Soit $\varepsilon>0$.\\
	$\exists N\in \N,\ \forall n\geq N,\ |u_n-l|\leq \displaystyle\frac{\varepsilon}{2}$.\\
	Alors, $\forall (p,q)\in \llbracket N;+\infty\llbracket,\ |u_p-u_q|=|u_p-l+l-u_q|\leq |u_p-l|+|l-u_q|\leq \varepsilon$.\\
	Donc $(u_n)_{n\in \N}$ est une suite de Cauchy.\\\\
	Soit $(u_n)\in \R^\N$ une suite de Cauchy.\\
	Montrons que $(u_n)$ est bornée, autrement dit que la suite $(|u_n|)$ ne tend pas vers $+\infty$.\\
	Supposons par l'absurde que $\unfty{\lim}|u_n|=+\infty$. Fixons $\varepsilon>0$.\\
	$\exists n_0\in \N,\ \forall p>q\geq n_0,\ |u_p-u_q|\leq \varepsilon$. Et $\exists n_1\in \N,\ \forall p\geq n_1,\ |u_p|>|u_q|+\varepsilon$.\\
	Donc $\forall p\geq N=\max(q,n_1),\ \varepsilon<|\ |u_p|-|u_q|\ |\leq |u_p-u_q|\leq \varepsilon$.\\
	Ceci est absurde donc $(u_n)$ est bornée.\\\\
	Alors d'après le théorème de Bolzano-Weierstrass $(u_n)$ admet une valeur d'adhérence $\ell$. On note $\varphi:\N\to\N$ strictement croissante telle que $u_{\varphi(n)}\unfty{\longrightarrow}\ell$.\\
	$\forall \varepsilon>0,\ \exists n\in \N,\ \forall k\geq n,\ |u_{\varphi(n)}-u_n|\leq \varepsilon$.\\
	C'est-à-dire $u_{\varphi(n)}-u_n\unfty{\longrightarrow}0$.\\
	Mais alors par somme, $u_n=u_n-u_{\varphi(n)}+u_{\varphi(n)}\unfty{\longrightarrow}\ell$.
	
	\subsection{Récurrence de Cauchy}
	\label{sec:recurrence-de-cauchy}
	\textcolor{blue}{\hyperref[Récurrence de Cauchy]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item $1\in A$ donc $0=1-1\in A$. Fixons $n\in \N^*$.\\
		Par récurrence immédiate en utilisant le troisième axiome de $A$, $\forall k\in \N,\ 2^k\in A$. Comme $(2^k)_{k\in \N}\unfty\longrightarrow+\infty$ on sait qu'il existe $k_0\in \N$ tel que $2^{k_0}>n$.\\
		Par récurrence immédiate sur le en utilisant le deuxième axiome de $A$, si $p\in A$ alors $\forall q\in \N,\ q\leq p\implies q\in A$. Ainsi $n\in A$.\\
		Par double inclusion, $A=\N$.\\
		\textit{Remarque : On vient de définir un raisonnement par récurrence. Il est aussi intéressant de noter que le raisonnement fonctionne encore si on remplace la condition $"\forall n\in A,\ 2n\in A"$ par $"\forall n\in A,\ \varphi(n)\in A"$ avec $\varphi$ n'importe quelle fonction de $\N$ dans $\N$ strictement croissante.}
		\item Notons pour $n\in \N^*,\ \P(n):"\forall (x_1,\dots,x_n)\in (\R_+)^n,\ \displaystyle\frac{1}{n}\sum_{k=1}^nx_k\geq \left(\prod_{k=1}^nx_k^n\right)^{1/n}"$.\\
		Pour $n=1$ il n'y a rien à faire. Supposons $\P(n)$ pour un certain $n\in \N^*$.\\
		Supposons que $n\geq 2$ et montrons $\P(n-1)$. On se donne $(x_1,\dots,x_{n-1})\in (\R_+)^{n-1}$.\\
		Posons $\forall k\in \crblanc{1}{n-1},\ y_k=x_k$ ainsi que $y_n=\displaystyle\frac{1}{n-1}\sum_{k=1}^{n-1}x_k$.\\
		On remarque que $\displaystyle\frac{1}{n}\sum_{k=1}^ny_k=\frac{1}{n}\left(\sum_{k=1}^{n-1}x_k+\frac{1}{n-1}\sum_{k=1}^{n-1}x_k\right)=\frac{1}{n-1}\sum_{k=1}^{n-1}x_k$.\\
		$\forall k\in \crblanc{1}{n},\ y_k\geq 0$. Donc par hypothèse de récurrence,\\
		$\displaystyle\frac{1}{n-1}\sum_{k=1}^{n-1}x_k=\frac{1}{n}\sum_{k=1}^ny_k\geq \left(\prod_{k=1}^ny_k\right)^{1/n}=\left(\prod_{k=1}^{n-1}x_k\right)^{1/n}\times\left(\frac{1}{n-1}\sum_{k=1}^{n-1}x_k\right)^{1/n}$.\\
		On en déduit $\displaystyle\left(\frac{1}{n-1}\sum_{k=1}^{n-1}x_k\right)^{1-1/n}\geq \left(\prod_{k=1}^{n-1}x_k\right)^{1/n}$ et puis en élevant à la puissance $\dfrac{n}{n-1}$ : $\displaystyle\frac{1}{n-1}\sum_{k=1}^{n-1}x_k\geq \left(\prod_{k=1}^{n-1}x_k\right)^{1/(n-1)}$.\\
		D'où $\P(n-1)$.\\
		Montrons maintenant $\P(2n)$. On se donne $(x_1,\dots,x_n,y_1,\dots,y_n)\in (\R_+)^{2n}$. En appliquant $\P(2)$ sur $\displaystyle\left(\frac{1}{n}\sum_{k=1}^nx_k,\frac{1}{n}\sum_{k=1}^ny_k\right)$ puis deux fois $\P(n)$, une fois sur $(x_1\dots,x_n)$ et une fois sur $(y_1\dots,y_n)$ on a :\\
		$\displaystyle\frac{1}{2n}\left(\sum_{k=1}^nx_k+\sum_{k=1}^ny_k\right)\geq \sqrt{\frac{1}{n}\sum_{k=1}^nx_k\cdot\frac{1}{n}\sum_{k=1}^ny_k}\geq\left(\prod_{k=1}^nx_k\prod_{k=1}^ny_k\right)^{1/2n}$.
	\end{enumerate}
	
	\subsection{Sommes de Riemann}
	\label{sec:sommes-de-riemann}
	\textcolor{blue}{\hyperref[Sommes de Riemann]{[Enoncé]}}\\
	
	\subsection{Formule d'Euler-Maclaurin}
	\label{sec:formule-deuler-maclaurin}
	\textcolor{blue}{\hyperref[Formule 
	d'Euler-Maclaurin]{[Enoncé]}}\\
	
	\subsection{Nature d'une suite \telecom{2}}
	\label{sec:nature-dune-suite}
	\textcolor{blue}{\hyperref[Nature d'une suite]{[Enoncé]}}\\
	Supposons que $(\sin(n))_{n\in \N}$ admet une limite $\ell\in [-1,1]$.\\
	$\forall n\in \N,\ \sin(n)^2+\cos(n)^2=1$. Donc $\cos(n)^2\unfty\longrightarrow 1-\ell^2$.\\
	De plus, $\forall n\in \N,\ \sin(2n)^2=4\cos(n)^2\sin(n)^2$.\\
	Donc par passage à la limite $\ell^2=4\ell^2(1-\ell^2)^2$ i.e $\ell=0$ ou $4(1-\ell^2)^2=1$.\\
	Dans le second cas, comme $1-\ell^2\geq 0,\ 1-\ell^2=\dfrac{1}{2}$ d'où $\ell^2=\dfrac{1}{2}$.\\
	Or $\forall n\in \N,\ \sin(n+1)=\sin(n)\cos(1)+\cos(n)\sin(1)\iff \cos(n)=\dfrac{\sin(n+1)-\sin(n)\cos(1)}{\sin(1)}$.\\
	Donc $\cos(n)^2\unfty\longrightarrow\left(\dfrac{\ell(1-\cos(1))}{\sin(1)}\right)^2$.\\
	Par unicité de la limite on a $(1-\ell^2)\sin(1)^2=\ell^2(\cos(1)-1)^2$. Pourtant $\ell=0$ et $\ell^2=\dfrac{1}{2}$ ne satisfont pas cette équation.
	Ceci est absurde donc $(\sin(n))_{n\in \N}$ diverge.
	
	\subsection{Valeurs d'adhérence d'une suite \centraleponts{4}}
	\label{sec:valeurs-dadherence-dune-suite}
	\textcolor{blue}{\hyperref[Valeurs d'adhérence d'une suite]{[Enoncé]}}
	\begin{enumerate}[leftmargin=*]
		\item Soient $(u_n)_{n\in \N}$ et $(v_n)_{n\in \N}$ deux suites réelles équivalentes avec $(v_n)$ de signe constant APCR. Alors les séries $\displaystyle\sum_{n\in \N}u_n$ et $\displaystyle\sum_{n\in \N}v_n$ sont de même nature.
		\item Soit $n\in \N^*$.\\
		$|z_n|^2=\displaystyle\prod_{k=1}^n\left|1+\frac{i}{k}\right|^2=\prod_{k=1}^n\left(1+\frac{1}{k^2}\right)\ne 0$.\\
		On considère alors la suite de terme général $x_n:=\ln|z_n|$.\\
		$2x_n=\displaystyle\sum_{k=1}^n\ln\left(1+\frac{1}{k^2}\right)$. Or $\displaystyle\ln\left(1+\frac{1}{k^2}\right)\ukfty\sim\frac{1}{k^2}$ et $\displaystyle\sum_{k\in \N^*}\frac{1}{k^2}$ est une série à termes positifs convergente. Donc par théorème de comparaison $(x_n)_{n\in \N^*}$ converge vers un certain réel $x$. On en déduit que $(|z_n|)_{n\in \N^*}$ converge vers $r:=e^x$.
		\item Tout d'abord $(z_n)$ est bornée donc elle admet une valeur d'adhérence (un disque est un compact de $\C$). Soit $\ell$ une valeur d'adhérence de $(z_n)$. On note $(\zeta_n)$ une suite extraite de $(z_n)$ qui converge vers $\ell$. Alors par continuité du module $|\zeta_n|\unfty\longrightarrow|\ell|$. Donc d'après la première question $|\ell|=r$.\\
		Déterminons un argument $\theta_k\in [-\pi,\pi[$ de $1+\dfrac{i}{k}$. On a $\begin{cases}
			\displaystyle\sqrt{1+\frac{1}{k^2}}\cos(\theta_k)=1\\
			\displaystyle\sqrt{1+\frac{1}{k^2}}\sin(\theta_k)=\frac{1}{k}
		\end{cases}$\\
		Donc $\tan(\theta_k)=\dfrac{1}{k}$. Or $\cos(\theta_k)>0$ donc $\theta_k\in \displaystyle\left]-\frac{\pi}{2},\frac{\pi}{2}\right[$ d'où $\theta_k=\arctan\left(\dfrac{1}{k}\right)$.\\
		Ainsi $z_n=\displaystyle\prod_{k=1}^n\sqrt{1+\frac{1}{k^2}}e^{i\theta_k}=|z_n|e^{i\sum\limits_{k=1}^n\arctan(1/k)}$.\\
		On sait que $\displaystyle\arctan\left(\frac{1}{k}\right)\ukfty\sim\frac{1}{k}$. La série $\displaystyle\sum_{k\in \N^*}\frac{1}{k}$ est à termes positifs et diverge donc par théorème de comparaison $\displaystyle\sum_{k\in \N^*}\theta_k$ diverge. On note désormais $S_n:=\displaystyle\sum_{k=1}^n\theta_k$.\\
		Ce que l'on à obtenu nous pousse à montrer que l'ensemble des valeurs d'adhérence de $(z_n)$ est exactement l'ensemble des complexes de module $r$. Fixons $\theta\in\R$ et $\varepsilon>0$.\\
		On va chercher à trouver une infinité d'entiers positifs $k$ tels que $|\theta+2k\pi-S_{n_k}|\leq \varepsilon$.\\
		$\forall A>0,\ \exists N\in \N,\ \forall n\geq N,\ S_n\geq A$. Si $A>\theta_1$ l'ensemble $\{n\in \N,\ S_n<A\}$ est non vide et majoré. On peut donc considérer son maximum $n_A$.\\
		Par définition $S_{n_A}<A$ et $S_{n_A+1}\geq A$. On prend $A=\theta+2k\pi$ et on note $n_k:=n_A$.\\
		On a alors $0<\theta+2k\pi-S_{n_k}\leq S_{n_k+1}-S_{n_k}=\theta_k$.\\
		Par continuité de $t\mapsto e^{it}$ on se donne $\delta>0$ tel que $\forall x,y\in \R,\ |x-y|\leq \delta\implies |e^{ix}-e^{iy}|\leq \varepsilon$. Et comme $\theta_k\ukfty\longrightarrow 0$ on peut prendre $K\in \N$ tel que pour $k\geq K,\ \theta_k\leq \delta$.\\
		Ainsi $\forall k\geq K,\ |e^{i\theta}-e^{iS_{n_k}}|=|e^{i(\theta+2k\pi-S_{n_k})}-1|\leq \varepsilon$.\\
		Ainsi $e^{iS_{n_k}}\ukfty\longrightarrow e^{i\theta}$ et par suite $z_{n_k}\ukfty\longrightarrow re^{i\theta}$.
	\end{enumerate}
	
	\subsection{Nature d'une série (1) \ccinp{1}}
	\label{sec:nature-dune-serie-1etoile1}
	\textcolor{blue}{\hyperref[Nature d'une série 1]{[Enoncé]}}\\
	On remarque que: \begin{align*}
		\sin\left(\pi\sqrt{1+n^2}\right)&\ \ \ =\ \ \ \sin\left(\pi n\sqrt{1+\frac{1}{n^2}}\right)\\
		&\unfty{=}\sin\left(\pi n\left[1+\frac{1}{2n^2}+\bigO{\frac{1}{n^3}}\right]\right)\\
		&\unfty{=}(-1)^n\sin\left(\frac{\pi}{2n}+\bigO{\frac{1}{n^2}}\right)\\
		&\unfty{=}(-1)^n\frac{\pi}{2n}+\bigO{\frac{1}{n^2}}
	\end{align*}
	D'après le critère spécial des séries alternées, $\displaystyle\sum\limits_{n\geq 0}(-1)^n\frac{\pi}{2n}$ converge et d'après le critère de Riemann, $\displaystyle\sum_{n\geq 1}\frac{1}{n^2}$ converge. De plus $\forall n\in \N^*,\ \displaystyle\frac{1}{n^2}\geq 0$.
	\\Donc $\displaystyle\sum\limits_{n\geq 0}\sin(\pi\sqrt{1+n^2})$ converge.
	
	\subsection{Nature d'une série (2) \telecom{2}}
	\label{sec:nature-dune-serie-2-etoile2}
	\textcolor{blue}{\hyperref[Nature d'une série 2]{[Enoncé]}}\\
	Soit $n\in \N$. En séparant les deux sommes en termes impairs et pairs,\\
	$(2+\sqrt 3)^n+(2-\sqrt 3)^n=\displaystyle\sum_{k=0}^n\binom{n}{k}\sqrt{3}^k2^{n-k}+\sum_{k=0}^n\binom{n}{k}(-1)^k\sqrt{3}^k2^{n-k}=\sum_{k=0}^{\lfloor n/2\rfloor}\binom{n}{2k}3^k2^{n-2k+1}:=K_n\in \Z$.\\
	Donc \begin{align*}
		\sin(\pi(2+\sqrt 3)^n)&=\sin(K_n\pi-\pi(2-\sqrt 3)^n)\\
		&=\sin(K_n\pi)\cos(\pi(2-\sqrt 3)^n)-\cos(K_n\pi)\sin(\pi(2-\sqrt 3)^n)\\
		&=(-1)^{K_n+1}\sin(\pi(2-\sqrt 3)^n)
	\end{align*}
	Or $4\leq 4+2\sqrt 3\iff 2^2\leq (1+\sqrt 3)^2\implies 0\leq 2-\sqrt 3<1\implies \sin(\pi(2-\sqrt 3)^n)\unfty\sim\pi(2-\sqrt 3)^n$.\\
	La série $\displaystyle\sum_{n\in \N}(2-\sqrt 3)^n$ est à termes positifs et convergente donc par théorème de comparaison $\displaystyle\sum_{n\in \N}\sin((2+\sqrt 3)^n)$ est absolument convergente.
	
	\subsection{Nature d'une série (3) \centraleponts{3}}
	\label{sec:nature-dune-serie-3-etoile3}
	\textcolor{blue}{\hyperref[Nature d'une série 3]{[Enoncé]}}\\
	Soit $\alpha\in \R$. Soit $n\in \N^*$.\\
	Remarquons déjà que $\displaystyle\frac{n^\alpha}{1+n^\alpha}\in [0,1]$ donc $\displaystyle\arccos\left(\frac{n^\alpha}{1+n^\alpha}\right)$ est bien défini.\\
	Si $\alpha<0$, $\displaystyle\arccos\left(\frac{n^\alpha}{1+n^\alpha}\right)\unfty\longrightarrow\arccos(0)=\frac{\pi}{2}$.\\
	Et pour $\alpha=0$, $\displaystyle\arccos\left(\frac{n^\alpha}{1+n^\alpha}\right)\unfty\longrightarrow\arccos\left(\frac{1}{2}\right)=\frac{\pi}{3}$.\\
	Par conséquent si $\alpha\leq 0,\ \displaystyle\sum_{n\geq 1}\arccos\left(\frac{n^\alpha}{1+n^\alpha}\right)$ diverge grossièrement.\\
	Supposons $\alpha>0$. Le terme général étant positif, cherchons-en un équivalent.\\
	$\displaystyle\frac{n^\alpha}{1+n^\alpha}=\frac{1}{1+n^{-\alpha}}\unfty=1-\frac{1}{n^\alpha}+\smallo{\frac{1}{n^\alpha}}$.
	On sait que $\forall x\in ]-1,1[,\ \sin(\arccos(x))=\sqrt{1-x^2}$.\\
	Donc $\displaystyle\sin\left(\arccos\left(\frac{n^\alpha}{1+n^\alpha}\right)\right)\unfty=\sqrt{1-\left(1-\frac{1}{n^\alpha}+\smallo{\frac{1}{n^\alpha}}\right)^2}\unfty=\sqrt{\frac{2}{n^\alpha}+\smallo{\frac{1}{n^\alpha}}}\unfty\sim\frac{\sqrt 2}{n^{\alpha/2}}$.\\
	Or $\sin(x)\uxzero\sim x$ donc $\displaystyle\arccos\left(\frac{n^\alpha}{1+n^\alpha}\right)\unfty\sim\frac{\sqrt 2}{n^{\alpha/2}}$.\\
	On en déduit que $\displaystyle\sum_{n\in \N}\arccos\left(\frac{n^\alpha}{1+n^\alpha}\right)$ converge si et seulement si $\alpha>2$.
	
	\subsection{Nature d'une série (4) \xens{3}}
	\label{sec:nature-dune-serie-4}
	\textcolor{blue}{\hyperref[Nature d'une série 4]{[Enoncé]}}\\
	Soit $n\geq 2$ un entier.\\
	$\ppcm(a_1,\dots,a_n)\geq \ppcm(a_{n-1},a_n)=\displaystyle\frac{a_{n-1}a_n}{\pgcd(a_{n-1}a_n)}>0$.\\
	Or on remarque que $\pgcd(a_{n-1},a_n)|a_n-a_{n-1}>0$. Donc $\pgcd(a_{n-1},a_n)\leq a_n-a_{n-1}$ d'où $\displaystyle\frac{\pgcd(a_{n-1},a_n)}{a_{n-1}a_n}\leq\frac{a_n-a_{n-1}}{a_{n-1}a_n}=\frac{1}{a_{n-1}}-\frac{1}{a_n}$.\\
	On montre par récurrence que pour tout $n\in \N^*,\ a_n\geq a_1+n-1$ et on en déduit que $a_n\unfty{\longrightarrow}+\infty$.\\
	Ainsi $\displaystyle\sum\limits_{n\geq 2}\frac{1}{\ppcm(a_1,\dots,a_n)}$ est une série à termes positifs majorée $\left(\text{par }\displaystyle\sum\limits_{n=2}^{+\infty}\frac{1}{a_{n-1}}-\frac{1}{a_n}=\frac{1}{a_1}\right)$ : elle converge.
	
	\subsection{Nature d'une série (5) \xens{4}}
	\label{sec:nature-dune-serie-5}
	\textcolor{blue}{\hyperref[Nature d'une série 5]{[Enoncé]}}\\
	Montrons le lemme suivant : (inégalité de réarrangement)\\
	Soient $a_1>\dots>a_n,b_1<\dots<b_n$ des réels. Alors pour toute permutation $\sigma\in \S_n$,
	$$S(\sigma):=\sum_{k=1}^na_ib_{\sigma(i)}\leq \sum_{k=1}^na_ib_i$$
	Soient $\sigma\in \S_n$ tel que $S(\sigma)$ soit minimale et $\tau=(ij)$, où $i<j$, une transposition.\\
	On remarque que $S(\sigma\circ\tau)-S(\sigma)=a_ib_{\sigma(j)}-a_ib_{\sigma(i)}+a_jb_{\sigma(i)}-a_jb_{\sigma(j)}=(a_j-a_i)(b_{\sigma(i)}-b_{\sigma(j)})$.\\
	$S(\sigma\circ\tau)-S(\sigma)\geq 0$ par minimalité de $S(\sigma)$ et $a_j-a_i<0$ car $j>i$. Donc $b_{\sigma(i)}\leq b_{\sigma(j)}$ d'où $\sigma(i)\leq \sigma(j)$.\\
	On a montré que $\sigma$ est une bijection de $\crblanc{1}{n}$ croissante, c'est donc l'identité d'où le résultat.\\
	\textit{Remarque : on peut aussi faire une récurrence en isolant les termes faisant apparaître l'indice $n+1$, ce qui revient en fait au même.}\\\\
	Fixons $n\in \N$. Tout d'abord, on peut minorer $\displaystyle\sum_{k=1}^n\frac{\alpha_k}{k^2}\geq \sum_{k=1}^n\frac{b_k}{k^2}$ avec $\beta_1,\dots,\beta_n\in \crblanc{1}{n}$. En effet, si $k\in \crblanc{1}{n}\backslash\{\alpha_1,\dots,\alpha_n\}$ alors au moins un des $n$ entiers $\alpha_1,\dots,\alpha_n$ est supérieur strictement à $n$, et on le minore alors par $k$.\\
	L'application $\sigma:k\in\crblanc{1}{n}\mapsto \beta_k$ est alors une bijection.\\
	D'après le lemme appliqué à $a_i=\dfrac{1}{i^2}$ et $b_i=i$ on a alors $\displaystyle\sum_{k=1}^n\frac{\alpha_k}{k^2}\geq \sum_{k=1}^n\frac{k}{k^2}=\sum_{k=1}^n\frac{1}{k}\unfty\longrightarrow+\infty$.
	
	\subsection{Calcul d'un équivalent \xens{4}}
	\label{sec:calcul-dun-equivalent-etoile3}
	\textcolor{blue}{\hyperref[Calcul d'un équivalent]{[Enoncé]}}\\
	\underline{$1^{ère}$ méthode :} Somme de Riemann\\
	
	
	\underline{$2^{nd}$ méthode :} Comparaison série-intégrale\\
	Posons $\forall n\in \N^*,\ S_n=n\ln(u_n)=\displaystyle\sum_{k=1}^nk\ln k$ ainsi que $f:t\in \R^*_+\mapsto t\ln t$.\\
	On veut une estimation du type $u_n\unfty=U_n(1+\smallo 1)$ donc $\ln(u_n)\unfty=\ln(U_n)+\ln(1+\smallo 1)\unfty=\ln(U_n)+\smallo 1$. Il faut donc estimer $S_n$ à la précision $\smallo n$.\\
	$f$ est dérivable sur $\R^*_+$ et $\forall t>0,\ f'(t)=\ln t+1$. Donc $f$ est croissante sur $[e^{-1},+\infty[\subset [1,+\infty[$.\\
	Ainsi si $k\geq 1$ et $t\in [k,k+1]$ on a
	$$k\ln k\leq t\ln t\leq (k+1)\ln(k+1)$$
	Puis en intégrant de $k$ à $k+1$ et en sommant de $1$ à $n$,
	$$S_n\leq\int_1^{n+1}t\ln t\ dt\leq S_n-2\ln 2+(n+1)\ln(n+1)$$
	C'est à dire :
	$$2\ln 2-(n+1)\ln(n+1)+\int_1^{n+1}t\ln t\ dt\leq S_n\leq \int_1^{n+1}t\ln t\ dt$$
	On va seulement utiliser la majoration et minorer $S_n$ par $0$.
	Calculons l'intégrale par IPP :\\
	$\displaystyle\int_1^{n+1}t\ln t\ dt=\left[\frac{t^2}{2}\ln t\right]_1^{n+1}-\int_1^{n+1}\frac{t}{2}\ dt=\frac{(n+1)^2}{2}\ln(n+1)-\frac{(n+1)^2}{4}+\frac{1}{4}$.\\
	On rappelle que $\ln(n+1)\unfty\sim\ln n$ car $\ln(n+1)-\ln n=\displaystyle\ln\left(1+\frac{1}{n}\right)\unfty=\smallo 1\unfty=\smallo{\ln n}$.\\
	Donc $\displaystyle\int_1^{n+1}t\ln t\ dt\unfty=\frac{n^2}{2}\ln n-\frac{n^2}{4}+\smallo n$.\\
	Posons $T_n=S_n-\dfrac{n^2\ln n}{2}+\dfrac{n^2}{4}$. On souhaite estimer $T_n$ à la précision $\smallo n$ et comme sa définition fait intervenir une somme une bonne idée peut être d'essayer d'estimer $T_{n+1}-T_n$ à la précision $\smallo 1$ puis de sommer l'estimation obtenue.
	\begin{align*}
		T_{n+1}-T_n&\ \ \,=\ \ \,(n+1)\ln(n+1)-\frac{(n+1)^2}{2}\ln(n+1)+\frac{(n+1)^2}{4}+\frac{n^2}{2}\ln n-\frac{n^2}{4}\\
		&\unfty=(n+1)\ln n+\frac{2n+1}{4}-\frac{2n+1}{2}\ln n+\left(\frac{(n+1)^2}{2}-n-1\right)\ln\left(1-\frac{1}{n+1}\right)+\smallo 1\\
		&\unfty=\frac{\ln n}{2}+\frac{2n+1}{4}+\left(n+1-\frac{(n+1)^2}{2}\right)\left(\frac{1}{n+1}+\frac{1}{2(n+1)^2}\right)+\smallo 1\\
		&\unfty=\frac{\ln n}{2}+\frac{2n+1}{4}1-\frac{n+1}{2}-\frac{1}{4}+\smallo 1\\
		&\unfty=\frac{1}{2}+\frac{\ln n}{2}+\smallo 1
	\end{align*}
	Donc en sommant $T_n-T_1=\displaystyle\sum_{k=1}^{n-1}T_{k+1}-T_k\unfty=\frac{n}{2}+\frac{1}{2}\sum_{k=1}^{n-1}\ln k+\smallo n$.\\
	On montre classiquement par comparaison série-intégrale $\displaystyle\sum_{k=1}^{n-1}\ln k\unfty=n\ln n-n+\smallo n$.\\
	Par conséquent $T_n=\dfrac{n\ln n}{2}+\smallo n$.\\
	Par suite, $S_n=T_n+\displaystyle\frac{n^2\ln n}{2}-\frac{n^2}{4}\unfty=\frac{n\ln n}{2}-\frac{n^2}{4}+\frac{n^2\ln n}{2}+\smallo n$.\\
	Finalement,
	\begin{align*}
		u_n&\ \ \,=\ \ \,\exp\left(\frac{S_n}{n}\right)\\
		&\unfty=\exp\left(-\frac{n}{4}+\frac{(n+1)\ln n}{2}+\smallo 1\right)\\
		&\unfty=n^{\frac{n+1}{2}}e^{-\frac{n}{4}}e^{\smallo 1}\\
		&\unfty\sim n^{\frac{n+1}{2}}e^{-\frac{n}{4}}
	\end{align*}
	
	\subsection{Sommation de relations de comparaison \ccinp{1}}
	\label{sec:sommation-de-relations-de-comparaison}
	\textcolor{blue}{\hyperref[Sommation de relations de comparaison]{[Enoncé]}}\\
	Non ! Le théorème du cours nous dit qu'on a la conclusion lorsque l'une des suites est de signe constant APCR (elles sont de toute façon de même signe APCR). Trouvons un contre exemple.\\
	Les suites de terme général $u_n=\dfrac{(-1)^n}{\sqrt n}$ et $v_n=\dfrac{(-1)^n}{\sqrt n}+\dfrac{1}{n}$ sont équivalentes.
	Or $\displaystyle\sum_{n\in \N^*}u_n$ converge par critère spécial et $\displaystyle\sum_{n\in \N^*}v_n$ diverge comme somme d'une série convergente et d'une série divergente.
	
	\subsection{\underline{Equivalent de séries de Riemann} \ccinp{1}}
	\label{sec:equivalent-de-series-de-riemann}
	\textcolor{blue}{\hyperref[Equivalent de séries de Riemann]{[Enoncé]}}\\
	\underline{$1^{ère}$ méthode :} Sommation de relations de comparaison\\
	On remarque que $\displaystyle\frac{1}{n^\alpha}-\frac{1}{(n+1)^\alpha}=\frac{(n+1)^\alpha-n^\alpha}{n^\alpha(n+1)^\alpha}=\frac{\left(1+\frac{1}{n}\right)^\alpha-1}{(n+1)^\alpha}\unfty\sim\frac{\alpha}{n^{\alpha+1}}$.\\
	La suite $\left(\dfrac{1}{n^\alpha}\right)$ est positive donc
	\begin{itemize}
		\item si $\alpha<1,\ \displaystyle\sum_{k=1}^n\frac{1}{k^\alpha}\unfty\sim\frac{1}{\alpha-1}\sum_{k=1}^n\left(\frac{1}{k^{\alpha-1}}-\frac{1}{(k+1)^{\alpha-1}}\right)\unfty\sim\frac{n^{1-\alpha}}{1-\alpha}$;
		\item si $\alpha>1,\ \displaystyle\sum_{k=n+1}^{+\infty}\frac{1}{k^\alpha}\unfty\sim\frac{1}{\alpha-1}\sum_{k=n+1}^{+\infty}\left(\frac{1}{k^{\alpha-1}}-\frac{1}{(k+1)^{\alpha-1}}\right)\unfty\sim\frac{1}{(\alpha-1)n^{\alpha-1}}$.
	\end{itemize}
	
	\underline{$2^{nd}$ méthode :} Comparaison série-intégrale\\
	On pose $f_\alpha:t\mapsto\dfrac{1}{t^\alpha}$. $f_\alpha$ est dérivable sur $\R^*_+$ et $\forall t>0,\ f_\alpha'(t)=-\dfrac{\alpha}{t^{\alpha+1}}$ est du signe de $-\alpha$.\\
	Fixons $k\in \N^*$. Soit $t\in [k,k+1]$.\\
	Si $\alpha<0$ alors $f_\alpha(k)\leq f_\alpha(t)\leq f_\alpha(k+1)$. D'où en intégrant sur $[k,k+1]$ :
	$$f_\alpha(k)\leq \displaystyle\int_k^{k+1}f_\alpha(t)dt\leq f_\alpha(k+1)$$
	Puis en sommant de $1$ à $n-1$ :\\
	$$\sum_{k=1}^{n-1}\frac{1}{k^\alpha}\leq \int_1^n\frac{dt}{t^\alpha}\leq \sum_{k=2}^n\frac{1}{k^\alpha}$$
	Càd
	$$1+\frac{n^{1-\alpha}-1}{1-\alpha}=1+\int_1^n\frac{dt}{t^\alpha}\leq\sum_{k=1}^n\frac{1}{k^\alpha}\leq \frac{1}{n^\alpha}+\int_1^n\frac{dt}{t^\alpha}=\frac{1}{n^\alpha}+\frac{n^{1-\alpha}-1}{1-\alpha}$$
	Si $0\leq\alpha<1$ on obtient les même inégalités dans l'autre sens, donc dans ces deux cas $\displaystyle\sum_{k=1}^n\frac{1}{k^\alpha}\unfty\sim\frac{n^{1-\alpha}}{1-\alpha}$ par encadrement.\\
	Si $\alpha>1$ on somme plutôt de $n$ à $+\infty$ :
	$$\sum_{k=n+1}^{+\infty}\frac{1}{k^\alpha}\leq \int_n^{+\infty}\frac{dt}{t^\alpha}\leq \sum_{k=n}^{+\infty}\frac{1}{k^\alpha}$$
	Càd
	$$\frac{1}{(\alpha-1)n^{\alpha-1}}-\frac{1}{n^\alpha}=\int_n^{+\infty}\frac{dt}{t^\alpha}-\frac{1}{n^\alpha}\leq\sum_{k=n+1}^{+\infty}\frac{1}{k^\alpha}\leq \int_n^{+\infty}\frac{dt}{t^\alpha}=\frac{1}{(\alpha-1)n^{\alpha-1}}$$
	Donc $\displaystyle\sum_{k=n+1}^{+\infty}\frac{1}{k^\alpha}\unfty\sim\frac{1}{(\alpha-1)n^{\alpha-1}}$ par encadrement.
	
	\subsection{\underline{Séries de Bertrand} \ccinp{2}}
	\label{sec:series-de-bertrand}
	\textcolor{blue}{\hyperref[Séries de Bertrand]{[Enoncé]}}\\
	Soient $\alpha,\beta\in \R$.
	\begin{itemize}
		\item Si $\alpha>1$ : on se donne $\gamma\in ]1,\alpha[$.\\
		$\dfrac{1}{n^\alpha\ln(n)^\beta}=\smallo{\dfrac{1}{n^\gamma}}$ car $\gamma<\alpha$ et $\displaystyle\sum_{n\geq 1}\frac{1}{n^\gamma}$ converge car $\gamma>1$. En outre la suite $\left(\dfrac{1}{n^\gamma}\right)_{n\in \N^*}$ est positive.\\
		On en déduit que $\displaystyle\sum_{n\geq 2}\frac{1}{n^\alpha\ln(n)^\beta}$ converge;
		\item Si $\alpha<1$ : on se donne $\gamma\in ]\alpha,1[$.\\
		$\dfrac{1}{n^\gamma}=\smallo{\dfrac{1}{n^\alpha\ln(n)^\beta}}$ car $\gamma>\alpha$ et $\displaystyle\sum_{n\geq 1}\frac{1}{n^\gamma}$ diverge car $\gamma<1$. En outre la suite $\left(\dfrac{1}{n^\gamma}\right)_{n\in \N^*}$ est positive.\\
		On en déduit que $\displaystyle\sum_{n\geq 2}\frac{1}{n^\alpha\ln(n)^\beta}$ diverge;
		\item Si $\alpha=1$ : on pose $f_\beta:t\mapsto\dfrac{1}{t\ln(t)^\beta}$.
		\begin{itemize}[label=\textbullet]
			\item Si $\beta<0$ : $\forall x,y\in [2,+\infty[,\ x\leq y\implies x\ln(x)^\beta\geq y\ln(y)^\beta\implies f_\beta(x)\leq f_\beta(y)$.\\
			Fixons $k\in \N^*$. Soit $t\in [k,k+1]$.\\
			Alors $f_\beta(k)\leq f_\beta(t)\leq f_\beta(k+1)$. D'où en intégrant sur $[k,k+1]$ :
			$$f_\beta(k)\leq \displaystyle\int_k^{k+1}f_\beta(t)dt\leq f_\beta(k+1)$$
			Puis en sommant de $2$ à $n-1$ :\\
			$$\sum_{k=2}^{n-1}\frac{1}{k^\beta}\leq \int_2^n\frac{dt}{t^\beta}\leq \sum_{k=3}^n\frac{1}{k^\beta}$$
			Càd
			$$\frac{1}{2\ln(2)^\beta}+\int_2^n\frac{dt}{t\ln(t)^\beta}\leq\sum_{k=2}^n\frac{1}{k\ln(k)^\beta}\leq \frac{1}{n\ln(n)^\beta}+\int_2^n\frac{dt}{t\ln(t)^\beta}$$
			On calcule avec $\beta\ne 1$, $\displaystyle\int_2^n\frac{dt}{t\ln(t)^\beta}=\left[\frac{\ln(t)^{1-\beta}}{1-\beta}\right]_2^n=\frac{1}{1-\beta}\left(\ln(n)^{1-\beta}-\ln(2)^{1-\beta}\right)$.\\
			Donc comme $\dfrac{\ln(n)^{1-\beta}}{1-\beta}\unfty\longrightarrow+\infty$, $\displaystyle\sum_{n\geq 2}\frac{1}{n\ln(n)^\beta}$ diverge;
			\item Si $\beta>0$ : $f_\beta$ est décroissante donc on a les mêmes inégalités dans l'autre sens.\\
			Si $\beta<1$, $\dfrac{1}{n\ln(n)^\beta}+\dfrac{\ln(n)^{1-\beta}}{1-\beta}\unfty\longrightarrow+\infty$ donc $\displaystyle\sum_{n\geq 2}\frac{1}{n\ln(n)^\beta}$ diverge.\\
			Si $\beta>1$, $\dfrac{\ln(n)^{1-\beta}}{1-\beta}\unfty\longrightarrow0$ donc la série $\displaystyle\sum_{n\geq 2}\frac{1}{n\ln(n)^\beta}$ est majorée. Etant à termes positifs elle converge.\\
			Enfin si $\beta=1$ alors $\displaystyle\int_2^n\frac{dt}{t\ln(t)}=\ln(\ln(n))-\ln(\ln(2))\unfty\longrightarrow+\infty$ donc $\displaystyle\sum_{n\geq 2}\frac{1}{n\ln(n)^\beta}$ diverge.
		\end{itemize}
	\end{itemize}
	
	\subsection{Critère de Raabe-Duhamel \ccinp{2}}
	\label{sec:critere-de-raabe-duhamel-etoile2}
	\textcolor{blue}{\hyperref[Critère de Raabe-Duhamel]{[Enoncé]}}\\
	\begin{enumerate}
		\item APCR, on a $\displaystyle\frac{v_{n}}{u_n}\leq\frac{v_{n+1}}{u_{n+1}}$ c'est-à-dire $\left(\displaystyle\frac{v_{n}}{u_n}\right)$ est croissante APCR. Donc, pour un certain $N\in\N$, on a pour tout $n\geq N, \; \displaystyle\frac{v_{N}}{u_N}\leq\frac{v_{n}}{u_n}$, c'est-à-dire $0\leq u_n\leq\displaystyle\frac{u_N}{v_N}v_n$
		\\Et donc $u_n\unfty{=}\bigO{v_n}$
		\item \begin{itemize}
			\item Soit $\gamma\in]1,\alpha[$. On remarque que $\displaystyle\left(\frac{n}{n+1}\right)
			^\gamma=\left(1-\frac{1}{n+1}\right)^\gamma\unfty{=}1-\frac{\gamma}{n}+\smallo{\frac{1}{n}}$.
			\\Ainsi $\displaystyle\frac{u_{n+1}}{u_n}-\frac{n^{\gamma}}{(n+1)^{\gamma}}\unfty{=}\frac{\gamma-\alpha}{n}+\smallo{\frac{1}{n}}$.
			\\Donc $\displaystyle\frac{u_{n+1}}{u_n}\leq\frac{n^{\gamma}}{(n+1)^{\gamma}}$. Et d'après la question 1, on a: $u_n\unfty{=}\bigO{\displaystyle\frac{1}{n^\gamma}}$.
			\\Et donc $\displaystyle\sum\limits_{n\geq 0}u_n$ converge.
			\item On prend cette fois $\gamma\in]\alpha,1[$. On a: $\displaystyle\frac{1}{n^{\gamma}}\smallo{u_n}$, et donc $\displaystyle\sum\limits_{n\geq 0}u_n$ diverge.
			\item On peut prendre $u_n=\displaystyle\frac{1}{n}$ et $v_n=\displaystyle\frac{1}{n\ln(n)^2}$ pour montrer que l'on ne peut conclure quand $\alpha=1$.
		\end{itemize}
	\end{enumerate}
	
	\subsection{Règle de d'Alembert \ccinp{2}}
	\label{sec:regle-de-dalembert}
	\textcolor{blue}{\hyperref[Règle de d'Alembert]{[Enoncé]}}\\
	\begin{itemize}
		\item Supposons $\ell<1$. Soit $\varepsilon>0$. Par hypothèse $\exists n_0\in \N,\ \forall n\geq n_0,\ \left|\dfrac{u_{n+1}}{u_n}-\ell\right|\leq \varepsilon$.\\
		D'où comme $(u_n)_{n\in \N}$ est positive, $\forall n\geq n_0,\ u_{n+1}\leq u_n(\ell+\varepsilon)$.\\
		Par récurrence immédiate $\forall n\geq n_0,\ u_n\leq u_{n_0}(\ell+\varepsilon)^{n-n_0}$. Alors en prenant $\varepsilon\in ]0,1-\ell[$, $0\leq\ell+\varepsilon<1$ donc la série $\displaystyle\sum_{n\in \N}(\ell+\varepsilon)^n$ converge et par suite $\displaystyle\sum_{n\in \N}u_n$ converge.
		\item Si $\ell>1$ alors $\exists n_0\in \N,\ \forall n\geq n_0,\ \dfrac{u_{n+1}}{u_n}\geq 1$. Donc $\forall n\geq n_0,\ u_{n+1}\geq u_n\geq u_{n_0}>0$. Ainsi $\displaystyle\sum_{n\in \N}u_n$ diverge grossièrement.
	\end{itemize}
	Montrons que dans le cas $\ell=1$ la série peut diverger ou converger.\\
	Pour $u_n=\displaystyle\frac{1}{n}$, $\displaystyle\frac{u_{n+1}}{u_n}=\frac{n+1}{n}\unfty\longrightarrow 1$ et la série $\displaystyle\sum_{n\in \N^*}\frac{1}{n}$ diverge.\\
	Pour $u_n=\displaystyle\frac{1}{n^2}$, $\displaystyle\frac{u_{n+1}}{u_n}=\frac{(n+1)^2}{n^2}\unfty\longrightarrow 1$ et la série $\displaystyle\sum_{n\in \N^*}\frac{1}{n^2}$ converge.
	
	\subsection{Règle de Cauchy \ccinp{2}}
	\label{sec:regle-de-cauchy}
	\textcolor{blue}{\hyperref[Règle de Cauchy]{[Enoncé]}}\\
	\begin{itemize}
		\item Supposons $\ell<1$. Soit $\varepsilon>0$. Par hypothèse $\exists n_0\in \N,\ \forall n\geq n_0,\ \left|\sqrt[n]{u_n}-\ell\right|\leq \varepsilon$.\\
		D'où $\forall n\geq n_0,\ u_n\leq (\ell+\varepsilon)^n$. Alors en prenant $\varepsilon\in ]0,1-\ell[$, $0\leq\ell+\varepsilon<1$ donc la série $\displaystyle\sum_{n\in \N}(\ell+\varepsilon)^n$ converge et par suite $\displaystyle\sum_{n\in \N}u_n$ converge.
		\item Si $\ell>1$ alors $\exists n_0\in \N,\ \forall n\geq n_0,\ \sqrt[n]{u_n}\geq 1$. Donc $\forall n\geq n_0,\ u_n\geq 1$. Ainsi $\displaystyle\sum_{n\in \N}u_n$ diverge grossièrement.
	\end{itemize}
	Montrons que dans le cas $\ell=1$ la série peut diverger ou converger.\\
	Pour $u_n=\left(1+\dfrac{1}{n}\right)^n$, $\sqrt[n]{u_n}=1+\dfrac{1}{n}\unfty\longrightarrow 1$ et la série $\displaystyle\sum_{n\in \N^*}\left(1+\frac{1}{n}\right)^n$ diverge grossièrement.\\
	($u_n=\displaystyle\frac{1}{n}$ fonctionne aussi.)\\
	Pour $u_n=\displaystyle\frac{1}{n^2}$, $\sqrt[n]{u_n}=n^{-2/n}=\exp\left(-\dfrac{2\ln n}{n}\right)\unfty\longrightarrow 1$ et la série $\displaystyle\sum_{n\in \N^*}\frac{1}{n^2}$ converge.
	
	\subsection{d'Alembert $\Rightarrow$ Cauchy \centraleponts{3}}
	\label{sec:dalembert-rightarrow-cauchy}
	\textcolor{blue}{\hyperref[d'Alembert implique Cauchy]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item \begin{itemize}
			\item Supposons $\ell\in \R_+$. Soit $\varepsilon>0$. Par hypothèse $\exists n_0\in \N,\ \forall n\geq n_0,\ (1-\varepsilon)\ell\leq\dfrac{u_{n+1}}{u_n}\leq (1+\varepsilon)\ell$.\\
			Càd comme $(u_n)_{n\in \N}$ est positive, $\forall n\geq n_0,\ u_n(1-\varepsilon)\ell\leq u_{n+1}\leq u_n(1+\varepsilon)\ell$.\\
			Par récurrence immédiate $\forall n\geq n_0,\ \dfrac{u_{n_0}}{(1-\varepsilon)^{n_0}\ell^{n_0}}(1-\varepsilon)^n\ell^n\leq u_n\leq \dfrac{u_{n_0}}{(1+\varepsilon)^{n_0}\ell^{n_0}}(1+\varepsilon)^n\ell^n$.\\
			D'où $\forall n\geq n_0,\ \dfrac{u_{n_0}}{\ell^{n_0}}(1-\varepsilon)^n\ell^n\leq u_n\leq \dfrac{u_{n_0}}{\ell^{n_0}}(1+\varepsilon)^n\ell^n$.\\
			D'où $\forall n\geq n_0,\ \sqrt[n]{\dfrac{u_{n_0}}{\ell^{n_0}}}(1-\varepsilon)\ell\leq \sqrt[n]{u_n}\leq \sqrt[n]{\dfrac{u_{n_0}}{\ell^{n_0}}}(1+\varepsilon)\ell$.\\
			Or $\sqrt[n]{\dfrac{u_{n_0}}{\ell^{n_0}}}\unfty\longrightarrow 1$ donc on peut trouver $n_1\in \N$ pour lequel $\forall n\geq n_1,\ \left|\sqrt[n]{\dfrac{u_{n_0}}{\ell^{n_0}}}-1\right|\leq \varepsilon$.\\
			Alors pour tout $n\geq \max(n_0,n_1)$, $(1-\varepsilon)^2\ell\leq \sqrt[n]{u_n}\leq (1+\varepsilon)^2\ell$.\\
			Finalement $\sqrt[n]{u_n}\unfty\longrightarrow\ell$.
			\item Supposons $\ell=+\infty$. Soit $A>0$. Par hypothèse $\exists n_0\in \N,\ \forall n\geq n_0,\ \dfrac{u_{n+1}}{u_n}\geq A$.\\
			Càd comme $(u_n)_{n\in \N}$ est positive, $\forall n\geq n_0,\ u_{n+1}\geq u_nA$.\\
			Par récurrence immédiate $\forall n\geq n_0,\ u_n\geq u_{n_0}A^{n-n_0}$.\\
			D'où $\forall n\geq n_0,\ \sqrt[n]{u_n}\geq \sqrt[n]{\dfrac{u_{n_0}}{A^{n_0}}}A$.\\
			Or $\sqrt[n]{\dfrac{u_{n_0}}{A^{n_0}}}\unfty\longrightarrow 1$ donc on peut trouver $n_1\in \N$ pour lequel $\forall n\geq n_1,\ \sqrt[n]{\dfrac{u_{n_0}}{A^{n_0}}}\geq \dfrac{1}{2}$.\\
			Alors pour tout $n\geq \max(n_0,n_1)$, $\sqrt[n]{u_n}\geq \dfrac{A}{2}$.\\
			Finalement $\sqrt[n]{u_n}\unfty\longrightarrow+\infty$.
		\end{itemize}
		\item Soit $\varepsilon>0$. On pose $v_n=\dfrac{u_n}{(\ell+\varepsilon)^n}$ et $w_n=\dfrac{(\ell-\varepsilon)^n}{u_n}$. Les suites $(v_n)_{n\in \N},\ (w_n)_{n\in \N}$ sont à termes strictement positifs.\\
		De plus $\displaystyle\frac{v_{n+1}}{v_n}=\frac{u_{n+1}}{u_n}(\ell+\varepsilon)^{-1}\unfty\longrightarrow\frac{\ell}{\ell+\varepsilon}<1$ et $\displaystyle\frac{w_{n+1}}{w_n}\unfty\longrightarrow\frac{\ell-\varepsilon}{\ell}<1$.\\
		Donc par le critère de d'Alembert les séries $\displaystyle\sum_{n\in \N}v_n$ et $\displaystyle\sum_{n\in \N}w_n$ converge. Leur terme général est donc de limite nulle d'où APCR $\ell-\varepsilon\leq \sqrt[n]{u_n}\leq \ell+\varepsilon$.
		\item On considère $x_n=\ln\left(\dfrac{u_{n+1}}{u_n}\right)$. Par continuité de $\ln$, $(x_n)_{n\in \N}$ converge vers $\ln(\ell)$ (avec les conventions $\ln(0)=-\infty$, $\ln(+\infty)=+\infty$). Donc d'après le lemme de Césaro $$\frac{1}{n}\sum_{k=0}^{n-1}\ln(u_{k+1})-\ln(u_k)=\frac{\ln(u_n)-\ln(u_0)}{n}\unfty\longrightarrow\ln(\ell)$$
		Donc $\dfrac{\ln(u_n)}{n}\unfty\longrightarrow\ln(\ell)$ puis par continuité de $\exp$, $\sqrt[n]{u_n}\unfty\longrightarrow\ell$.
		\item La réciproque est fausse. Pour $u_n=2+(-1)^n$ :
		\begin{itemize}
			\item $\sqrt[2n]{u_{2n}}=e^{\ln(3)/n}\unfty\longrightarrow 1$ et $\sqrt[2n+1]{u_{2n +1}}=1\unfty\longrightarrow 1$ donc $\sqrt[n]{u_n}\unfty\longrightarrow 1$;
			\item $\dfrac{u_{2n+2}}{u_{2n+1}}=3\unfty\longrightarrow 3$ et $\dfrac{u_{2n+1}}{u_{2n}}=\dfrac{1}{3}\unfty\longrightarrow\dfrac{1}{3}$ donc $\left(\dfrac{u_{n+1}}{u_n}\right)_{n\in \N}$ n'admet pas de limite.
		\end{itemize}
	\end{enumerate}
	
	\subsection{\underline{Transformation d'Abel et règle d'Abel} \centraleponts{2}}
	\label{sec:transformation-dabel-et-regle-dabel}
	\textcolor{blue}{\hyperref[Transformation et règle d'Abel]{[Enoncé]}}\\
	
	\subsubsection{Une série de Dirichlet}
	
	\subsection{Equation différentielle discrète \centraleponts{3}}
	\label{sec:equation-differentielle-discreteetoile3}
	\textcolor{blue}{\hyperref[Equation différentielle discrète]{[Enoncé]}}\\
	\begin{enumerate}
		\item La série $\displaystyle\sum a_n^2$ est à termes positifs donc la suite $(S_n)$ converge ou diverge vers $+\infty$.\\ Supposons qu'elle converge vers un certain $l\in\R$. Puisque pour tout $n\in \N^*,\ S_n\geq a_1^2>0$, $l$ est strictement positif. Donc $(a_n)$ converge vers $\displaystyle\frac{1}{l}$. Or ceci est absurde car $\displaystyle\sum a_n^2$ divergerait grossièrement. Par conséquent, la série $\displaystyle\sum a_n^2$ diverge vers $+\infty$ et $a_n$ tend vers 0.
		\item Soient $n\in\N^*$ et $y\in[S_{n-1},S_n]$\\Par croissance de $t\to t^2$ sur $\R^+$, $$(S_n-S_{n-1})S_{n-1}^2\leq\displaystyle\int_{S_{n-1}}^{S_n}t^2dt\leq(S_n-S_{n-1})S_{n}^2$$
		On remarque que $(S_n-S_{n-1})S_{n-1}^2=a_n^2S_{n-1}^2=a_n^2(S_n-a_n)^2=a_n^2S_n^2-2S_na_n^3+a_n^4$\\ Puisque $\lim\limits_{n\to+\infty}a_nS_n=1$ et $\lim\limits_{n\to +\infty}a_n=0$, on en déduit que $\displaystyle\int_{S_{n-1}}^{S_n}t^2dt\unfty{\longrightarrow}1$ d'après le théorème des gendarmes.
		\item On remarque que $\displaystyle\sum\limits_{k=1}^n\displaystyle\int_{S_{k-1}}^{S_k}t^2dt=\displaystyle\int_{0}^{S_n}t^2dt=\frac{S_n^3}{3}$.
		\\ Or $\displaystyle\int_{S_{n-1}}^{S_n}t^2\unfty{\sim}1$ donc par sommation de relation de comparaison pour les séries divergentes à termes positifs, $\displaystyle\sum\limits_{k=1}^n\displaystyle\int_{S_{k-1}}^{S_k}t^2dt\unfty{\sim}n$. Par conséquent, on a $S_n \unfty{\sim}\sqrt[3]{3n}$.
		\\Et finalement $a_n\unfty{\sim}\displaystyle\frac{1}{\sqrt[3]{3n}}$.
	\end{enumerate}
	
	\subsection{Critère spécial des séries alternées}
	\label{sec:critere-special-des-series-alternees}
	\textcolor{blue}{\hyperref[Critère spécial des séries alternées]{[Enoncé]}}\\
	
	\subsection{Calcul d'une somme de série (1) \xens{3}}
	\label{sec:calcul-dune-somme-de-serie-1-etoile3}
	\textcolor{blue}{\hyperref[Calcul d'une somme de série 1]{[Enoncé]}}\\
	$\forall n\in \N^*,\ u_n=\displaystyle\frac{n(n+1)(2n+1)}{6}$. $\displaystyle\frac{1}{u_n}\unfty{=}\bigO{\frac{1}{n^3}}$ donc $\displaystyle\sum\limits_{n\geq 1}\frac{1}{u_n}$ converge par comparaison à une série de Riemann.\\
	On décompose en éléments simples $F(X)=\displaystyle\frac{6}{X(X+1)(2X+1)}=\displaystyle\frac{a}{X}+\displaystyle\frac{b}{X+1}+\displaystyle\frac{c}{2X+1}$.\\
	$\begin{cases}
		a=\lim\limits_{x\to 0}xF(x)=6\\
		b=\lim\limits_{x\to -1}(x+1)F(x)=6\\
		c=\lim\limits_{x\to -\frac{1}{2}}(2x+1)F(x)=-24
	\end{cases}$
	Donc $\displaystyle\sum\limits_{n=1}^{+\infty}\frac{1}{u_n}=6\sum\limits_{n=1}^{+\infty}\frac{1}{n}+\frac{1}{n+1}-\frac{4}{2n+1}$\\
	Posons pour $n\in \N^*,\ S_n=\displaystyle\sum\limits_{k=1}^{n}\frac{1}{u_k}$ ainsi que $H_n=\displaystyle\sum\limits_{k=1}^{n}\frac{1}{k}$.\\
	On montre classiquement que $H_n\unfty{=}\ln(n)+\gamma+\smallo{1}$ où $\gamma$ est une constante.\\
	Ainsi,
	\begin{align*}
		\displaystyle\frac{1}{6}S_n&\ \ \ =H_n+H_{n+1}-1-4\left(\displaystyle\sum\limits_{k=2}^{2n+1}\frac{1}{k}-\sum\limits_{k=1}^n\frac{1}{2k}\right)\\
		&\ \ \ =H_n+H_{n+1}-1-4\left(H_{2n+1}-1\right)+2H_n\\
		&\unfty{=}3\ln(n)+\gamma+\ln(n+1)+3\gamma+3-4\ln(2n+1)-4\gamma+\smallo{1}\\
		&\unfty{=}\ln\left(\displaystyle\frac{n^3(n+1)}{(2n+1)^4}\right)+3+\smallo{1}\\
		&\unfty{=}3-\ln(16)+\smallo{1}
	\end{align*}\\
	Finalement, $\displaystyle\sum\limits_{n=1}^{+\infty}\frac{1}{u_n}=18-24\ln(2)$.
	
	\subsection{Calcul d'une somme de série (2) \telecom{1}}
	\label{sec:calcul-dune-somme-de-serie-2-etoile1}
	\textcolor{blue}{\hyperref[Calcul d'une somme de série 2]{[Enoncé]}}\\
	\underline{$1^{ère}$ méthode :}\\
	$\forall n\in \N^*,\ u_n=\displaystyle\frac{1}{n}\sum\limits_{k=1}^n\frac{1}{1+\displaystyle\frac{k}{n}}$. La fonction $f:x\mapsto \displaystyle\frac{1}{1+x}$ est continue sur $[0,1]$ donc $(u_n)_{n\in \N^*}$ converge et,\\\\
	$\unfty{\lim}u_n=\unfty{\lim}\displaystyle\frac{
		1-0}{n}\sum\limits_{k=1}^nf\left(\frac{k}{n}\right)=\int_0^1f(x)dx=\ln 2$.\\
	\underline{$2^{ème}$ méthode :}\\
	$\forall n\in \N^*,\ u_n=\displaystyle\sum\limits_{k=n+1}^{2n}\frac{1}{k}=H_{2n}-H_n$, avec $H_n=\displaystyle\sum\limits_{k=1}^n\frac{1}{k}$.
	En utilisant le développement asymptotique classique de la série harmonique, $u_n\unfty{=}\ln(2n)+\gamma-\ln(n)-\gamma+\smallo{1}\unfty{=}\ln(2)+\smallo{1}\unfty{\longrightarrow}\ln(2)$.
	
	\subsection{Calcul d'une somme de série (3) \etoile{3}}
	\label{sec:calcul-dune-somme-de-serie-3-etoile3}
	\textcolor{blue}{\hyperref[Calcul d'une somme de série 3]{[Enoncé]}}\\
	
	\subsection{Problème de Bâle}
	\label{sec:probleme-de-bale}
	\textcolor{blue}{\hyperref[Problème de Bâle]{[Enoncé]}}
	
	\subsubsection{Lemme de Riemann-Lebesgue}
	\begin{enumerate}[leftmargin=*]
		\item cf. \ref{Lemme de Riemann-Lebesgue : cas des fonction C1}. Il suffira ensuite de prendre la partie réelle et la partie imaginaire pour obtenir le résultat.
		\item Soit $n\in\N^*$.\\
		Par intégration par parties, on a 
		\[\int_{0}^{\pi}x\cos(nx)dx=\frac{-1+(-1)^n}{n^2}\]
		et \[\int_{0}^{\pi}x^2\cos(nx)dx=\frac{2(-1)^n\pi}{n^2}\]
		Il suffit donc de prendre $u=-1$ et $v=\frac{1}{2\pi}$ pour avoir 
		\[\int_{0}^{pi}(ax+bx^2)\cos(nx)dx=\frac{1}{n^2}\]
		\item Soit $x\in]0,\pi]$. Puisque $e^{ix}\ne 1$,
		\[\sum_{k=1}^{n}e^{ikx} = e^{ix}\frac{e^{inx}-1}{e^{ix}-1} = e^{i\frac{(n+1)x}{2}}\frac{e^{i\frac{nx}{2}}-e^{-i\frac{nx}{2}}}{e^{i\frac{x}{2}}-e^{-i\frac{x}{2}}} = e^{i\frac{(n+1)x}{2}}\frac{\sin\left(\frac{nx}{2}\right)}{\sin\left(\frac{x}{2}\right)}\]
		Ainsi, en passant à la partie réelle, 
		\[\sum_{k=1}^{n}\cos(kx)=\frac{\sin\left(\frac{nx}{2}\right)}{\sin\left(\frac{x}{2}\right)}\]
		\item $\varphi$ est une fonction de classe $\mathcal{C}^1$ sur $]0,\pi]$.\\
		De plus, $\lim\limits_{x\to 0}\varphi(x)=2$ car $\sin\left(\frac{x}{2}\right)\underset{x\to 0}{\sim}\frac{x}{2}$.\\
		Pour tout $x\in]0,1]$, \[\varphi'(x)=\frac{\sin\left(\frac{x}{2}\right)-\frac{x}{2}\cos\left(\frac{x}{2}\right)}{\sin^2\left(\frac{x}{2}\right)}\]
		On sait que $\sin\left(\frac{x}{2}\right)=\frac{x}{2}+\o_{x\to 0}(x^2)$ et $\cos\left(\frac{x}{2}\right)=1+\o_{x\to 0}(x)$ donc 
		\[\varphi'(x)=\o_{x\to 0}(1)\]
		et donc \[\lim\limits_{x\to 0}\varphi'(x)=0\]
		Donc $\varphi$ est prolongeable par continuité en une fonction de classe $\mathcal{C}^1$ sur $[0,\pi]$.
		\item Soit $p\in\N^*$
		\begin{align*}
			\sum_{n=1}^{p}\frac{1}{n^2}&=\sum_{n=1}^{p}\int_{0}^{\pi}(ux+vx^2)\cos(nx)dx\\
			&=\int_{0}^{\pi}(ux+vx^2)\sum_{n=1}^{p}\cos(nx)dx\\
			&=\int_{0}^{\pi}(u+vx)\left(\frac{1}{2}\varphi(x)\sin\left(\left(p+\frac{1}{2}\right)x\right)-\frac{x}{2}\right)dx\\
			&=\frac{1}{2}\int_{0}^{\pi}(u+vx)\varphi(x)\sin\left(\left(p+\frac{1}{2}\right)x\right)dx-\frac{1}{2}\int_{0}^{\pi}(ux+vx^2)dx
		\end{align*}
		La fonction $x\mapsto (u+vx)\varphi(x)$ étant de classe $\mathcal{C}^1$ sur $[0,\pi]$, on peut appliquer la question $1$ :
		\[\lim\limits_{p\to+\infty}\int_{0}^{\pi}(u+vx)\varphi(x)\sin\left(\left(p+\frac{1}{2}\right)x\right)dx=0\]
		Par conséquent, on a :
		\[\lim\limits_{p\to+\infty}\sum_{n=1}^{p}\frac{1}{n^2}=-\frac{1}{2}\int_{0}^{\pi}(ux+vx^2)dx=-\frac{u\pi^2}{4}-\frac{v\pi^3}{6}=\frac{\pi^2}{6}\]
		d'où : 
		\[\zeta(2)=\frac{\pi^2}{6}\]
		\item 
		On remarque qu'il s'agit de la somme des $\frac{1}{n^2}$ mais seulement en gardant les termes pour $n$ impairs. Cette somme est plus petite que $\zeta(2)$ à termes positifs donc elle converge.\\
		Ainsi \[\sum_{n=1}^{+\infty}\frac{1}{(2n-1)^2}=\zeta(2)-\sum_{n=1}^{+\infty}\frac{1}{(2n)^2}\]
		Donc : 
		\[\sum_{n=1}^{+\infty}=\left(1-\frac{1}{4}\right)\zeta(2)=\frac{3}{4}\zeta(2)=\frac{\pi^2}{8}\]
		\item On peut appliquer le CSSA sinon on peut simplement dire que la série converge absolument donc elle converge.\\
		On réapplique la même méthode. On cherche des constantes $u$ et $v$ tels que \[\forall n\in\N^*, \int_{0}^\pi(ux+vx^2)\cos(nx)dx=\frac{(-1)^n}{n^2}\]
		On constate que pour $u=0$ et $v=-\frac{1}{2\pi}$, on obtient bien le résultat pour tout $n\in\N^*$.\\
		On a encore : \[\lim\limits_{p\to+\infty}\sum_{n=1}^{p}\frac{(-1)^n}{n^2}=-\frac{u\pi^2}{4}-\frac{v\pi^3}{6}=\frac{\pi^2}{12}\]
	\end{enumerate}
	\subsubsection{Série de fonctions}
	\subsubsection{Série entière}
	\subsection{Nombre moyen de diviseurs d'un entier \etoile{4}}\label{sec:nombre-moyen-de-diviseurs-dun-entier-etoile4}
		\textcolor{blue}{\hyperref[Nombre moyen de diviseurs d'un entier]{[Enoncé]}}\\
	\begin{enumerate}
		\item Soit $x\in [1,+\infty[$.
		\begin{align*}
			F(x)&=\displaystyle\sum_{n=1}^{\lfloor x\rfloor}\sum\limits_{d|n}1\\
			&=\displaystyle\sum_{n=1}^{\lfloor x\rfloor}\sum\limits_{\substack{(d,d')\in \crblanc{1}{x}^2\\dd'=n}}1\\
			&=\displaystyle\sum\limits_{\substack{(d,d')\in \crblanc{1}{x}^2\\dd'\in \crblanc{1}{x}}}1\\
			&=\displaystyle\sum\limits_{d\leq x}\sum\limits_{d'\leq\frac{x}{d}}1\\
			&=\displaystyle\sum_{d=1}^{\lfloor x\rfloor}\lfloor\frac{x}{d}\rfloor
		\end{align*}
		Or, $\forall d\in \crblanc{1}{x},\ \displaystyle\frac{x}{d}-1<\lfloor\frac{x}{d}\rfloor\leq\frac{x}{d}$.\\
		On en déduit l'encadrement:
		$$\displaystyle\sum\limits_{d=1}^{\lfloor x\rfloor}\left(\frac{x}{d}-1\right)<F(x)\leq \sum\limits_{d=1}^{\lfloor x\rfloor}\frac{x}{d}$$
		Ou encore,
		$$x\sum\limits_{d=1}^{\lfloor x\rfloor}\frac{1}{d}-\lfloor x\rfloor<F(x)\leq x\sum\limits_{d=1}^{\lfloor x\rfloor}\frac{1}{d}$$
		Or on sait que $\displaystyle\sum\limits_{d=1}^{\lfloor x\rfloor}\frac{1}{d}\uxfty{\sim}\ln\lfloor x\rfloor\uxfty{\sim}\ln x$.\\
		Donc par encadrement, $F(x)\uxfty{\sim}x\ln x$.
		\item Il ne sert à rien de pousser le développement de $\displaystyle\sum\limits_{d=1}^{\lfloor x\rfloor}\frac{1}{d}$ un cran plus loin car dans l'encadrement de $F(x)$ ci-dessus, l'écart entre le majorant et le minorant est en $\bigO{x}$. Pour avoir un développement asymptotique à l'ordre $2$ on va utiliser une autre expression de $F(x)$. L'idée est de couper la somme $F(x)=\displaystyle\sum\limits_{\substack{(d,d')\in \crblanc{1}{x}^2\\dd'\in \crblanc{1}{x}}}1$ selon la position de $d$ et $d'$ par rapport à $\displaystyle\sqrt x$. Si $dd'\leq x$, on a toujours $d\leq \displaystyle\sqrt x$ ou $d'\leq \displaystyle\sqrt x$. Par conséquent, on a
		$$F(x)=2\sum\limits_{\substack{d\in \crblanc{1}{\displaystyle\sqrt x}\\dd'\in \crblanc{1}{x}}}1-\sum\limits_{(d,d')\in \crblanc{1}{\displaystyle\sqrt x}^2}1$$
		ce qui donne
		$$F(x)=2\sum\limits_{d\leq\displaystyle\sqrt x}\lfloor\frac{x}{d}\rfloor-\lfloor\displaystyle\sqrt x\rfloor^2$$
		et alors,
		\begin{align*}
			\forall u\in \R,\ u-1<\lfloor u\rfloor\leq u&\implies 2\sum\limits_{d=1}^{\lfloor\displaystyle\sqrt x\rfloor}\left(\frac{x}{d}-1\right)-x\leq F(x)\leq 2\sum\limits_{d=1}^{\lfloor\displaystyle\sqrt x\rfloor}\frac{x}{d}-(\displaystyle\sqrt x-1)^2\\
			&\implies F(x)\uxfty{=}2x\displaystyle\sum\limits_{d=1}^{\lfloor\displaystyle\sqrt x\rfloor}\frac{1}{d}+\bigO{\displaystyle\sqrt x}-x+\bigO{\displaystyle\sqrt x}
		\end{align*}
		Avec \begin{align*}
			\displaystyle\sum\limits_{d=1}^{\lfloor\displaystyle\sqrt x\rfloor}\frac{1}{d}&\uxfty{=}\ln\lfloor\displaystyle\sqrt x\rfloor+\gamma+\bigO{\frac{1}{\displaystyle\sqrt x}}\\
			&\uxfty{=}\ln(\displaystyle\sqrt x+\bigO{1})+\gamma+\bigO{\frac{1}{\displaystyle\sqrt x}}\\
			&\uxfty{=}\ln(\displaystyle\sqrt x)+\ln\left(1+\bigO{\frac{1}{\displaystyle\sqrt x}}\right)+\gamma+\bigO{\frac{1}{\displaystyle\sqrt x}}\\
			&\uxfty{=}\displaystyle\frac{1}{2}\ln x+\gamma+\bigO{\frac{1}{\displaystyle\sqrt x}}
		\end{align*}
		On obtient enfin,
		$$F(x)\uxfty{=}x\ln x+(2\gamma-1)x+\bigO{\displaystyle\sqrt x}$$
	\end{enumerate}
	
	
	\subsection{Théorème de réarrangement de Riemann \etoile{5}}\label{sec:theoreme-de-rearrangement-de-riemann-etoile5}
		\textcolor{blue}{\hyperref[Théorème de réarrangement de Riemann]{[Enoncé]}}\\
	Montrons dans un premier temps que la suite $(a_n)_{n\in \N}$ prend une infinité de valeurs positives et négatives. On note $P=\{n\in \N,\ a_n\geq 0\}$ et $N=\N\setminus P=\{n\in \N,\ a_n<0\}$\\
	Supposons par l'absurde que $(a_n)_{n\in \N}$ prenne un nombre fini de valeurs négatives.\\
	Alors on peut noter $n_0=\max N$ et dans ce cas la série $\displaystyle\sum\limits_{n\in \N}a_n$ est de même nature que $\displaystyle\sum\limits_{n>n_0}a_n=\sum\limits_{n>n_0}|a_n|$. Donc $\displaystyle\sum\limits_{n\in \N}a_n$ diverge ce qui est absurde.\\
	De même, $(a_n)_{n\in \N}$ ne peut pas prendre un nombre fini de valeurs positives.\\\\
	$P$ admet alors un minimum en tant que partie non vide de $\N$.\\
	On va construire $\sigma$ par récurrence :\\
	on pose $\sigma(0)=0,\ S_n=\displaystyle\sum\limits_{k=0}^na_{\sigma(k)}$ et pour tout $n\in \N,\ \sigma(n+1)=
	\begin{cases}
		\min(P\setminus\{\sigma(k),\ k\in \crblanc{0}{n}\})&\mbox{si }S_n<\alpha\\
		\min(N\setminus\{\sigma(k),\ k\in \crblanc{0}{n}\})&\mbox{si }S_n\geq\alpha
	\end{cases}$\\
	$\sigma$ est injective par définition. Montrons qu'elle est surjective.\\
	Supposons par l'absurde qu'il existe $k\in \N^*$ qui ne soit pas dans l'image de $\sigma$ (0 l'est par définition). Deux cas se posent :
	\begin{itemize}
		\item Si $k\in P$, alors $\sigma$ ne prend qu'un nombre fini de valeurs dans $P$ (incluses dans $\crblanc{0}{k-1}$), donc à partir du rang $k+1$, $\sigma$ est à valeurs dans $N$ et donc $\forall n\geq k+1,\ S_n\geq\alpha$. La suite $(S_n)_{n>k}$ est décroissante en tant que suite des sommes partielles d'une série à termes négatifs, étant minorée elle converge et donc $\displaystyle\sum\limits_{n>k}a_{\sigma(n)}$ converge absolument. Ceci contredit ce qui a été démontré en préambule donc $k\in \sigma(\N)$.
		\item Si $k\in N$ alors de même, $\displaystyle\sum\limits_{n>k}a_\sigma(n)$ ne peut pas converger absolument.
	\end{itemize}
	Ainsi $\sigma$ est bien bijective de $\N$ dans $\N$.\\\\
	Montrons maintenant que $\displaystyle\sum\limits_{n=0}^{+\infty}a_{\sigma(n)}=\alpha$. Fixons $\varepsilon>0$.\\
	Comme la série $\displaystyle\sum\limits_{n\in \N}a_n$ converge, on a $a_n\unfty{\longrightarrow}0$. On a aussi $a_{\sigma(n)}\unfty{\longrightarrow}0$. En effet, $\exists n_0\in \N,\ \forall n\geq n_0,\ |a_n|<\varepsilon$. Puis par injectivité de $\sigma$, $E=\{n\in \N,\ \sigma(n)<n_0\}$ est fini. On en déduit que $\forall n\geq n_1=\max(n_0,\max(E)),\ |a_{\sigma(n)}|<\varepsilon$.\\
	D'après ce qui a été fait en préambule, $\exists p>n_1,\ \sigma(p)\in P\land \sigma(p+1)\in N$. Montrons que $\forall n\geq p,\ |S_n-\alpha|\leq\varepsilon$.\\
	$\sigma(p)\in P\implies S_{p-1}<\alpha$ et $\sigma(p+1)\in N\implies S_p\geq\alpha$. Or $|S_p-S_{p-1}|=|a_{\sigma(p+1)}|<\varepsilon$.\\
	Ainsi $S_p\in [\alpha-\varepsilon,\alpha+\varepsilon]$. Fixons $n>p$.\\
	Supposons par l'absurde que $S_n>\alpha+\varepsilon$. Comme on passe de $S_{n-1}$ à $S_n$ par un saut de longueur $a_{\sigma(n)}<\varepsilon$, on ne peut avoir $S_{n-1}<\alpha$. Cela entraîne $a_{\sigma(n)}<0$ et donc $S_{n-1}>S_n$. Mais alors de proche en proche, on obtient $\alpha+\varepsilon<S_n<\dots<
	S_p$ ce qui est absurde. Donc $S_n\leq\alpha+\varepsilon$.\\
	Supposons par l'absurde que $S_n<\alpha-\varepsilon$. Comme on passe de $S_{n-1}$ à $S_n$ par un saut de longueur $a_{\sigma(n)}<\varepsilon$, on ne peut avoir $S_{n-1}\geq\alpha$. Cela entraîne $a_{\sigma(n)}\geq 0$ et donc $S_{n-1}\leq S_n$. Mais alors de proche en proche, on obtient $\alpha-\varepsilon>S_n\geq S_{n-1}\geq\dots\geq S_p$ ce qui est absurde. Donc $S_n\geq\alpha-\varepsilon$.\\
	Finalement, $|S_n-\alpha|\leq \varepsilon$.\\\\
	On a donc construit une bijection $\sigma$ de $\N$ dans $\N$ telle que $\displaystyle\sum\limits_{n=0}^{+\infty}a_{\sigma(n)}=\alpha$.
	
	\subsection{Moyennes arithmétique, géométrique et harmonique \etoile{1}}\label{sec:moyennes-arithmetique-geometrique-et-harmonique-etoile1}
		\textcolor{blue}{\hyperref[Moyennes arithémtique, géométrique et harmonique]{[Enoncé]}}\\
	On rappelle que $\ln$ est concave sur $\R^*_+$.\\
	$\displaystyle\sum\limits_{k=1}^n\frac{1}{n}=1$ et $\displaystyle\frac{1}{n}\geq 0$ donc d'après l'inégalité de Jensen :
	$$\displaystyle\frac{1}{n}\sum\limits_{k=1}^n\ln(a_k)\leq \ln\left(\displaystyle\frac{1}{n}\sum\limits_{k=1}^n a_k\right)$$
	C'est à dire par passage à l'exponentielle,
	$$G_n=\displaystyle\displaystyle\sqrt[n]{\prod\limits_{k=1}^n a_k}\leq \displaystyle\frac{1}{n}\sum\limits_{k=1}^n a_k=A_n$$
	$-\ln$ est convexe sur $\R^*_+$.\\
	$\displaystyle\sum\limits_{k=1}^n\frac{1}{n}=1$ et $\displaystyle\frac{1}{n}\geq 0$ donc d'après l'inégalité de Jensen :
	$$-\ln(G_n)=\displaystyle\frac{1}{n}\sum\limits_{k=1}^n\ln\left(\frac{1}{a_k}\right)\leq \ln\left(\displaystyle\frac{1}{n}\sum\limits_{k=1}^n\frac{1}{a_k}\right)=-\ln(H_n)$$
	D'où,
	$$G_n\geq H_n$$
	
	\subsection{Inégalité de Carleman}\label{sec:inegalite-de-carleman}
		\textcolor{blue}{\hyperref[Inégalité de Carleman]{[Enoncé]}}\\
	
	\newpage
\section{Correction Intégrale}
	\subsection{Règle de Bioche}
	\label{Règle de Bioche corrigé}
		\textcolor{blue}{\hyperref[bioche]{[Enoncé]}}\\
		
	\subsection{Intégrale de Wallis \etoile{2}}
	\label{Intégrale de Wallis corrigé}
	\textcolor{blue}{\hyperref[wallis]{[Enoncé]}}\\
	Cet exercice n'est pas guidé car il s'agit d'un classique à connaître vraiment par cœur.
	\begin{enumerate}[leftmargin=*]
		\item Trouvons une relation de récurrence. 
		\\Soit $n\in\N$. Les fonctions $\sin$ et $t\mapsto\sin(t)^{n+1}$ sont de classe $\mathcal{C}^1$ donc par IPP, on a: \begin{align*}
			W_{n+2}=&\left[-\cos(t)\sin(t)^{n+1}\right]_0^{\frac{\pi}{2}}+(n+1)\displaystyle\int_0^{\frac{\pi}{2}}\cos(t)^2\sin(t)^ndt\\
			=&(n+1)\displaystyle\int_0^{\frac{\pi}{2}}(1-\sin(t)^2)\sin(t)^ndt\\
			=&(n+1)W_n-(n+1)W_{n+2}
		\end{align*}
		\\C'est-à-dire: $(n+2)W_{n+2}=(n+1)W_n$.
		\\Maintenant, montrons par récurrence que: $\forall n\in\N,(n+1)W_nW_{n+1}=\displaystyle\frac{\pi}{2}$
		\\Pour $n=0$, on a $W_0=\displaystyle\frac{\pi}{2}$ et $W_1=1$, donc la relation est bien vérifiée.
		\\Supposons que pour un certain $n\in\N$, on a $(n+1)W_nW_{n+1}=\displaystyle\frac{\pi}{2}$
		\begin{align*}
			(n+2)W_{n+2}W_{n+1}=&(n+2)\displaystyle\frac{n+1}{n+2}W_nW_{n+1} &\mbox{d'après ce qui précède}\\
			=&(n+1)W_nW_{n+1}\\
			=&\displaystyle\frac{\pi}{2} &\mbox{d'après HR}
		\end{align*}
		Donc, on a montré par récurrence que pour tout $n\in\N $, $(n+1)W_nW_{n+1}=\displaystyle\frac{\pi}{2}$
		\\Il ne nous reste plus qu'à montrer que $W_n\sim W_{n+1}$.
		\\Pour cela, montrons que $(W_n)$ est décroissante.
		\\On sait que pour tout $t\in\left[0,\displaystyle\frac{\pi}{2}\right],\; 0\leq \sin(t)\leq 1$. Ainsi pour tous $n\in\N$ et $t\in\left[0,\displaystyle\frac{\pi}{2}\right]$, on a $0\leq \sin(t)^{n+1}\leq\sin(t)^n$. Et donc par croissance de l'intégrale, on a, $0\leq W_{n+1}\leq W_n$.
		\\Ainsi, on en déduit que $(W_n)$ est décroissante et donc: $\forall n\in\N, \quad W_{n+2}\leq W_{n+1}\leq W_n$ cad $\displaystyle\frac{n+1}{n+2}W_n\leq W_{n+1}\leq W_n$.
		\\Par conséquent, on a $W_{n+1}\sim W_n$.
		\\Finalement, puisque:$(n+1)W_nW_{n+1}=\displaystyle\frac{\pi}{2}$, on a $nW_n^2\sim \displaystyle\frac{\pi}{2}$.
		\\Et donc ainsi $W_n\sim\displaystyle\sqrt{\frac{\pi}{2n}}$.
		
		\item On a démontré que pour tout $n\in\N, \; (n+2)W_{n+2}=(n+1)W_n$.
		\\Ainsi, on a $\forall n\in\N, \; \displaystyle\frac{W_{2n+2}}{W_{2n}}=\frac{2n+1}{2n+2}$, donc \begin{align*}
			\displaystyle\prod\limits_{k=0}^{n-1}\frac{W_{2k+2}}{W_{2k}}=&\prod\limits_{k=0}^{n-1}\frac{2k+1}{2k+2}\\
			\implies\frac{W_{2n}}{W_{0}}=&\frac{1}{2^{n-1}n!}\prod\limits_{k=0}^{n-1}2k+1\\
			\implies W_{2n}=&\frac{(2n)!}{2^{2n}(n!)^2}\frac{\pi}{2}
		\end{align*}
		De la même manière, on obtient: $\forall n\in\N,\; W_{2n+1}=\displaystyle\frac{2^{2p}(p!)^2}{(2p+1)!}$
		\\On peut également montrer ces résultats par récurrence.
	\end{enumerate}
	
	\subsection{Formule de Stirling}
	\label{Formule de Stirling corrgié}
	\textcolor{blue}{\hyperref[stirling]{[Enoncé]}}\\
	
	\subsection{Intégrale de Gauss}
	\label{Intégrale de Gauss corrigé}
	\textcolor{blue}{\hyperref[gauss]{[Enoncé]}}
	\subsubsection{Wallis}
	
	
	\subsubsection{Intégrales auxiliaires}
	
	\subsubsection{Equivalent du reste}
	
	\subsection{Intégrale de Fresnel \etoile{3}}
	\label{Intégrale de Fresnel corrigé}
	\textcolor{blue}{\hyperref[fresnel]{[Enoncé]}}\\
	\begin{enumerate}
		\item Notons $\fonction{f}{(\R_+)^2}{\C}{(x,t)}{\displaystyle\frac{e^{-(t^2+i)x^2}}{t^2+i}}$.
		\begin{itemize}
			\item Pour tout $x\in \R_+,\ t\mapsto f(x,t)\in \text{CM}(\R_+,\C)$ et $|f(x,t)|=\displaystyle\frac{e^{-(xt)^2}}{\sqrt{t^4+1}}\leq\frac{1}{\sqrt{t^4+1}}\utfty{\sim}\frac{1}{t^2}$ donc $t\mapsto f(x,t)\in L^1(\R_+,\C)$ ;
			\item Pour tout $t\in \R_+,\ x\mapsto f(x,t)\in \mathcal C^1(\R_+,\C)$ et $\forall (x,t)\in (\R_+)^2,\ \displaystyle\frac{\partial f}{\partial x}(x,t)=-2xe^{-(t^2+i)x^2}$ ;
			\item $\forall x\in \R_+,\ t\mapsto\displaystyle\frac{\partial f}{\partial x}(x,t)\in \text{CM}(\R_+,\C)$ ;
			\item Soient $a,b$ deux réels tels que $0<a\leq b$.\\
			$\forall x\in [a,b],\ \forall t\in \R_+,\ \displaystyle\left|\frac{\partial f}{\partial x}(x,t)\right|=2xe^{-(tx)^2}\leq2be^{-(ta)^2}$.\\
			Et la fonction $\varphi:t\mapsto2be^{-(ta)^2}$ est intégrable sur $\R_+$ puisqu'elle est continue par morceaux sur $\R_+$ et que $\varphi(t)\utfty{=}\smallo{\displaystyle\frac{1}{t^2}}$ (car $a>0$).
		\end{itemize}
		Ainsi d'après le théorème de transfert $\mathcal C^1$, $I$ est $\mathcal C^1$ sur $\displaystyle\bigcup_{0<a\leq b}[a,b]=\R^*_+$ et, $\forall x\in \R^*_+,\ I'(x)=\displaystyle\int_0^{+\infty}-2xe^{-(t^2+i)x^2}dt$.
		\item Fixons $x\in \R^*_+$. Posons $u=tx$ :\\
		$I'(x)=\displaystyle-2xe^{-ix^2}\int_0^{+\infty}e^{-(tx)^2}dt=-2e^{-ix^2}\int_0^{+\infty}e^{-u^2}du=-\sqrt{\pi}e^{-ix^2}$.\\
		De plus, pour tout $t\in \R^*_+,\ f(x,t)\uxfty{\longrightarrow}0$ et pour tout $(x,t)\in (\R_+)^2,\ |f(x,t)|\leq \displaystyle\frac{1}{\sqrt{t^4+1}}$. Donc d'après le théorème de convergence dominée, $\uxfty{\lim}I(x)=\displaystyle\int_0^{+\infty}0\ dt=0$.\\
		Donc en intégrant l'expression de $0$ à $+\infty,\ \displaystyle\int_0^{+\infty}e^{-it^2}dt=\frac{I(0)}{\sqrt{\pi}}$.\\
		Enfin, $I(0)=\displaystyle\int_0^{+\infty}\frac{1}{t^2+i}dt=\int_0^{+\infty}\frac{t^2}{t^4+1}dt-i\int_0^{+\infty}\frac{1}{t^4+1}dt$. On pose $u=\displaystyle\frac{1}{t}$ dans la première intégrale pour avoir :\\
		$\displaystyle\int_0^{+\infty}\frac{t^2}{t^4+1}dt=\int_{+\infty}^0\frac{\displaystyle\frac{1}{u^2}}{\displaystyle\frac{1}{u^4}+1}\left(-\frac{du}{u^2}\right)=\int_0^{+\infty}\frac{1}{u^4+1}du$.\\
		On peut alors écrire
		\begin{align*}
			4\displaystyle\int_0^{+\infty}\frac{1}{u^4+1}du&=\int_0^{+\infty}\frac{2(u^2+1)}{u^4+1}du\\
			&=\int_0^{+\infty}\frac{2(u^2+1)}{(u^2+1)^2-(u\sqrt{2})^2}du\\
			&=\int_0^{+\infty}\frac{u^2-u\sqrt{2}+1+u^2+u\sqrt{2}+1}{(u^2-u\sqrt{2}+1)(u^2+u\sqrt{2}+1)}\\
			&=\int_0^{+\infty}\left(\frac{1}{u^2-u\sqrt{2}+1}+\frac{1}{u^2+u\sqrt{2}+1}\right)du
		\end{align*}
		Et donc $\displaystyle\int_0^{+\infty}\frac{1}{u^4+1}du=\sqrt{2}\left[\arctan(u\sqrt{2}-1)+\arctan(u\sqrt{2}+1)\right]_0^{+\infty}=\pi\sqrt{2}$ d'où $\displaystyle\int_0^{+\infty}\frac{1}{u^4+1}du=\frac{\pi}{2\sqrt{2}}$.\\
		Finalement, $\displaystyle\int_0^{+\infty}e^{-it^2}dt=\frac{1}{\sqrt{\pi}}\times\frac{\pi}{2\sqrt{2}}(1-i)=\sqrt{\frac{\pi}{2}}\frac{1-i}{2}$.
	\end{enumerate}
	
	\subsection{Intégrale de Dirichlet}
	\label{Intégrale de Dirichlet corrigé}
	\textcolor{blue}{\hyperref[dirichlet]{[Enoncé]}}\\
	\subsubsection{Semi-convergence \etoile{2}}
	La fonction $f:t\mapsto \displaystyle\frac{\sin t}{t}$ est continue par morceaux sur $\R^*_+$ et est prolongeable par continuité en $0$ en posant $f(0)=1$.\\
	\underline{\textbf{Convergence :}}\\
	Les fonctions $t\mapsto -\cos t$ et $t\mapsto \displaystyle\frac{1}{t}$ sont $\mathcal C^1$ sur $[1,+\infty[$ (le crochet ne converge pas si on intègre en $0$) et $\utfty{\lim}\displaystyle-\frac{\cos t}{t}=0$ donc par IPP,\\
	$\displaystyle\int_1^{+\infty}f(t)dt=\left[-\frac{\cos(t)}{t}\right]_1^{+\infty}-\int_1^{+\infty}\frac{\cos t}{t^2}dt=\cos(1)-\int_1^{+\infty}\frac{\cos t}{t^2}dt$.\\
	La dernière intégrale converge puisque $\displaystyle\frac{\cos t}{t^2}\utfty{=}\bigO{\frac{1}{t^2}}$.\\
	Ainsi $\displaystyle\int_0^{+\infty}\frac{\sin t}{t}dt=\int_0^1\frac{\sin t}{t}+\cos(1)-\int_1^{+\infty}\frac{\cos t}{t^2}dt$ converge.\\\\
	\underline{\textbf{Non convergence absolue :}}\\
	\underline{première méthode :}\\
	Dans $\R_+\cup\{+\infty\}$, $\displaystyle\int_0^{+\infty}\frac{|\sin t|}{t}dt=\sum_{n=0}^{+\infty}\int_{n\pi}^{(n+1)\pi}\frac{|\sin t|}{t}dt$.\\
	$\forall n\in \N,\ \displaystyle\int_{n\pi}^{(n+1)\pi}\frac{|\sin t|}{t}dt=\int_0^\pi\frac{|\sin(t+n\pi)|}{t+n\pi}dt=\int_0^\pi\frac{|\sin t|}{t+n\pi}dt=\int_0^\pi\frac{\sin t}{t+n\pi}dt\geq\int_0^\pi\frac{\sin t}{(n+1)\pi}=\frac{2}{(n+1)\pi}$.\\
	Ainsi $\displaystyle\int_0^{+\infty}\frac{|\sin t|}{t}dt$ diverge par comparaison à une série de Riemann.\\\\
	\underline{deuxième méthode :}\\
	On remarque que comme pour tout réel positif $t,\ |\sin t|\leq 1$, On a l'inégalité $|\sin t|\geq \sin^2(t)=\displaystyle\frac{1-\cos(2t)}{2}$.\\
	D'une part, par une IPP similaire à celle que l'on a utilisé pour montrer la convergence de l'intégrale de Dirichlet on montre que $\displaystyle\int_1^{+\infty}\frac{\cos(2t)}{2t}dt$ converge.
	D'autre part $\displaystyle\int_0^{+\infty}\frac{1}{2t}dt=+\infty$ et enfin $\displaystyle\int_0^1\frac{|\sin t|}{t}dt$ converge.\\
	Finalement, $\displaystyle\int_0^{+\infty}\frac{|\sin t|}{t}dt\geq \int_0^1\frac{|\sin t|}{t}dt+\int_1^{+\infty}\frac{1}{2t}dt+\int_1^{+\infty}\frac{\cos(2t)}{2t}dt$ diverge vers $+\infty$.
	
	\subsubsection{Une autre expression \etoile{2}}
	On remarque que $t\mapsto 1-\cos(t)$ est une primitive de $\sin$ sur $\R^*_+$ et que $\displaystyle\lim_{t\to 0}\frac{1-\cos(t)}{t}=-\cos'(0)=\sin(0)=0$ donc par IPP :\\
	$I=\displaystyle\left[\frac{1-\cos(t)}{t}\right]_0^{+\infty}+\int_0^{+\infty}\frac{1-\cos(t)}{t^2}dt=\int_0^{+\infty}\frac{1-\cos(2t)}{(2t)^2}\frac{dt}{2}=\int_0^{+\infty}\frac{1-\cos(2t)}{2t^2}dt=\int_0^{+\infty}\frac{\sin^2(t)}{t^2}dt$.
	
	\subsubsection{Premier calcul \etoile{2}}
	\begin{enumerate}[leftmargin=*]
		\item Montrons d'abord que $(u_n)_{n\in \N}$ est bien définie. Fixons $n\in \N$.\\
		$f_n:t\mapsto \displaystyle\frac{\sin((2n+1)t)}{\sin(t)}$ est continue par morceaux sur $]0,\pi/2]$ et $f_n(t)\utzero{\sim}\displaystyle\frac{(2n+1)t}{t}=2n+1$ donc l'intégrale est faussement impropre en $0$.\\
		Ensuite, $\sin((2n+3)t)-\sin((2n+1)t)=\sin((2n+2)t+t)-\sin((2n+2)t-t)=2\sin(t)\cos((2n+2)t)$.\\
		Ainsi $u_{n+1}-u_n=\displaystyle\int_0^{\pi/2}\frac{1}{\sin(t)}(\sin((2n+3)t)-\sin((2n+1)t))dt=\int_0^{\pi/2}2\cos((2n+2)t)dt=\left[\frac{\sin((2n+2)t)}{n+1}\right]_0^{\pi/2}=0$.
		On en déduit que $u_n$ est constamment égal à $u_0=\displaystyle\int_0^{\pi/2}dt=\frac{\pi}{2}$.
		\item Tout d'abord, $v_n$ est bien défini pour tout $n\in \N$ pour les mêmes raisons que $u_n$.
		Notons $\varphi:t\mapsto \displaystyle\frac{1}{\sin(t)}-\frac{1}{t}$.\\
		$\varphi$ est de classe $\mathcal C^1$ sur $]0,\pi/2]$ et,\\
		$\varphi(t)=\displaystyle\frac{t-\sin(t)}{t\sin(t)}\utzero{=}\frac{\frac{t^3}{6}+\smallo{t^3}}{t\sin(t)}\utzero{\sim}\frac{\frac{t^3}{6}}{t^2}=\frac{t}{6}\utzero{\longrightarrow}0$ puis,\\
		$\varphi'(t)=\displaystyle-\frac{\cos(t)}{\sin^2(t)}+\frac{1}{t^2}=\frac{\sin^2(t)-t^2\cos(t)}{t^2\sin^2(t)}\utzero{=}\frac{t^2\left(1-\frac{t^2}{6}+\smallo{t^2}\right)^2-t^2\left(1-\frac{t^2}{2}+\smallo{t^2}\right)}{t^2\sin^2(t)}\utzero{=}\frac{\frac{t^2}{3}+\smallo{t^2}}{\sin^2(t)}\utzero{\sim}\frac{1}{3}\utzero{\longrightarrow}\frac{1}{3}$.\\
		Ainsi $\varphi$ est prolongeable en une fonction de classe $\mathcal C^1$ sur $[0,\pi/2]$ en posant $\varphi(0)=\displaystyle\frac{1}{6}$ et $\varphi'(0)=\displaystyle\frac{1}{3}$.\\
		On peut donc faire une IPP :\\
		$\forall n\in \N,\ v_n-u_n=\displaystyle\int_0^{\pi/2}\sin((2n+1)t)\varphi(t)dt=\left[-\frac{\cos((2n+1)t)}{2n+1}\varphi(t)\right]_0^{\pi/2}+\int_0^{\pi/2}\frac{\cos((2n+1)t)}{2n+1}\varphi'(t)dt$.\\
		Or d'après le théorème des bornes atteintes, $\varphi$ et $\varphi'$ sont bornées sur $[0,\pi/2]$. Ainsi en notant $M$ un majorant de $\varphi$ et $M'$ un majorant de $\varphi'$ sur $[0,\pi/2]$,\\
		$\forall n\in \N,\ |v_n-u_n|\leq \displaystyle\frac{2M}{2n+1}+\frac{\pi M'}{2(2n+1)}\unfty{\longrightarrow}0$.\\
		Par conséquent $v_n-u_n\unfty{\longrightarrow}0$.
		\item D'après ce qui a été fait précédemment on sait que $v_n\unfty{\longrightarrow}\displaystyle\frac{\pi}{2}$.\\
		Or $\forall n\in \N,\ v_n=\displaystyle\int_0^{(2n+1)\pi}\frac{\sin(t)}{\displaystyle\frac{t}{2n+1}}\cdot\frac{dt}{2n+1}=\int_0^{(2n+1)\pi}\frac{\sin(t)}{t}dt$.\\
		Il reste à montrer que l'intégrale de Dirichlet converge (cf. \ref{Intégrale de Dirichlet}) pour avoir $\unfty{\lim}v_n=I$ et donc $I=\displaystyle\frac{\pi}{2}$.
	\end{enumerate}
	
	\subsubsection{Second calcul \etoile{3}}
	\begin{enumerate}[leftmargin=*]
		\item Notons $\fonction{f}{(\R^*_+)^2}{\R}{(x,t)}{\displaystyle\frac{\sin(t)}{t}e^{-xt}}$.\\
		\begin{itemize}
			\item Si $x\in \R^*_+,\ f(x,t)\utzero{\longrightarrow}1$ et $f(x,t)\utfty{=}\smallo{\displaystyle\frac{1}{t^2}}$. Donc $\forall x\in \R^*_+,\ t\mapsto f(x,t)\in \text{CM}(\R^*_+,\R)\cap L^1(\R^*_+,\R)$ ;
			\item $\forall t\in \R^*_+,\ x\mapsto f(x,t)\in \mathcal C^1(\R_+,\R)$. $\forall (x,t)\in (\R^*_+)^2,\ \displaystyle\frac{\partial f}{\partial x}(x,t)=-\sin(t)e^{-xt}$ ;
			\item $\forall x\in \R^*_+,\ t\mapsto\displaystyle\frac{\partial f}{\partial x}(x,t)\in \text{CM}(\R^*_+,\R)$ ;
			\item Soit $a>0$. $\forall x\in [a,+\infty[,\ \forall t\in \R^*_+,\ \left|\displaystyle\frac{\partial f}{\partial x}(x,t)\right|\leq e^{-at}$.\\
			$\varphi:t\mapsto \displaystyle\frac{|\sin(t)|}{t}e^{-at}\in L^1(\R^*_+,\R)$.
		\end{itemize}
		Ainsi d'après le théorème de transfert $\mathcal C^1,\ F\in \mathcal C^1(\R^*_+,\R)$ et $\forall x\in \R^*_+,\ F'(x)=-\displaystyle\int_0^{+\infty}\sin(t)e^{-xt}dt$.\\
		Pour calculer cette intégrale on passe passe en complexe : $\forall x\in \R^*_+,\ F'(x)=-\operatorname{Im}\left(\displaystyle\int_0^{+\infty}e^{(i-x)t}dt\right)$ (qui converge absolument).\\
		$\forall x\in \R^*_+,\ \displaystyle\int_0^{+\infty}e^{(i-x)t}dt=\left[\frac{e^{(i-x)t}}{i-x}\right]_{t=0}^{t\to+\infty}=\frac{1}{x-i}=\frac{x+i}{|x-i|^2}=\frac{x}{1+x^2}+\frac{1}{1+x^2}i$.\\
		On en déduit que $\forall x\in \R^*_+,\ F'(x)=-\displaystyle\frac{1}{1+x^2}$.
		\item Donc $\exists C\in \R,\ \forall x\in \R^*_+,\ F(x)=-\arctan(x)+C$.\\
		Montrons que $F$ tend vers $0$ en $+\infty$ à l'aide du théorème de convergence dominée. On a déjà fait la domination dans la question $1$.\\
		De plus, pour tout $t\in \R^*_+,\ f(x,t)\uxfty{\longrightarrow}0$ et la fonction nulle est continue par morceaux sur $\R^*_+$.\\
		Ainsi $F(x)\uxfty{\longrightarrow}\displaystyle\int_0^{+\infty}0\ dt=0$ et $C=\displaystyle\frac{\pi}{2}$.\\
		Enfin $\arctan$ étant continue en $0$, $F$ l'est aussi et en faisant tendre $x$ vers $0$ on obtient :
		$$\displaystyle\int_0^{+\infty}\frac{\sin(t)}{t}dt=F(0)=-\arctan(0)+\frac{\pi}{2}=\frac{\pi}{2}$$
	\end{enumerate}
	
	\subsection{Intégrale du reste de l'intégrale de Dirichlet \etoile{3}}
	\label{Intégrale du reste de l'intégrale de Dirichlet corrigé}
	\textcolor{blue}{\hyperref[restedirichlet]{[Enoncé]}}\\
	On sait (cf. \ref{Intégrale de Dirichlet}) que pour tout $x\in \R_+$ l'intégrale $\displaystyle\int_x^{+\infty}\frac{\sin t}{t}dt$ converge.\\
	Alors d'après le théorème fondamental de l'analyse $F:x\mapsto\displaystyle\int_x^{+\infty}\frac{\sin t}{t}dt$ est $\mathcal C^1$ sur $\R_+$ de dérivée $F'=x\mapsto -\displaystyle\frac{\sin x}{x}$. Fixons $A>0$.\\
	Par IPP, $\displaystyle\int_0^A1\cdot F(x)dx=\left[xF(x)\right]_0^A-\int_0^AxF'(x)dx=AF(A)+\int_0^A\sin x\ dx=AF(A)+1-\cos A$.\\
	Ensuite encore par IPP, $F(A)=\displaystyle\int_A^{+\infty}\frac{\sin t}{t}dt=\left[-\frac{\cos t}{t}\right]_A^{+\infty}-\int_A^{+\infty}\frac{\cos t}{t^2}dt=\frac{\cos A}{A}-\int_A^{+\infty}\frac{\cos t}{t^2}dt$.\\
	Donc $\displaystyle\int_0^AF(x)dx=1-A\int_A^{+\infty}\frac{\cos t}{t^2}dt$. Posons maintenant $u=\displaystyle\frac{t}{A}$ dans la dernière intégrale:\\
	$A\displaystyle\int_A^{+\infty}\frac{\cos t}{t^2}dt=A\int_1^{+\infty}\frac{\cos(Au)}{A^2u^2}Adu=\int_1^{+\infty}\frac{\cos(Au)}{u^2}du$.\\\\
	Enfin, une dernière IPP permet d'obtenir :\\
	$\displaystyle\int_1^{+\infty}\frac{\cos(Au)}{u^2}du=\left[-\frac{\sin(Au)}{Au^2}\right]_1^{+\infty}-\int_1^{+\infty}\frac{2\sin(Au)}{Au^3}du=\frac{\sin A}{A}-\frac{2}{A}\int_1^{+\infty}\frac{\sin(Au)}{u^3}du$.\\\\
	On remarque que le premier terme de cette somme tend vers $0$ lorsque $A$ tend vers $+\infty$. Pour ce qui est du deuxième, on a par inégalité triangulaire $\displaystyle\left|\int_1^{+\infty}\frac{2\sin(Au)}{u^3}du\right|\leq \int_1^{+\infty}\frac{2}{u^3}du=\left[-\frac{1}{u^2}\right]_1^{+\infty}=1$. Donc $\displaystyle\left|\frac{2}{A}\int_1^{+\infty}\frac{\sin(Au)}{u^3}du\right|\leq \frac{1}{A}$ d'où $\displaystyle\lim_{A\to+\infty}\frac{2}{A}\int_1^{+\infty}\frac{\sin(Au)}{u^3}du=0$.\\
	Finalement, $\displaystyle\lim_{A\to+\infty}A\int_1^{+\infty}\frac{\cos t}{t^2}dt=0$ et $\displaystyle\int_0^{+\infty}\left(\int_x^{+\infty}\frac{\sin t}{t}dt\ \right)dx=1$.
	
	\subsection{Intégrale d'Euler}
	\label{Intégrale d'Euler corrigé}
	\textcolor{blue}{\hyperref[euler_1]{[Enoncé]}}\\
	Démontrons avant de commencer que $I$ est bien défini.\\
	La fonction $t\mapsto(\ln\sin(t))$ est continue par morceau sur $]0,\frac{\pi}{2}]$.\\
	On sait que : \[\sin(t)\underset{t\to 0}{\sim}t\]
	Ainsi : \[\ln(\sin(t))=\ln(t+\underset{t\to 0}{o}(t))=\ln(t)+\ln(1+\underset{t\to 0}{o}(1))\]
	Par conséquent, \[\ln(\sin(t))\underset{t\to 0}{\sim}\ln(t)=\underset{t\to 0}{o}\left(\frac{1}{\sqrt(t)}\right)\]
	Donc $t\mapsto \ln(\sin(t))$ est intégrale en $0$.\\
	Donc l'intégrale est bien définie.
	
	\begin{enumerate}[leftmargin=*]
		\item On pose $t=\frac{\pi}{2}-u$
		\[\int_0^{\pi/2}\ln(\sin(t))dt=\int_{\pi/2}^{0}\ln\left(\sin\left(\frac{\pi}{2}-u\right)\right)(-du)=\int_{0}^{\pi/2}\ln(\cos(u))du\]
		D'où : \[I=J\]
		\item On a : \[I+J=\int_{0}^{\pi/2}\ln(\sin(t)\cos(t))dt=\int_{0}^{\pi/2}\left[\ln(\sin(2t)-\ln(2)\right]dt\]
		car $\sin(2t)=2\cos(t)\sin(t)$ pour tout $t\in\R$.
		Ainsi, on a : \[I+J=\int_{0}^{\pi/2}\ln(\sin(2t))dt-\frac{\pi\ln(2)}{2}=\frac{1}{2}\int_{0}^{\pi}\ln(\sin(u))du-\frac{\pi\ln(2)}{2}\]
		Montrons que $\displaystyle 2I=\int_{0}^{\pi}\ln(\sin(t))dt$.\\
		On effectue le changement de variable $u=\pi-t$,
		\[I=\int_{0}^{\pi/2}\ln(\sin(t))dt=\int_{\pi}^{\pi/2}\ln(\sin(\pi-u))(-du)=\int_{\pi/2}^{\pi}\ln(\sin(u))du\]
		Ainsi d'après la relation de Chasles, \[2I=\int_{0}^{\pi}\ln(\sin(t))dt\]
		Donc : \[I+J=I-\frac{\pi\ln(2)}{2}\]
		\item On a donc aisément que : \[I=-\frac{\pi\ln(2)}{2}\]
		\end{enumerate}
	
	
	\subsection{Fonction intégrale}
	\label{Fonction intégrale corrigé}
	\textcolor{blue}{\hyperref[fonction_intégrale]{[Enoncé]}}\\
	Soit $x\in\R^*_+$.\\
	$\displaystyle t\mapsto \frac{\ln(t)}{x^2+t^2}$ est continue par morceau sur $]0,+\infty[$. 
	On remarque que \[\frac{\ln(t)}{x^2+t^2}=\underset{t \to 0}{O}\left(\ln(t)\right)=\underset{t \to 0}{o}\left(\frac{1}{\sqrt{t}}\right)\]
	et \[\frac{\ln(t)}{x^2+t^2}=\underset{t \to 0}{o}\left(\frac{1}{t^{\frac{3}{2}}}\right)\]
	Ainsi $\displaystyle t\mapsto \frac{\ln(t)}{x^2+t^2}$ est intégrale sur $\R^*_+$.\\
	Maintenant, donnons une expression de $I$ à l'aide de fonctions usuelles.\\
	Soit $x\in\R^*_+$.
	\[I(x)=\int_{0}^{+\infty}\frac{\ln(t)}{x^2+t^2}dt=\frac{1}{x^2}\int_{0}^{+\infty}\frac{\ln(t)}{1+\left(\frac{t}{x}\right)^2}dt\]
	On pose $t=ux$ : \[I(x)=\frac{1}{x^2}\int_{0}^{+\infty}\frac{\ln(ux)}{1+u^2}xdu=\frac{1}{x}\int_{0}^{+\infty}\frac{\ln(u)}{1+u^2}du+\frac{\ln(x)}{x}\int_{0}^{+\infty}\frac{1}{1+u^2}du\]
	Ainsi, on obtient l'expression suivante : \[I(x)=\frac{I(1)}{x}+\frac{\pi\ln(x)}{2x}\]
	Calculons maintenant que $I(1)$.
	On pose $u=\frac{1}{t}$.
	\[I(0)=\int_{+\infty}^{0}\frac{\ln\left(\frac{1}{u}\right)}{1+\left(\frac{1}{u}\right)^2}\left(-\frac{1}{u^2}\right)\,du
	=-\int_{0}^{+\infty}\frac{\ln(u)}{1+u^2}\,du=-I(0)\]
	Donc $I(0)=0$.
	Par conséquent, pour tout $x\in\R^*_+$, \[I(x)=\frac{\pi\ln(x)}{2x}\]
	Reste plus qu'à prouver que $I$ admet un maximum et le déterminer.\\
	Il est clair que $I$ est dérivable sur $\R^*_+$.\\
	\[\forall x\in\R^*_+, I'(x)=\frac{\pi}{2}\frac{1-\ln(x)}{x^2}\]
	
	\begin{center}
		\begin{tikzpicture}
			\tkzTabInit[lgt=2,espcl=2]%
			{$x$ /1 , $I'(x)$ /1 , $I(x)$ /2}%
			{$0$, $e$, $+\infty$}
			\tkzTabLine{d, + , z , +,}
			\tkzTabVar{-/ $-\infty$ , +/ $\frac{\pi}{2e}$, -/ $+\infty$}
		\end{tikzpicture}
	\end{center}
	Donc $I$ admet un maximum sur $\R^*_+$ qui est : \[\max\limits_{x\in\R^*_+}I=I(e)=\frac{\pi}{2e}\]
	
	\subsection{Intégrales de Bertrand}
	\label{Intégrale de Bertrand corrigé}
	\textcolor{blue}{\hyperref[intbertrand]{[Enoncé]}}\\
	\subsection{Intégrabilité des cosinus de polynômes}
	\label{Intégrabilité des cosinus de polynômes corrigé}
	\textcolor{blue}{\hyperref[intégrabilitécospolynome]{[Enoncé]}}\\
	\subsection{Nature d'une intégrale (1) \telecom{2}}
	\label{Nature d'une intégrale (1) corrigé}
	\textcolor{blue}{\hyperref[Nature d'une intégrale (1)]{[Enoncé]}}\\
	$\arccos$ est une fonction continue par morceaux et strictement positive sur $[0,1[$. Cherchons un équivalent de $\arccos$ en $1^-$.\\
	On sait que $\cos(t)\utzero=1-\dfrac{t^2}{2}+\smallo{t^2}$ et $\arccos(t)\underset{t\to 1^-}\longrightarrow 0$.\\
	Donc $2(1-t)\underset{t\to 1^-}=\arccos(t)^2+\smallo{\arccos(t)^2}\underset{t\to 1^-}\sim\arccos(t)^2$.\\
	Ainsi $\forall \alpha\in \R,\ \displaystyle\frac{1}{\arccos(t)^\alpha}\underset{t\to 1^-}\sim\frac{1}{2^{\alpha/2}(1-t)^{\alpha/2}}$.\\
	On en déduit que $\displaystyle\int_0^1\frac{dt}{\arccos(t)^\alpha}$ converge si et seulement si $\alpha>2$.
	
	\subsection{Nature d'une intégrale (2)}
	\label{Nature d'une intégrale (2) corrigé}
	\textcolor{blue}{\hyperref[Nature d'une intégrale (2)]{[Enoncé]}}\\
	
	\subsection{Divergence grossière}
	\label{Divergence grossière corrigé}
	\textcolor{blue}{\hyperref[divergencegrossière]{[Enoncé]}}\\
	\subsection{Espace $L^2$ et dérivation}\label{sec:espace-L2-et-derivation}
	\textcolor{blue}{\hyperref[Espace L^2 et  dérivation]{[Enoncé]}}\\
	\subsection{Intégrale de Frullani}\label{sec:integrale-de-frullani}
	\textcolor{blue}{\hyperref[frullani]{[Enoncé]}}\\
	
	\subsection{Calcul d'une intégrale (1) \etoile{3}}\label{sec:calcul-dune-integrale-1-etoile3}
	\textcolor{blue}{\hyperref[calculintégrale1]{[Enoncé]}}\\
	Soit $n$ un entier supérieur ou égal à $2$.\\
	Tout d'abord, $f_n:t\mapsto \displaystyle\prod\limits_{k=1}^n\frac{1}{t+k}$ est continue par morceaux sur $\R^*_+$ et $f_n(t)\utfty{\sim} \displaystyle\frac{1}{t^n}$. Donc $I_n=\displaystyle\int_0^{+\infty}f_n(t)dt$ converge par comparaison à une intégrale de Riemann ($n>1$).\\
	Notons $F(X)=\displaystyle\prod\limits_{k=1}^n\frac{1}{X+k}=\displaystyle\sum\limits_{k=1}^n\frac{\lambda_k}{X+k}$ la décomposition en éléments simples de $F$.\\\\
	$\forall k\in \crblanc{1}{n},\ \lambda_k=\lim\limits_{t\to -k}(t+k)F(t)=\displaystyle\prod\limits_{\substack{1\leq i\leq n\\i\ne k}}\frac{1}{i-k}=(-1)^{k-1}\prod\limits_{i=1}^{k-1}\frac{1}{k-i}\prod\limits_{i=k+1}^n\frac{1}{i-k}=\frac{(-1)^{k-1}}{(k-1)!(n-k)!}=\frac{(-1)^{k-1}k}{n!}\binom{n}{k}=\frac{(-1)^{k-1}}{(n-1)!}\binom{n-1}{k-1}$.\\\\
	Soit $A\in \R_+$.\\
	$\displaystyle\int_0^Af_n(t)dt=\sum\limits_{k=1}^n\frac{(-1)^{k-1}}{(n-1)!}\binom{n-1}{k-1}\int_0^A\frac{dt}{t+k}=\sum\limits_{k=1}^n\frac{(-1)^{k-1}}{(n-1)!}\binom{n-1}{k-1}(\ln(A+k)-\ln(k))$\\
	Or, $\displaystyle\sum\limits_{k=1}^n\frac{(-1)^{k-1}}{(n-1)!}\binom{n-1}{k-1}\left(\ln(A)+\ln\left(1+\frac{k}{A}\right)-\ln(k)\right)\underset{A\to +\infty}{=}\ln(A)\sum\limits_{k=1}^n\frac{(-1)^{k-1}}{(n-1)!}\binom{n-1}{k-1}+\smallo{1}+\sum\limits_{k=1}^n\frac{(-1)^k}{(n-1)!}\binom{n-1}{k-1}\ln(k)$\\
	Et, $\displaystyle\sum\limits_{k=1}^n\frac{(-1)^{k-1}}{(n-1)!}\binom{n-1}{k-1}=\frac{1}{(n-1)!}\sum\limits_{k=1}^n(-1)^{k-1}\binom{n-1}{k-1}=\frac{1}{(n-1)!}(1-1)^{n-1}=0$.\\
	Donc $I_n=\displaystyle\frac{1}{(n-1)!}\sum\limits_{k=1}^n(-1)^k\binom{n-1}{k-1}\ln(k)$.
	
	\subsection{Calcul d'une intégrale (2) \etoile{2}}\label{sec:calcul-dune-integrale-2-etoile2}
	\textcolor{blue}{\hyperref[calculintégrale2]{[Enoncé]}}\\
	$\forall x\in ]0,1],\ \displaystyle\left\lfloor\frac{1}{x}\right\rfloor\geq 1$ et $\forall n\in \N^*,\ \displaystyle\left\lfloor\frac{1}{x}\right\rfloor=n\iff n\leq \frac{1}{x}<n+1\iff \frac{1}{n+1}<x\leq \frac{1}{n}$.\\
	La fonction $x\mapsto \displaystyle x\left\lfloor\frac{1}{x}\right\rfloor$ est continue par morceaux et positive sur $]0,1]$. On peut donc calculer dans $\R_+\cup\{+\infty\}$ :\\
	$I=\displaystyle\sum\limits_{n=1}^{+\infty}\int_{1/(n+1)}^{1/n}xn\ dx=\sum\limits_{n=1}^{+\infty}n\left[\frac{x^2}{2}\right]_{1/(n+1)}^{1/n}=\sum\limits_{n=1}^{+\infty}\frac{n}{2}\left(\frac{1}{n^2}-\frac{1}{(n+1)^2}\right)$\\
	Or, $\forall n\in \N^*,\ \displaystyle n\left(\frac{1}{n^2}-\frac{1}{(n+1)^2}\right)=\frac{1}{n}-\frac{n}{(n+1)^2}=\frac{1}{n}-\frac{1}{n+1}+\frac{1}{(n+1)^2}$.\\
	Donc $I=\displaystyle\frac{1}{2}\left[\sum\limits_{n=1}^{+\infty}\left(\frac{1}{n}-\frac{1}{n+1}\right)+\sum\limits_{n=1}^{+\infty}\frac{1}{(n+1)^2}\right]=\frac{1}{2}\left[1+\sum\limits_{n=2}^{+\infty}\frac{1}{n^2}\right]=\frac{1}{2}\sum\limits_{n=1}^{+\infty}\frac{1}{n^2}=\frac{\pi^2}{12}$.
	
	\subsection{Calcul d'une intégrale (3)}\label{sec:calcul-dune-integrale-3}
	\textcolor{blue}{\hyperref[calculintégrale3]{[Enoncé]}}\\
	
	\subsection{Calcul d'une intégrale (4)}\label{sec:calcul-dune-integrale-4}
	\textcolor{blue}{\hyperref[calculintégrale4]{[Enoncé]}}\\
	
	\subsection{Permutation Série-intégrale (1)}\label{sec:permutation-serie-integrale-1}
	\textcolor{blue}{\hyperref[Permutation Série-Intégrale 1]{[Enoncé]}}\\
	\subsection{Permutation Série-intégrale (2)}\label{sec:permutation-serie-integrale-2}
	\textcolor{blue}{\hyperref[Permutation série-intégrale 2]{[Enoncé]}}\\
	\subsection{Fonction d'écart Logarithmique intégral \etoile{2}}\label{sec:fonction-decart-logarithmique-integral-etoile2}
	\textcolor{blue}{\hyperref[logint]{[Enoncé]}}\\
	Montrons par récurrence $\mathcal P(n):"\exists C_n\in \R,\ \forall x\geq 2,\ \operatorname{Li}(x)=\displaystyle\frac{x}{\ln x}\sum\limits_{k=0}^n\frac{k!}{(\ln x)^k}+\int_2^x\frac{(n+1)!}{(\ln t)^{n+2}}dt+C_n\ "$ pour tout $n\in \N$.\\
	Fixons $x\geq 2$.\\
	Tout d'abord, $\forall n\in \N,\ t\mapsto \displaystyle\frac{1}{(\ln t)^{n+2}}\in \mathcal C^1([2,x],\R)$. Donc par IPP :\\
	$\operatorname{Li}(x)=\displaystyle\int_2^x1\cdot\frac{1}{\ln t}dt=\left[\frac{t}{\ln t}\right]_2^x+\int_2^xt\cdot\frac{1}{t(\ln t)^2}dt=\frac{x}{\ln x}-\frac{2}{\ln 2}+\int_2^x\frac{dt}{(\ln t)^2}$.\\
	D'où $\mathcal P(0)$ en posant $C_0=\displaystyle-\frac{2}{\ln 2}$.\\
	Supposons $\mathcal P(n)$ pour un certain $n\in \N$. Similairement par IPP :\\
	$\displaystyle\int_2^x\frac{(n+1)!}{(\ln t)^{n+2}}dt=\left[\frac{t}{\ln t}\cdot\frac{(n+1)!}{(\ln t)^{n+1}}\right]+\int_2^x\frac{(n+2)!}{(\ln t)^{n+3}}dt=\frac{x}{\ln x}\cdot\frac{(n+1)!}{(\ln x)^{n+1}}-\frac{2(n+1)!}{(\ln 2)^{n+2}}+\int_2^x\frac{(n+2)!}{(\ln t)^{n+3}}dt$.\\
	On en déduit $\mathcal P(n+1)$ en posant $C_{n+1}=C_n-\displaystyle\frac{2(n+1)!}{(\ln 2)^{n+2}}$.\\
	Ainsi $\forall n\in \N,\ \mathcal P(n)$.\\
	Montrons que $\forall n\in \N,\ \operatorname{Li} (x)\uxfty{=}\displaystyle\frac{x}{\ln x}\sum\limits_{k=0}^n\frac{k!}{(\ln x)^k}+\smallo{\displaystyle\frac{x}{(\ln x)^{n+1}}}$. Fixons $n\in \N$\\
	$\displaystyle\frac{x}{(\ln x)^{n+1}}\uxfty{\longrightarrow}+\infty$ donc $C_n\uxfty{=}\smallo{\displaystyle\frac{x}{(\ln x)^{n+1}}}$.\\
	Ensuite, $\displaystyle\frac{d}{dx}\left(\frac{x}{(\ln x)^{n+1}}\right)=\frac{1}{(\ln x)^{n+1}}-\frac{n+1}{(\ln x)^{n+2}}\uxfty{\sim}\frac{1}{(\ln x)^{n+1}}$ et $\displaystyle\frac{(n+1)!}{(\ln x)^{n+2}}\uxfty{=}\smallo{\frac{1}{(\ln x)^{n+1}}}$.\\
	Donc comme $x\mapsto\displaystyle\frac{1}{(\ln x)^{n+1}}$ est positive au voisinage de $+\infty$, d'après les théorèmes d'intégrations de relations de comparaisons,
	\begin{itemize}
		\item $\displaystyle\int_2^x\frac{(n+1)!}{(\ln t)^{n+2}}dt\uxfty{=}\smallo{\int_2^x\frac{1}{(\ln t)^{n+1}}dt}$
		\item $\displaystyle\int_2^x\frac{1}{(\ln t)^{n+1}}dt\uxfty{\sim}\int_2^x\left(\frac{1}{(\ln t)^{n+1}}-\frac{n+2}{(\ln t)^{n+2}}\right)dt=\frac{x}{(\ln x)^{n+1}}-\frac{2}{(\ln 2)^{n+1}}\uxfty{\sim}\frac{x}{(\ln x)^{n+1}}$.
	\end{itemize}
	Ainsi $\displaystyle\int_2^x\frac{(n+1)!}{(\ln t)^{n+2}}dt\uxfty{=}\smallo{\frac{x}{(\ln x)^{n+1}}}$ d'où $\operatorname{Li}(x)\uxfty{=}\displaystyle\frac{x}{\ln x}\sum\limits_{k=0}^n\frac{k!}{(\ln x)^k}+\smallo{\displaystyle\frac{x}{(\ln x)^{n+1}}}$.
	
	\subsection{Intégrale de Bernoulli}\label{sec:integrale-de-bernoulli}
	\textcolor{blue}{\hyperref[intégralebernoulli]{[Enoncé]}}\\
	
	\subsection{Lemme de Riemann-Lebesgue : cas des fonctions $\mathcal{C}^1$ \etoile{1}}\label{sec:lemme-de-riemann-lebesgue--cas-des-fonctions-mathcalc1-etoile1}
		\textcolor{blue}{\hyperref[riemannlebesgue]{[Enoncé]}}\\
	Soit $\lambda\in \R^*_+$. $t\mapsto e^{i\lambda t}$ et $\phi$ sont de classes $\mathcal{C}^1$ sur $[a,b]$ donc par IPP:\\
	$\left|\displaystyle\int_a^b\phi(t)e^{i\lambda t}dt\right|=\left|\left[\displaystyle\frac{\phi(t)e^{i\lambda t}}{i\lambda}\right]_a^b-\displaystyle\int_a^b\frac{\phi'(t)e^{i\lambda t}}{i\lambda}dt\right|\leq \displaystyle\frac{2||\phi||_{\infty,[a,b]}}{\lambda}+\frac{(b-a)||\phi'||_{\infty,[a,b]}}{\lambda}$ (Le théorème des bornes atteintes justifie que $\phi$ et $\phi'$ sont bornées sur $[a,b]$).\\\\
	Donc $\lim\limits_{\lambda\to +\infty}\displaystyle\int_a^b\phi(t)e^{i\lambda t}dt=0$.
	
	
	
	\subsection{Intégrale de Poisson (1) \etoile{2}}\label{sec:integrale-de-poisson-1-etoile2}
	\textcolor{blue}{\hyperref[intpoisson1]{[Enoncé]}}\\
	Soit $\rho\in \R\setminus\{-1,1\}$. On pose pour $n\in \N^*,\ S_n=\displaystyle\frac{\pi}{n}\sum\limits_{k=0}^{n-1}\ln\left(1-2\cos\left(\frac{k\pi}{n}\right)\rho+\rho^2\right)$. Fixons $n\in \N^*$.\\
	\begin{align*}
		S_n&=\displaystyle\frac{\pi}{n}\sum\limits_{k=0}^{n-1}\ln\left[(\rho-e^{ik\pi/n})(\rho-e^{-ik\pi/n})\right]\\
		&=\displaystyle\frac{\pi}{n}\ln\left(\prod\limits_{k=0}^{n-1}(\rho-e^{ik\pi/n})(\rho-e^{-ik\pi/n})\right)\\
		&=\displaystyle\frac{\pi}{n}\ln\left(\frac{\rho-1}{\rho+1}\displaystyle\prod\limits_{k=1}^{n}(\rho-e^{-ik\pi/n})\prod\limits_{k=0}^{n-1}(\rho-e^{ik\pi/n})\right)\\
		&=\displaystyle\frac{\pi}{n}\ln\left(\frac{\rho-1}{\rho+1}\displaystyle\prod\limits_{k=1}^{n}(\rho-e^{-i(k-2n)\pi/n})\prod\limits_{k=0}^{n-1}(\rho-e^{ik\pi/n})\right)\\
		&=\displaystyle\frac{\pi}{n}\ln\left(\frac{\rho-1}{\rho+1}\displaystyle\prod\limits_{k=1}^{n}(\rho-e^{i(2n-k)\pi/n})\prod\limits_{k=0}^{n-1}(\rho-e^{ik\pi/n})\right)\\
		&=\displaystyle\frac{\pi}{n}\ln\left(\frac{\rho-1}{\rho+1}\displaystyle\prod\limits_{k=n}^{2n-1}(\rho-e^{ik\pi/n})\prod\limits_{k=0}^{n-1}(\rho-e^{ik\pi/n})\right)\\
		&=\displaystyle\frac{\pi}{n}\ln\left(\frac{\rho-1}{\rho+1}\prod\limits_{k=0}^{2n-1}(\rho-e^{ik\pi/n})\right)\\
		&=\displaystyle\frac{\pi}{n}\ln\left(\frac{(\rho^{2n}-1)(\rho-1)}{\rho+1}\right)
	\end{align*}
	$\theta\mapsto \ln(1-2\cos(\theta)\rho+\rho^2)$ est continue sur $[0,\pi]$ donc $S_n\unfty{\longrightarrow}I(\rho)$.\\
	Si $\rho\in ]-1,1[,\ I(\rho)=\unfty{\lim}S_n=0$,\\
	et si $\rho\in \R\setminus\{-1,1\}$, alors $S_n\unfty{\sim}\displaystyle\frac{\pi}{n}\ln(\rho^{2n})\unfty{\sim}2\pi\ln(|\rho|)$ d'où $I(\rho)=2\pi\ln(|\rho|)$.
	
	\subsection{Intégrale de Poisson (2) \etoile{3}}\label{sec:integrale-de-poisson-2-etoile3}
	\textcolor{blue}{\hyperref[intpoisson2]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*\\]
		\item Soit $\rho\in \R^*\setminus\{-1,1\}$.\\
		$I\left(\displaystyle\frac{1}{\rho}\right)=\displaystyle\int_0^\pi \ln\left(1-2\cos(\theta)\frac{1}{\rho}+\frac{1}{\rho^2}\right)d\theta=\displaystyle\int_0^\pi \left(\ln(1-2\cos(\theta)\rho+\rho^2)-\ln(\rho^2)\right)d\theta=I(\rho)-2\pi\ln(|\rho|)$.
		\item Remarquons d'abord que $I$ est paire. En effet en posant $\varphi=\pi-\theta$ on a,\\
		$I(-\rho)=\displaystyle\int_0^\pi \ln(1+2\cos(\theta)\rho+\rho^2)d\theta=\displaystyle\int_0^\pi \ln(1-2\cos(\varphi)\rho+\rho^2)d\varphi=I(\rho)$.
		\begin{align*}
			2I(\rho)&=I(\rho)+I(-\rho)\\
			&=\displaystyle\int_0^\pi \ln\left[(1+2\cos(\theta)\rho+\rho^2)(1-2\cos(\theta)\rho+\rho^2)\right]d\theta\\
			&=\displaystyle\int_0^\pi \ln\left[(1+\rho^2)^2-4\cos^2(\theta)\rho^2\right]d\theta\\
			&=\displaystyle\int_0^\pi \ln\left[1+2(1-2\cos^2(\theta))\rho^2+\rho^4\right]d\theta\\
			&=\displaystyle\int_0^\pi \ln(1-2\cos(2\theta)\rho^2+\rho^4)d\theta\\
			(\alpha=2\theta)\ &=\displaystyle\int_0^{2\pi} \ln(1-2\cos(\alpha)\rho^2+\rho^4)\frac{d\alpha}{2}\\
			(\beta=\alpha-\pi)\ &=\displaystyle\int_{-\pi}^\pi \frac{1}{2}\ln(1+2\cos(\beta)\rho^2+\rho^4)d\beta\\
			\text{(Par parité)}\ &=\displaystyle\int_{-\pi}^0 \ln(1+2\cos(\beta)\rho^2+\rho^4)d\beta\\
			(\gamma=\pi-\beta)\ &=\displaystyle\int_{0}^\pi \ln(1-2\cos(\gamma)\rho^2+\rho^4)d\gamma\\
			&=I(\rho^2)
		\end{align*}
		Par récurrence immédiate, $\forall n\in \N^*,\ I\left(\rho^{2^n}\right)=2^nI(\rho)$.
		\item Montrons que $I$ est continue sur $]-1,1[$. Notons $\fonction{\Phi}{]-1,1[\times]0,\pi[}{\R}{(\rho,\theta)}{\ln(1-2\cos(\theta)\rho+\rho^2)}$.\\
		$\forall \rho\in ]-1,1[,\ \theta\mapsto \Phi(\rho,\theta)\in \text{CM}(]0,\pi[,\R)\times L^1(]0,\pi[,\R)$;\\
		$\forall \theta\in [0,\pi],\ \rho\mapsto \Phi(\rho,\theta)\in \mathcal{C}^0(]-1,1[,\R)$;
		\begin{align*}
			\forall (\rho,\theta)\in ]-1,1[\times]0,\pi[,\ \left|\Phi(\rho,\theta)\right|&=\left|\ln((\rho-\cos(\theta))^2+\sin^2(\theta))\right|\\
			&\leq\max\{\left|\Phi(\cos(\theta),\theta)\right|,\left|\Phi(-1,\theta)\right|,\left|\Phi(1,\cos(\theta))\right|\}\\
			&=\max\{\left|\ln(\sin^2(\theta))\right|,\left|\ln(2+2\cos(\theta))\right|,\left|\ln(2-2\cos(\theta))\right|\}
		\end{align*}\\
		Or $\fonction{f}{]0,\pi[}{\R}{\theta}{\ln(\sin^2(\theta))=2\ln(\sin(\theta))}\in L^1(]0,\pi[,\R)$, en effet $f$ est continue par morceaux sur $]0,\pi[$ et\\
		$\begin{cases}
			f(\theta)\underset{\theta\to 0^+}{=}2\ln(\theta+\smallo{\theta})\underset{\theta\to 0^+}{=}2\ln(\theta)+\smallo{1}\underset{\theta\to 0^+}{=}\smallo{\displaystyle\frac{1}{\displaystyle\sqrt{\theta}}}\\
			f(\theta)\underset{\theta\to \pi^-}{=}2\ln(\pi-\theta+\smallo{\pi-\theta})\underset{\theta\to \pi^-}{=}\smallo{\displaystyle\frac{1}{\displaystyle\sqrt{\pi-\theta}}}
		\end{cases}$\\\\\\
		$\fonction{g}{]0,\pi]}{\R}{\theta}{\ln(2-2\cos(\theta))}\in L^1(]0,\pi[,\R)$, en effet $g$ est continue par morceaux sur $]0,\pi]$ et\\\\
		$g(\theta)\underset{\theta\to 0^+}{=}\ln(\theta^2+\smallo{\theta^2})\underset{\theta\to 0^+}{=}2\ln(\theta)+\ln(1+\smallo{1})\underset{\theta\to 0^+}{=}\smallo{\displaystyle\frac{1}{\displaystyle\sqrt{\theta}}}$.\\
		Et de même, $\fonction{h}{[0,\pi[}{\R}{\theta}{\ln(2+2\cos(\theta))}\in L^1([0,\pi[,\R)$.\\
		Donc finalement, $\fonction{\Psi}{]0,\pi[}{\R}{\theta}{\max\{f(\theta),g(\theta),h(\theta)\}}\in L^1(]0,\pi[,\R)$ puisque\\
		$\Psi=\displaystyle\frac{1}{2}(f+\max(g,h)+|f-\max(g,h)|)=\frac{1}{2}\left(f+\frac{1}{2}\left(g+h+|g-h|\right)+\left|f-\frac{1}{2}(g+h+|g-h|)\right|\right)$.\\
		Ainsi $I$ est continue sur $]-1,1[$ par transfert de continuité.\\
		En particulier, $I$ est continue en $0$ donc,\\
		$\rho\in ]-1,1[\implies \rho^{2^n}\unfty{\longrightarrow}0\implies 
		2^nI(\rho)=I\left(\rho^{2^n}\right)\unfty{\longrightarrow}I(0)=0\implies I(\rho)=0$\\
		Maintenant, si $\rho\in \R\setminus[-1,1]$, alors $\displaystyle\frac{1}{\rho}\in ]-1,1[$ et donc d'après la question $1$, $I(\rho)=2\pi\ln(|\rho|)+I\left(\displaystyle\frac{1}{\rho}\right)=2\pi\ln(|\rho|)$.
	\end{enumerate}
	
	\subsection{Mines-Ponts MP 2024 (Chaïma Prime)}\label{sec:mines-ponts-mp-2024-chaima-prime}
	\textcolor{blue}{\hyperref[chaima]{[Enoncé]}}\\
	
	\subsection{Une suite d'intégrales (1)}\label{sec:une-suite-dintegrales-1}
	\textcolor{blue}{\hyperref[suiteintégrale1]{[Enoncé]}}\\
	\subsection{Une suite d'intégrales (2)}\label{sec:une-suite-dintegrales-2}
	\textcolor{blue}{\hyperref[suiteintégrale2]{[Enoncé]}}\\
	\subsection{Une suite d'intégrales (3)}\label{sec:une-suite-dintegrales-3}
	\textcolor{blue}{\hyperref[suiteintégrale3]{[Enoncé]}}\\
	\subsection{Nombre d'Apéry}\label{sec:nombre-dapery}
	\textcolor{blue}{\hyperref[Apery]{[Enoncé]}}\\\\
	\subsection{Comportement asymptotique (1)}\label{sec:comportement-asymptotique-1}
	\textcolor{blue}{\hyperref[comportementasymp1]{[Enoncé]}}\\
	\subsection{Comportement asymptotique (2)}\label{sec:comportement-asymptotique-2}
	\textcolor{blue}{\hyperref[comportementasymp2]{[Enoncé]}}\\
	\subsection{Théorème de d'Alembert-Gauss (1) \etoile{2}}\label{sec:theoreme-de-dalembert-gauss-1-etoile2}
	\textcolor{blue}{\hyperref[alembertgauss1]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item Notons $\fonction{f}{\R_+\times[0,2\pi]}{\C}{(r,\theta)}{\displaystyle\frac{1}{P(re^{i\theta})}}$.\\
		Puisque $P$ ne s'annule pas sur $\C$,
		\begin{itemize}
			\item $\forall r\in \R_+,\ \theta\mapsto f(r,\theta)\in \text{CM}([0,2\pi],\C)$;
			\item $\forall \theta\in [0,2\pi],\ r\mapsto f(r,\theta)\in \mathcal C^1(\R_+,\C)$;
			\item $\forall (r,\theta)\in \R_+\times[0,2\pi],\ \displaystyle\left|\frac{\partial f}{\partial r}(r\theta)\right|=\left|\frac{-e^{i\theta}P'(re^{i\theta})}{P(re^{i\theta})^2}\right|=\left|\frac{P'(re^{i\theta})}{P(re^{i\theta})^2}\right|$.\\
			Fixons $a\in \R_+$ et notons $D_a=\{z\in \C,\ |z|\leq a\}$.\\
			Les fonctions $z\mapsto P(z)^2$ et $z\mapsto P'(z)$ sont continues sur $D_a$ et de plus $P$ ne s'annule pas sur $\C$ donc la fonction $z\mapsto \displaystyle\frac{P'(re^{i\theta})}{P(re^{i\theta})^2}$ est continue sur $D_a$ qui est un compact. Elle est donc bornée par un certain $M\in \R_+$ sur $D_a$.\\
			Ainsi $\forall (r,\theta)\in [0,a]\times[0,2\pi],\ re^{i\theta}\in D_a\implies \displaystyle\left|\frac{P'(re^{i\theta})}{P(re^{i\theta})^2}\right|\leq M$.\\
			Enfin la fonction $\theta\mapsto M$ est intégrable sur $[0,2\pi]$.
		\end{itemize}
		On en déduit d'après le théorème de transfert $\mathcal C^1$ que $F$ est $\mathcal C^1$ sur $\bigcup\limits_{a\in \R_+}D_a=\R_+$ et que $\forall r\in \R^*_+,\ F'(r)=\displaystyle\int_0^{2\pi}-\frac{e^{i\theta}P'(re^{i\theta})}{P(re^{i\theta})^2}d\theta$.
		\item On calcule $\forall r\in \R^*_+,\ F'(r)=\displaystyle\int_0^{2\pi}\frac{1}{ir}\cdot\frac{-ire^{i\theta}P'(re^{i\theta})}{P(re^{i\theta})^2}d\theta=\left[\frac{1}{irP(re^{i\theta})}\right]_0^{2\pi}=0$.\\
		Donc $F$ est constante sur $\R^*_+$. Etant continue en $0$ elle est constante sur $\R_+$.
		\item Appliquons le théorème de convergence dominée pour déterminer la limite de $F$ en $+\infty$.\\
		Par inégalité triangulaire, $\forall r\in \R_+,\ |F(r)|\leq \displaystyle\int_0^{2\pi}\frac{d\theta}{|P(re^{i\theta})|}$. Or comme $P$ n'est pas constant, $|P(z)|\underset{|z|\to +\infty}{\longrightarrow}+\infty$.\\
		Alors, $\forall \theta\in [0,2\pi],\ |f(r,\theta)|\underset{r\to +\infty}{\longrightarrow}0$. Les autres hypothèses ont été vérifiées dans la question $1$.\\
		Par conséquent $\displaystyle\int_0^{2\pi}\frac{d\theta}{|P(re^{i\theta})|}\underset{r\to +\infty}{\longrightarrow}\int_0^{2\pi}0\ d\theta=0$.\\
		Ainsi $F$ est constamment nulle.\\
		Ceci est absurde car $F(0)=\displaystyle\int_0^{2\pi}\frac{d\theta}{P(0)}=\frac{2\pi}{P(0)}\ne 0$.\\
		On en déduit le théorème de d'Alembert-Gauss.
	\end{enumerate}

	\subsection{Fonction Gamma d'Euler}\label{sec:fonction-gamma-deuler}
	\textcolor{blue}{\hyperref[Fonction Gamma d'Euler]{[Enoncé]}}\\
	\label{Gamma}
	\begin{enumerate}[leftmargin=*]
		\item Pour tout $x\in\R$ la fonction $f_x :t\mapsto t^{x-1}e^{-t}$ est continue par morceaux sur $]0,+infty[$.
		\begin{itemize}
			\item $t^{x-1}e^{-t}\sim_{x\to+\infty}e^{-t}$ donc $f_x$ est intégrale en $+\infty$.
			\item $t^{x-1}e^{-t} \underset{x\to 0}{\sim}t^{x-1}$.\\
			Ainsi, $f_x$ est intégrale en $0$ si et seulement si $1-x<1$ i.e. $0<x$.
		\end{itemize}
		Donc $\Gamma$ est défini sur $\R^*_+$.
		\item Soit $x\in\R^*_+$.\\ 
		Les fonctions $t\mapsto t^x$ et $t\mapsto e^{-t}$ sont de classe $\mathcal{C}^1$ sur $\R^*_+$. Donc par intégration par parties :
		\[\Gamma(x+1)=\int_{0}^{+\infty}t^xe^{-t}=[-t^xe^{-t}]^{+\infty}_0+ \int_{0}^{+\infty}t^{x-1}e^{-t}=x\Gamma(x)\]
		Montrons par récurrence que pour tout $n\in\N, \Gamma(n+1)=n!$
		Pour $n=0$, \[\Gamma(1)=\int_{0}^{+\infty}e^{-t}dt=[-e^{-t}]^{+\infty}_0=1=0!\]
		Supposons que pour un certain $n\in\N$, $\Gamma(n+1)=n!$.
		\begin{align*}
			\Gamma(n+2)&=(n+1)\Gamma(n+1) &\text{ d'après la question 2}\\
			&=(n+1)n!&\text{d'après l'hypothèse de récurrence}
			&=(n+1)!
		\end{align*}
		On a donc montré par récurrence que pour tout $n\in\N,\Gamma(n+1)=n!$
		\item D'après la question 2, pour tout $x\in\R^*_+$, \[\Gamma(x)=\frac{\Gamma(x+1)}{x}\]
		On en déduit donc que \[\Gamma(x)\underset{x\to 0^+}{\sim}\frac{\Gamma(1)}{x}=\frac{1}{x}\]
		\item On pose la fonction :\[f:(x,t)\mapsto t^xe^{-t}\]
		\begin{itemize}
			\item Pour tout $t\in\R^*_+$, $x\mapsto f(x,t)$ est de classe $\mathcal{C}^{+\infty}$ sur $\R^*_+$,
			\item Pour tout $x\in\R^*_+$, $t\mapsto \dpartial{f}{k}{x}=\ln(t)^kt^{x-1}e^{-t}$ est continue par morceaux sur $\R^*_+$.
			\item Soit $a,b\in\R^*_+$..\\
			On définit $\varphi:t\mapsto\begin{cases}
				t^{a-1} &\text{quand } t\in]0,1]\\
				t^{b-1}e^{-t}&\text{quand } t\in]1,+\infty[
			\end{cases}$
			On obtient la majoration suivante : \[ \forall x\in[a,b],\forall t\in\R^*_+,\quad\left|\dpartial{f}{k}{x}(x,t)\right|\leq |\ln(t)|^k\varphi(t)\]
			Puisque $t\mapsto |\ln(t)|^k\varphi(t)$ est continue par morceaux sur $\R^*_+$, \[|\ln(t)|^k\varphi(t)=\underset{x\to 0^+}{o}\left(\frac{1}{t^{1-\tfrac{a}{2}}}\right)\] et \[|\ln(t)|^k\varphi(t)=\underset{x\to +\infty}{o}\left(\frac{1}{t^2}\right)\]
			on en déduit que $t\mapsto |\ln(t)|^k\varphi(t)$ est intégrable sur $\R^*_+$.\\
		\end{itemize}
			Donc par transfert de classe, $\Gamma$ est de classe $\mathcal{C}^{\infty}$ sur $\R^*_+$.
			\item $\forall x\in\R^*_+$, \[\Gamma''(x)=\int_{0}^{+\infty}\ln(t)^2t^{x-1}e^{-t}dt\].
			Donc $\Gamma''$ est (stricte)-positive sur $\R^*_+$. Ainsi $\Gamma$ est convexe (strictement) sur $\R^*_+$.
			\item On pose $f:x\mapsto \ln(\Gamma(x))$.\\
			$f$ est de classe $\mathcal{C}^2$ sur $\R_+^*$.\\
			\[\forall x\in\R^*_+,\quad f'(x)=\frac{\Gamma'(x)}{\Gamma(x)}\] 
			et \[\forall x\in\R^*_+,\quad f''(x)=\frac{\Gamma''(x)\Gamma(x)-\Gamma'(x)^2}{\Gamma(x)^2}\]
			Pour montrer que $f$ est convexe, il suffit de montrer que $\Gamma''(x)\Gamma(x)\geq\Gamma'(x)^2$ pour tout $x\in\R^*_+$\\
			Pour cela, on se place dans $\mathcal{C}^0(\R^*_+,\R)$ muni du produit scalaire canonique.
			Soit $x\in\R^*_+$.\\
			Les fonctions $t\mapsto \ln(t)t^{\tfrac{x-1}{2}}e^{-t/2}$ et $t\mapsto t^{\tfrac{x-1}{2}}e^{-t/2}$ sont continues sur $\R^*_+$.\\
			D'après l'inégalité de Cauchy-Schwarz, 
			\[\left(\int_{0}^{+\infty}\ln(t)t^{\tfrac{x-1}{2}}e^{-t/2}t^{\tfrac{x-1}{2}}e^{-t/2}dt \right)^2\leq\left(\int_{0}^{+\infty}\left(t^{\tfrac{x-1}{2}}e^{-t/2}\right)^2dt\right)\left(\int_{0}^{+\infty}\left(\ln(t)t^{\tfrac{x-1}{2}}e^{-t/2}\right)^2dt\right)\]
			c'est-à-dire : 
			\[\Gamma'(x)^2\leq \Gamma(x)\Gamma''(x)\]
			Donc $\Gamma$ est log-convexe.\\
			\textit{\underline{Remarque} : Une autre méthode consiste à utiliser l'inégalité de Hölder \ref{Normes p}. Cette démonstration est laissé au lecteur curieux.}
			
		
	\end{enumerate}
	\subsubsection{Point critique et limite en $+\infty$}
	\subsubsection{Valeur en les demi-entiers}
	\subsubsection{Théorème de Bohr-Mollerup \etoile{4}}
	On montre (cf. \ref{Fonction Gamma d'Euler}) que $\Gamma$ vérifie les conditions de l'énoncé. Donnons nous $f$ qui vérifie les trois conditions de l'énoncé.\\
	On va montrer que la fonction $W:x\mapsto \ln\circ f(x)-\ln\circ\Gamma(x)$ est constante. On remarque déjà que $W$ est $1$-périodique sur $\R^*_+$, en effet $\forall x>0,\ W(x+1)=\ln(f(x+1))-\ln(\Gamma(x+1))=\ln(xf(x))-\ln(x\Gamma(x))=\ln(x)+\ln\circ f(x)-\ln(x)-\ln\circ\Gamma(x)=W(x)$. Fixons $n\in \N$ et $x\in ]0,1]$.\\
	On va utiliser la croissance des pentes sur $\ln\circ f$, qui est convexe, au points $n,\ n+1,\ n+x+1,\ n+2$ :
	\begin{align*}
		&\ln\circ f(n+1)-\ln\circ f(n)\leq \frac{\ln\circ f(n+x+1)-\ln\circ f(n+1)}{x}\leq \ln\circ f(n+2)-\ln\circ f(n+1)\\
		\iff&\ln(n)\leq \frac{\ln\circ f(n+x+1)-\ln\circ f(n+1)}{x}\leq\ln(n+1)
	\end{align*}
	Puis sur $\ln\circ\Gamma$ :
	\begin{align*}
		&\ln\circ\Gamma(n+1)-\ln\circ\Gamma(n)\leq \frac{\ln\circ\Gamma(n+x+1)-\ln\circ\Gamma(n+1)}{x}\leq \ln\circ\Gamma(n+2)-\ln\circ\Gamma(n+1)\\
		\iff&\ln\circ\Gamma(n+1)-\ln\circ\Gamma(n+2)\leq \frac{\ln\circ\Gamma(n+1)-\ln\circ\Gamma(n+x+1)}{x}\leq \ln\circ\Gamma(n)-\ln\circ\Gamma(n+1)\\
		\iff&-\ln(n+1)\leq \frac{\ln\circ\Gamma(n+1)-\ln\circ\Gamma(n+x+1)}{x}\leq-\ln(n)
	\end{align*}
	D'où en sommant :
	\begin{align*}
		&\ln(n)-\ln(n+1)\leq \frac{W(n+x+1)-W(n+1)}{x}\leq \ln(n+1)-\ln(n)\\
		\text{Par 1-périodicité} \iff&-\ln\left(1+\frac{1}{n}\right)\leq \frac{W(x)-W(1)}{x}\leq \ln\left(1+\frac{1}{n}\right)\\
		\iff&-\ln\left(1+\frac{1}{n}\right)\leq \frac{W(x)}{x}\leq \ln\left(1+\frac{1}{n}\right)
	\end{align*}
	Et donc en faisant tendre $n$ vers $+\infty,\ \displaystyle\frac{W(x)}{x}=0$ c'est à dire $W(x)=0$.\\
	Ceci étant vrai pour tout $x\in]0,1]$, par $1$-périodicité $W$ est nulle sur $\R^*_+$ c'est à dire $f=\Gamma$.
	\subsubsection{Formules de Gauss et Weierstrass}
	\subsubsection{Lien entre les gamma d'Euler}
	\subsubsection{Formule de duplication de Legendre}
	\subsubsection{Intégrale de Raabe}
	\subsubsection{Généralisation de la formule de Stirling}
	\subsection{Fonction Beta d'Euler}\label{sec:fonction-beta-deuler}
	\textcolor{blue}{\hyperref[Fonction Bêta d'Euler]{[Enoncé]}}\\
	\subsubsection{Lien avec une intégrale d'Euler}
	\subsubsection{Lien entre $\Gamma$ et B}
	\subsection{Inégalité intégrale-dérivée \etoile{1}}\label{sec:inegalite-integrale-derivee-etoile1}
	\textcolor{blue}{\hyperref[inegaliteintder]{[Enoncé]}}\\
	D'après l'inégalité de Taylor-Lagrange, $\forall c\in [a,b]$ \[\displaystyle\left|\int_a^b f(t)dt\right|\leq \int_a^c|f(t)-f(a)|dt\leq \int_a^c(t-a)\normep{\infty}{f'}dt=\frac{(c-a)^2}{2}\normep{\infty}{f'}\].\\
	En utilisant deux fois cela pour $c=\displaystyle\frac{a+b}{2}$,\\
	\[\displaystyle\left|\int_a^b f(t)dt\right|\leq \left|\int_a^cf(t)dt\right|+\left|-\int_b^cf(t)dt\right|\leq \frac{(c-a)^2}{2}M+\frac{(b-c)^2}{2}M=\frac{(b-a)^2}{4}\normep{\infty}{f'}\].
	
	\subsection{Majoration de l'erreur dans la méthode des trapèzes}\label{sec:majoration-de-lerreur-dans-la-methode-des-trapezes}
	\textcolor{blue}{\hyperref[trapèze]{[Enoncé]}}\\
	Déja pour mettre les idées en place, représentons-nous à quoi correspond la méthode des trapèzes.
	\begin{center}
		\includegraphics[width=0.60\textwidth]{trapeze.png}
	\end{center}
	On définit la subdivision régulière $(x_1,\dots,x_n)$ du segment $[a,b]$.\\
	On pose $f_i$ l'unique fonction affine tel que $f_i(x_i)=f(x_i)$ et $f_i(x_{i+1})=f(x_{i+1})$.\\
	Montrons que pour tout $x\in[x_i,x_{i+1}]$, il existe $c_x\in]x_i,x_{i+1}[$ tel que :
	\[f(x)-f_i(x_i)=(x-x_i)(x_{i+1}-x)\frac{f''(c_x)}{2}\]
	Si $x=x_i$ ou $x=x_{i+1}$, le résultat est immédiatement vrai.\\
	Soit $x\in]x_i,x_{i+1}[$.
	On pose \[g:t\mapsto f(t)-f_i(t)-\frac{(t-x_i)(t-x_{i+1})}{(x-x_i)(x-x_{i+1})}[f(x)-f_i(x)]\]
	On vérifie aisément que cette fonction est de classe $\mathcal{C}^2$ sur $[x_i,x_{i+1}]$.
	On remarque que cette fonction s'annule en $x_i$, en $x$ et en $x_{i+1}$.\\
	Ainsi, d'après le théorème de Rolle, on en déduit : 
	\begin{itemize}
		\item $\exists c_1\in]x_i,x[$ tel que $g'(c_1)=0$,
		\item $\exists c_2\in]x,x_{i+1}[$ tel que $g'(c_2)=0$.
	\end{itemize}
	De nouveau, d'après le théorème de Rolle, il existe $c_x\in]c_1,c_2[\subset ]x_i,x_{i+1}[$ tel que $g''(c_x)=0$.\\
	Maintenant, calculons la dérivée seconde de $g$. Après calculs, on obtient :
	\[\forall t\in[x_i,x_{i+1}],\quad g''(t)=f''(t)-2\frac{[f(x)-f_i(x)]}{(x-x_i)(x-x_{i+1})}\]
	Par conséquent, en évaluant en $c_x$, on en déduit que :
	\[f(x)-f_i(x)=(x-x_i)(x_{i+1}-x)\frac{f''(c_x)}{2}\]
	Ainsi, en notant $M=\normep{\infty}{f''}$, on a :
	\[|f(x)-f_i(x)|\leq (x-x_i)(x_{i+1})\frac{M}{2}\]
	Donc : \[\left|\int_{x_i}^{x_{i+1}}f(x)-f_i(x) dx\right|\leq \frac{M}{2}\int_{x_i}^{x_{i+1}}(x-x_i)(x_{i+1}-x)dx\]
	Or :
	\[\int_{x_i}^{x_{i+1}}(x-x_i)(x_{i+1}-x)dx=\frac{(x_{i+1}-x_i)^3}{6}\]
	Donc, on en déduit l'inégalité suivante, 
	 \[\left|\int_{x_i}^{x_{i+1}}f(x)-f_i(x) dx\right|\leq \frac{M(x_{i+1}-x_i)^3}{12}\]
	 Et puisque les $(x_i)$ forment une subdivision régulière de $[a,b]$, on a $x_{i+1}-x_i=\frac{b-a}{n}$, donc :  \[\left|\int_{x_i}^{x_{i+1}}f(x)-f_i(x) dx\right|\leq \frac{M(b-a)^3}{12n^3}\]
	Donc en notant $T_n$ la somme des aires de trapèzes, on a finalement :
	\begin{align*}
		\left|\int_{a}^{b}f(x)dx-T_n\right|&\leq\sum_{i=0}^{n-1}\left|\int_{x_i}^{x_{i+1}}\left(f(x)-f_i(x)\right)dx\right|\\
		&\leq\sum_{i=0}^{n-1}\frac{M(b-a)^3}{12n^3}\\
		&\leq \frac{M(b-a)^3}{12n^2}
	\end{align*} 
	Ce résultat est vrai pour tout $n\in\N^*$, en particulier il est vrai pour $n=1$.
	Donc \[\left| \int_a^b f(t)dt-\frac{(b-a)}{2}(f(a)+f(b))\right| \leq \frac{(b-a)^3}{12}\left\|f''\right\|_\infty\]
	
	\subsection{Inégalité de Young \etoile{2}}\label{sec:inegalite-de-young-etoile2}
	\textcolor{blue}{\hyperref[young]{[Enoncé]}}\\
	Soit $(a,b)\in [0,c]\times[0,f(c)]$. Tout d'abord d'après le théorème de la bijection, $f$ est bijective de $[0,c]$ dans $[0,f(c)]$ et $f^{-1}$ est continue sur $[0,f(c)]$.\\
	De plus $f$ est $\mathcal C^1$ et strictement croissante sur $[0,f^{-1}(b)]$, on peut donc effectuer le changement de variable $t=f(u)$ dans la seconde intégrale : $\displaystyle\int_0^bf^{-1}(t)dt=\int_0^{f^{-1}(b)}uf'(u)du$.\\
	Puis par IPP, $\displaystyle\int_0^{f^{-1}(b)}uf'(u)du=\left[uf(u)\right]_0^{f^{-1}(b)}-\int_0^{f^{-1}(b)}f(u)du=bf^{-1}(b)-\int_0^{f^{-1}(b)}f(t)dt$.\\
	Donc $\displaystyle\int_0^a f(t)dt +\int_0^b f^{-1}(t)dt=\int_{f^{-1}(b)}^af(t)dt+bf^{-1}(b)$.\\
	Enfin par croissance de l'intégrale,
	\begin{itemize}
		\item Si $a\geq f^{-1}(b),\ \displaystyle\int_{f^{-1}(b)}^af(t)dt\geq (a-f^{-1}(b))b$ d'où $\displaystyle\int_0^a f(t)dt +\int_0^b f^{-1}(t)dt\geq ab$ ;
		\item Si $a\leq f^{-1}(b),\ \displaystyle\int_a^{f^{-1}(b)}f(t)dt\leq (f^{-1}(b)-a)b$ c'est à dire $\displaystyle\int_{f^{-1}(b)}^af(t)dt\geq (a-f^{-1}(b))b$ d'où $\displaystyle\int_0^a f(t)dt +\int_0^b f^{-1}(t)dt\geq ab$.
	\end{itemize}
	Dans tous les cas, $\displaystyle\int_0^a f(t)dt +\int_0^b f^{-1}(t)dt\geq ab$.\\\\
	On remarque que si $a=f^{-1}(b)$ c'est à dire si $b=f(a)$, alors il y a égalité.\\
	Réciproquement, s'il y a égalité alors l'inégalité $\displaystyle\int_{f^{-1}(b)}^af(t)dt\geq (a-f^{-1}(b))b$ est une égalité.\\
	Autrement dit $\displaystyle\int_{f^{-1}(b)}^a(f(t)-b)dt=0$. Cependant par stricte croissance de $f$, la fonction $t\mapsto f(t)-b$ est de signe constant sur $I=[f^{-1}(b),a]\cup[a,f^{-1}(b)]$ qui est un intervalle. Cette fonction est continue donc d'après la stricte positivité de l'intégrale, $\forall t\in I,\ f(t)=b$. En particulier, $f(a)=b$.
	
	\subsection{Transformée de Laplace}\label{sec:transformee-de-laplace}
	\textcolor{blue}{\hyperref[laplace]{[Enoncé]}}\\
	
	
	\subsection{Théorème des résidus (version faible)}\label{sec:theoreme-des-residus-version-faible}
	\textcolor{blue}{\hyperref[residus]{[Enoncé]}}\\
	
	\newpage
\section{Correction Fonctions réelles}
	\subsection{Formule de Leibniz \etoile{1}}\label{sec:formule-de-leibniz-etoile1}
	\textcolor{blue}{\hyperref[leibniz]{[Enoncé]}}\\
	Soient $I$ un intervalle de $\R,\ n\in \N$ et $f,g$ deux fonctions de classe $\mathcal C^n$ sur $I$ à valeurs dans $\R$. $f\times g$ est de classe $\mathcal C^n$ sur $I$ et :
	\[(f\times g)^{(n)}=\displaystyle\sum_{k=0}^n\binom{n}{k}f^{(k)}g^{(n-k)}\]
	\underline{Démonstration :}\\
	$n=0$ :\\
	Soient $I$ un intervalle de $\R$ et $f,g$ deux fonctions continues sur $I$ à valeurs dans $\R$. $f\times g$ est continue sur $I$ et $(f\times g)^{(0)}=f\times g=\displaystyle\sum_{k=0}^0\binom{0}{k}f^{(k)}g^{(0-k)}$.\\\\
	Supposons le résultat vrai pour un certain $n\in \N$. Soient $I$ un intervalle de $\R$ et $f,g$ deux fonctions de classe $\mathcal C^{n+1}$ sur $I$ à valeurs dans $\R$. A fortiori $f$ et $g$ sont de classe $\mathcal C^n$ sur $I$ donc par hypothèse de récurrence, $f\times g$ est de classe $\mathcal C^n$ sur $I$ et $(f\times g)^{(n)}=\displaystyle\sum_{k=0}^n\binom{n}{k}f^{(k)}g^{(n-k)}$.\\
	Pour tout $k\in \crblanc{0}{n},\ f^{(k)}$ et $g^{(n-k)}$ sont de classe $\mathcal C^1$ sur $I$ donc $(f\times g)^{(n)}$ est de classe $\mathcal C^1$ sur $I$ c'est à dire $f\times g$ est de classe $\mathcal C^{n+1}$ sur $I$.\\
	De plus,
	\begin{align*}
		(f\times g)^{(n+1)}&=\displaystyle\left(\sum_{k=0}^n\binom{n}{k}f^{(k)}g^{(n-k)}\right)'\\
		&=\sum_{k=0}^n\binom{n}{k}\left(f^{(k+1)}g^{(n-k)}+f^{(k)}g^{(n+1-k)}\right)\\
		&=\sum_{k=0}^n\binom{n}{k}f^{(k+1)}g^{(n-k)}+\sum_{k=0}^n\binom{n}{k}f^{(k)}g^{(n+1-k)}\\
		&=\sum_{k=1}^{n+1}\binom{n}{k-1}f^{(k)}g^{(n+1-k)}+\sum_{k=0}^n\binom{n}{k}f^{(k)}g^{(n+1-k)}\\
		&=\sum_{k=0}^{n+1}\binom{n}{k-1}f^{(k)}g^{(n+1-k)}+\sum_{k=0}^{n+1}\binom{n}{k}f^{(k)}g^{(n+1-k)}\\
		&=\sum_{k=0}^{n+1}\left(\binom{n}{k-1}+\binom{n}{k}\right)f^{(k)}g^{(n+1-k)}\\
		&=\sum_{k=0}^{n+1}\binom{n+1}{k}f^{(k)}g^{(n+1-k)}
	\end{align*}
	Ainsi par récurrence simple, la propriété est vraie quel que soit $n\in \N$.
	
	\subsection{Fonction discontinue en tout point \etoile{1}}\label{sec:fonction-discontinue-en-tout-point-etoile1}
	\textcolor{blue}{\hyperref[discontinuetoutpoint]{[Enoncé]}}\\
	L'exemple classique est la fonction indicatrice de $\Q$, $\mathbbm{1}_\Q:x\in \R\mapsto \begin{cases}1&\mbox{si }x\in \Q\\0&\mbox{si }x\in \R\setminus\Q\end{cases}$. Fixons $a\in \R$ et supposons pas l'absurde que $\mathbbm{1}_\Q$ est continue en $a$.\\
	Supposons que $a\in \R\setminus\Q$. Comme $\Q$ est dense dans $\R$, $\exists (x_n)\in \Q^\N,\ \unfty{\lim}x_n=a$.\\
	$\forall n\in \N,\ \mathbbm{1}_\Q(x_n)=1\implies \unfty{\lim}\mathbbm{1}_\Q(x_n)=1$. Or par continuité de $\mathbbm{1}_\Q$ en $a$, $\unfty{\lim}\mathbbm{1}_\Q(x_n)=\mathbbm{1}_\Q(a)=0$ ce qui est absurde.\\
	Donc $a\in \Q$. Cependant pas densité de $\R\setminus\Q$ dans $\R$, $\exists (y_n)\in \left(\R\setminus\Q\right)^\N,\ \unfty{\lim}y_n=a$.\\
	De même, $\forall n\in \N,\ \mathbbm{1}_\Q(y_n)=0\implies \unfty{\lim}\mathbbm{1}_\Q(y_n)=0$. Or par continuité de $\mathbbm{1}_\Q$ en $a$, $\unfty{\lim}\mathbbm{1}_\Q(y_n)=\mathbbm{1}_\Q(a)=1$.\\
	Ceci est absurde donc $\mathbbm{1}_\Q$ n'est pas continue en $a$.\\
	Finalement $\mathbbm{1}_\Q$ n'est continue en aucun point de $\R$.
	
	\subsection{Fonction nulle part dérivable}\label{sec:fonction-nulle-part-derivable}
	\textcolor{blue}{\hyperref[nullepartdérivable]{[Enoncé]}}\\
	
	\subsection{Theorème de Rolle}\label{sec:theoreme-de-rolle}
	\textcolor{blue}{\hyperref[Théorème de Rolle]{[Enoncé]}}\\
	\subsection{Dérivée symétrique \etoile{1}}\label{sec:derivee-symetrique-etoile1}
	\textcolor{blue}{\hyperref[deriveesymetrique]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item Supposons que $f$ soit dérivable en un point $a\in \R$.\\
		$\displaystyle\frac{f(a+h)-f(a-h)}{2h}=\frac{f(a+h)-f(a)}{2h}+\frac{f(a)-f(a-h)}{2h}\underset{h\to 0}{\longrightarrow}\frac{f'(a)}{2}+\frac{f'(a)}{2}=f'(a)$ qui est finie par hypothèse.
		\item Ce n'est pas une condition nécessaire. Considérons la fonction $f:x\mapsto |x|$.\\
		$f$ n'est pas dérivable en $0$ pourtant, $\displaystyle\frac{f(h)-f(-h)}{2h}=0\underset{h\to 0}{\longrightarrow}0$.
	\end{enumerate}
	
	\subsection{Fonction de Pringsheim \etoile{2}}\label{sec:fonction-de-pringsheim-etoile2}
	\textcolor{blue}{\hyperref[fpringsheim]{[Enoncé]}}\\
	On reconnaît bien évidemment la fonction indicatrice de $\Q$ !\\
	Soit $x\in \Q$. On note $x=\displaystyle\frac{a}{b}$ avec $a\in \Z$ et $b\in \N^*$.\\\\
	A partir du rang $n=b,\ n!x$ est un entier.\\
	Ainsi, $\forall n\geq b,\ |\cos(n!\pi x)|=1$. D'où $\forall n\geq b,\ \underset{m\to +\infty}{\lim}|\cos(n!\pi x)|^m=1$.\\
	Enfin $f(x)=\unfty{\lim}\ \underset{m\to +\infty}{\lim}|\cos(n!\pi x)|^m=1$.\\
	Supposons maintenant que $x\in \R\setminus\Q$. Alors, $\forall n\in \N,\ n!x\notin \N$.\\
	En effet si il existe $n\in \N$ tel que $a=n!x\in \N$ alors $x=\displaystyle\frac{a}{n!}\in \Q$ ce qui est absurde.\\
	Ainsi, $\forall n\in \N,\ |\cos(n!\pi x)|<1$. D'où $\forall n\in \N,\ \underset{m\to +\infty}{\lim}|\cos(n!\pi x)|^m=0$.\\
	On en déduit que $f(x)=\unfty{\lim}\ \underset{m\to +\infty}{\lim}|\cos(n!\pi x)|^m=0$.\\
	On a montré que $f=\mathbbm{1}_\Q$.
	
	\subsection{$f\circ f=\Id_{\R_+}$ \etoile{2}}\label{sec:fcirc-fidr-etoile2}
	\textcolor{blue}{\hyperref[fof=I]{[Enoncé]}}\\
	$f$ est bijective donc en particulier injective. Etant continue, elle est strictement monotone sur $\R_+$.\\
	Supposons que $f$ est décroissante.\\
	$\forall x\in \R_+,\ f(x)\leq f(0)$. Donc $f(0)+1\notin f(\R_+)$ ce qui est absurde car $f$ est surjective.\\
	Ainsi $f$ est strictement croissante. Supposons par l'absurde que $f\ne \Id_{\R_+}$. Il existe alors $x\in \R_+$ tel que $f(x)\ne x$.\\
	Mais alors $f(x)>x\iff f\circ f(x)>f(x)\iff x>f(x)$ ce qui est absurde.\\
	Par conséquent $f=\Id_{\R_+}$.
	
	\subsection{Point fixe d'une fonction continue et décroissante sur $\R$ \etoile{1}}\label{sec:point-fixe-dune-fonction-continue-et-decroissante-sur-r-etoile1}
	\textcolor{blue}{\hyperref[pfcd]{[Enoncé]}}\\
	$-f$ est croissante donc elle admet une limite $l_+\in \R\cup\{+\infty\}$ en $+\infty$ et une limite $l_-\in \R\cup\{-\infty\}$ en $-\infty$.\\
	Alors la fonction $g=\Id_\R-f$ est continue et strictement croissante sur $\R$, $\lim\limits_{-\infty}g=-\infty$ et $\lim\limits_{+\infty}g=+\infty$. Ainsi d'après le théorème de la bijection, $g$ est bijective de $\R$ dans $\R$.\\
	Par conséquent, $\exists!\ x\in \R,\ f(x)=x$.
	
	\subsection{Un théorème du point fixe (1) \etoile{1}}\label{sec:un-theoreme-du-point-fixe-1-etoile1}
	\textcolor{blue}{\hyperref[theopointfixe1]{[Enoncé]}}\\
	Posons $g=f-\Id_{[0,1]}$.\\
	$g$ est continue sur $[0,1]$, $g(0)=f(0)\geq 0$ et $g(1)=f(1)-1\leq 0$.\\
	Alors d'après le TVI, $\exists x\in [0,1],\ g(x)=0$. c'est à dire $\exists x\in [0,1],\ f(x)=x$.
	
	\subsection{Un théorème du point fixe (2) \etoile{2}}\label{sec:un-theoreme-du-point-fixe-2-etoile2}
	\textcolor{blue}{\hyperref[theopointfixe2]{[Enoncé]}}\\
	Par hypothèse $(a,b)\in f(I)^2$ donc $\exists (\alpha,\beta)\in I^2,\ f(\alpha)=a,\ f(\beta)=b$.\\
	Posons $g=f-\Id_I$. $g$ est continue sur $I$.\\
	$(\alpha,\beta)\in I^2$ donc $a\leq \alpha$ et $\beta\leq b$.\\
	Par conséquent, $g(\alpha)=f(\alpha)-\alpha=a-\alpha\leq 0$ et $g(\beta)=f(\beta)-\beta=b-\beta\geq 0$.\\
	Alors d'après le TVI, $\exists x\in [a,b],\ g(x)=0$. C'est à dire $\exists x\in [a,b],\ f(x)=x$.
	
	\subsection{Point fixe de $f\circ f$ \etoile{1}}\label{sec:point-fixe-de-fcirc-f-etoile1}
	\textcolor{blue}{\hyperref[pointfixe fof]{[Enoncé]}}\\
	Supposons que $f$ n'ait pas de point fixe. Alors étant continue, $f<\Id_\R$ ou $f>\Id_\R$.\\
	Si $f<\Id_\R$ alors $\forall x\in \R,\ f(f(x))<f(x)<x$ Or $f\circ f$ admet un point fixe et est continue donc ceci est absurde.\\
	De même si $f>\Id_\R$ alors $\forall x\in \R,\ f(f(x))>f(x)>x$ ce qui est absurde.\\
	Finalement $f$ admet un point fixe.
	
	\subsection{Point fixe de $f\circ g$ et $g\circ f$ \etoile{2}}\label{sec:point-fixe-de-fcirc-g-et-gcirc-f-etoile2}
	\textcolor{blue}{\hyperref[pointfixecommute]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item La fonction $f\circ g-\Id_\R$ est continue et strictement décroissante sur $\R$ elle est donc injective.\\
		Ensuite, par décroissance de $f\circ g,\ \forall x\in \R_+,\ f\circ g(x)-x\leq f\circ g(0)-x$ et $\forall x\in \R_-,\ f\circ g(x)-x\geq f\circ g(0)-x$.\\
		Par conséquent $\uxfty{\lim}f\circ g(x)-x=-\infty$ et $\underset{x\to -\infty}{\lim}f\circ g(x)-x=+\infty$.\\
		D'après le théorème des valeurs intermédiaire $f\circ g-\Id$ s'annule sur $\R$ c'est à dire $f\circ g$ admet un point fixe. De plus puisque qu'elle est injective sur $\R$ ce point est unique.
		\item Notons $L$ le point fixe de $f\circ g$.\\
		$f\circ g(L)=L\implies g\circ f(g(L))=g(L)$ et donc $g\circ f$ admet $g(L)$ comme point fixe.\\
		Soit $L'$ un point fixe de $g\circ f$.\\
		$g\circ f(L')=L'\implies f\circ g(f(L'))=f(L')$.\\
		Alors d'après la question $1,\ f(L')=L$ puis $g\circ f(L')=L'=g(L)$.\\
		Ainsi $g(L)$ est l'unique point fixe de $g\circ f$.
	\end{enumerate}
	
	\subsection{Racine carrée de cos \etoile{3}}\label{sec:racine-carree-de-cos-etoile3}
	\textcolor{blue}{\hyperref[sqrtcos]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item Posons $g=\Id_\R-\cos$. $g$ est dérivable sur $\R$ et $\forall x\in \R,\ g'(x)=1+\sin(x)\geq 0$. De plus il n'y a égalité qu'en un nombre dénombrable de point donc $g$ est strictement croissante sur $\R$.\\
		Comme $g(0)=-1<0$, $\displaystyle g\left(\frac{\pi}{2}\right)=\frac{\pi}{2}\geq 0$ et comme $g$ est continue sur $\R$, $\exists!x\in \left[0,\displaystyle\frac{\pi}{2}\right],\ \cos(x)=x$.
		\item Supposons qu'une telle fonction existe.\\
		Alors $f(x)=f(\cos(x))=f\circ f(f(x))=\cos(f(x))$.\\
		Autrement dit $f(x)$ est un point fixe de $\cos$. Par unicité de ce point fixe, $f(x)=x$.
		Ensuite en dérivant $f\circ f=\cos :\\
		f'\times f'\circ f=-\sin$.\\
		Puis en évaluant en $x$ :\\
		$f'(x)f'(f(x))=f'(x)^2=-\sin(x)<0$.\\
		Ceci est absurde donc il n'existe pas de fonction $f:\R\to \R$ dérivable sur $\R$ telle que $f\circ f=\cos$.
		\item Supposons encore qu'une telle fonction existe.\\
		Soient $x,y\in [0,\pi]$ tels que $f(x)=f(y)$.\\
		Alors $f\circ f(x)=f\circ f(y)$ c'est à dire $\cos(x)=\cos(y)$ c'est à dire $x=y$ par injectivité de $\cos$ sur $[0,\pi]$. Ainsi $f$ est injective sur $[0,\pi]$. Etant continue elle est strictement monotone sur $[0,\pi]$.\\
		Mais alors $f\circ f$ est strictement croissante sur $[0,\pi]$. En effet,
		\begin{itemize}
			\item $f$ strictement croissante $\implies f(x)>f(y)\implies f(f(x))>f(f(y))$;
			\item $f$ strictement décroissante $\implies f(x)<f(y)\implies f(f(x))>f(f(y))$.
		\end{itemize}
		Or ceci est absurde car $\cos$ n'est pas strictement croissante sur $[0,\pi]$.\\
		Finalement il n'existe pas de fonction $f:\R\to \R$ continue sur $\R$ telle que $f\circ f=\cos$.
	\end{enumerate}
	
	\subsection{Trigonométrie \etoile{1}}\label{sec:trigonometrie-etoile1}
	\textcolor{blue}{\hyperref[trigo]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item Soit $x\in [-1,1]$. Posons $\alpha=\arcsin(x)$ et $\beta=\arccos(x)$. $\alpha\in \displaystyle\left[-\frac{\pi}{2},\frac{\pi}{2}\right]$ et $\beta\in [0,\pi]$.\\
		$\sqrt{1-x^2}=\sqrt{1-\sin^2(\alpha)}=|\cos(\alpha)|=\cos(\arcsin(x))$.\\
		$\sqrt{1-x^2}=\sqrt{1-\cos^2(\beta)}=|\sin(\beta)|=\sin(\arccos(\alpha))$.
		\item Posons $\theta=\arcsin(x)\in \displaystyle\left[-\frac{\pi}{2},\frac{\pi}{2}\right]$.\\
		$\displaystyle\arctan\left(\frac{x}{\sqrt{1-x^2}}\right)=\arctan\left(\frac{\sin(\theta)}{\sqrt{1-\sin^2(\theta)}}\right)=\arctan\left(\frac{\sin(\theta)}{\cos(\theta)}\right)=\arctan(\tan(\theta))=\theta=\arcsin(x)$.\\
		Attention ! L'avant dernière égalité est vraie car $\arctan$ est la fonction réciproque de $\tan:\displaystyle\left[-\frac{\pi}{2},\frac{\pi}{2}\right]\to \R$.
		\item Posons $f:x\mapsto \arctan(x)+\arctan\left(\displaystyle\frac{1}{x}\right)$.\\
		$f$ est impaire : $\forall x\ne 0,\ f(-x)=\displaystyle\arctan(-x)+\arctan\left(-\frac{1}{x}\right)=-\arctan(x)-\arctan\left(\frac{1}{x}\right)=-f(x)$.\\
		$f$ est dérivable sur $\R^*_+$.\\
		$\forall x>0,\ \displaystyle f'(x)=\frac{1}{1+x^2}-\frac{1}{x^2}\times\frac{1}{1+\displaystyle\frac{1}{x}}=0$.\\
		$\R^*_+$ est un intervalle donc $\exists C\in \R,\ \forall x>0,\ f(x)=C$.\\
		De plus $C=\uxfty{\lim}f(x)=\displaystyle\frac{\pi}{2}$.\\
		Donc $\begin{cases}
			\forall x>0,\ \displaystyle\arctan(x)+\arctan\left(\frac{1}{x}\right)=\frac{\pi}{2}\\
			\forall x<0,\ \displaystyle\arctan(x)+\arctan\left(\frac{1}{x}\right)=-\frac{\pi}{2}
		\end{cases}$.
		\item Posons $g:x\mapsto\arcsin(x)+\arccos(x)$. $g$ est impaire sur $[-1,1]$ et dérivable sur $]-1,1[$ et,\\
		$\forall x\in ]-1,1[,\ g'(x)=\displaystyle\frac{1}{\sqrt{1-x^2}}-\frac{1}{\sqrt{1-x^2}}=0$.\\
		Donc $\exists C'\in \R,\ \forall x\in ]-1,1[,\ g(x)=C'$.\\
		On calcule $C'=\displaystyle\lim_{x\to 1}g(x)=g(1)=\frac{\pi}{2}-0=\frac{\pi}{2}$.\\
		Ainsi $\forall x\in [-1,1],\ \arcsin(x)+\arccos(x)=\displaystyle\frac{\pi}{2}$.
		\item On déduit de la formule d'addition de $\tan : \forall (a,b)\in \displaystyle\left]-\frac{\pi}{2},\frac{\pi}{2}\right[^2,\ \tan(a)\tan(b)\ne 1\implies\tan(a+b)=\frac{\tan(a)+\tan(b)}{1-\tan(a)\tan(b)}$, l'identité $\tan(4x)=\displaystyle\frac{2\tan(2x)}{1-\tan(2x)^2}=\frac{\displaystyle2\frac{2\tan(x)}{1-\tan(x)^2}}{1-\displaystyle\left(\frac{2\tan(x)}{1-\tan(x)^2}\right)^2}=\frac{4\tan(x)(1-\tan^2(x))}{(1-\tan^2(x))^2-4\tan^2(x)}$.\\\\
		$\displaystyle\tan\left(4\arctan\left(\frac{1}{5}\right)-\arctan\left(\frac{1}{239}\right)\right)=\frac{\tan\left(4\arctan\left(\frac{1}{5}\right)\right)-\tan\left(\arctan\left(\frac{1}{239}\right)\right)}{1+\tan\left(4\arctan\left(\frac{1}{5}\right)\right)\tan\left(\arctan\left(\frac{1}{239}\right)\right)}$.\\
		On calcule $\displaystyle\tan\left(4\arctan\left(\frac{1}{5}\right)\right)=\frac{\displaystyle\frac{4}{5}\left(1-\left(\frac{1}{5}\right)^2\right)}{\displaystyle\left(1-\left(\frac{1}{5}\right)^2\right)^2-4\left(\frac{1}{5}\right)^2}=\frac{\displaystyle\frac{96}{125}}{\displaystyle\frac{576}{625}-\frac{4}{25}}=\frac{96}{125}\times\frac{625}{476}=\frac{120}{119}$.\\
		Puis $\displaystyle\tan\left(4\arctan\left(\frac{1}{5}\right)-\arctan\left(\frac{1}{239}\right)\right)=\frac{\displaystyle\frac{120}{119}-\frac{1}{239}}{\displaystyle1+\frac{120}{119}\times\frac{1}{239}}=1$.\\
		Or $\displaystyle\frac{1}{5}\leq \frac{\sqrt{8}-2}{2}$ donc par croissance de $\arctan$,\\
		$\displaystyle\arctan\left(\frac{1}{239}\right)\leq \arctan\left(\frac{1}{5}\right)\leq 4\arctan\left(\frac{1}{5}\right)\leq 4\arctan\left(\frac{\sqrt{8}-2}{2}\right)$ et $\displaystyle\arctan\left(\frac{1}{239}\right)\geq 0$.\\
		Posons $x=\displaystyle\tan\left(\frac{\pi}{8}\right)$.\\
		On sait que $x\geq \arctan(0)=0$ et que $1=\displaystyle\tan\left(\frac{\pi}{4}\right)=\frac{2x}{1-x^2}$ donc que $1-2x-x^2=0$ d'où $x=\displaystyle\frac{\sqrt{8}-2}{2}$.\\
		Ainsi, $\displaystyle 0\leq 4\arctan\left(\frac{1}{5}\right)-\arctan\left(\frac{1}{239}\right)\leq \frac{\pi}{2}$.\\
		On en déduit par bijectivité de $\tan:\displaystyle\left]-\frac{\pi}{2},\frac{\pi}{2}\right[$ :
		$$\displaystyle 4\arctan\left(\frac{1}{5}\right)-\arctan\left(\frac{1}{239}\right)=\frac{\pi}{4}$$
	\end{enumerate}
	
	\subsection{Règle de l'Hôpital}\label{sec:regle-de-lhopital}
	\textcolor{blue}{\hyperref[hopital]{[Enoncé]}}\\
	
	\subsection{Théorème de Darboux}\label{sec:theoreme-de-darboux}
	\textcolor{blue}{\hyperref[darboux]{[Enoncé]}}\\
	Soit $f:\R\to \R$ dérivable sur un intervalle $I$.\\
	
	\subsubsection{Réciproque du TVI \etoile{1}}
	La réciproque est fausse, il suffit de prendre une fonction dérivable dont la dérivée n'est pas continue.\\
	L'exemple classique est $f:x\mapsto \begin{cases} x^2\sin\left(\displaystyle\frac{1}{x}\right)&\mbox{ si }x\ne 0\\ 0&\mbox{ si }x=0\end{cases}$.\\
	D'après le théorème de Darboux, pour tout intervalle $I$ de $\R\ f'(I)$ est un intervalle. Pourtant $f'$ n'est pas continue sur $\R$.
	
	\subsubsection{Fonction non primitivable \etoile{1}}
	On considère a fonction partie entière $E:x\in \R\mapsto \lfloor x\rfloor$.\\
	Supposons que $E$ admette une primitive $F$ sur un intervalle $I$ d'intérieur non vide de $\R$.\\
	Par définition, $\forall x\in I,\ F'(x)=E(x)$. Donc $F'(I)$ n'est pas un singleton et $F'(I)\subset E(\R)=\Z$. On en déduit que $F'(I)$ n'est pas un intervalle.\\
	Ceci contredit le théorème de Darboux ainsi $E$ n'admet pas de primitive.
	
	\subsubsection{Condition suffisante pour être de classe $\mathcal{C}^1$ \etoile{3}}
	$f$ est convexe donc $f'$ est croissante sur $I$. Fixons $c\in \ring{I}$.\\
	D'après le théorème de la limite monotone, $f'$ admet des limites en $c^+$ et en $c^-$ et $\underset{c^-}{\lim}f'\leq \underset{c^+}{\lim}f'$.\\
	Or d'après le théorème de Darboux $f'(I)$ est un intervalle.\\
	Alors $z<f'(c)\implies z\leq \underset{c^-}{\lim}f'$ et $f'(c)<z\implies \underset{c^+}{\lim}f'<z$.\\
	Ainsi si $z\in \R$, $\underset{c^-}{\lim}f'=f'(c)=\underset{c^-}{\lim}f'$ et $f'$ est continue en $c$.\\
	Si $I$ admet un maximum $b$ alors en considérant $\underset{b^-}{\lim}f'$ et en utilisant le théorème de Darboux on obtient $\underset{b^-}{\lim}f'=f'(b)$.\\
	De même si $I$ admet un minimum $a$ alors $\underset{a^+}{\lim}f'=f'(a)$.\\
	Finalement $f'$ est continue sur $I$ c'est à dire $f$ est de classe $\mathcal{C}^1$ sur $I$.
	
	\subsection{Dérivée et inverse confondu}\label{sec:derivee-et-inverse-confondu}
	\textcolor{blue}{\hyperref[dérivinv]{[Enoncé]}}\\
	
	
	\subsection{Fonction croissante et convexe sur $\R$ \etoile{1}}\label{sec:fonction-croissante-et-convexe-sur-r-etoile1}
	\textcolor{blue}{\hyperref[croissanteconvexe]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item On sait que $\forall x\in \R,\ f'(x)\geq 0$. De plus $f$ n'est pas constante donc il existe $y\in \R,\ f'(y)>0$.\\
		Alors comme $f$ est convexe, elle est au dessus de sa tangente en $y$:\\
		$\forall x\in \R,\ f(x)\geq f'(y)(x-y)+f(y)$.\\
		Or comme $f'(y)>0,\ f'(y)(x-y)+f(y)\uxfty{\longrightarrow}+\infty$. Ainsi $\lim\limits_{+\infty}f=+\infty$.
		\item Comme $f$ n'est pas constante on sait qu'il existe deux réels $x,y$ tels que $f(x)\ne f(y)$. Quitte à échanger $x$ et $y$ supposons que $x<y$. Par croissance, $f(x)<f(y)$\\
		Comme $f$ est convexe, on sait que l'application $\fonction{p}{\R\setminus\{x\}}{\R}{u}{\displaystyle\frac{f(u)-f(x)}{u-x}}$ est croissante.\\
		Donc $\forall u\geq y,\ p(u)\geq p(y)$.\\
		Or, $\forall u\geq y,\ p(u)\geq p(y)\iff f(u)\geq \displaystyle\frac{u-x}{y-x}(f(y)-f(x))+f(x)$.\\
		$y-x>0$ et $f(y)-f(x)>0$ donc $\displaystyle\lim_{u\to +\infty}\frac{u-x}{y-x}(f(y)-f(x))+f(x)=+\infty$.\\
		Ainsi $\lim\limits_{+\infty}f=+\infty$.
	\end{enumerate}
	
	\subsection{Convexité des fonctions continues sur un intervalle \etoile{4}}\label{sec:convexite-des-fonctions-continues-sur-un-intervalle-etoile4}
	\textcolor{blue}{\hyperref[convexitecontinue]{[Enoncé]}}\\
	Si $f$ est convexe sur $I$ alors pour $\lambda=\displaystyle\frac{1}{2}$,\\
	$$\forall (x,y)\in I^2,\ \displaystyle f\left(\frac{x+y}{2}\right)=f(\lambda x+(1-\lambda)y)\leq\lambda f(x)+(1-\lambda)f(y)=\frac{f(x)+f(y)}{2}$$
	Réciproquement, supposons que $\forall (x,y)\in I^2,\ \displaystyle f\left(\frac{x+y}{2}\right)\leq \frac{f(x)+f(y)}{2}$.\\
	Montrons par récurrence la propriété $\mathcal P(n):"\forall (x_1,\dots,x_n)\in I^n,\ \displaystyle f\left(\frac{x_1+\dots+x_n}{n}\right)\leq \frac{f(x_1)+\dots+f(x_n)}{n}"$ pour $n\geq 2$.\\
	$\mathcal P(1)$ est vraie par hypothèse. Supposons $\mathcal P(n)$ pour un certain $n\geq 2$ puis montrons $\mathcal P(2n)$ et $\mathcal P(n-1)$ si $n\ne 2$. Fixons $(x_1,\dots,x_{2n}\in I^{2n})$.\\
	En posant $x=\displaystyle\frac{x_1+\dots+x_n}{n}$ et $y=\displaystyle\frac{x_{n+1}+\dots+x_{2n}}{n}$ on a $(x,y)\in I^2$ d'où :\\
	$\displaystyle f\left(\frac{x_1+\dots+x_{2n}}{2n}\right)=f\left(\frac{x+y}{2}\right)\leq \frac{f(x)+f(y)}{2}$.\\
	Puis par hypothèse de récurrence, $f(x)\leq \displaystyle\frac{f(x_1)+\dots+f(x_n)}{n}$ et $f(y)\leq \displaystyle\frac{f(x_{n+1})+\dots+f(x_{2n})}{n}$ d'où $\mathcal P(n+1)$.\\\\
	Ensuite, supposons que $n\ne 2$ et donnons nous un $n-1$-uplet $(x_1,\dots,x_{n-1})$ de $I^{n-1}$.\\
	Posons $x_n=\displaystyle\frac{x_1+\dots+x_{n-1}}{n-1}$. On a :\\
	$\displaystyle f(x_n)=f\left(\frac{x_1+\dots+x_n}{n}\right)\leq\frac{f(x_1)+\dots+f(x_n)}{n}$.\\
	C'est à dire $f(x_n)\leq \displaystyle\frac{f(x_1)+\dots+f(x_{n-1})}{n-1}$ d'où $\mathcal P(n-1)$.\\
	Ainsi par récurrence de Cauchy, pour tout entier $n\geq 2,\ \mathcal P(n)$.\\\\
	On peut alors en déduire que si $\lambda=\displaystyle\frac{a}{b}\in ]0,1[$ avec $a\in \N$ et $b\in \N\setminus\{0,1\}$ alors, en posant $x_1=\dots=x_a=x$ et $x_{a+1}=\dots=x_b=y$ on a par $\mathcal P(b)$:\\
	$\forall (x,y)\in I^2,\ f(\lambda x+(1-\lambda)y)=\displaystyle f\left(\frac{ax+(b-a)y}{b}\right)=f\left(\frac{x_1+\dots+x_b}{b}\right)\leq\frac{f(x_1)+\dots+f(x_b)}{b}=\frac{af(x)+(b-a)f(y)}{b}=\lambda f(x)+(1-\lambda)f(y)$.\\
	On conclut par densité de $\Q$ dans $\R$ et continuité de $f$.
	
	\subsection{Convexe sur un ouvert $\implies$ continue \etoile{3}}\label{sec:convexe-sur-un-ouvert-implies-continue-etoile3}
	\textcolor{blue}{\hyperref[convexeouvert]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item Soit $x\in I$.\\
		La fonction $p_x:y\mapsto \displaystyle\frac{f(x)-f(y)}{x-y}$ est croissante sur $I\setminus\{x\}$ donc elle admet une limite en $x$ par valeurs supérieures et par valeurs inférieures. Ces deux limites sont finies car $x$ est un point intérieur à $I$ donc $f$ est dérivable, à gauche et à droite, en $x$. On note $f_g'(x)$ et $f_d'(x)$ ces deux limites.\\
		On a $\displaystyle\frac{f(x+h)-f(x)}{h}\underset{h\to 0^-}{=}f_g'(x)+\smallo{1}$ donc $f(x+h)-f(x)\underset{h\to 0^-}{=}hf_g'(x)+\smallo{h}\underset{h\to 0^-}{=}\smallo{1}$.\\
		Autrement dit $f(x+h)\underset{h\to 0^-}{\longrightarrow}f(x)$.\\
		De même, $\displaystyle\frac{f(x+h)-f(x)}{h}\underset{h\to 0^+}{=}f_d'(x)+\smallo{1}$ donc $f(x+h)\underset{h\to 0^+}{\longrightarrow}f(x)$.\\
		Ainsi $f(x+h)\underset{h\to 0}{\longrightarrow}f(x)$ c'est à dire $f$ est continue en $x$.
		\item L'hypothèse $I$ ouvert est essentielle. Considérons $f:x\mapsto\begin{cases}e^x&\mbox{si }x>0\\1&\mbox{si }x=0\end{cases}$.\\ %Faire un graphe prcq ça se voit bien.
		$f$ est deux fois dérivables sur $\R^*_+$ et $\forall x>0,\ f''(x)=e^x\geq 0$. Donc $f$ est convexe sur $\R^*_+$.\\
		De plus, si $\lambda\in [0,1]$ et $x>0$, $f(\lambda x+(1-\lambda)\times0)=e^{\lambda x}\leq \lambda e^x$ par convexité de la fonction exponentielle sur $\R_+$.\\
		Ainsi $f(\lambda x+(1-\lambda)\times0)\leq \lambda e^x+(1-\lambda)=\lambda f(x)+(1-\lambda)f(0)$ d'où $f$ est convexe sur $\R_+$.\\
		Pourtant $f$ n'est pas continue en $0$.
		\item On sait que $f$ est dérivable à droite et gauche en tout point de $I$. Soit $(x,y)\in I^2$ tel que $x<y$. Pour tous $s,t\in I$ tels que $x\ne s<y$ et $x<t\ne y$, $p_x(s)\leq p_x(y)=p_y(x)\leq p_x(t)$. En faisant tendre $s$ vers $x^\pm$ et $t$ vers $y^\pm$ on en déduit que $f_g'(x)\leq f_g'(y),\ f_d'(x)\leq f_d'(y),\ f_g'(x)\leq f_d'(y),\ f_d'(x)\leq f_g'(y)$.\\
		En particulier $f_d'$ est croissante donc d'après le théorème de Froda (cf. \ref{Théorème de Froda}) l'ensemble de ses points de discontinuité est au plus dénombrable. Montrons qu'en tous les points $x\in I$ où $f_d'$ est continue, $f_g'$ et $f_d'$ coïncident, auquel cas $f$ est dérivable en $x$.\\
		Fixons $x\in I$ tel que $f_d'$ est continue en $I$. Pour tout $s\in I$ tel que $s<x$, on a $f_d'(s)\leq f_g'(x)\leq f_d'(x)$. Donc par continuité de $f_g'$ en $x$ et le théorème des gendarmes, en faisant tendre $s$ vers $x$, il suit que $f_g'(x)=f_d'(x)$.
	\end{enumerate}
	
	\subsection{Fonctions logarithmiquement convexes \etoile{3}}\label{sec:fonctions-logarithmiquement-convexes-etoile3}
	\textcolor{blue}{\hyperref[logconvexe]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item Supposons que $f$ est log-convexe. Fixons $(x,y)\in I^2$ et $\lambda\in ]0,1[$. Par hypothèse,\\
		$\ln(f(\lambda x+(1-\lambda)y))\leq \lambda\ln(f(x))+(1-\lambda)\ln(f(y))$ puis par concavité du logarithme, $\lambda\ln(f(x))+(1-\lambda)\ln(f(y))\leq \ln(\lambda f(x)+(1-\lambda)f(y))$.\\
		Donc par passage à l'exponentielle, $f(\lambda x+(1-\lambda)y)\leq \lambda f(x)+(1-\lambda)f(y)$ d'où $f$ est convexe.\\\\
		La réciproque est fausse, la fonction $x\mapsto x^2$ est convexe sur $\R^*_+$ mais pas log-convexe.
		\item Supposons que $f$ est log-convexe. Fixons $\alpha>0$.\\
		$\forall (x,y)\in I^2,\ \forall \lambda\in [0,1],\ \ln\left(f(\lambda x+(1-\lambda)y)^\alpha\right)=\alpha\ln(f(\lambda x+(1-\lambda)y))\leq\alpha[\lambda\ln(f(x))+(1-\lambda)\ln(f(y))]=\lambda\ln\left(f(x)^\alpha\right)+(1-\lambda)\ln\left(f(y)^\alpha\right)$.\\
		Donc $f^\alpha$ est log-convexe et donc $f^\alpha$ est convexe d'après la question précédente.\\\\
		Réciproquement, supposons que pour tout $\alpha>0$, $f^\alpha$ est convexe. Fixons $(x,y)\in I^2$ et $\lambda\in [0,1]$.\\
		$\forall \alpha>0,\ f(\lambda x+(1-\lambda)y)^\alpha\leq \lambda f(x)^\alpha+(1-\lambda)f(y)^\alpha\iff \ln(f(\lambda x+(1-\lambda)y))\leq \displaystyle\frac{\ln\left(\lambda f(x)^\alpha+(1-\lambda)f(y)^\alpha\right)}{\alpha}$.\\
		Or \begin{align*}
			\lambda f(x)^\alpha+(1-\lambda)f(y)^\alpha&\ \ =\ \ \lambda e^{\alpha\ln(f(x))}+(1-\lambda)e^{\alpha\ln(f(y))}\\
			&\underset{\alpha\to 0^+}{=}\lambda(1+\alpha\ln(f(x))+\smallo{\alpha})+(1-\lambda)(1+\alpha\ln(f(y))+\smallo{\alpha})\\
			&\underset{\alpha\to 0^+}{=}1+\alpha(\lambda\ln(f(x))+(1-\lambda)\ln(f(y)))
		\end{align*} Par conséquent $\ln(f(\lambda x+(1-\lambda)y))\leq \displaystyle\lim_{\alpha\to 0}\frac{\ln\left(\lambda f(x)^\alpha+(1-\lambda)f(y)^\alpha\right)}{\alpha}=\lambda\ln(f(x))+(1-\lambda)\ln(f(y))$ et $f$ est log-convexe.
		\item Si $f$ est log convexe alors pour tout $c>0$ la fonction $\ln\circ\varphi_c=\ln\circ f+\ln(c)\Id_I$ est convexe comme somme de fonctions convexes.\\
		Réciproquement, supposons que $\varphi_c$ soit convexe quel que soit $c>0$.\\
		$\forall c>0,\ f(\lambda x+(1-\lambda)y)c^{\lambda x+(1-\lambda)y}\leq \lambda f(x)c^x+(1-\lambda)f(y)c^y$.\\
		Posons $\Phi:c\mapsto \displaystyle\frac{\lambda f(x)c^x+(1-\lambda)f(y)c^y}{c^{\lambda x+(1-\lambda)y}}=\lambda f(x)c^{(1-\lambda)(x-y)}+(1-\lambda)f(y)c^{\lambda(y-x)}$.\\
		$\Phi$ est dérivable sur $\R^*_+$ et $\forall c>0,\ \Phi'(c)=\lambda(1-\lambda)(x-y)\left(f(x)c^{(1-\lambda)(x-y)-1}-f(y)c^{\lambda(y-x)-1}\right)$.\\
		Fixons $c>0$. L'inégalité à vérifier est trivialement réalisée si $x=y$. On suppose donc $x\ne y$.\\
		Supposons $x>y$ :\\
		$\Phi'(c)\geq 0\iff f(x)c^{(1-\lambda)(x-y)-1}-f(y)c^{\lambda(y-x)-1}\geq 0\iff \displaystyle\frac{f(x)}{f(y)}\geq c^{y-x}\iff \ln(c)\geq \frac{\ln(f(x))-\ln(f(y))}{y-x}=\ln(c_0)$.\\
		On obtient les mêmes variations pour $x<y$.\\
		\begin{tikzpicture}
			\tkzTabInit{$c$ / 1 , $\Phi'(c)$ / 1,Variations de $\Phi$/2}{$0$, $c_0$,$+\infty$}
			\tkzTabLine{,-,z,+}
			\tkzTabVar{+/,-/$\Phi(c_0)$,+/}
		\end{tikzpicture}\\
		La meilleure inégalité possible est celle pour $c=c_0$, il y a des chances que ce soit celle que l'on recherche.\\
		$\Phi(c_0)=\lambda f(x)c_0^{(1-\lambda)(x-y)}+(1-\lambda)f(y)c_0^{\lambda(y-x)}=\lambda f(x)e^{(\lambda-1)\ln(f(x)/f(y))}+(1-\lambda)f(y)e^{\lambda\ln(f(x)/f(y))}=\lambda f(x)^\lambda f(y)^{1-\lambda}+(1-\lambda)f(x)^\lambda f(y)^{1-\lambda}=f(x)^\lambda f(y)^{1-\lambda}$.\\
		Ainsi, $f(\lambda x+(1-\lambda)y)\leq f(x)^\lambda f(y)^{1-\lambda}$ c'est à dire $f$ est log-convexe.
		\item $\ln\circ(f\times g)=\ln\circ f+\ln\circ g$ est convexe comme somme de fonctions convexes donc $f\times g$ est log-convexe.\\
		Soit $c>0$. Notons $\varphi_c:x\mapsto f(x)c^x$ et $\psi_c:x\mapsto g(x)c^x$.\\
		$x\mapsto (f+g)(x)c^x=\varphi_c+\psi_c$ est convexe comme somme de fonctions convexe.\\
		Ainsi d'après la question précédente $f+g$ est log-convexe.
	\end{enumerate}
	
	\subsection{Etude d'une fonction définie implicitement}\label{sec:etude-dune-fonction-definie-implicitement}
	\textcolor{blue}{\hyperref[fdi]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
	\item On remarque que $g\circ(-g+2Id_\R)=Id_\R$ donc $g$ est bijective.\\
	Puisque $g$ est bijective, elle est a fortiori injective , et puisque $g$ est continue, elle est strictement monotone.\\
	Supposons que $g$ est strictement décroissante.\\
	Alors $g^2$ est strictement croissante, ce qui est absurde car une somme de deux fonctions décroissante est décroissante.\\
	Donc $g$ est strictement croissante.
	\item On pose $h=g-Id_\R$.\\
	On remarque que pour tout $x\in\R$, $h(g(x))=h(x)$.\\
	Montrons que $h$ est une fonction constante.\\
	Puisque $g$ est bijective,pour tout $y\in\R$, il existe un unique $x\in\R$ tel que $g(x)=y$.\\
	Ainsi, $h(y)=h(g(x))=h(x)$.
	Par conséquent, en faisant parcourir $y$ sur $\R$, $x$ parcourt $\R$ également, ce qui impose que $h$ est constante.\\
	Donc \[\exists c\in\R, \forall x\in\R, g(x)-x=c \text{ i.e. } g(x)=x+c\]
	On vérifie  que $\forall c\in\R$ la fonction $x\mapsto x+c$ vérifie la propriété. 
	
	\end{enumerate}
	
	\subsection{Inégalités de Kolmogorov \etoile{4}}\label{sec:inegalite-de-kolmogorov-etoile4}
	\textcolor{blue}{\hyperref[Kolmogorov]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item Si $M_k=0$ alors $f^{(k)}=0$ donc $f$ est une fonction polynomiale. Or $f$ est bornée car $M_0<+\infty$ donc $f$ est constante.\\
		Par conséquent $\forall k\in \crblanc{1}{n},\ M_k=0$. Les inégalités sont alors trivialement vérifiées.
		\item
		\begin{enumerate}[label=\alph*.]
			\item Soit $i\in \crblanc{1}{n-1}$. $f$ est $\mathcal C^n$ sur $[x,x+h_i]$ donc d'après l'inégalité de Taylor-Lagrange,\\\\
			$\displaystyle\left|f(x+h_i)-\sum_{k=0}^{n-1}\frac{h_i^k}{k!}f^{(k)}(x)\right|\leq \frac{M_n}{n!}h_i^n$.\\\\
			Donc par inégalité triangulaire,\\\\
			$\displaystyle\left|\sum_{k=1}^{n-1}\frac{h_i^k}{k!}f^{(k)}(x)\right|=\left|\sum_{k=0}^{n-1}\frac{h_i^k}{k!}f^{(k)}(x)-f(x+h_i)-f(x)+f(x+h_i)\right|\leq |f(x+h_i)-f(x)|+\frac{M_n}{n!}h_i^n\leq 2M_0+\frac{M_n}{n!}h_i^n$.\\\\
			Pour conclure il suffit de poser $H=\max\limits_{1\leq i\leq n}h_i$.
			\item On note $X(x)$ le vecteur de $\C^{n-1}$ dont les composantes sont les $\displaystyle\frac{f^{(k)}(x)}{k!}$ pour $1\leq k\leq n-1$, $K=2M_0+\displaystyle\frac{M_n}{n!}H^n$ et $A=\left(h_i^j\right)_{1\leq i,j\leq n-1}$. On vient de montrer que $\normep{\infty}{AX(x)}\leq K$. Or ceci étant vrai pour tout $h_1,\dots,h_{n-1}$ strictement, ça l'est en particulier pour $(h_i)_{1\leq i\leq n-1}=(i)_{1\leq i\leq n-1}$.\\
			On reconnaît alors que la matrice $A$ est de Vandermonde :
			$$A=\begin{pmatrix}
				1&1&\cdots&1\\
				2&2^2&\cdots&2^{n-1}\\
				\vdots&\vdots& &\vdots\\
				n-1&(n-1)^2&\cdots&(n-1)^{n-1}
			\end{pmatrix}$$
			Son déterminant est $(n-1)!\displaystyle\prod_{1\leq i<j\leq n-1}(j-i)\ne 0$ donc elle est inversible.\\
			Ainsi, on a $\normep{\infty}{X(x)}=\normep{\infty}{A^{-1}AX(x)}\leq{|||A^{-1}|||}_\infty\normep{\infty}{AX(x)}\leq K{|||A^{-1}|||}_\infty$.\\
			Ceci étant vrai pour tout $x\in \R$, on obtient par passage au sup que $\forall k\in \crblanc{1}{n},\ M_k\leq K{|||A^{-1}|||}_\infty<+\infty$.
		\end{enumerate}
		\item
		\begin{enumerate}[label=\alph*.]
			\item Soit $x\in \R$.\\
			D'après l'inégalité de Taylor-Lagrange, $|f(x+h)-f(x)-f'(x)h|\leq \displaystyle\frac{M_2}{2}h^2$ et $|f(x-h)-f(x)+f'(x)h|\leq \displaystyle\frac{M_2}{2}h^2$.\\
			Donc \begin{align*}
				|f'(x)|&=\frac{1}{2h}|f'(x)h+f(x)-f(x+h)+f(x+h)-f(x)+f'(x)h+f(x)-f(x-h)+f(x-h)-f(x)|\\
				&\leq\frac{1}{2h}(|f'(x)h+f(x)-f(x+h)|+|f(x+h)-f(x-h)|+|f'(x)h-f(x)+f(x-h)|)\\
				&\leq\frac{M_2h}{2}+\frac{M_0}{h}.
			\end{align*}
			Puis par passage au sup, $M_1\leq \displaystyle\frac{M_2h}{2}+\frac{M_0}{h}$.
			\item On pose $G:h\in \R^*_+\mapsto \displaystyle\frac{M_2h}{2}+\frac{M_0}{h}$. $G$ est dérivable sur $\R^*_+$ et, $\forall h>0,\ G'(h)=\displaystyle\frac{M_2}{2}-\frac{M_0}{h^2}$.\\
			Donc $\forall h>0,\ G'(h)\geq 0\iff h\geq \displaystyle\sqrt{\frac{2M_0}{M_2}}$.\\
			Donc $G$ admet un minimum en $\displaystyle\sqrt{\frac{2M_0}{M_2}}$ et $M_1\leq G\left(\displaystyle\sqrt{\frac{2M_0}{M_2}}\right)=\sqrt{2M_0M_2}$.
		\end{enumerate}
		\item
		\begin{enumerate}[label=\alph*.]
			\item Par croissance de $(u_n)_{n\in \N^*}$,\\
			$\displaystyle\frac{1}{k}\sum_{i=1}^ku_i\leq \frac{1}{k}\sum_{i=1}^ku_k=u_k\leq u_{k+1}=\frac{1}{n-k}\sum_{i=k+1}^nu_{k-1}\leq \frac{1}{n-k}\sum_{i=k+1}^nu_i$.
			\item Soit $k\in \crblanc{1}{n-1}$.
			\begin{align*}
				&2x_k\leq x_{k-1}+x_{k+1}\\
				\iff& \ln(M_k^2)-k(n-k)\ln 2\leq \ln(M_{k-1}M_{k+1})-\frac{\ln 2}{2}((k-1)(n-k+1)+(k+1)(n-k-1))\\
				\iff& \ln(M_k^2)-k(n-k)\ln 2\leq \ln(M_{k-1}M_{k+1})-k(n-k)\ln 2-\frac{\ln 2}{2}(k-n+k-1-k+n-k-1)\\
				\iff& \ln(M_k^2)\leq \ln(M_{k-1}M_{k+1})+\ln 2
			\end{align*}
			Or en appliquant la question $3.b$ à $f^{(k-1)}$ on a $M_k\leq \sqrt{2M_{k-1}M_{k+1}}$ d'où $\ln(M_k^2)\leq \ln 2+\ln(M_{k-1}M_{k+1})$ d'où le résultat.
			\item D'après la question précédente $\forall k\in \crblanc{1}{n-1},\ x_k-x_{k-1}\leq x_{k+1}-x_k$.\\
			Donc d'après la question $4.a$, si $k\in \crblanc{1}{n}$ alors $\displaystyle\frac{1}{k}\sum_{i=1}^k(x_i-x_{i-1})\leq \frac{1}{n-k}\sum_{i=k+1}^n(x_i-x_{i-1})$.\\
			C'est à dire $\displaystyle\frac{x_k-x_0}{k}\leq \frac{x_n-x_k}{n-k}$ ou encore $\displaystyle n\left(\ln(M_k)-\frac{\ln 2}{2}k(n-k)\right)\leq k\ln(M_n)+(n-k)\ln(M_0)$.\\
			Enfin, par passage à l'exponentielle on obtient $M_k\leq 2^{\frac{k(n-k)}{2}}M_0^{1-\frac{n}{k}}M_n^{\frac{k}{n}}$.
		\end{enumerate}
	\end{enumerate}
	
	\subsection{Lemme de Croft \etoile{2}}\label{sec:lemme-de-croft-etoile2}
	\textcolor{blue}{\hyperref[croft]{[Enoncé]}}\\
	Soit $\varepsilon>0$. Par uniforme continuité de $f,\ \exists\eta>0,\ \forall (x,y)\in \R_+^2,\ |x-y|\leq\eta\implies|f(x)-f(y)|\leq\displaystyle\frac{\varepsilon}{2}$.\\
	Par hypothèse la suite $(f(n\eta))_{n\in \N}$ converge vers $0$. Donc $\exists N\in \N,\ \forall n\geq N,\ |f(n\eta)|\leq\displaystyle\frac{\varepsilon}{2}$.\\
	Soit $x\geq N\eta$. $\exists n=\displaystyle\lfloor x\rfloor\geq N,\ n\eta\leq x\eta<(n+1)\eta$.\\
	D'une part, $|x-n\eta|\leq \eta$ donc $|f(x)-f(n\eta)|\leq\displaystyle\frac{\varepsilon}{2}$ et d'autre part, $n\geq N$ donc $|f(n\eta)|\leq\displaystyle\frac{\varepsilon}{2}$.\\
	Ainsi par inégalité triangulaire, $|f(x)|\leq |f(x)-f(n\eta)|+|f(n\eta)|\leq \varepsilon$.\\
	Par conséquent $\uxfty{\lim}f(x)=0$.
	
	\subsection{Inégalité intégrale de Jensen \etoile{1}}\label{sec:inegalite-integrale-de-jensen-etoile1}
	\textcolor{blue}{\hyperref[jensenint]{[Enoncé]}}\\
	Soit $n\in \N^*$. Notons pour $k\in \crblanc{0}{n-1},\ x_k=a+k\times\displaystyle\frac{b-a}{n}\in [a,b]$.\\
	$\displaystyle\frac{1}{n}\geq 0$ et $\displaystyle\sum_{k=0}^{n-1}\frac{1}{n}=1$ donc d'après l'inégalité de Jensen appliquée à $\varphi$ qui est convexe :\\
	$\displaystyle\varphi\left(\sum_{k=0}^{n-1}\frac{1}{n}f(x_k)\right)\leq \sum_{k=0}^{n-1}\frac{1}{n}\varphi\circ f(x_k)$.\\
	Or comme $\varphi\circ f$ est continue par morceaux sur $[a,b]$, d'après le cours $\displaystyle\frac{b-a}{n}\sum_{k=0}^{n-1}\varphi\circ f(x_k)\unfty{\longrightarrow}\int_a^b\varphi\circ f(t)dt$.\\
	De même, $\displaystyle\frac{b-a}{n}\sum_{k=0}^{n-1}f(x_k)\unfty{\longrightarrow}\int_a^bf(t)dt$.\\
	Ainsi par continuité de $\varphi$, le passage à la limite donne :
	$$\displaystyle\varphi\left(\frac{1}{b-a}\int_a^bf(t)dt\right)\leq \frac{1}{b-a}\int_a^b\varphi\circ f(t)dt$$
	
	\newpage
\section{Correction Polynômes}
	\subsection{Théorème de d'Alembert-Gauss (2) \etoile{3}}
	\label{sec:theoreme-de-dalembert-gauss-2}
	\textcolor{blue}{\hyperref[alembertgauss2]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item $\P$ est une partie non vide et minorée (par $0$) de $\R$. Elle admet donc une borne inférieure.
		\item Soit $z\in \C$ de module $r$. Par la seconde inégalité triangulaire puis la première :\\
		$|P(z)|=\displaystyle\left|a_nz^n+\sum_{k=0}^{n-1}a_kz^k\right|\geq \left||a_nz^n|-\left|-\sum_{k=0}^{n-1}a_kz^k\right|\right|\geq |a_n|r^n-\left|\sum_{k=0}^{n-1}a_kz^k\right|\geq |a_n|r^n-\sum_{k=0}^{n-1}|a_k|r^k$.
		\item Le membre de droite est équivalent à $|a_n|r^n$ pour $r\to\infty$ donc $\lim\limits_{|z|\to+\infty}|P(z)|=+\infty$.
		\item \begin{enumerate}[label=\alph*.]
			\item Par caractérisation séquentielle de la borne inférieure $\exists (u_n)\in \C^\N,\ |P(u_n)|\unfty\longrightarrow\alpha$. D'après la question précédente si $(u_n)_{n\in \N}$ n'est pas bornée alors $|P(u_n)|\unfty\longrightarrow+\infty$ donc $(u_n)_{n\in \N}$ est bornée.
			\item Par le théorème de Bolzano-Weierstrass on peut extraire de $(u_n)_{n\in \N}$ une suite $(v_n)_{n\in \N}$ qui converge. On note $z_0$ sa limite.\\
			Par continuité de $|P|$, $|P(v_n)|\unfty\longrightarrow |P(z_0)|$ et d'autre part $|P(v_n)|\unfty\longrightarrow\alpha$ comme suite extraite. Donc par unicité de la limite $|P(z_0)|=\alpha$.
		\end{enumerate}
		\item \begin{enumerate}[label=\alph*.]
			\item $\displaystyle\inf_{z\in \C}|Q(z)|=\frac{1}{|P(z_0)|}\inf_{z\in \C}|P(z)|=1=|Q(0)|$.
			\item Notons $Q=\displaystyle\sum_{k=0}^nb_kX^k$ ainsi que $p$ la plus petite puissance des monômes non constants non nuls de $Q$ (il y en a une car $P$ n'est pas constant donc $Q$ n'est pas constant).\\
			$Q(X)=Q(0)+b_pX^p+\displaystyle\sum_{k=p+1}b_kX^k=1+b_pX^p+\sum_{k=p+1}^nb_pX^p$.
			\item On a \begin{align*}
				|Q(re^{i\theta/p})|-1&\ \, =\left|1+r^p\left(b_pe^{-i\theta}+r\sum_{k=p+1}^nb_ke^{-ik\theta/p}r^{k-p-1}\right)\right|-1\\
				&\underset{r\to0^+}{=}|1+\rho r^p+\smallo{r^p}|-1\\
				&\underset{r\to0^+}{=}\rho r^p+\smallo{r^p}\\
				&\underset{r\to0^+}{\sim}\rho r^p
			\end{align*}
			$\rho r^p$ est strictement négatif au voisinage de $0^+$ donc $|Q(re^{i\theta/p})|-1$ aussi.
		\end{enumerate}
		\item Ce dernier résultat contredit la minimalité de $\alpha$ donc $\alpha=0$. Autrement dit $P(z_0)=0$ et le théorème est démontré.
	\end{enumerate}
	
	\subsection{\underline{Bernoulli} \ccinp{2}}
	\label{sec:Bernoulli}
	\textcolor{blue}{\hyperref[Bernoulli]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item
		\begin{enumerate}[label=\alph*.]
			\item On pose $Q\in \R[X]$ tel que $\forall x\in \R,\ \tilde Q(x)=\displaystyle\int_0^xP(t)dt$ et $a=\displaystyle\int_0^1\tilde Q(x)dx$.\\
			Alors $Q(X)=\tilde Q(X)-a$ vérifie $\displaystyle\int_0^1Q(x)dx=\int_0^1\tilde Q(x)dx-a=0$. $x\mapsto\tilde Q(x)$ est continue sur $\R$ donc d'après le TFA $x\mapsto Q(x)$ est une primitive de $P$ sur $\R$. Enfin si on note $P=\displaystyle\sum_{k=0}^na_kX^k$ alors $\forall x\in \R,\ \tilde Q(x)=\displaystyle\sum_{k=0}^na_k\frac{x^{k+1}}{k+1}$. $\R$ étant infini $\tilde Q(X)$ est bien un polynôme à coefficients réels. Par suite $Q\in \R[X]$.\\
			Enfin si $Q_1,Q_2\in \R[X]$ vérifient $Q_1'=P=Q_2'$ et $\displaystyle\int_0^1Q_1(x)dx=0=\int_0^1Q_2(x)dx$ alors $\exists c\in \R,\ Q_1=Q_2+c$ et $c=\displaystyle\int_0^1(Q_1(x)-Q_2(x))dx=\int_0^1Q_1(x)dx-\int_0^1Q_2(x)dx=0$.\\
			Ainsi $Q_1=Q_2$.
			\item Construisons $B_n$ par récurrence. On pose $B_0=1$. Supposons avoir construit, pour un certain $n\in \N^*$, $B_0,\dots,B_{n-1}$ comme dans l'énoncé. $nB_{n-1}\in \R[X]$ donc d'après la question précédente $\exists!B_n\in \R[X],\ B'n=nB_{n-1}$ et $\displaystyle\int_0^1B_n(x)dx=0$.\\
			On conclut qu'il existe une unique suite de polynôme réels qui vérifie la condition de l'énoncé.
			\item $B_1'=B_0=1$ donc $\exists b_1\in \R,\ B_1=X+b_1$. De plus $\displaystyle\int_0^1B_1(x)dx=\frac{1}{2}+b_1=0$ donc $B_1=X-\dfrac{1}{2}$.\\
			$B_2'=2B_1=2X-1$ donc $\exists b_2\in \R,\ B_1=X^2-X+b_2$. De plus $\displaystyle\int_0^1B_2(x)dx=\frac{1}{3}-\frac{1}{2}+b_2=0$ donc $B_2=X^2-X+\dfrac{1}{6}$.\\
			\item Le calcul de $B_0,B_1,B_2$ nous pousse à conjecturer $\P(n)"\forall n\in \N,\ \deg B_n=n"$. Montrons cette proposition par récurrence.\\
			On a $\P(0)$. Supposons $\P(n-1)$ pour un certain $n\in \N^*$. Alors $\deg B_n'=\deg nB_{n-1}=n-1$. Donc $\P(n)$.\\
			Par récurrence, $\forall n\in \N,\ \deg B_n=n$.
		\end{enumerate}
		\item 
		\begin{enumerate}[label=\alph*.]
			\item $\forall n\geq 2,\ B_n(1)-B_n(0)=\displaystyle\int_0^1B_n'(x)dx=n\int_0^1B_{n-1}(x)dx=0$.
			\item Montrons que la suite de terme général $A_n(X)=(-1)^nB_n(1-X)$ vérifie la relation de récurrence qui définie $(B_n)_{n\in \N}$. L'unicité de la solution donnera le résultat obtenu question 1.b.\\
			$A_0(X)=B_0(1-X)=1=B_0(X)$ et $\forall n\in \N^*,\ A_n'(X)=(-1)^{n+1}B_n'(1-X)=nA_{n-1}(X)$ et $\displaystyle\int_0^1A_n(x)dx=\int_0^1A_n(1-x)dx=(-1)^n\int_0^1B_n(x)dx=0$.\\
			On en déduit que $\forall n\in \N^*,\ B_{2n+1}(0)=-B_{2n+1}(1)=-B_{2n+1}(0)$ d'où $B_{2n+1}(0)=B_{2n+1}(1)=0$.
			\item On rappelle que $B_n$ est de degré $n$ donc la formule de Taylor en $0$ s'écrit :
			$$B_n=\sum_{k=0}^n\frac{B_n^{(k)}(0)}{k!}X^k=\sum_{k=0}^n\frac{n(n-1)\dots(n-k+1)B_{n-k}(0)}{k!}X^k=\sum_{k=0}^n\binom{n}{k}b_{n-k}X^k$$
			\item Soit $n\in \N$. Avec les questions $2.b$ et $2.c$ on a :\\
			\begin{align*}
				b_{2n+2}&=B_{2n+2}(1)\\
				&=\sum_{k=0}^{2n+2}\binom{2n+2}{k}b_{2n+2-k}\\
				&=\sum_{k=0}^{2n+2}\binom{2n+2}{2n+2-k}b_k\\
				&=\sum_{k=0}^{2n+2}\binom{2n+2}{k}b_k
			\end{align*}
			Soit $n\in \N^*$. $2n+1>2n-1\geq 1$ donc $b_{2n+1}=b_{2n-1}=0$.\\
			Ainsi $b_{2n+2}=b_{2n+2}+\displaystyle\binom{2n+2}{2n}b_{2n}+\sum_{k=0}^{2n-2}\binom{2n+2}{k}b_k$.\\
			i.e $b_{2n}=-\displaystyle\frac{1}{(n+1)(2n+2)}\sum_{k=0}^{2n-2}\binom{2n+2}{k}b_k$.
		\end{enumerate}
	\end{enumerate}
	
	\subsection{\underline{Lagrange} \ccinp{1}}
	\label{sec:Lagrange}
	\textcolor{blue}{\hyperref[Lagrange]{[Enoncé]}}\\
	\begin{enumerate}
		\item 
		On sait que: $\dim(\K_{n-1}[X])=n=\dim(\K^n)$, ainsi il suffit de montrer que $\Psi$ est injective.
		\\Soit $P\in\Ker(\Psi)$
		\\On a alors $(P(x_1),\dots,P(x_n))=(0,\dots,0)$. Donc P est un polynôme de degré au plus $n-1$ qui admet $n$ racines. Donc $P$ est nul.
		\\Ainsi $\Psi$ est bijective.
		\item 
		On note $(e_1,\dots,e_n)$ la base canonique de $\K^{n}$.
		On pose pour tout $k\in\crblanc{1}{n}$,$L_k=\Psi^{-1}(e_k)$
		Ainsi pour tout $(i,j)\in\crblanc{1}{n}^2$,$L_i(x_j)=\delta_{i,j}$.
		Et on remarque que $P$ et $\displaystyle\sum\limits_{k=1}^nP(x_k)L_k$ coïncident sur $n$ points et sont tous deux de degré au plus $n-1$. 
		\\Donc $P=\displaystyle\sum\limits_{k=1}^nP(x_k)L_k$
	\end{enumerate}
	
	\subsection{\underline{Tchebychev} \ccinp{2}}
	\label{sec:Tchebychev}
	\textcolor{blue}{\hyperref[Tchebychev]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item 
		\begin{enumerate}[label=\alph*.]
			\item On développe
			\begin{align*}
				\cos(n\theta)&=\operatorname{Re}\left[\cos(\theta)+i\sin(\theta))^n\right]\\
				&=\operatorname{Re}\left[\sum_{k=0}^n\binom{n}{k}\cos^{n-k}(\theta)i^k\sin^k(\theta)\right]\\
				&=\operatorname{Re}\left[\sum_{k=0}^{\lfloor\frac{n}{2}\rfloor}(-1)^k\binom{n}{2k}\cos^{n-2k}(\theta)\sin^{2k}(\theta)+i\sum_{k=0}^{\lfloor\frac{n-1}{2}\rfloor}(-1)^k\binom{n}{2k+1}\cos^{n-2k-1}(\theta)\sin^{2k+1}(\theta)\right]\\
				&=\sum_{k=0}^{\lfloor\frac{n}{2}\rfloor}(-1)^k\binom{n}{2k}\cos^{n-2k}(\theta)(1-\cos^{2k}(\theta))
			\end{align*}
			Le polynôme $T_n(X)=\displaystyle\sum_{k=0}^{\lfloor\frac{n}{2}\rfloor}(-1)^k\binom{n}{2k}X^{n-2k}(1-X^{2k})$ est à coefficients réels, de degré inférieur à $n$ et vérifie $\forall \theta\in \R,\ T_n(\cos(\theta))=\cos(n\theta)$.
			\item Soit $S_n\in \R_n[X]$ tel que $\forall \theta\in \R,\ S_n(\cos(\theta))=\cos(n\theta)$.\\
			Alors $S_n$ et $T_n$ coïncident sur $\cos(\R)=[-1,1]$ qui est infini. Donc $S_n=T_n$.
		\end{enumerate}
		\item Soit $\theta\in \R$. Par les formules de Simpson :
		$$2\cos(\theta)\cos((n+1)\theta)=\cos((n+2)\theta)+\cos(n\theta)$$
		i.e $T_{n+2}(\cos(\theta))=2\cos(\theta)T_{n+1}(\cos(\theta))-T_n(\cos(\theta))$.\\
		i.e $\forall x\in [-1,1],\ T_{n+2}(x)=2xT_{n+1}(x)-T_n(x)$.
		\item On calcule aisément $T_0=1,\ T_1=X,\ T_2=2X^2-1$. Montrons par récurrence double sur $n\in \N^*$ la proposition $H(n):"T_n\T{ est de degré }n\T{ et son coefficient dominant est }d_n:=2^{n-1}"$.\\
		on a clairement $H(1)$ et $H(2)$. Supposons $H(n)$ et $H(n+1)$ pour un certain $n\in \N^*$.\\
		On sait que $T_{n+2}=2XT_{n+1}-T_n$. Par hypothèse de récurrence $\deg(T_n)=n<n+2=\deg(2XT_{n+1}$ Donc $\deg(T_{n+2})=\deg(2XT_{n+1})=n+2$. De plus, $d_{n+2}=2d_{n+1}=2^{n+1}$.\\
		Ainsi par récurrence double, $\forall n\in \N^*,\ \deg(T_n)=n$ et $d_n=2^{n-1}$.
		\item L'expression trouvée question 1.a donne les deux résultats.\\
		Sinon, la même récurrence double montre que $T_n$ est à coefficients entiers. Et si $n=2k+1$ est impair, $T_n(0)=\displaystyle T_n\left(\cos\left(\frac{\pi}{2}\right)\right)=\cos\left(\frac{\pi}{2}+k\pi\right)=0$.
		\item 
		\begin{enumerate}[label=\alph*.]
			\item Pour tout $k\in \crblanc{0}{n-1}, \theta_k=\dfrac{\pi}{2n}+\dfrac{k\pi}{n}$.\\
			On a $\displaystyle\frac{\pi}{2n}=0<\theta_0<\theta_1<\dots<\theta_{n-1}=\frac{2n-1}{2n}\pi<\pi$. Or $\cos$ est strictement décroissante et continue sur $[0,\pi]$, en particulier elle est injective sur $[0,\pi]$.\\
			En outre, $\forall k\in \crblanc{0}{n-1},\ T_n(\cos(\theta_k))=\cos(n\theta_k)=\cos\left(\dfrac{\pi}{2}+k\pi\right)=0$.\\
			$T_n$ étant de degré $n$ et de coefficient dominant $2^{n-1}$, $T_n(X)=\displaystyle2^{n-1}\prod_{k=0}^{n-1}(X-\cos(\theta_k))$.
			\item Soit $x\in [-1,1]$. $\exists \theta\in \R,\ x=\cos(\theta)$. Donc $|T_n(x)|=|T_n(\cos(\theta)|=|\cos(n\theta)|\leq 1$. De plus $T_n(1)=T_n(\cos(0))=\cos(0)=1$.\\
			On en déduit que $\normep{\infty}{T_n}=1$.\\
			Ensuite, $\forall k\in \crblanc{0}{n-1},\ |T_n(c_k)|=|\cos(k\pi)|=|(-1)^k|=1=\normep{\infty}{T_n}$.
		\end{enumerate}
		\item 
		\begin{enumerate}[label=\alph*.]
			\item Soit $h\in E$. La fonction $H:t\mapsto\dfrac{h(t)}{\sqrt{1-t^2}}$ est continue par morceaux sur $]-1,1[$.\\
			D'après le théorème des bornes atteintes $h$ est bornée sur $[-1,1]$ donc $H(t)=\dfrac{h(t)}{\sqrt{1-t}\sqrt{1+t}}\underset{t\to1^-}=\bigO{\dfrac{1}{(1-t)^{1/2}}}$. Or $t\mapsto \dfrac{1}{(1-t)^{1/2}}$ est positive et intégrable au voisinage de $1^-$. Donc $H$ est intégrable en $1^-$.\\
			De même, $H(t)\underset{t\to-1^+}=\bigO{\dfrac{1}{(1+t)^{1/2}}}$ donc $H$ est intégrable en $-1^+$.\\
			Finalement $H$ est intégrable sur $]-1,1[$.\\
			Pour tout $f,g\in E$, $fg\in E$ donc $t\mapsto \dfrac{f(t)g(t)}{\sqrt{1-t^2}}$ est intégrable sur $]-1,1[$.
			\item On a montré que $\proscal{\cdot}{\cdot}$ est bien définie sur $E^2$.\\
			c'est clairement une application symétrique et la bilinéarité est conséquence directe de la linéarité de l'intégrale.\\
			Enfin, si $f\in E$ alors $t\mapsto \dfrac{f(t)^2}{\sqrt{1-t^2}}$ est continue et positive sur $]-1,1[$ donc $\proscal{f}{f}=\displaystyle\int_{-1}^1\frac{f(t)^2}{\sqrt{1-t^2}}dt\geq 0$, avec égalité ssi $\forall t\in ]-1,1[,\ \dfrac{f(t)^2}{\sqrt{1-t^2}}=0$.\\
			Ceci revient à $\forall t\in ]-1,1[,\ f(t)=0$. On en déduit par continuité de $f$ en $-1$ et $1$ que $f$ est nulle sur $[-1,1]$, càd $f=0$.
			\item Soient $n,m\in \N$. $\proscal{T_n}{T_m}=\displaystyle\int_{-1}^1\frac{T_n(t)T_m(t)}{\sqrt{1-t^2}}dt$.\\
			Effectuons le changement de variables $\theta=\arccos(t)$. C'est possible car $\arccos:]-1,1[\to]0,\pi[$ est une bijection décroissante de classe $\mathcal C^1$. $d\theta=-\dfrac{dt}{\sqrt{1-t^2}}$.\\
			$\proscal{T_n}{T_m}=\displaystyle\int_\pi^0T_n(\cos(\theta))T_m(\cos(\theta))(-d\theta)=\int_0^\pi\cos(n\theta)\cos(m\theta)d\theta$.\\
			Or $\cos(n\theta)\cos(m\theta)=\dfrac{\cos((n+m)\theta)+\cos((n-m)\theta)}{2}$.\\
			Si $k\in\Z\backslash\{0\}$, $\displaystyle\int_0^\pi\cos(k\theta)d\theta=\left[\frac{\sin(k\theta)}{k}\right]_0^\pi=0$.\\
			Et $\displaystyle\int_0^\pi\cos(0\times\theta)d\theta=\int_0^\pi d\theta=\pi$.\\
			Donc $\proscal{T_n}{T_m}=\begin{cases}
				0&\mbox{si }n\ne m\\
				\dfrac{\pi}{2}&\mbox{sinon}
			\end{cases}$
		\end{enumerate}
	\end{enumerate}
	
	\subsubsection{Angles rationnels dont le cosinus est rationnel \etoile{3}}
	\begin{enumerate}[leftmargin=*]
		\item $\exists k\in \Z,\ \alpha=\dfrac{k\pi}{2}$. Notons $k=4q+r$ la division euclidienne de $k$ par $4$.\\
		$\cos(\alpha)=\displaystyle\cos\left(2q\pi+r\frac{\pi}{2}\right)=\cos\left(r\frac{\pi}{2}\right)$.
		\begin{itemize}
			\item Si $r=0,\ \cos(\alpha)=1$;
			\item Si $r=1,\ \cos(\alpha)=0$;
			\item Si $r=2,\ \cos(\alpha)=-1$;
			\item Si $r=3,\ \cos(\alpha)=0$.
		\end{itemize}
		\item 
		\begin{enumerate}[label=\alph*.]
			\item On rappelle que $T_q\in \Z[X]$ et $T_q(0)=0$.\\
			On a $T_q(\cos(\alpha))=\cos(q\alpha)=\cos(p\pi)=(-1)^p$.\\
			Donc en appliquant le théorème de la racine rationnelle à $T_n+(-1)^{p+1}$ (cf.\ref{Théorème de la racine rationnelle}) on obtient $a|(-1)^{p+1}$ et $b|2^{q-1}$ d'où $a\in \{-1,1\}$ et l'existence de $r\in \N$ tel que $b=2^r$.
			\item Si $r=0$ on retrouve $\cos(\alpha)=\pm1$ ce qui est exclus ici.\\
			Si $r=1$ alors $\cos(\alpha)=\pm\dfrac{1}{2}$ d'où $\alpha\in \displaystyle\left\{\pm\frac{2\pi}{3},\pm\frac{\pi}{3}\right\}$.\\
			Supposons $r\geq 2$. Comme $\cos(2\alpha)=2\cos(\alpha)^2-1\in \Q$ on a $\cos(2\alpha)=\dfrac{\varepsilon'}{2^{r'}}$ pour un certain $\varepsilon'\in \{-1,1\}$ et $r'\in \N$.\\
			Donc $\displaystyle\frac{\varepsilon'}{2^{r'}}=\frac{1}{2^{2r-1}}-1<0$. On en déduit $\varepsilon'=-1$ et $2^{2r-1}=2^{r'}(2^{2r-1}-1)$.\\
			Comme $2^{2r-1}-1$ est impair et est un diviseur positif de $2^{2r-1}$, il vaut $1$. Càd $2r-1=1$ ou encore $r=1$ ce qui est absurde.
		\end{enumerate}
		\item Supposons que $q$ s'écrit $q=4m$ avec $m\in \N$. comme $\cos(\alpha)\in \Q$, $\cos(m\alpha)$ aussi. Pourtant $\cos(m\alpha)=\cos\left(\dfrac{p\pi}{4}\right)=\pm\dfrac{\sqrt 2}{2}\notin\Q$.\\
		Supposons que $q$ s'écrive $q=2m$ avec $m$ impair. Alors $2\alpha=\dfrac{p}{m}$ satisfait les hypothèse du cas de la question 2. Donc avec $\cos(2\alpha)=\cos(\alpha)^2-1$ on en déduit que les valeurs possibles pour $\cos(\alpha)$ sont $-1,1,0,\pm\dfrac{1}{2}$ et $\pm\dfrac{\sqrt{3}}{2}$. La seule compatible avec la forme de $\alpha$ est $0$ ce qui impose $q=2$, ici exclus.
		\item On a montré que les seuls couples $(\alpha,\cos(\alpha))$ avec $\alpha\in ]-\pi,\pi]$ possibles sont $$(0,1),(\pi,-1),\left(\pm\frac{\pi}{2},0\right),\left(\pm\frac{\pi}{3},\frac{1}{2}\right),\left(\pm\frac{2\pi}{3},-\frac{1}{2}\right)$$
		\item $\alpha\in \pi\Q\iff \dfrac{\pi}{2}-\alpha\in\pi\Q$. Donc avec $\sin(\alpha)=\cos\left(\dfrac{\pi}{2}-\alpha\right)$, Les couples possibles sont :
		$$(0,0),\left(\pm\frac{\pi}{2},\pm1\right),\left(\pm\frac{\pi}{6},\pm\frac{1}{2}\right),\left(\pm\frac{5\pi}{6},\pm\frac{1}{2}\right)$$
		\item Supposons $\tan(\alpha)\in \Q$ avec $\alpha\in \left]-\dfrac{\pi}{2},\dfrac{\pi}{2}\right[$. Comme $\cos(2\alpha)=\dfrac{1-\tan^2(\alpha)}{1+\tan^2(\alpha)}$, $\cos(2\alpha)\in \Q$.\\
		$\cos(2\alpha)\ne -1$ donc on a $\tan^2(\alpha)=\dfrac{1-\cos(2\alpha)}{1+\cos(2\alpha)}$ d'où $\tan(\alpha)\in \left\{0,\pm1,\pm\sqrt 3,\pm\dfrac{\sqrt 3}{3}\right\}$. En enlevant les valeur irrationnelle reste $\tan(\alpha)\in\{-1,0,1\}$. Cela donne $\alpha\in \left\{-\dfrac{\pi}{4},0,\dfrac{\pi}{4}\right\}$.
	\end{enumerate}
	
	\subsubsection{Triangle à angles rationnels sont tous les côtés ont un longueur rationnelle \etoile{2}}
	Un angle exprimé en degré est rationnel ssi l'angle exprimé en radian est dans $\pi\Q$. Notons $A,B,C$ les sommet d'un tel triangle. D'après le théorème d'Al-Kashi, $AC^2=AB^2+BC^2+\cos(\widehat{ABC})$ où $\widehat{ABC}$ est exprimé en radian. Donc $\cos(\widehat{ABC})\in \Q$. On en déduit que $\widehat{ABC}\in \displaystyle\left\{\frac{\pi}{2},\frac{\pi}{3},\frac{2\pi}{3}\right\}$. De même pour les autres angles. Comme leur somme doit faire $\pi$ la seule possibilité est qu'ils soient tous égaux à $\dfrac{\pi}{3}$. On a donc un triangle équilatéral.
	
	\subsubsection{Triangles dont les sommets sont à coordonnées rationnelles \etoile{2}}
	Soit $A,B,C$ des points à coordonnées entières formant un triangle non plat. Un des angles au moins n'est pas égal à $\dfrac{\pi}{2}$. Supposons que c'est $\widehat{ABC}$. Notons $\Vec{AB}=\begin{pmatrix}x\\y\end{pmatrix}$ et $\Vec{BC}=\begin{pmatrix}x'\\y'\end{pmatrix}$\\
	Alors $|\tan(\widehat{ABC})|=\displaystyle\frac{|\sin(\widehat{ABC})|}{|\cos(\widehat{ABC})|}=\frac{\norme{\Vec{AB}}\norme{\Vec{BC}}|\sin(\widehat{ABC})|}{\norme{\Vec{AB}}\norme{\Vec{BC}}|\cos(\widehat{ABC})|}=\frac{\norme{\Vec{AB}\wedge\Vec{BC}}}{|\Vec{AB}\cdot\Vec{BC}|}=\left|\frac{xy'-yx'}{xx'+yy'}\right|\in \Q$.\\
	Donc $\widehat{ABC}=\dfrac{\pi}{4}$.\\
	Ainsi la seule possibilité est d'avoir un triangle rectangle isocèle.
	
	\subsection{\underline{Hilbert} \ccinp{2}}
	\label{sec:Hilbert}
	\textcolor{blue}{\hyperref[Hilbert]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item $(H_k)_{0\leq k\leq n}$ est une famille de $n+1$ polynômes a degrés échelonnés de $\C_n[X]$ qui est de dimension $n+1$. C'est donc une base de $\C_n[X]$.
		\item $\Delta(H_0)=1-1=0$.\\
		$\forall k\in \crblanc{1}{n},\ k!\Delta(H_k)=\displaystyle\prod_{j=-1}^{k-2}(X-j)-\prod_{j=0}^{k-1}(X-j)=(X+1-(X-k+1))\prod_{j=0}^{k-2}(X-j)=k!H_{k-1}$.\\
		Ainsi $\Delta(H_k)=H_{k-1}$.
		\item Soient $k,l\in \crblanc{0}{n}$. D'après la question précédente $\Delta^l(H_k)=\begin{cases}
			0&\mbox{si }l>k\\
			H_{k-l}&\mbox{sinon}
		\end{cases}$\\
		Or $H_p(0)=\begin{cases}
			1&\mbox{si }p=0\\
			0&\mbox{sinon}
		\end{cases}$\\
		Donc $\Delta^l(H_k)=\begin{cases}
			1&\mbox{si }k=l\\
			0&\mbox{sinon}
		\end{cases}$
		\item Soit $P\in \C_n[X]$. D'après la question 1 il existe des réels $\lambda_0,\dots,\lambda_n$ tels que $P=\displaystyle\sum_{k=0}^n\lambda_kH_k$. On remarque que $\Delta\in \L(\C_n[X])$.\\
		Donc $\forall l\in \crblanc{0}{n},\ \Delta^l(P)(0)=\displaystyle\sum_{k=0}^n\lambda_k\Delta^l(H_k)(0)=\lambda_l$.
		\item Soit $k\in \Z$.
		\begin{itemize}
			\item Si $0\leq k\leq n-1$ alors $H_n(k)=0$;
			\item Si $k\geq n$ alors $H_n(k)=\displaystyle\frac{1}{n!}\prod_{j=0}^{n-1}(k-j)=\frac{1}{n!}\prod_{j=k-n-1}^kj=\binom{k}{n}$;
			\item Si $k<0$ alors $H_n(k)=\displaystyle\frac{(-1)^n}{n!}\prod_{j=0}^{n-1}(j-k)=\frac{(-1)^n}{n!}\prod_{j=-k}^{n-k-1}j=(-1)^n\binom{n-k-1}{n}$.
		\end{itemize}
		\item On sait que les coefficients binomiaux sont des entiers donc $H_n(\Z)\subset \Z$.
		\item Soit $P\in \C_n[X]$. Les deux implications découlent de la structure d'anneau de $\Z$.\\
		Si $P(\Z)\subset \Z$ alors par récurrence immédiate $\forall k\in \crblanc{0}{n},\ \Delta^k(P)(\Z)\subset \Z$. Réciproquement, si $\forall k\in \crblanc{0}{n},\ \Delta^k(P)(0)\in \Z$ alors $\forall j\in \Z,\ P(j)=\displaystyle\sum_{k=0}^{n-1}\Delta^k(P)(0)H_k(j)\in \Z$.
	\end{enumerate}
	
	\subsection{\underline{Laguerre} \centraleponts{3}}
	\label{sec:Laguerre}
	\textcolor{blue}{\hyperref[Laguerre]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item D'après la formule de Leibniz $\forall n\in \N,\ \forall x\in \R$,
		$$h_n^{(n)}(x)=\sum_{k=0}^n\binom{n}{k}\frac{d^k}{dx^k}(e^{-x})\frac{d^{n-k}}{dx^{n-k}}(x^n)=\sum_{k=0}^n\binom{n}{k}(-1)^k\frac{n!}{k!}x^ke^{-x}$$
		Donc $L_n(X)$ est un polynôme de degré $n$ et de coefficient dominant $\dfrac{(-1)^n}{n!}$.
		\item Soient $P,Q\in \R[X]$. La fonction $f:x\mapsto P(x)Q(x)e^{-x}$ est continue par morceaux sur $\R_+$ et $f(x)\uxfty=\bigO{x^{\deg(PQ)}e^{-x}}\uxfty=\smallo{\dfrac{1}{x^2}}$. Donc $f$ est intégrale sur $\R_+$, en particulier l'intégrale $\displaystyle\int_0^{+\infty}P(x)Q(x)e^{-x}dx$ converge.\\
		Ensuite, il est évident que $\proscal{\cdot}{\cdot}$ est symétrique et bilinéaire. Fixons $P\in \R[X]$.\\
		La fonction $x\mapsto P(x)^2e^{-x}$ est continue et positive sur $\R_+$. Ainsi par stricte positivité de l'intégrale $\proscal{P}{P}\geq 0$ avec égalité ssi $\forall x\in \R,\ P(x)^2e^{-x}=0$. Dans ce cas $P$ est nul sur $\R$ qui est infini donc $P$ est le polynôme nul.\\
		On conclut que $\proscal{\cdot}{\cdot}$ est un produit scalaire sur $\R[X]$.
		\item $L_0=1$.\\
		$\forall n\in \N,\ \proscal{L_0}{X^n}=\displaystyle\int_0^{+\infty}x^ne^{-x}dx=\Gamma(n+1)=n!$.
		\item Soit $k\in \crblanc{0}{n}$. D'après la formule de Leibniz $\forall x\in \R$,
		$$h_n^{(k)}(x)=\sum_{j=0}^k\binom{k}{j}\frac{d^{k-j}}{dx^{k-j}}(e^{-x})\frac{d^j}{dx^j}(x^n)=\sum_{j=0}^k\binom{k}{j}(-1)^{k-j}\frac{n!}{(n-j)!}x^{n-j}e^{-x}$$
		On pose $Q_k=\displaystyle\sum_{j=0}^k(-1)^{k-j}\binom{k}{j}\frac{n!}{(n-j)!}X^{k-j}=\sum_{j=0}^k(-1)^k\binom{k}{j}\frac{n!}{(n-k+j)!}X^j$.
		\item Soient $n\in \N$, $p\in \crblanc{0}{n}$ et $P\in \R[X]$. Les fonctions en jeux sont de classe $\mathcal C^\infty$ sur $\R_+$ donc par IPP successives :\\
		$n!\proscal{L_n}{P}=\displaystyle\int_0^{+\infty}h_n^{(n)}P(x)dx=\sum_{j=0}^{p-1}\left[(-1)^jh_n^{(n-j-1)}(x)P^{(j)}(x)\right]_0^{+\infty}+(-1)^p\int_0^{+\infty}h_n^{(n-p)}(x)P^{(p)}(x)dx$.\\
		Or pour $j\in \crblanc{0}{p-1}$, la question précédente montre que $h_n^{(n-j-1)}(0)=0$\\
		et $h_n^{(n-j-1)}(x)P^{(j)}(x)\uxfty\longrightarrow0$.\\
		On en déduit $\proscal{L_n}{P}=\displaystyle\frac{(-1)^p}{n!}\int_0^{+\infty}h_n^{(n-p)}(x)P^{(p)}(x)dx$.
		\item Soient $n\geq m\in \N$. D'après la question précédente :
		$$\proscal{L_n}{L_m}=\frac{(-1)^n}{n!}\int_0^{+\infty}h_n(x)L_m^{(n)}(x)dx=\frac{(-1)^n}{n!}\int_0^{+\infty}x^nL_m^{(n)}(x)e^{-x}=\frac{(-1)^n}{n!}\proscal{X^n}{L_m^{(n)}}$$
		On rappelle qu'on a montré question 1 que $L_m$ est de degré $m$ et de coefficient dominant $\dfrac{(-1)^m}{m!}$.\\
		Si $n>m$ alors $L_m^{(n)}=0$ d'où $\proscal{L_n}{L_m}=0$.\\
		Et si $m=n$ alors $L_m^{(n)}=(-1)^nL_0$ d'où $\proscal{L_n}{L_m}=\dfrac{1}{n!}\proscal{X^n}{L_0}=1$.
	\end{enumerate}
	
	\subsection{\underline{Legendre} \ccinp{2}}
	\label{sec:Legendre}
	\textcolor{blue}{\hyperref[Legendre]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item $Q_0=1,\ Q_1'=2X,\ Q_2''=(X^4-2X^2+1)''=12X^2-4,\ Q_3'''=(X^6-3X^4+3X^2-1)'''=120X^3-72X$.\\
		$P_0=1,\ P_1=X,\ P_2=\displaystyle\frac{3}{2}X^2-\frac{1}{2},\ P_3=\frac{5}{2}X^3-\frac{3}{2}X$.
		\item $\deg(Q_n)=2n$ donc $\deg(P_n)=\deg(Q_n^{(n)})=n$.
		\item On remarque que la dérivé d'un polynôme pair est impaire et que la dérivée d'un polynôme impair est paire : $P(-X)=P(X)\implies -P'(-X)=P'(X)$ et $P(-X)=-P(X)\implies -P'(-X)=-P'(X)\implies P'(-X)=P'(X)$.\\
		$Q_n$ est pair donc sa dérivée $n$-ième a la parité de $n$. On en déduit que $P_n(0)=0$ si $n$ est impair et $P_n'(0)=0$ si $n$ est pair ($P_n'$ est impair).
		\item Soient $m\in \N$ et $n=2m$. $Q_n=\displaystyle\sum_{k=0}^n\binom{n}{k}(-1)^{n-k}X^{2k}$ donc $Q_n^{(n)}=\displaystyle\sum_{k=m}^{2m}\binom{2m}{k}(-1)^k\frac{(2k)!}{(2k-2m)!}X^{2(k-m)}$.\\
		Ainsi $P_n(0)=\displaystyle\frac{(-1)^m}{2^{2m}}\binom{2m}{m}=(-1)^m\frac{(2m)!}{2^{2m}(m!)^2}$.\\
		De même, $Q_{n+1}^{(n+2)}=\displaystyle\sum_{k=m+1}^{2m+1}\binom{2m+1}{k}(-1)^k\frac{(2k)!}{(2k-2m-2)!}X^{2k-2m-2}$.\\
		Donc $P_n'(0)=\displaystyle\frac{(-1)^{m+1}(2m+2)}{2^{2m+1}}\binom{2m+1}{m+1}=(-1)^{m+1}\frac{(2m+1)!}{2^{2m}(m!)^2}$.
		\item $Q_n'=2nX(X^2-1)^{n-1}$ donc $(X^2-1)Q_n'=2nXQ_n$. On dérive $(n+1)$-fois cette expression :
		$$(X^2-1)Q_n^{(n+2)}+2(n+1)XQ_n^{(n+1)}=2nXQ_n^{(n+1)}+2n(n+1)Q_n^{(n)}$$
		D'où en simplifiant et en divisant par $2^nn!,\ (X^2-1)P_n''+2XP_n'=n(n+1)P_n$.
		\item $Q_n=(X-1)^n(X+1)^n$ donc $-1,1$ sont racines de $Q_n$ de multiplicités $n$. Ainsi $\forall k\in \crblanc{0}{n-1},\ Q_n^{(k)}(-1)=Q_n^{(k)}(1)=0$.
		\item Remarquons que $P_n$ admet au plus $n$ racines distinctes car il est de degré $n$.\\
		Montrons par récurrence sur $k\in \crblanc{0}{n}$ la propriété $H(k):"Q_n^{(k)}\T{ admet au moins }k\T{ racines distinctes dans }]-1,1["$.\\
		$H(0)$ est évidemment vraie.\\
		Supposons $H(k)$ pour un certain $k\in \crblanc{0}{n-1}$. On note $-1<x_1<\dots<x_n<1$ les racines en questions. On note aussi $x_0=-1$ et $x_{n+1}=1$, dont on sait qu'ils sont racines de $Q_n^{(k)}$.\\
		Pour tout $i\in \crblanc{0}{k},\ Q_n^{(k)}$ est continu sur $[x_i,x_{i+1}]$, dérivable sur $]x_i,x_{i+1}[$ et $Q_n^{(k)}(x_i)=Q_n^{(k)}(x_{i+1})=0$. Donc d'après le théorème de Rolle, il existe $y_1,\dots y_{k+1}$ des racines de $Q_n^{(k+1)}$ telles que
		$$-1<y_1<x_1<y_2<x_2<\dots<y_{k+1}<1$$
		D'où $H(k+1)$.\\
		Par récurrence $\forall k\in \crblanc{0}{n},\ H(k)$. En particulier $H(n)$ donne le résultat voulu.
	\end{enumerate}
	
	\subsection{\underline{Hermite} \centraleponts{3}}
	\label{sec:Hermite}
	\textcolor{blue}{\hyperref[Hermite]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item Soient $P,Q\in \R[X]$. Alors $P(t)Q(t)\underset{|t|\to+\infty}=\bigO{x^{\deg(P)+\deg(Q)}}$ donc $P(t)Q(t)e^{-t^2/2}\underset{|t|\to+\infty}=\smallo{\dfrac{1}{t^2}}$.\\
		L'intégrale est donc bien définie.\\
		Il est évident que $\proscal{P}{Q}=\proscal{Q}{P}$. La bilinéarité est conséquence directe de la linéarité de l'intégrale.\\
		Ensuite $\proscal{P}{P}=\displaystyle\int_{-\infty}^{+\infty}P(t)^2e^{-t^2/2}dt$. La fonction $t\mapsto P(t)^2e^{-t^2/2}$ est continue et positive sur $\R$. Donc par (stricte) positivité de l'intégrale, $\proscal{P}{P}\geq 0$, avec égalité ssi $\forall t\in \R,\ P(t)^2e^{-t^2/2}=0$ ssi $\forall t\in \R,\ P(t)=0$ ssi $P=0$.
		\item Il faut d'abord s'assurer que $H_n$ est un polynôme. Montrons par récurrence que $\forall x\in \R,\ \dfrac{d^n}{dx^n}\left(e^{-\frac{x^2}{2}}\right)=P_n(x)e^{-x^2/2}$. On aura alors $P_n=(-1)^nH_n$.\\
		C'est vrai pour $n=0$ avec $P_0=1$. Supposons que ce soit vrai pour un certain $n\in \N$. Fixons $x\in \R$.\\
		Alors $\displaystyle\frac{d^{n+1}}{dx^{n+1}}\left(e^{-\frac{x^2}{2}}\right)=\frac{d}{dx}\left(P_n(x)e^{-x^2/2}\right)=(P_n'(x)-xP_n(x))e^{-x^2/2}$.\\
		La propriété est donc vrai au rang $n+1$ pour $P_{n+1}=P_n'-XP_n$.\\
		La même récurrence montre aussi que $P_n$ est de degré $n$ pour tout $n\in \N$.\\
		Ensuite on suppose sans perte de généralité $n>m$. On calcule alors par IPP successives :
		\begin{align*}
			\proscal{H_n}{H_m}&=\int_{-\infty}^{+\infty}(-1)^n\frac{d^n}{dx^n}\left(e^{-\frac{x^2}{2}}\right)H_m(x)dx\\
			&=\sum_{k=0}^{n-1}\left[(-1)^{n+k}\frac{d^{n-k-1}}{dx^{n-k-1}}\left(e^{-x^2/2}\right)H_m^{(k)}(x)\right]_{-\infty}^{+\infty}+\int_{-\infty}^{+\infty}e^{-x^2/2}H_m^{(n)}(x)dx
		\end{align*}
		Les termes de la somme sont tous nul car on a vu que $P(x)e^{-x^2/2}\underset{|x|\to+\infty}\longrightarrow 0$ pour tout $P\in \R[X]$.\\
		Le terme intégral est nul car $H_m^{(n)}=0$ (dérivée $n>m$-ième d'un polynôme de degré $m$).\\
		Ainsi $\proscal{H_n}{H_m}=0$.
		\item Le calcul précédent est toujours valable. Il donne :\\
		$$\proscal{H_n}{H_n}=\int_{-\infty}^{+\infty}H_n^{(n)}(x)e^{-x^2/2}dx$$
		Or $H_n^{(n)}$ est un polynôme constant égal à $n!d$ où $d$ est le coefficient dominant de $H_n$. Dans la récurrence faîte à la question précédente, on obtient $P_{n+1}=P_n'-XP_n$ i.e $H_{n+1}=XH_n-H_n'$. Cette relation donne par récurrence que le coefficient dominant de $H_{n+1}$ est égal à celui de $H_n$. Comme $H_0=1$, $H_n^{(n)}=n!$.\\
		Ainsi $\proscal{H_n}{H_n}=n!\displaystyle\int_{-\infty}^{+\infty}e^{-x^2/2}dx=n!\sqrt{2\pi}$.
		\item D'après la formule de Leibniz
		$$\frac{d^{n+1}}{dx^{n+1}}\left(e^{-x^2/2}\right)=-\frac{d^n}{dx^n}\left(xe^{-x^2/2}\right)=-\left(x\frac{d^n}{dx^n}\left(e^{-x^2/2}\right)+n\frac{d^{n-1}}{dx^{n-1}}\left(e^{-x^2/2}\right)\right)$$
		D'où :
		$$H_{n+1}=XH_n-nH_{n-1}$$
		\item On rappelle qu'on a $H_{n+1}=XH_n-H_n'$. On identifie donc $H_n'=nH_{n-1}$ et l'injectant l'équation précédente, écrite à l'ordre $n+1$, on obtient :
		$$H_n''-XH_n'+nH_n=0$$
	\end{enumerate}
	
	\subsection{\underline{Bernstein} \centraleponts{3}}
	\label{sec:Bernstein}
	\textcolor{blue}{\hyperref[Bernstein]{[Enoncé]}}\\
	
	\subsection{\underline{Polynômes cyclotomiques} \xens{3}}
	\label{sec:polynomes-cyclotomiques}
	\textcolor{blue}{\hyperref[Polynômes cyclotomiques]{[Enoncé]}}\\
	
	\subsection{Suite de polynômes définis par récurrence}
	\label{sec:suite-de-polynomes-definis-par-recurrence}
	\textcolor{blue}{\hyperref[Suite de polynômes définis par récurrence]{[Enoncé]}}\\
	
	\subsection{Equation polynomiale (1)}
	\label{sec:équation-polynomiale-(1)}
	\textcolor{blue}{\hyperref[Equation polynomiale (1)]{[Enoncé]}}\\
	
	\subsection{Equation polynomiale (2)}
	\label{sec:équation-polynomiale-(2)}
	\textcolor{blue}{\hyperref[Equation polynomiale (1)]{[Enoncé]}}\\
	
	\subsection{Equation polynomiale (3)}
	\label{sec:équation-polynomiale-(3)}
	\textcolor{blue}{\hyperref[Equation polynomiale (3)]{[Enoncé]}}\\
	
	\subsection{Equation polynomiale (4)}
	\label{sec:équation-polynomiale-(4)}
	\textcolor{blue}{\hyperref[Equation polynomiale (4)]{[Enoncé]}}\\
	
	\subsection{Equation polynomiale (5)}
	\label{sec:équation-polynomiale-(5)}
	\textcolor{blue}{\hyperref[Equation polynomiale (5)]{[Enoncé]}}\\
	
	\subsection{Equation de Shapiro}
	\label{sec:équation-de-shapiro}
	\textcolor{blue}{\hyperref[Equation de Shapiro]{[Enoncé]}}\\
	
	\subsection{Degré d'une différence \telecom{1}}
	\label{sec:degré-d'une-différence}
	\textcolor{blue}{\hyperref[Degré d'une différence]{[Enoncé]}}
	On sait que $X^3-1=(X-1)(X-j)(X-\overline j)$ avec $j=e^{2i\pi/3}$. Donc $P^3-Q^3=(P-Q)(P-jQ)(P-\overline jQ)$.\\
	Comme $P-Q\ne 0,\ \deg(P^3-Q^3)=\deg(P-Q)+\deg(P-jQ)+\deg(P-\overline jQ)\geq \deg(P-jQ)+\deg(P-\overline jQ)$.\\
	Or pour tout $z\in \C$, $\deg(P-zQ)\ne n$ ssi le coefficient dominant de $P$ est égal à celui de $zQ$. Comme $j\notin\R$, le coefficient dominant de $jQ$ n'est pas réel. De même pour celui de $\overline jQ$.\\
	Ainsi comme celui de $P$ est réel, $\deg(P-jQ)=\deg(P-\overline jQ)=n$ d'où $\deg(P^3-Q^3)\geq 2n$.
	
	\subsection{Théorème de la racine rationnelle \telecom{2}}
	\label{sec:theoreme-de-la-racine-rationnelle}
	\textcolor{blue}{\hyperref[Théorème de la racine rationnelle]{[Enoncé]}}\\
	$\dfrac{p}{q}$ irréductible équivaut à $p\wedge q=1$.\\
	On sait que $0=\displaystyle P\left(\frac{p}{q}\right)=\sum_{k=0}^na_k\frac{p^k}{q^k}=q^{-n}\sum_{k=0}^na_kp^kq^{n-k}$.\\
	Donc $-a_0q^n=\displaystyle p\sum_{k=1}^na_kp^{k-1}q^{n-k}$.\\
	Or $\displaystyle\sum_{k=1}^na_kp^{k-1}q^{n-k}\in \Z$ donc $p|a_0q^n$ d'où par le lemme de Gauss $p|a_0$.\\
	De même $-a_np^n=\displaystyle q\sum_{k=0}^{n-1}a_kp^kq^{n-1-k}$ donc $q|a_np^n$ d'où $q|a_n$.
	
	\subsection{Critère d'Eisenstein \etoile{3}}
	\label{sec:critere-deisenstein-etoile3}
	\textcolor{blue}{\hyperref[Eisenstein]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item
		\begin{enumerate}[label=\alph*.]
			\item Notons $P=\displaystyle\sum_{k=0}^na_kX^k$ et $Q=\displaystyle\sum_{k=0}^mb_kX^k$.\\
			On considère $\tilde P=\displaystyle\frac{P}{c(P)}$ et $\tilde Q=\displaystyle\frac{Q}{c(Q)}$. $\tilde P$ et $\tilde Q$ sont à coefficients entiers et on montre aisément qu'ils sont de contenu $1$ (on dit qu'ils sont \textit{primitifs}). Il suffit donc de montrer le résultat pour $P$ et $Q$ de contenus égaux à $1$. Dans ce cas il faut montrer que $c(PQ)=1$.\\
			Soit $p$ un nombre premier. On sait, comme $P$ et $Q$ sont primitifs, qu'il existe des coefficients de $P$ et $Q$ qui ne sont pas divisibles par $p$. On note $i=\min\{k\in \crblanc{0}{n},\ p\nmid a_k\}$ et $j=\min\{k\in \crblanc{0}{m},\ p\nmid b_k\}$.\\
			D'après la formule du produit de Cauchy le coefficient de $X^{i+j}$ dans $PQ$ est congrus à $a_ib_j$ modulo $p$. Il n'est donc pas divisible par $p$ d'où $p\nmid c(PQ)$. On en déduit que $c(PQ)=1$.\\\\
			\underline{Preuve plus rapide qui sort un peu du programme :}\\
			Supposons que $p$ est un diviseur premier de $c(PQ)$. Alors $p$ divise tous les coefficients de $PQ$. On note $\overline P$ le polynôme de $\Z/p\Z$ dont les coefficients sont les classes des coefficients de $P$. On note de même $\overline Q$ et $\overline{PQ}=\overline P\cdot\overline Q$.\\
			On a $\overline{PQ}=0$ donc comme $(\Z/p\Z)[X]$ est intègre (on l'a en fait remontré dans la première preuve) on en déduit que $\overline P=0$ ou $\overline Q=0$. Ceci est absurde car $p$ ne divise ni $c(P)$ ni $c(Q)$. Ainsi $c(PQ)=1$.
			\item Soient $P,Q\in \Q[X]$ unitaires. Il est évident que si $P,Q\in \Z[X]$ alors $S=PQ\in \Z[X]$. Supposons réciproquement que $PQ\in \Z[X]$. On note $a$ le $\pgcd$ des dénominateurs des coefficients de $P$ et $b$ celui des dénominateurs des coefficients de $Q$, de sorte que $aP,bQ\in \Z[X]$. On considère $\tilde P=\displaystyle\frac{aP}{c(aP)}$ et $\tilde Q=\displaystyle\frac{bQ}{c(bQ)}$ de sorte que $c(\tilde P)=c(\tilde Q)=1$.\\
			On sait que $\tilde P\tilde Q=\displaystyle\frac{a}{c(aP)}\cdot\frac{b}{c(bQ)}S$. On remarque que le contenu de $S$ vaut $1$ car il est unitaire. Donc en passant au contenu, $\displaystyle 1=c(\tilde P)c(\tilde Q)=\frac{a}{c(aP)}\cdot\frac{b}{c(bQ)}$. De plus $\displaystyle\frac{a}{c(aP)}$ et $\displaystyle\frac{b}{c(bQ)}$ sont des entiers. Ils valent donc tous les deux $\pm1$. Ainsi $P=\pm\tilde P\in \Z[X]$ et $Q=\pm\tilde Q\in \Z[X]$.
		\end{enumerate}
		\item Supposons pas l'absurde qu'il existe deux polynômes à coefficients rationnels $B=\displaystyle\sum_{k=0}^db_kX^k$ et $C=\displaystyle\sum_{k=0}^{n-d}c_kX^k$ tels que $A=BC$ et $0<d=\deg(B)<n$. Quitte à les diviser par leur coefficient dominant on peut supposer que $B$ et $C$ sont unitaires.\\
		Alors d'après la question $1$, $B$ et $C$ sont à coefficients entiers.
		On sait que $p|a_0=b_0c_0$ et comme $p^2\nmid a_0$, $p$ divise un et un seul des deux entiers $b_0,c_0$. On suppose sans perte de généralité que c'est $b_0$.\\
		Montrons par récurrence forte que $\forall k\in \crblanc{0}{d},\ p|b_k$.\\
		On vient de faire l'initialisation. Supposons que pour un certain entier $k\in \crblanc{0}{d-1},\ \forall i\in \crblanc{0}{k},\ p|b_i$.\\
		D'après l'hypothèse de l'énoncé $p|a_{k+1}=\displaystyle\sum_{i=\max(0,k+1+d-n)}^{k+1}b_ic_{k+1-i}$. Donc par hypothèse de récurrence $p|b_{k+1}c_0$.\\
		Or $p\nmid c_0$ donc d'après le lemme d'Euclide $p|b_{k+1}$.\\
		Mais alors en particulier $p|b_d=1$ ce qui est absurde. On en déduit que $B$ ou $C$ est constant et donc que $A$ est irréductible dans $\Q[X]$.\\\\
		\underline{Preuve plus rapide qui sort un peu du programme :}\\
		On reprend à $A=BC$ avec $B,C\in \Z[X]$ unitaires. On note $\overline A$ le polynôme de $\Z/p\Z$ dont les coefficients sont les classes des coefficients de $A$. On note de même $\overline B$ et $\overline C$ et $\overline{BC}=\overline B\cdot\overline C$.\\
		L'hypothèse de l'énoncé se traduit par $\overline A=X^n$. Donc $X^n=\overline B\cdot\overline C$ d'où comme $(\Z/p\Z)[X]$ est intègre (on l'a en fait montré dans la réponse à la question $1$). $\overline B=X^k$ et $\overline C=X^{n-k}$. On repasse dans $\Z[X]$ : on a obtenu que $\forall i\in \crblanc{0}{k-1},\ p|b_i$ et $\forall j\in \crblanc{0}{n-k-1},\ p|c_i$.\\
		En particulier $p|b_0$ et $p|c_0$ d'où $p^2|b_0c_0=a_0$ ce qui est absurde.
	\end{enumerate}
	
	\subsubsection{Irréductibilité des polynômes cyclotomiques d'indices premiers \etoile{2}}
	$\Phi_p(X)=\displaystyle\frac{X^p-1}{X-1}$ donc $\Psi_p(X)=\displaystyle\frac{(X+1)^p-1}{X}=\sum_{k=1}^p\binom{p}{k}X^{k-1}=X^{p-1}+\sum_{k=0}^{p-2}\binom{p}{k+1}X^k$.\\
	Or si $k\in \crblanc{0}{p-2}$ alors $p|\displaystyle\prod_{i=p-k}^pi=\binom{p}{k+1}(k+1)!$. Et comme $p$ est premier et $0<k+1<p,\ \pgcd(p,(k+1)!)=1$. Donc d'après le lemme de Gauss $p|\displaystyle\binom{p}{k+1}$.\\
	De plus $p^2\nmid\displaystyle\binom{p}{1}=p$.\\
	Par conséquent d'après le critère d'Eisenstein $\Psi_p$ est irréductible dans $\Q[X]$.\\
	Pour conclure il suffit d'évaluer, pour $B,C\in \Q[X]$, l'égalité $\Phi_p=BC$ en $X+1$. On obtient $B(X+1)$ ou $C(X+1)$ est constant d'où $B$ ou $C$ est constant et $\Phi_p$ est irréductible dans $\Q[X]$.
	
	\subsubsection{Dimension de $\R$ en tant que $\Q$-espace vectoriel \etoile{3}}
	\begin{enumerate}[leftmargin=*]
		\item $f_\alpha$ est un morphisme d'algèbre donc son noyau est un idéal de $\Q[X]$.\\\\
		Montrons que tous les idéaux de $\Q[X]$ sont principaux (i.e engendré par un seul élément). Soit $I$ un idéal non nul de $\Q[X]$. L'ensemble des degrés des éléments de $I\setminus\{0\}$ est une partie non vide de $\N$, elle admet donc un minimum. On considère un polynôme $\Pi$ qui réalise ce minimum. Quitte à le multiplier par l'inverse de son coefficient dominant (qui est dans $\Q$ car $\Q$ est un corps) on peut aussi supposer $\Pi$ unitaire. Montrons que $I=\Pi\Q[X]$.\\
		Par absorbance $\Pi\Q[X]\subset I$. Réciproquement si $P\in I$ alors on pose $P=Q\Pi+R$ la division euclidienne de $P$ par $\Pi$. Comme $\Q$ est un corps et comme $\Pi,P\in \Q[X]$, l'algorithme de division euclidienne assure que $Q,R\in \Q[X]$.\\
		Alors $R=P-Q\pi\in I$. par conséquent $R$ ne peut pas être non nul car sinon la condition $\deg(R)<\deg(\Pi)$ contredirait la minimalité de $\pi$ en degré. Ainsi $R=0$ et $P\in \Pi\Q[X]$.\\\\
		On peut alors se donner un polynôme unitaire $\Pi_\alpha$ tel que $\Ker(f_\alpha)=\Pi_\alpha\Q[X]$. Comme $P\in \Ker(f_\alpha)$ on a $\Pi_\alpha|P$. Or d'après le critère d'Eisenstein $P$ est irréductible dans $\Q[X]$. On en déduit que $P$ et $\Pi_\alpha$ sont associés, et donc qu'ils sont égaux étant tous deux unitaires.
		\item Soit $(q_0,\dots,q_n)\in \Q^{n+1}$ tel que $\displaystyle\sum_{k=0}^nq_k\alpha^k=0$.\\
		On a donc $Q(\alpha)=0$ avec $Q=\displaystyle\sum_{k=0}^nq_kX^k\in \Q[X]$ i.e $Q\in \Ker(f_\alpha)$ d'où $P|Q$.\\
		Enfin, $\deg(Q)\leq n<n+1=\deg(P)$ donc $Q=0$. C'est à dire $\forall k\in \crblanc{0}{n},\ q_k=0$.\\
		En outre la famille $(1,\alpha,\dots,\alpha^n)$ est $\Q$-libre.
		\item Pour $n\in \N^*$ on considère la polynôme $P_n=X^n-2$.\\
		$P_n$ vérifie le critère d'Eisenstein ($p=2$). Donc la famille $(1,\sqrt 2,\dots,{\sqrt 2}^n)$ est libre dans $\Q$.\\
		Ainsi $\R$ n'admet pas de famille $\Q$-libre maximale : $\R$ est un $\Q$-espace vectoriel de dimension infinie.
	\end{enumerate}
	
	\subsection{Points critiques des polynômes de Hilbert \centraleponts{3}}
	\label{sec:points-critiques-des-polynômes-de-hilbert}
	\textcolor{blue}{\hyperref[Points critiques des polynômes de Hilbert]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item Notons $f_n:x\mapsto F_n(x)$. $f_n$ est $\mathcal C^\infty$ sur $]0,1[$ car $F_n$ n'admet pas de pôle dans cet intervalle.\\
		Ensuite d'après le cours $F_n(X)=\displaystyle\sum_{k=0}^n\frac{1}{X-k}$. Donc $\lim\limits_{x\to 0^+}f(x)=+\infty$ et $\lim\limits_{x\to 1^-}f(x)=-\infty$.\\
		De plus $\forall x\in ]0,[1,\ f_n'(x)=-\displaystyle\sum_{k=0}^n\frac{1}{(X-k)^2}<0$. Donc $f_n$ est strictement décroissante sur $]0,1[$.\\
		D'après le théorème de la bijection $f_n$ s'annule exactement une fois sur $]0,1[$.
		\item Fixons $n\geq 2$. $f_n(x_n)=0$ donc $\displaystyle\frac{1}{x_n}=\sum_{k=1}^n\frac{1}{k-x_n}\geq \sum_{k=1}^n\frac{1}{k}:=H_n$.\\
		On sait que $H_n\unfty\longrightarrow+\infty$ donc $x_n\unfty\longrightarrow 0$.
		\item Fixons $n\geq 2$.\\
		On réécrit de même $\displaystyle H_n\leq\frac{1}{x_n}=\frac{1}{1-x_n}+\sum_{k=2}^n\frac{1}{k-x_n}\leq\frac{1}{1-x_n}+\sum_{k=2}^n\frac{1}{k-1}=\frac{1}{1-x_n}+H_{n-1}=\frac{1}{1-x_n}-\frac{1}{n}+H_n$.\\
		Or on montre classiquement (cf. \ref{Série harmonique}) que $H_n\unfty\sim\ln n$ d'où $\displaystyle\frac{1}{1-x_n}-\frac{1}{n}+H_n\unfty\sim\ln n$ puis $x_n\unfty\sim\dfrac{1}{\ln n}$.
	\end{enumerate}
	
	\subsection{Zéros du sinus tronqué}
	\label{sec:zeros-du-sinus-tronqué}
	\textcolor{blue}{\hyperref[Zéros du sinus tronqué]{[Enoncé]}}\\
	
	\subsection{Exponentielle tronquée \ccinp{1}}
	\label{sec:exponentielle-tronquée}
	\textcolor{blue}{\hyperref[Exponentielle tronquée]{[Enoncé]}}\\
	Soit $z\in \C$ une racine de $P$. Supposons par l'absurde que $P'(z)=0$.\\
	On a $0=P'(z)=\displaystyle\sum_{k=0}^{n-1}\frac{z^k}{k!}=P(z)-z^n=-z^n$ donc $z=0$. Ceci est absurde puisque $P(0)=1\ne 0$. On en déduit que $P$ est scindé à racines simples.
	
	\subsection{Les fonctions localement polynomiales sont polynomiales \centraleponts{2}}
	\label{sec:les-fonctions-localement-polynomiale-sont-polynomiales}
	\textcolor{blue}{\hyperref[Les fonctions localement polynomiales sont polynomiales]{[Enoncé]}}\\
	On sait déjà que $f$ est égal à un certain polynôme $P$ sur un intervalle $[0,\varepsilon]$. L'idée va être de trouver le plus grand intervalle sur lequel $f$ est égale à $P$.\\
	On introduit donc $s:=\sup\{t>0,\ \forall x\in [0,t],\ f(x)=P(x)\}\in \R_+\cup\{+\infty\}$. Le but est de montrer que $s=+\infty$.\\
	Supposons par l'absurde $s\in \R$. Alors $\exists 0<\alpha<s,\ \exists Q\in \R[X],\ \forall x\in ]s-\alpha,s+\alpha[,\ f(x)=Q(x)$. En particulier $\forall x\in [s-\alpha,s[,\ P(x)=f(x)=Q(x)$. $P$ et $Q$ coïncident en une infinité de points, ils sont donc égaux. Ceci contredit la maximalité de $s$ et on en déduit que $s=+\infty$.\\
	On peut faire de même pour montrer que $f$ est polynomiale sur $]-\infty,1]$. Ce polynôme coïncide avec $P$ sur $[0,1]$, ils sont donc égaux et par suite $\forall x\in \R,\ f(x)=P(x)$.
	
	\subsection{Intégrales de polynômes \telecom{1}}
	\label{sec:integrales-de-polynomes-etoile1}
	\textcolor{blue}{\hyperref[Intégrales de polynômes]{[Enoncé]}}\\
	Notons $(L_0,\dots,L_n)$ la base de Lagrange aux points $x_0,\dots,x_n$. Fixons $P\in \K_n[X]$.\\
	On sait que $P=\displaystyle\sum_{i=0}^nP(x_i)L_i$.\\
	Donc $\displaystyle\int_a^bP(x)dx=\sum_{i=0}^n\int_a^bP(x_i)L_i(x)dx=\sum_{i=0}^nP(x_i)\int_a^bL_i(x)dx=\sum_{i=0}^n\lambda_iP(x_i)$ avec $\lambda_i=\displaystyle\int_a^bL_i(x)dx$.
	
	\subsection{Théorème de Gauss-Lucas \centraleponts{2}}
	\label{sec:theoreme-de-gauss-lucas-etoile2}
	\textcolor{blue}{\hyperref[gausslucas]{[Enoncé]}}\\
	\label{Gauss-Lucas}
	\begin{enumerate}
		\item Soit $\alpha$ une racine de $P'$. Si $\alpha$ est racine de $P$, il n'y a rien à faire. Sinon, On sait que $\displaystyle\frac{P'}{P}=\sum\limits_{k=1}^r{\frac{n_k}{X-z_k}}$. Alors,
		$$0=\frac{P'(\alpha)}{P(\alpha)}=\sum\limits_{k=1}^r{\frac{n_k}{\alpha-z_k}}=\sum\limits_{k=1}^r{\frac{n_k\cdot\overline{\alpha-z_k}}{|\alpha-z_k|^2}}$$
		et en passant au conjugué:
		\begin{align*}
			\sum\limits_{k=1}^r{\frac{n_k(\alpha-z_k)}{|\alpha-z_k|^2}}&=0\\
			\iff \alpha\sum\limits_{k=1}^r{\frac{n_k}{|\alpha-z_k|^2}}&=\sum\limits_{k=1}^r{\frac{n_k}{|\alpha-z_k|^2}z_k}
		\end{align*}
		Notons $\lambda=\displaystyle\sum\limits_{k=1}^r{\frac{n_k}{|\alpha-z_k|^2}}$. En posant pour $k\in \crblanc{1}{n},\ \lambda_k=\displaystyle\frac{n_k}{\lambda|\alpha-z_k|^2}\geq 0$ on a
		$$\alpha=\sum\limits_{k=1}^r{\lambda_kz_k}\text{ et } \sum\limits_{k=1}^r{\lambda_k}=1$$
		\item si les $z_k$ sont tous réels alors $\alpha$ l'est aussi : $P'$ est à racines réelles.
	\end{enumerate}
	
	\subsubsection{Une application \etoile{3}}
	\begin{enumerate}
		\item Notons $\mathcal{C}=\{C\subset R_P,\ \text{Conv}(C)=\text{Conv}(R_P)\}$ et $\mathcal{D}=\{|C|,\ C\in \mathcal{C}\}$.\\
		$\mathcal{D}$ est une partie non vide ($R_P\in \mathcal{C})$ de $\N^*$ (Conv$(\emptyset)=\emptyset\ne \text{Conv}(R_P)$ puisque $P$ a une racine par le théorème de d'Alembert-Gauss), elle admet donc un minimum. Notons $C_0$ tel que $|C_0|=\min\mathcal{D}$.\\
		Fixons $C\in \mathcal{C}$ telle que $C\subset C_0$. Alors $|C|\leq |C_0|$ et par définition de $C_0$, $|C_0|\leq |C|$. Donc $|C|=|C_0|$ d'où $C=C_0$.\\\\
		Fixons $a,b\in \text{Conv}(R_P)\setminus R_{P,\min}$ ainsi que $t\in ]0,1[$. $\text{Conv}(R_P)$ est convexe par définition donc $\gamma(t)=ta+(1-t)b\in \text{Conv}(R_P)$. Supposons que $\gamma(t)\in R_{P,\min}$.\\
		Quitte à réindicer, on peut supposer que $R_{P,\min}=\{z_k,\ k\in \crblanc{1}{m}\}$ pour un certain $m\in \crblanc{1}{r}$. $a,b\in \text{Conv}(R_P)=\text{Conv}(R_{P,\min})$ donc il existe $(\lambda_1,\dots,\lambda_m),(\mu_1,\dots,\mu_m)\in (\R_+)^m$ tels que $\displaystyle\sum\limits_{k=1}^m\lambda_k=1=\sum\limits_{k=1}^m\mu_k$, $a=\displaystyle\sum\limits_{k=1}^m\lambda_k z_k$ et $b=\displaystyle\sum\limits_{k=1}^m\mu_k z_k$.\\
		Notons $p\in \crblanc{1}{m}$ tel que $\displaystyle\sum\limits_{k=1}^m(t\lambda_k+(1-t)\mu_k)z_k=z_p$, c'est à dire tel que $\displaystyle\sum\limits_{\substack{1\leq k\leq m\\k\ne p}}\nu_k z_k=(1-\nu_p)z_p$. avec $\nu_k=t\lambda_k+(1-t)\mu_k$.\\
		On remarque que $\displaystyle\sum\limits_{k=1}^m\nu_k=1$ et que $\forall k\in \crblanc{1}{m},\ \nu_k\geq 0$.\\\\
		Si $\nu_p<1$ alors on a $z_p=\displaystyle\sum\limits_{\substack{1\leq k\leq m\\k\ne p}}\frac{\nu_k}{1-\nu_p}z_k$ avec $\displaystyle\sum\limits_{\substack{1\leq k\leq m\\k\ne p}}\frac{\nu_k}{1-\nu_p}=1$ et $\forall k\in \crblanc{1}{m}\setminus\{p\},\ \displaystyle\frac{\nu_k}{1-\nu_p}\geq 0$. Donc $z_p\in \text{Conv}(z_k,\ k\in \crblanc{1}{m}\setminus\{p\})$ ce qui contredit la minimalité de $R_{P,\min}$.\\
		Et si $\nu_p=1$ alors $\forall k\in \crblanc{1}{m}\setminus\{p\},\ \nu_k=0$. D'où, comme $0<t<1$, $\forall k\in \crblanc{1}{m}\setminus\{p\},\ \lambda_k=\mu_k=0$ d'où $a=b=z_p$. Ceci est absurde car $a\notin R_{P,\min}$ par exemple.\\\\
		Ainsi, $\gamma(t)\notin R_{P,\min}$ et donc Conv$(R_P)\setminus R_{P,\min}$ est convexe.
		\item Tout d'abord, si $P$ n'a qu'une seule racine alors il n'y a rien à montrer. Supposons que $P$ a au moins deux racines distinctes. $\exists Q\in \C[X],\ n(n-1)P=QP''$ avec $n=\deg(P)$ (de manière à ce que $Q$ soit unitaire). De plus, $(P\ne 0\land P''|P)\implies P''\ne 0$. Donc $n\geq 2$ et $\deg(Q)=2$.\\
		On dérive $\displaystyle\frac{P'}{P}$ sur $\R$ :\\
		$\forall x\in \R,\ \displaystyle\frac{P''(x)P(x)-P'(x)^2}{P(x)^2}=\frac{\frac{n(n-1)P(x)^2}{Q(x)}-P'(x)^2}{P(x)^2}=\frac{n(n-1)}{Q(x)}-\left(\frac{P'(x)}{P(x)}\right)^2=-\sum\limits_{k=1}^r\frac{n_k}{(x-z_k)^2}$.\\
		$\iff \forall x\in \R,\ \displaystyle\sum\limits_{k=1}^r\frac{n_k}{(x-z_k)^2}=\left(\sum\limits_{k=1}^r{\frac{n_k}{x-z_k}}\right)^2-\frac{n(n-1)}{Q(x)}$.\\\\
		Soit $p\in \crblanc{1}{r}$. On multiplie dans la relation par $(x-z_p)^2$ puis on l'évalue en $x=z_p$:\\\\
		Si $z_p$ n'est pas racine double de $Q$ alors, $n_p=n_p^2$ d'où $n_p=1$ car $n_p>0$.\\
		Et si $z_p$ est racine double de $Q$ alors $Q=(X-z_p)^2$ et, $n_p(n_p-1)=n(n-1)$ d'où $n_p=n$ ce qui est absurde car dans ce cas $z_p$ est la seule racine de $P$.\\
		On en déduit que $P$ est scindé à racines simples.\\
		D'après la question $1$, $R_{P'}\subset$ Conv$(R_{P,\min})$. De plus, comme $P$ est à racines simples, aucune racine de $P'$ n'est racine de $P$. On a donc $R_{P'}\subset B=\text{Conv}(R_{P,\min})\setminus R_{P,\min}$ puis $R_{P''}\subset \text{Conv}(R_{P'})\subset \text{Conv}(B)=B$ puisque $B$ est convexe.\\
		D'autre part, $|R_{P''}|=|R_P|-2$ et $P''|P\implies R_{P''}\subset R_P$.\\
		Ainsi, il y a au moins $n-2$ éléments de $R_P$ qui ne sont pas dans $R_{P,\min}$, c'est à dire qu'il y a au plus deux racines de $P$ qui sont dans $R_{P,\min}$, c'est à dire qu'il y a exactement deux racines de $P$ qui permettent d'exprimer chaque racine de $P$ comme barycentre à coefficients positifs d'elles mêmes (il ne peut pas en avoir une seule car on a vu que $|R_{P,\min}|>1$).\\
		Ceci montre que les racines de $P$ sont alignées.
		\item La réciproque est fausse en général. Tous les polynômes à racines réelles ont leur racines alignées (sur la droite des réels), il suffit donc de trouver un contre exemple parmi ces polynômes.\\
		On prend $P=X^2(X-1)=X^3-X^2$. $P''=6X-2$ ne divise pas $P$.
	\end{enumerate}
	
	\subsection{Graphe d'un polynôme \telecom{2}}
	\label{sec:graphe-d'un-polynôme}
	\textcolor{blue}{\hyperref[Graphe d'un polynôme]{[Enoncé]}}\\
	Notons $G=\{(x,P(x)),\ x\in \R\}$ le graphe de $P$. Soient $((x_i,y_i))_{0\leq i\leq n}\in G^{n+1}$ distincts et alignés. Par hypothèse il existe une droite passant par tous ces points. Notons $y=ax+b$ l'équation de cette droite.\\
	$\forall i\in \crblanc{0}{n},\ P(x_i)=y_i=ax_i+b$. Donc le polynôme $P-aX-b$ a $n+1$ racines distinctes. Ceci est absurde car $\deg(P-aX-b)=n$.
	
	\subsection{Polynômes qui commutent avec cosinus \centraleponts{3}}
	\label{sec:polynomes-qui-commutent-avec-cosinus-etoile3}
	\textcolor{blue}{\hyperref[polycommutecos]{[Enoncé]}}\\
	On note $(*):\forall x\in \R,\ P(\cos(x))=\cos(P(x))$
	\begin{enumerate}
		\item Notons $\lambda\in \R$ tel que $P(X)=\lambda$.\\
		En évaluant $(*)$ en n'importe quel point on obtient $\lambda=\cos(\lambda)$.
		Posons $f:x\mapsto x-\cos(x)$. $f$ est dérivable sur $\R$ et,
		$$\forall x\in \R,\ f'(x)=1-\sin(x)\geq 0$$
		De plus, il n'y a égalité que sur un nombre dénombrable de points donc $f$ est strictement croissante sur $\R$.\\
		$\lim\limits_{-\infty}{f}=-\infty<0<+\infty=\lim\limits_{+\infty}{f}$ donc d'après le théorème de la bijection, $\exists!\ \lambda\in \R,\ f(\lambda)=0 \text{ i.e }\cos(\lambda)=\lambda$.
		\item Notons $P(X)=aX+b$ avec $a\ne 0$.\\
		On dérive deux fois la relation $(*),\forall x\in \R$:
		\begin{align*}
			-a\sin(x)&=-a\sin(ax+b)\\
			\iff \sin(x)&=\sin(ax+b)\ \ \ \ \ \ \ (\text{car }a\ne 0)
		\end{align*}
		puis :
		$$\cos(x)=a\cos(ax+b)\overset{(*)}{=}a^2\cos(x)+ab$$
		Donc $(**):\forall x\in \R,\ (a^2-1)\cos(x)=ab$
		D'où $a^2-1=0$ c'est à dire $a=1$ ou $a=-1$.\\
		En reportant dans $(**)$ on a $ab=0$. Or $a\ne 0$ donc on en déduit que $b=0$.\\
		On vérifie alors que $a=1$, qui donne $P=X$, fonctionne et $a=-1$, qui donne $P=-X$, ne fonctionne pas.
		\item Supposons que $\deg(P)\geq 2$.\\
		En dérivant $(*)$:
		$$(*'): \forall x\in \R,\ -\sin(x)P'(\cos(x))=-P'(x)\sin(P(x))$$
		$\cos(\R)=[-1,1]$ et $x\mapsto P'(x)$ est continue sur $[-1,1]$ donc d'après le théorème des bornes atteintes, $x\mapsto P'(\cos(x))$ est bornée sur $\R$. Ainsi le membre de gauche de $(*')$ est borné sur $\R$. Notons $M\in \R^+$ tel que $\forall x\in \R,\ |\sin(x)P'(\cos(x))|\leq M$. $\deg(P)\geq 2$ assure que $|P'(x)|\underset{x\to +\infty}{\longrightarrow}+\infty$, on peut alors se donner $A>0$ tel que $\forall x>A, |P'(x)|>M$.\\
		Enfin $x\mapsto P(x)$ est continue sur $\R$ et $P(x)\underset{x\to +\infty}{\longrightarrow}\pm\infty$ donc $P(]A,+\infty[)\ \bigcap\ \displaystyle\frac{\pi}{2}+ \pi\Z\ne \emptyset$ ce qui permet d'assurer l'existence de $x_0>A$ tel que $|\sin(P(x_0))|=1$ de sorte que $M<|P'(x_0)\sin(P(x_0))|=|\sin(x_0)P'(\cos(x_0))|\leq M$.\\
		Ceci est absurde donc les seuls polynômes solutions sont $P=X$ et $P=\lambda$.
	\end{enumerate}
	
	\subsection{Relation trigonométrique polynomiale \etoile{3}}
	\label{sec:relation-trigonometrique-polynomiale-etoile3}
	\textcolor{blue}{\hyperref[relationtrigopoly]{[Enoncé]}}\\
	soit $P\in \R[X]$ vérifiant $(0):\forall t\in \R,P(\cos t)+P(\sin t)=1$. Fixons $t\in \R$\\
	$(1): P(\cos(-t))+P(\sin(-t))=P(\cos t)+P(-\sin t)=1$\\
	Donc $(1)-(0): P(-\sin t)=P(\sin t)$\\
	Ainsi, $\forall x\in [-1,1],\ P(-x)=P(x)$. Comme $[-1,1]$ est infini, $P(-X)=P(X)$. Donc $P$ est pair c'est à dire $P\in \R[X^2]$ c'est à dire $\exists Q\in \R[X],\ P(X)=Q(X^2)$.\\
	Alors $P(\cos t)+P(\sin t)=1\iff Q(\cos^2 t)+Q(\sin^2 t)=1\iff Q(\cos^2 t)+Q(1-\cos^2 t)=1$.\\
	Ainsi, $\forall x\in [0,1],\ Q(x)+Q(1-x)=1$. Donc $(2): Q(X)+Q(1-X)=1$.\\
	Posons $R(X)=Q(X+1/2)-1/2$.\\
	$(2)\iff R(X)+R(-X)=Q(1/2+X)+Q(1/2-X)-1=Q(1/2+X)+Q(1-(1/2+X))-1=1-1=0$. donc $R$ est impair c'est à dire $R\in X\R[X^2]$ c'est à dire $\exists S\in \R[X],\ R(X)=XS(X^2)$.
	En reportant jusqu'à revenir à $P$ on a obtenu qu'il existe $S\in \R[X]$ tel que :
	$$P(X)=\left(X^2-\displaystyle\frac{1}{2}\right)S\left[\left(X^2-\displaystyle\frac{1}{2}\right)^2\right]+\displaystyle\frac{1}{2}$$
	Réciproquement, fixons $S\in \R[X]$ et posons $P(X)=\left(X^2-\displaystyle\frac{1}{2}\right)S\left[\left(X^2-\displaystyle\frac{1}{2}\right)^2\right]+\displaystyle\frac{1}{2}$.\\\\
	$\forall t\in \R,\ P(\cos t)+P(\sin t)=1+\left(\cos^2 t-\displaystyle\frac{1}{2}\right)S\left[\left(\cos^2 t-\displaystyle\frac{1}{2}\right)^2\right]+\left(\sin^2 t-\displaystyle\frac{1}{2}\right)S\left[\left(\sin^2 t-\displaystyle\frac{1}{2}\right)^2\right]$\\
	Or on remarque que $\left(\cos^2 t-\displaystyle\frac{1}{2}\right)^2-\left(\sin^2 t-\displaystyle\frac{1}{2}\right)^2=(\cos^2 t+\sin^2 t-1)(\cos^2 t-\sin^2 t)=0$.\\
	Donc $\forall t\in \R,\ P(\cos t)+P(\sin t)=1+(\cos^2 t+\sin^2 t-1)S\left[\left(\sin^2 t-\displaystyle\frac{1}{2}\right)^2\right]=1$.\\\\\\
	Ainsi l'ensemble des solutions de $(0)$ est $\mathcal{E}=\left\{\left(X^2-\displaystyle\frac{1}{2}\right)S\left[\left(X^2-\displaystyle\frac{1}{2}\right)^2\right]+\displaystyle\frac{1}{2},\ S\in \R[X]\right\}$.
	
	\subsection{Division euclidienne (1) \ccinp{1}}
	\label{sec:division-euclidienne-(1)}
	\textcolor{blue}{\hyperref[Division euclidienne (1)]{[Enoncé]}}\\
	Notons $P=X^{42}+X^{1729}+X^{11\, 111}$ et $A=X^2+X+1$. On écrit $P=AQ+R$ la division euclidienne de $P$ par $A$. On montre classiquement que $A=(X-j)(X-\overline j)$ avec $j=e^{2i\pi/3}$, vérifiant $j^3=1$.\\
	En évaluant en $j$ on obtient $aj+b=R(j)=j^{3\times 14}+j^{1728+1}+j^{11\,112-1}=1+j+j^{-1}=1+j+j^2=0$.\\
	On en déduit $R(\overline j)=P(\overline j)=\overline{P(j)}=0$. $R$ est de degré au plus $1$ et a deux racines, c'est donc le polynôme nul.\\
	Autrement dit $X^2+X+1|X^{42}+X^{1729}+X^{11\, 111}$.
	
	\subsection{Division euclidienne (2) \ccinp{1}}
	\label{sec:division-euclidienne-(2)}
	\textcolor{blue}{\hyperref[Division euclidienne (2)]{[Enoncé]}}\\
	Notons $P=(\cos\theta+X\sin(\theta))^n$ et $A=X^2+1$. On écrit $P=AQ+R$ la division euclidienne de $P$ par $A$ avec $R=aX+b\in \R[X]$. En évaluant en $i$ on obtient $ai+b=e^{in\theta}$ d'où $a=\cos(n\theta)$ et $b=\sin(n\theta)$.
	
	\subsection{Fonctions trigonométriques polynomiale ? \ccinp{1}}
	\label{sec:fonctions-trigonométriques-polynomiales-?}
	\textcolor{blue}{\hyperref[Fonctions trigonométriques polynomiales ?]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item \underline{$1^{\T{ère}}$ méthode :} Sur $\R$\\
		$\cos$ est bornée donc si c'était une fonction polynomiale, elle serait constante ce qui n'est pas le cas.\\
		\underline{$2^{\T{nd}}$ méthode :} Sur $\R$\\
		$\cos$ n'est pas identiquement nulle et s'annule une infinité de fois sur $\R$.\\
		\underline{$3^{\T{ème}}$ méthode :} Sur un intervalle d'intérieur non vide quelconque\\
		$\cos''=-\cos$ donc si c'était une fonction polynomiale, elle serait identiquement nulle (pour des raisons de degrés) ce qui n'est pas le cas.
		\item Soit $P$ un éventuel polynôme égal à $\tan$ sur un intervalle d'intérieur non vide $I$. $P$ n'est pas constant car $\tan$ est injective sur $I$.\\
		En dérivant $P'=1+P^2$. Pourtant $\deg(P')<\deg(P)\leq \deg(P^2)=\deg(1+P^2)$.
	\end{enumerate}
	
	\subsection{Logarithme rationnel ? \telecom{2}}
	\label{sec:logarithme-rationnel-?}
	\textcolor{blue}{\hyperref[Logarithme rationnel ?]{[Enoncé]}}\\
	\underline{$1^{\T{ère}}$ solution:} par le degré\\
	Supposons qu'une telle fraction rationnelle $R=\displaystyle\frac{P}{Q}$ existe.\\
	$R'(X)=\displaystyle\frac{1}{X}\iff \displaystyle\frac{P'(X)Q(X)-P(X)Q'(X)}{Q(X)^2}=\displaystyle\frac{1}{X}\iff X(P'(X)Q(X)-P(X)Q'(X))=Q(X)^2$.\\
	Donc \begin{align*}
		2\deg(Q)&=\deg(Q^2)\\
		&=\deg(X(P'(X)Q(X)-P(X)Q'(X)))\\
		&=1+\deg(P'(X)Q(X)-P(X)Q'(X))\\
		&\leq 1+\max(\deg(P'Q),\deg(QP'))\\
		(P,Q\text{ ne peuvent pas être tous les deux constants})&= 1+\deg(P)+\deg(Q)-1=\deg(P)+\deg(Q).
	\end{align*}
	On en déduit que $\deg(Q)\leq \deg(P)$ et donc que $R\in \K[X]$.\\
	Mais alors $R'\in \K[X]$ ce qui est absurde donc il n'existe pas de fraction rationnelle dont la dérivée vaut $\displaystyle\frac{1}{X}$.\\
	\textit{Cette solution a pour avantage d'être assez élémentaire, toutefois elle ne s'adapte pas vraiment à des fractions rationnelles plus sophistiqués que $\displaystyle\frac{1}{X}$.}\\
	
	\underline{$2^{\T{nd}}$ solution:} par l'étude de fonction\\
	Supposons qu'une telle fraction rationnelle $R$ existe.\\
	Notons $z$ un pôle de $R$ de module maximal.
	$\forall x>|z|,\ R'(x)=\displaystyle\frac{1}{x}$.\\
	Donc, $\exists C\in \C,\forall x>|z|,\ R(x)=\ln(x)+C$.\\
	Alors $\lim\limits_{x\to +\infty}{R(x)}=+\infty$ ce qui implique $\deg(R)>0$ et $\lim\limits_{x\to +\infty}{\displaystyle\frac{R(x)}{x}}=0$ ce qui implique $\deg\left(\displaystyle\frac{R(X)}{X}\right)<0$ c'est à dire $\deg(R)<1$.\\
	Ceci est absurde donc il n'existe pas de fraction rationnelle dont la dérivée vaut $\displaystyle\frac{1}{X}$.\\
	\textit{Cette solution, bien que très différente de la précédente, possède le même défaut que celle-ci pour ce qui est d'essayer de généraliser l'exercice...}\\
	
	\underline{$3^{\T{ème}}$ solution:} par l'étude de la multiplicité de $0$\\
	Supposons qu'une telle fraction rationnelle $R=\displaystyle\frac{P}{Q}$ avec $P\land Q=1$ existe.\\
	$R'(X)=\displaystyle\frac{1}{X}\iff \displaystyle\frac{P'(X)Q(X)-P(X)Q'(X)}{Q(X)^2}=\displaystyle\frac{1}{X}\iff X(P'(X)Q(X)-P(X)Q'(X))=Q(X)^2:(*)$\\
	Donc $X|Q^2$ et d'après le lemme d'Euclide, $X|Q$. Notons $m$ la multiplicité de $0$ en tant que racine de $Q$. On a montré que $m\geq 1$.\\
	Ensuite, intéressons nous à la multiplicité de $0$ dans $P'Q-PQ'$. D'une part, puisque $P\land Q=1,\ P(0)\ne 0$ et donc la multiplicité de $0$ dans $PQ'$ est $m-1$. D'autre part la multiplicité de $0$ dans $P'Q$ est supérieure à $m$. Donc la multiplicité de $0$ dans $P'Q-PQ'$ est $m-1$.\\
	Finalement d'après la relation $(*),\ 1+m-1=2m$ c'est à dire $m=0$.\\
	Ceci est absurde donc il n'existe pas de fraction rationnelle dont la dérivée vaut $\displaystyle\frac{1}{X}$.\\
	\textit{Cette solution a pour mérite de s'adapter à toutes les fractions rationnelles qui possèdent un pôle simple ! Il suffit d'étudier la multiplicité de ce pôle (au lieu de $0$ ici).}
	
	\subsection{Une fraction rationnelle}
	\label{sec:une-fraction-rationnelle}
	\textcolor{blue}{\hyperref[fractionrationnelle]{[Enoncé]}}\\
	
	\subsection{Dérivé d'un polynôme scindé sur $\R$ \centraleponts{3}}
	\label{sec:dérivé-d'un-polynôme-scindé-sur-R}
	\textcolor{blue}{\hyperref[Dérivé d'un polynôme scindé sur R]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item Notons $x_1<\dots<x_r$ les racines distinctes de $P$.
		Soit $i\in \crblanc{1}{r-1}$. On sait que $x_i$ est racine de $P'$ de multiplicité $m_i-1$ (en considérant que $x_i$ n'est pas racine de $P'$ si $m_i-1=0$).\\
		De plus $x_i<x_{i+1},\ P(x_i)=0=P(x_{i+1}) \text{ et }x\mapsto P(x)$ est continue sur $[x_i,x_{i+1}]$ et dérivable sur $]x_i,x_{i+1}[$. Donc d'après le théorème de Rolle, $\exists y_i\in ]x_i,x_{i+1}[,\ P'(y_i)=0$. De par la définition des $y_i$ on a $y_1<\dots<y_{r-1}$.\\
		On a donc trouvé $r-1+\displaystyle\sum\limits_{i=1}^r{(m_i-1)}=\deg(P)-1$ racines de $P'$, comptées avec multiplicité.\\
		Comme $1\leq\deg(P')=\deg(P)-1$, $P'$ n'a pas d'autre racine. Elles sont donc bien toutes réelles.
		\item On pose $f:t\mapsto P(t)e^{\alpha t}$.\\
		$\forall t\in \R,\ f'(t)=0\iff (P'(t)+\alpha P(t))e^{\alpha t}=0\iff P'(t)+\alpha P(t)=0$.\\
		On fait la même preuve que pour la question 1 en appliquant Rolle à $f$ entre deux racines consécutives de $P$.
	\end{enumerate}
	
	\subsection{Une condition nécessaire pour qu'un polynôme soit scindé sur $\R$ \centraleponts{3}}
	\label{sec:une-condition-nécessaire-pour-qu'un-polynôme-soit-scindé-sur-R}
	\textcolor{blue}{\hyperref[Une condition nécessaire pour qu'un polynôme soit scindé sur R]{[Enoncé]}}\\
	\begin{enumerate}
		\item On écrit $P=\Lambda\displaystyle\prod\limits_{i=1}^r{(X-x_i)^{m_i}}$, où $S=\{x_i,i\in \crblanc{1}{r}\}$ est l'ensemble des racines de $P$.\\
		On sait alors que $\displaystyle\frac{P'}{P}=\displaystyle\sum\limits_{i=1}^r{\displaystyle\frac{m_i}{X-x_i}}$ et par dérivation, $\forall x\in \R\setminus S,\ \displaystyle\frac{P''(x)P(x)-(P'(x))^2}{(P(x))^2}=\displaystyle\sum\limits_{i=1}^r{-\displaystyle\frac{m_i}{(x-x_i)^2}}\leq 0$.\\\\
		c'est à dire $\forall x\in \R\setminus S,\ P''(x)P(x)-(P'(x))^2\leq 0$.\\
		L'inégalité est trivialement vérifiée sur $S$.
		\item \underline{\textbf{Première méthode: théorème de Rolle}}\\
		\underline{Initialisation:}\\
		Quitte à réindicer on peut supposer $x_1<\dots<x_r$.
		Soit $i\in \crblanc{1}{r-1}$. On sait que $x_i$ est racine de $P'$ de multiplicité $m_i-1$ (en considérant que $x_i$ n'est pas racine de $P'$ si $m_i-1=0$).\\
		De plus $x_i<x_{i+1},P(x_i)=0=P(x_{i+1}) \text{ et }x\mapsto P(x)$ est continue sur $[x_i,x_{i+1}]$ et dérivable sur $]x_i,x_{i+1}[$ donc d'après le théorème de Rolle, $\exists y_i\in ]x_i,x_{i+1}[,\ P'(y_i)=0$. De par la définition des $y_i$ on a $y_1<\dots<y_{r-1}$.\\
		On a donc trouvé $r-1+\displaystyle\sum\limits_{i=1}^r{(m_i-1)}=\deg(P)-1$ racines de $P'$, comptées avec multiplicité.\\
		Comme $\deg(P')\leq \deg(P)-1$, $P'$ n'a pas d'autre racine. Elles sont donc bien toutes réelles.\\
		\underline{Hérédité:}\\
		Soit $k\in \crblanc{1}{n-2}$ tel que $P^{(k)}$ n'ai que des racines réelles. En appliquant le résultat précédant à $P^{(k)}$ on obtient directement le résultat voulu.\\
		\underline{Conclusion}: Pour tout $k\in \crblanc{1}{n-1}$, $P^{(k)}$ est à racines réelles.\\\\
		\underline{\textbf{Deuxième méthode: théorème de Gauss-Lucas}}\\
		l'exercice \ref{Gauss-Lucas} montre que si $P$ est à racines réelles alors $P'$ l'est aussi. Une récurrence similaire à celle de l'autre méthode permet de conclure.
		\item On applique le résultat de la question $1$ à $P,P',\dots,P^{(n-1)}$:
		$$\forall x\in \R,\forall k\in \crblanc{1}{n-1},\ P^{(k+1)}(x)P^{(k-1)}(x)-(P^{(k)}(x))^2\leq 0$$
		En particulier d'après la formule de Taylor, pour $x=0$:
		\begin{align*}
			\forall k\in \crblanc{1}{n-1},\ (k+1)!\ a_{k+1}\cdot (k-1)!\ a_{k-1}&\leq (k!)^2a_k^2\\
			\iff a_{k+1}a_{k-1}\displaystyle\frac{k+1}{k}&\leq a_k^2
		\end{align*}
		Enfin si $a_{k+1}a_{k-1}\leq 0$, l'inégalité est trivialement vérifiée,\\
		et si $a_{k+1}a_{k-1}>0$ alors $\displaystyle\frac{k+1}{k}\geq 1\implies a_{k+1}a_{k-1}\leq a_{k+1}a_{k-1}\displaystyle\frac{k+1}{k}\leq a_k^2$.
	\end{enumerate}
	
	\subsection{Une condition nécessaire pour qu'un polynôme soit dissocié sur $\R$ \telecom{2}}
	\label{sec:une-condition-nécessaire-pour-qu'un-polynôme-soit-dissocié-sur-R}
	\textcolor{blue}{\hyperref[Une condition nécessaire pour qu'un polynôme soit dissocié sur R]{[Enoncé]}}\\
	\begin{enumerate}
		\item Notons $x_1<\dots<x_r$ les racines distinctes de $P$.
		Soit $i\in \crblanc{1}{r-1}$. On sait que $x_i$ est racine de $P'$ de multiplicité $m_i-1$ (en considérant que $x_i$ n'est pas racine de $P'$ si $m_i-1=0$).\\
		De plus $x_i<x_{i+1},\ P(x_i)=0=P(x_{i+1}) \text{ et }x\mapsto P(x)$ est continue sur $[x_i,x_{i+1}]$ et dérivable sur $]x_i,x_{i+1}[$. Donc d'après le théorème de Rolle, $\exists y_i\in ]x_i,x_{i+1}[,\ P'(y_i)=0$. De par la définition des $y_i$ on a $y_1<\dots<y_{r-1}$.\\
		On a donc trouvé $r-1+\displaystyle\sum\limits_{i=1}^r{(m_i-1)}=\deg(P)-1$ racines de $P'$, comptées avec multiplicité.\\
		Comme $1\leq\deg(P')=\deg(P)-1$, $P'$ n'a pas d'autre racine. Elles sont donc bien toutes réelles.
		\item On remarque que $\forall k\in \crblanc{0}{n-1},\ a_k^2+a_{k+1}^2>0\iff (a_k\ne 0\T{ ou }a_{k+1}\ne 0)$.\\
		Par la formule de Taylor $\forall k\in\crblanc{0}{n},\ a_k=\dfrac{P^{(k)}(0)}{k!}$. Donc si il existe $k\in \crblanc{0}{n-1}$ tel que $a_k=a_{k+1}$, alors $P^{(k)}(0)=P^{(k+1)}(0)=0$. Autrement dit $0$ est racine double de $P^{(k)}$.\\
		Pourtant par une récurrence immédiate sur la question 1, $P$ scindé à racines simples sur $\R$ donne $P^{(k)}$ scindé à racines simples sur $\R$ pour tout $k<\deg(P)$.
	\end{enumerate}
	
	\subsection{Suite de polynômes scindés sur $\R$ \xens{3}}
	\label{sec:suite-de-polynômes-scindés-sur-R}
	\textcolor{blue}{\hyperref[Suite de polynômes scindés sur R]{[Enoncé]}}\\
	Notons pour $n\in \N,\ P_n=\displaystyle\prod_{k=1}^{d_n}(X-x_{n,k})$.\\
	Alors $\forall n\in \N,\ \forall z\in \C,\ |P_n(z)|=\displaystyle\prod_{k=1}^{d_n}|z-x_k|\geq\prod_{k=1}^{d_n}|\T{Im}(z-x_k)|=\prod_{k=1}^{d_n}|\T{Im}(z)|\geq \min(|\T{Im}(z)|^n,|\T{Im}(z)|)$.\\
	Donc en passant à la limite, $\forall z\in \C,\ |P(z)|\geq \min(|\T{Im}(z)|^n,|\T{Im}(z)|)$.\\
	En particulier $\forall z\in \C,\ P(z)=0\implies \T{Im}(z)=0$. Donc $P$ est constant ou scindé sur $\R$. Or si $P=C$ est constant alors $z=i(1+|C|)$ contredit l'inégalité.
	
	\subsection{Borne de Cauchy \telecom{2}}
	\label{sec:borne-de-cauchy}
	\textcolor{blue}{\hyperref[Borne de Cauchy]{[Enoncé]}}\\
	Soit $z$ une racine de $P$. Si $|z|\leq 1$ il n'y a rien à faire, on suppose donc $|z|>1$. Notons $M=\max\limits_{0\leq k\leq n-1}|a_k|$.\\
	On a avec $|z|\ne 1$, $|z^n|=\displaystyle\left|-\sum_{k=0}^{n-1}a_kz^k\right|\leq \sum_{k=0}^{n-1}|a_k|z^k\leq M\sum_{k=0}^{n-1}|z|^k=M\frac{|z|^n-1}{|z|-1}$.\\
	Or comme $|z|>1$, $\dfrac{|z|^n-1}{|z|-1}\leq \dfrac{|z|^n}{|z|-1}$ donc $1\leq \dfrac{M}{|z|-1}$ càd $|z|\leq 1+\max\limits_{0\leq k\leq n-1}|a_k|$.
	
	\subsection{Théorème d'Eneström-Kakeya \centraleponts{3}}
	\label{sec:théorème-d'eneström-kakeya}
	\textcolor{blue}{\hyperref[Théorème d'Eneström-Kakeya]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item Soit $z\in \C$ une racine de $P$. $P(0)=a_0\ne0$ donc $z\ne 0$. On pose en suivant l'indication $Q(X)=(X-1)P(X)$.\\
		$Q(z)=0\implies 0=a_nz^{n+1}+\displaystyle\sum_{k=1}^n(a_{k-1}-a_k)z^k-a_0\implies a_n=\sum_{k=1}^n\frac{a_{k-1}-a_k}{z^{n+1-k}}+\frac{a_0}{z^{n+1}}$.\\
		D'où $a_n\leq \displaystyle\sum_{k=1}^n\frac{a_k-a_{k-1}}{|z|^{n+1-k}}+\frac{a_0}{|z^{n+1}|}$. Si $|z|>1$ alors $a_n<\displaystyle\sum_{k=1}^n(a_k-a_{k-1})+a_0=a_n$.\\
		Ceci est absurde donc $|z|\leq 1$.
		\item On définit $r$ et $R$ comme dans l'énoncé. Montrons que $\tilde P=P(RX)=\displaystyle\sum_{k=0}^na_kR^kX^k$ vérifie les hypothèses de la question 1. Notons pour $k\in \crblanc{0}{n},\ b_k=a_kR^k$ et fixons $k\in \crblanc{0}{n-1}$.\\
		$b_{k+1}-b_k=R^k(a_{k+1}R-a_k)\geq R^k\left(a_{k+1}\dfrac{a_k}{a_{k+1}}-a_k\right)=0$.\\
		Soit $z$ une racine de $P$. Alors $\tilde P\left(\dfrac{z}{R}\right)=P(z)=0$.\\
		Donc d'après la question 1, $\left|\dfrac{z}{R}\right|\leq 1$ càd $|z|\leq R$.\\
		Pour avoir la minoration on considère le polynôme réciproque de $P$, $Q=X^nP\left(\dfrac{1}{X}\right)$ (cf. \ref{Polynôme réciproque}). On montre alors que $Q=\displaystyle\sum_{k=0}^na_{n-k}X^k$ et que ses racines sont exactement les inverses des racines de $P$. Similairement à ce qu'on vient de faire que le polynôme $\tilde Q=Q\left(\dfrac{X}{r}\right)$ les hypothèses de la question 1 et donc ses racines sont de module au plus $\dfrac{1}{r}$. Ainsi les racines de $P$ sont de module au moins $r$.
	\end{enumerate}
	
	\subsection{Perturbations de polynômes}
	\label{sec:pertubations-de-polynômes}
	\textcolor{blue}{\hyperref[Pertubations de polynômes]{[Enoncé]}}\\
	
	\subsection{Polynômes à coefficients dans $\{-1,0,1\}$}
	
	
	\subsubsection{Polynômes scindés}
	\label{sec:polynômes-scindés}
	\textcolor{blue}{\hyperref[Polynômes scindés]{[Enoncé]}}\\
	
	\subsubsection{Ensemble des racines (1)}
	\label{sec:ensemble-des-racines-(1)}
	\textcolor{blue}{\hyperref[Ensemble des racines (1)]{[Enoncé]}}\\
	
	\subsubsection{Ensemble des racines (2)}
	\label{sec:ensemble-des-racines-(2)}
	\textcolor{blue}{\hyperref[Ensemble des racines (2)]{[Enoncé]}}\\
	
	\subsection{Théorème de Bernstein \centraleponts{4}}
	\label{sec:theoreme-de-bernstein}
	\textcolor{blue}{\hyperref[Théorème de Bernstein]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item Remarquons que $1$ est racine de $P(\lambda X)-P(\lambda)$ donc $Q_\lambda$ est un polynôme et de plus $$Q_\lambda(1)=\lim\limits_{z\to 1}\dfrac{P(\lambda z)-P(\lambda)}{z-1}=P(\lambda X)'(1)=\lambda P'(\lambda)$$
		Les racines de $X^n+1$ sont les racines $n$-ième de $-1$, $X^n+1$ est donc scindé à racines simples. Par conséquent il existe des complexes $\alpha_{\lambda,1},\dots,\alpha_{\lambda,n}$ tels que $\displaystyle\frac{Q_\lambda(X)}{X^n+1}=\sum_{k=1}^n\frac{\alpha_{\lambda,k}}{X-\zeta_k}$. On a $\alpha_{\lambda,k}=\displaystyle\lim_{\zeta\to\zeta_k}\frac{(\zeta-\zeta_k)Q_\lambda(\zeta_k)}{\zeta^n+1}=\frac{Q_\lambda(\zeta_k)}{(X^n+1)'(\zeta_k)}=\frac{Q_\lambda(\zeta_k)}{n\zeta^{n-1}}=-\frac{\zeta_k(P(\lambda\zeta_k)-P(\lambda))}{n(\zeta_k-1)}$.\\
		Ainsi $\displaystyle\frac{Q_\lambda(X)}{X^n+1}=\frac{1}{n}\sum_{k=1}^n\frac{\zeta_k(P(\zeta_k\lambda)-P(\lambda))}{(\zeta_k-1)(\zeta_k-X)}$.\\
		En particulier $\lambda P'(\lambda)=Q_\lambda(1)=\displaystyle\frac{2}{n}\sum_{k=1}^n\frac{\zeta_kP(\zeta_k\lambda)}{(\zeta_k-1)^2}-\dfrac{2}{n}P(\lambda)\sum_{k=1}^n\frac{\zeta_k}{(\zeta_k-1)^2}$.
		\item On applique la question 2 à $P=X^n$ :
		$$n\lambda^n=\frac{2}{n}\left(\sum_{k=1}^n\frac{\zeta_k(\zeta_k^n\lambda^n-\lambda^n)}{(\zeta_k-1)^2}\right)=-\frac{4}{n}\sum_{k=1}^n\frac{\zeta_k\lambda^n}{(\zeta_k-1)^2}$$
		D'où en évaluant en $\lambda=1$ :
		$$\sum_{k=1}^n\frac{\zeta_k}{(\zeta_k-1)^2}=-\frac{n^2}{4}$$
		En remplaçant dans le résultat de la question 2, comme $\C$ est infini on obtient l'égalité des polynômes :
		$$XP'(X)=\displaystyle\frac{n}{2}P(X)+\frac{2}{n}\sum_{k=1}^n\frac{\zeta_kP(\zeta_kX)}{(\zeta_k-1)^2}$$
		\item Soit $z\in \U$.\\
		$|P'(z)|=|zP'(z)|\leq \displaystyle\frac{n}{2}|P(z)|+\frac{2}{n}\sum_{k=1}^n\frac{|P(\zeta_kz)|}{|\zeta_k-1|^2}\leq \left(\frac{n}{2}+\frac{2}{n}\sum_{k=1}^n\frac{1}{|\zeta_k-1|^2}\right)\sup_{z\in \U}|P(z)|$.\\
		Or $\forall k\in \crblanc{1}{n},\ \zeta_k\in \U\implies \displaystyle\frac{\zeta_k}{(\zeta_k-1)^2}=\frac{1}{(1-\zeta_k^{-1})(\zeta_k-1)}=-\frac{1}{(\overline{\zeta_k}-1)(\zeta_k-1)}=-\frac{1}{|\zeta_k-1|^2}$.\\
		Et finalement $\displaystyle\sup_{z\in \U}|P'(z)|\leq \left(\frac{n}{2}+\frac{2}{n}\cdot\frac{n^2}{4}\right)\sup_{z\in \U}|P(z)|=n\sup_{z\in \U}|P(z)|$.
	\end{enumerate}
	
	\subsection{Etude d'un polynôme défini implicitement}\label{sec:etude-dun-polynome-defini-implicitement}
	\textcolor{blue}{\hyperref[etudepolyimplicite]{[Enoncé]}}\\
	
	\subsection{P'|P \telecom{1}}
	\label{sec:P'|P}
	\textcolor{blue}{\hyperref[P'|P]{[Enoncé]}}\\
	Soit $P\in \C[X]$ tel que $P'|P$. Tout d'abord si $P'=0$ alors $P'|P$ si et seulement si $P=0$. On suppose maintenant que ce n'est pas le cas. Notons $P=\displaystyle\prod\limits_{i=1}^n\left(X-z_i\right)^{m_i}$ où $m_i$ est la multiplicité de $z_i$ en tant que racines de $P$. Alors pour tout $i\in \crblanc{1}{n}$, la multiplicité de $z_i$ en tant que racine de $P'$ est $m_i-1$ (en considérant que $z_i$ n'est pas racine si sa multiplicité est nulle).\\
	On sait que $P'$ n'a pas d'autre racine que celles de $P$ donc $\deg(P')=\deg(P)-1=\displaystyle\sum\limits_{i=1}^n(m_i-1)=\sum\limits_{i=1}^nm_i-n=\deg(P)-n$. On en déduit que $n=1$ : $P$ n'a qu'une racine.\\
	Réciproquement si il existe $\lambda\in \C,\ a\in \C^*$ et $n\in \N^*$ tels que $P=a\left(X-\lambda\right)^n$ alors $P'=an\left(X-\lambda\right)^{n-1}$ divise $P$.\\
	Finalement, $P'|P\iff \exists (a,\lambda)\in \C^2,\ \exists n\in \N^*,\ P=a\left(X-\lambda\right)^n$.
	
	\subsection{Polynôme positif (1) \centraleponts{3}}
	\label{sec:polynôme-positif-(1)}
	\textcolor{blue}{\hyperref[Polynôme positif (1)]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item Il est clair que $P$ et $Q$ ont même degré et même coefficient dominant $\lambda\ne 0$. On a $P(x)\uxfty\sim\lambda x^n$ donc comme $P$ est positif, $\lambda x^n$ est positif au voisinage de $+\infty$ d'où $\lambda>0$. De plus, si $P$ était de degré impair alors $P(x)\underset{x\to-\infty}{\sim}\lambda x^n\implies \lim\limits_{x\to-\infty}P(x)=-\infty$ ce qui est absurde. Donc $P$, et a fortiori $Q$, sont de degré pair. L'équivalent $Q(x)\underset{|x|\to+\infty}{\sim}\lambda x^n$ donne alors $\lim\limits_{|x|\to+\infty} Q(x)=+\infty$.
		\item D'après la question 1 il existe $R>0$ tel que $\forall x\in \R,\ |x|>R\implies Q(x)\geq Q(0)$. Or $Q$ est continue donc d'après le théorème des bornes atteintes $Q$ admet un minimum $m$ sur $[-R,R]$. Par définition $\forall x\in \R\backslash[-R,R],\ Q(x)\geq Q(0)\geq m$. Ainsi $m$ est un minimum global de $Q$.
		\item Il suffit de montrer $m\geq 0$. Notons $x_0$ tel que $Q(x_0)=m$. Alors $Q'(x_0)=0$.\\
		Or $Q'=Q-P$ donc $Q(x_0)=Q'(x_0)+P(x_0)=P(x_0)\geq 0$.
	\end{enumerate}
	
	\subsection{Théorème de Pythagore polynomial \centraleponts{3}}
	\label{sec:théorème-de-pythagore-polynomial}
	\textcolor{blue}{\hyperref[Théorème de Pythagore polynomial]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item Notons $P=\Lambda\displaystyle\prod\limits_{i=1}^p{(X^2+a_iX+b_i)^{n_i}}\displaystyle\prod\limits_{j=1}^q{(X-x_j)^{m_j}}$ la décomposition de $P$ en facteurs irréductibles dans $\R[X]$.\\
		Tout d'abord, $P(x)\underset{x\to +\infty}{\sim}\Lambda x^{\deg(P)}$. Donc $\Lambda x^{\deg(P)}$ est du signe de $P(x)$ au voisinage de $+\infty$ c'est à dire $\Lambda\geq 0$.\\
		Ensuite, supposons qu'il existe $k\in \crblanc{1}{q}$ tel que $m_k$ est impair.\\
		En notant $Q=\displaystyle\frac{P}{(X-x_k)^{m_k}}$ on a $P(x)\underset{x\to x_k}{\sim}Q(x_k)(x-x_k)^{m_k}$. Or $x\mapsto Q(x_k)(x-x_k)^{m_k}$ change de signe en $x_k$. Ceci est absurde car $x\mapsto P(x)$ elle, ne change pas de signe. On en déduit que les racines réelles de $P$ sont de multiplicités paires.
		\item Chacun des polynômes $R_i=X^2+a_iX+b_i$ peut s'écrire $R_i=(X-\omega_i)(X-\overline{\omega_i})$ pour un certain $\omega_i\in \C$.\\
		Donc en posant $C=\displaystyle\sqrt{\Lambda}\displaystyle\prod\limits_{j=1}^q{(X-x_j)^{m_j/2}}\displaystyle\prod\limits_{i=1}^p{(X-\omega_i)}$ on a bien $P=C\overline{C}$ et $C\in \C[X]$.\\
		\item $A=\text{Re}(C)$ et $B=\text{Im}(C)$ fonctionnent.
	\end{enumerate}
	
	\subsection{Polynômes à valeurs carrées}
	\label{sec:polynomes-à-valeurs-carrées}
	\textcolor{blue}{\hyperref[Polynômes à valeurs carrées]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item Soit $x>a$. Par récurrence :\\
		$n=1$ : $\Delta(f)(x)=f(x+1)-f(x)$. $f$ est continue sur $[x,x+1]$, dérivable sur $]x,x+1[$ donc d'après le théorème de Rolle, $\exists y\in ]x,x+1[,\ \Delta(f)(x)=f'(y)$. i.e $\exists \theta\in ]0,1[,\ \Delta(f)(x)=f'(x+\theta)$.\\
		Supposons le résultat vrai pour un certain $n\in \N^*$.\\
		$\Delta^{n+1}(f)(x)=\Delta(\Delta^n(f))(x)=f^{(n)}(x+\theta+1)-f^{(n)}(x+\theta)$.\\
		$f^{(n)}$ est continue sur $[x+\theta,x+\theta+1]$, dérivable sur $]x+\theta,x+\theta+1[$ donc d'après le théorème de Rolle, $\exists z\in ]x+\theta,x+\theta+1[,\ \Delta^{n+1}(f)(x)=f^{(n+1)}(z)$. i.e $\exists\varphi\in ]\theta,\theta+1[\subset[0,n+1],\ \Delta^{n+1}(f)(x)=f^{(n+1)}(x+\varphi)$.
		\item Justifions déjà que $P$ est strictement positif sur $]a,+\infty[$ pour $a$ assez grand. Pour cela déterminons la limite de $P$ en $+\infty$. Si la suite $(P(n))_{n\in \N}$ prend une infinité de fois la même valeur alors $P$ est constant, et est égal à $P(0)$ par exemple qui est le carré d'un entier, et donc le carré du polynôme constant égal à cet entier. Sinon, comme la suite $(P(n))_{n\in \N}$ est à valeurs dans $\N$, elle ne peut pas être bornée (par principe des tiroirs) et tend donc vers $+\infty$. Ainsi $\uxfty\lim P(x)=+\infty$ et par suite $\exists a>0,\ \forall x>a,\ P(x)>0$.\\
		Alors par composition $f:x\mapsto \sqrt{P(x)}\in \mathcal C^\infty(]a,+\infty[)$. Donc d'après la question 1,\\
		$$\forall x>a,\ \forall n\in \N^*,\ \exists \theta\in [0,n],\ \Delta^n(f)(x)=f^{(n)}(x+\theta)$$
		Pour l'instant j'ai tenté pas mal de trucs mais ça marche pas :[, affaire à suivre.
	\end{enumerate}
	
	\subsection{Polynômes réciproques \ccinp{2}}
	\label{sec:polynomes-reciproques-etoile2}
	\textcolor{blue}{\hyperref[polyrecip]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item $X^nP\left(\displaystyle\frac{1}{X}\right)=X^n\displaystyle\sum\limits_{k=0}^n{a_kX^-k}=\displaystyle\sum\limits_{k=0}^n{a_kX^{n-k}}=\displaystyle\sum\limits_{k=0}^n{a_{n-k}X^k}$. Donc $P$ est un polynôme réciproque si et seulement si $\forall k\in \crblanc{0}{n},\ a_k=a_{n-k}$.
		\item Soient $P,Q$ deux polynôme réciproques de degrés respectifs $p$ et $q$. $R=PQ$ est de degré $r=p+q$ et $R(X)=P(X)Q(X)=X^pP\left(\displaystyle\frac{1}{X}\right)X^qQ\left(\displaystyle\frac{1}{X}\right)=X^rR\left(\displaystyle\frac{1}{X}\right)$. Donc $R=PQ$ est réciproque.
		\item On note encore $p=\deg(P)$ et $q=\deg(Q)$. $F=\displaystyle\frac{P}{Q}$ est un polynôme de degré $f=p-q$ et $F(X)=\displaystyle\frac{P(X)}{Q(X)}=\displaystyle\frac{X^pP\left(\displaystyle\frac{1}{X}\right)}{X^qQ\left(\displaystyle\frac{1}{X}\right)}=X^fF\left(\displaystyle\frac{1}{X}\right)$. Donc $F=\displaystyle\frac{P}{Q}$ est réciproque.
		\item \begin{enumerate}
			\item On sait que $P(0)=a_0=a_n\ne 0$ en tant que coefficient dominant. De plus $P\left(\displaystyle\frac{1}{\alpha}\right)=\displaystyle\frac{1}{\alpha^n}P(\alpha)=0$.
			\item On dérive la relation:
			$$P'(X)=nX^{n-1}P\left(\displaystyle\frac{1}{X}\right)-X^{n-2}P'\left(\displaystyle\frac{1}{X}\right)$$
			Donc en évaluant en $1$ on obtient $P'(1)=-P'(1)$ d'où $P'(1)=0$. Donc $1$ est une racine de $P$ de multiplicité supérieure ou égale à $2$.
			\item $P(-1)=(-1)^nP(-1)=-P(-1)$ donc $P(-1)=0$.
			\item On évalue la relation dérivée en $-1$:
			$$P'(-1)=n(-1)^{n-1}P(-1)+(-1)^{n-1}P'(-1)=-P'(-1)$$
			Donc $P'(-1)=0$.
		\end{enumerate}
		\item Soit $P=\displaystyle\sum\limits_{k=0}^{2n}{a_kX^k}$ un polynôme réciproque de degré $2n$. D'après la question $1$, si $\alpha$ est racine de $P$ alors $\alpha^{-1}$ l'est aussi. Donc si $\alpha\ne \alpha^{-1}$, c'est à dire si $\alpha \not \in \{-1,1\}$, $(X-\alpha)(X-\alpha^{-1})=X^2-(\alpha+\alpha^{-1})X+1|P$. Et si $\varepsilon\in \{-1,1\}$ est racine de $P$ alors d'après les questions $4$.b et $4$.d, $(X-\varepsilon)^2=X^2-2\varepsilon+1|P$. Dans tous les cas, $\exists b_1\in \C,\ X^2+b_1X+1|P$\\
		Supposons qu'il existe $p\in \crblanc{1}{n-1}\text{ et }b_1,\dots,b_p\in \C$ tels que $Q=\displaystyle\prod\limits_{r=1}^p{(X^2+b_rX+1)}|P$.\\
		On remarque que pour tout $r\in \crblanc{1}{p}$, $X^2+b_rX+1$ est réciproque. Donc d'après la question $2,\ Q$ est réciproque. Puis d'après la question $3,\ R=\displaystyle\frac{P}{Q}$ est réciproque, de degré pair (car $P$ et $Q$ le sont) et non constant ($\deg(Q)=2p<2n=\deg(P)$). Donc $\exists b_{p+1}\in \C,\ X^2+b_{p+1}X+1|R$.
		Ainsi, $\displaystyle\prod\limits_{r=1}^{p+1}{(X^2+b_rX+1)}|P$.\\
		Par récurrence, $\exists b_1,\dots,b_n\in \C,\ (X^2+b_1X+1)\dots(X^2+b_nX+1)|P$. Comme ces deux polynômes ont même degré, $P=a_{2n}(X^2+b_1X+1)\dots(X^2+b_nX+1)$.\\
		Si $\deg(P)=2n+1$ est impair alors d'après la question $4.c$, $X+1|P$. Mais alors $Q=\displaystyle\frac{P}{X+1}$ est réciproque d'après la question $3$.\\
		Et donc on déduit de ce qui a été fait précédemment que $P$ se factorise en $P=a_{2n}(X+1)(X^2+b_1X+1)\dots(X^2+b_nX+1)$.
	\end{enumerate}
	
	\subsection{Polynômes surjectifs \etoile{5}}
	\label{sec:polynomes-surjectifs-etoile5}
	\textcolor{blue}{\hyperref[polysurj]{[Enoncé]}}\\
	\begin{enumerate}
		\item On a déjà $P(\C)\subset \C$. Fixons $a\in \C$.\\
		Si $P$ n'est pas constant alors $Q=P-a$ n'est pas constant et d'après le théorème de d'Alembert-Gauss, $Q$ s'annule sur $\C$. Il existe donc $z\in \C$ tel que  $P(z)=a$ i.e $a\in P(\C)$. Donc $P(\C)=\C$. De plus si $P$ est constant alors $P(\C)\ne \C$. Les polynômes recherchés sont les polynômes non constants.
		\item Posons pour $Q=\displaystyle\sum\limits_{k=0}^{+\infty}q_kX^k\in \C[X],\ \overline{Q}=\displaystyle\sum\limits_{k=0}^{+\infty}\overline{q_k}X^k$.\\
		Supposons que $P(\U)=\U$. Tout d'abord, $P$ n'est pas constant.\\
		Notons $P=\displaystyle\sum\limits_{k=0}^n{a_kX^k}$ avec $n=\deg(P)$.\\
		$\forall z\in \U,\ \displaystyle\frac{1}{P(z)}=\overline{P(z)}=\overline{P}(\overline{z})=\overline{P}\left(\displaystyle\frac{1}{z}\right)$.\\
		Donc $\forall z\in \U,\ P(z)\overline{P}\left(\displaystyle\frac{1}{z}\right)=1$.\\
		Donc $\forall z\in \U,\ P(z)\cdot z^n\overline{P}\left(\displaystyle\frac{1}{z}\right)=z^n$.\\\\
		Or $X^n\overline{P}\left(\displaystyle\frac{1}{X}\right)=\overline{X^nP\left(\displaystyle\frac{1}{X}\right)}=\displaystyle\sum\limits_{k=0}^n{\overline{a_{n-k}}X^k}$ est un polynôme. Donc comme $\U$ est infini on a l'égalité entre polynômes:
		$$P(X)\cdot X^n\overline{P}\left(\displaystyle\frac{1}{X}\right)=X^n$$
		Ainsi $P|X^n$. De plus $\deg(P)=n=\deg(X^n)$ donc $P(X)=a_nX^n$. Enfin, $1=|P(1)|=|a_n|$ c'est à dire $a_n\in \U$.\\
		Réciproquement, si il existe $\alpha\in \U$ et $n\in \N^*$ tel que $P(X)=\alpha X^n$ alors:\\
		$\begin{cases}
			(\forall z\in \U,\ |P(z)|=|\alpha||z|^n=1)\implies P(\U)\subset \U\\
			\left(\forall z\in \U,\ P\left(e^{i\displaystyle\frac{\arg(z)-\arg(\alpha)}{n}}\right)=z\right)\implies \U\subset P(\U)
		\end{cases}$
		\item Tout d'abord, si $P$ est à coefficients réels alors $P(\R)\subset \R$. Si de plus $P$ est de degré impair alors $\lim\limits_{x\to +\infty}{P(x)}=\pm\infty=-\lim\limits_{x\to -\infty}{P(x)}$. Donc comme $x\mapsto P(x)$ est continue sur $\R$, d'après le TVI $P(\R)=\R$.\\
		Réciproquement, supposons que $P=\displaystyle\sum\limits_{k=0}^{+\infty}{a_kX^k}\in \C[X]$ vérifie $P(\R)=\R$. On note $\overline{P}=\displaystyle\sum\limits_{k=0}^{+\infty}{\overline{a_k}X^k}$. $\forall x\in \R,\ P(x)=\overline{P(x)}=\overline{P}(x)$. $P$ et $\overline{P}$ coïncident sur une infinité de points, ils sont donc égaux.\\
		Donc $\forall k\in \N,\ \overline{a_k}=a_k$ i.e $\forall k\in \N,\ a_k\in \R$ i.e $P\in \R[X]$.\\
		De plus si $P$ est de degré pair alors $\lim\limits_{|x|\to +\infty}{P(x)}=\pm\infty$. Supposons que $\lim\limits_{|x|\to +\infty}{P(x)}=+\infty$. Alors $\exists r\in \R^+,\ |x|> r\implies P(x)>P(0)$. De plus, $f_P:x\mapsto P(x)$ est continue sur $[-r,r]$ donc d'après le théorème des bornes atteintes $f_P$ admet un minimum $m$ sur $[-r,r]$. Par définition, $m\leq P(0)$. Ainsi, $m$ est un minimum global de $f_P$ et donc $m-1$ par exemple n'est pas dans $P(\R)$.\\
		Similairement, si $\lim\limits_{|x|\to +\infty}{P(x)}=-\infty$ alors $f_P$ admet un maximum $M$ sur $\R$ et donc $M+1$ par exemple n'est pas dans $P(\R)$. Ainsi $P$ est de degré impair.\\
		On conclut que $P(\R)=\R$ si et seulement si $P\in \R[X]$ et est de degré impair.
		\item Supposons que $P(\Q)=\Q$. Notons $d=\deg(P)$ et $(L_0,\dots,L_d)$ la base de Lagrange aux points $0,\dots,d$.\\
		On sait que $P=\displaystyle\sum\limits_{k=0}^d{P(k)L_k}$. Or pour tout $k\in \crblanc{0}{d},\ P(k)\in \Q$ et $L_k=\displaystyle\prod\limits_{\substack{0\leq i\leq d\\i\ne k}}{\displaystyle\frac{X-i}{k-i}}\in \Q[X]$. Donc $P\in \Q[X]$.\\
		Si $P$ est constant alors $P(\Q)\ne \Q$.\\
		Si $d=1$ alors on peut écrire $P(X)=aX+b$ avec $(a,b)\in \Q^*\times \Q$. Dans ce cas pour tout $c\in \Q$, l'équation $P(x)=c$ admet une (unique) solution $x=\displaystyle\frac{c-b}{a}\in \Q$.\\
		Enfin si $d\geq 2$ on écrit $P=\displaystyle\sum\limits_{k=0}^d{\displaystyle\frac{a_k}{b_k}X^k}$ avec $(a_k,b_k)\in \Z^2$ pour tout $k\in \crblanc{0}{d}$. Posons $Q=\ppcm(b_0,\dots,b_d)P$ et pour tout $k\in \crblanc{0}{d},\ c_k=\ppcm(b_0,\dots,b_d)\displaystyle\frac{a_k}{b_k}$ de sorte que $Q=\displaystyle\sum\limits_{k=0}^d{c_kX^k}\in \Z[X]$ et $Q(\Q)=P(\Q)=\Q$.
		Soit $p$ un nombre premier strictement supérieur à $|c_d|$. $\displaystyle\frac{1}{p}\in Q(\Q)$ donc il existe $a$ et $b$ deux entiers premiers entre eux tels que $x=\displaystyle\frac{a}{b}$ vérifie $Q(x)=\displaystyle\frac{1}{p}$. On a alors
		$$Q(x)=\displaystyle\frac{1}{p}=\displaystyle\sum\limits_{k=0}^d{c_kb^{-k}a^k}$$
		c'est à dire
		$$b^d=p\displaystyle\sum\limits_{k=0}^d{c_kb^{d-k}a^k}$$
		Donc $p|b^d$, puis par le lemme d'Euclide, $p|b$. Ecrivons $b=p^{\nu}b'$ avec $\nu$ la valuation $p$-adique de $b$. On reprend:
		\begin{align*}
			b^d&=p\displaystyle\sum\limits_{k=0}^d{c_kb^{d-k}a^k}\\
			\iff p^{\nu d-1}(b')^d&=\displaystyle\sum\limits_{k=0}^d{c_k(b')^{d-k}p^{\nu(d-k)}a^k}\\
			\implies 0&\equiv c_da^d [p]\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (\nu\geq 1,d\geq 2)
		\end{align*}
		Or $a$ et $b$ sont premiers entre eux donc $p|b\implies p\not |\ a$ et donc d'après le lemme d'Euclide, $p|c_d$. Ceci est absurde car $p>|c_d|$.\\\\
		Finalement on conclut que $P(\Q)=\Q \iff \exists a,b\in \Q^*\times \Q,\ P(X)=aX+b$.
		\item Soit $P$ un tel polynôme. Le raisonnement que l'on va utiliser fonctionne avec les seules hypothèses $P(\R\backslash\Q)\subset\R\backslash\Q$ et $P$ non constant (ce qui est évident avec l'inclusion réciproque).\\
		Tout d'abord $P$ est à valeurs réelles car $\R\backslash\Q$ est infini (question 3).\\
		Ensuite, montrons que $P$ est à coefficients rationnels. On a vu dans la question précédente qu'il suffit que $P$ soit à valeur rationnelle sur une partie infini de $\Q$. Supposons que ce n'est pas le cas. Alors il existe une partie finie $A$ de $\Q$ telle que $P(\Q\backslash A)\subset \R\backslash\Q$. Par conséquent $P(\R)\subset\R\backslash\Q\cup P(A)$ d'où $\widering{P(\R)}=\emptyset$ ce qui contredit le fait que $P$ n'est pas constant.\\
		Ainsi $P$ est à coefficients rationnels. On en déduit alors $P(\Q)\subset\Q\subset\R\backslash P(\R\backslash\Q)$ et par conséquent l'égalité :
		$$P(\Q)\sqcup P(\R\backslash\Q)=P(\R)=(P(\R)\cap\Q)\sqcup(P(\R)\cap\R\backslash\Q)$$
		Cela impose que les inclusions $P(\Q)\subset P(\R)\cap\Q$ et $P(\R\backslash\Q)\subset P(\R)\cap\R\backslash\Q$ sont en fait des égalités.\\
		Or $P(\R)$ est un intervalle non borné (TVI + $P$ non constant). Quitte à prendre $-P$ il n'est pas majoré et quitte à prendre $P-q$ pour $q\in \Q$ supérieur à l'inf de $P$ sur $\R_+$, il contient $\R_+$ (ces opérations conserve l'hypothèse $P(\R\backslash\Q)=\R\backslash\Q$. Enfin, quitte à multiplier $P$ par le ppcm des dénominateurs de ses coefficients, $P\in \Z[X]$. Ainsi si $p$ est un nombre premier, $\dfrac{1}{p}\in P(\Q)$ et on en déduit comme dans la question précédente que si $P$ est de degré au moins $2$ alors $p|\lambda$ avec $\lambda$ le coefficient dominant de $P$. Pour $p>|\lambda|$ ceci est absurde donc $\exists a,b\in \Q,\ P(X)=aX+b$.\\
		Ces polynômes sont bien solutions puisque pour $\alpha\in\R\backslash\Q,\ P(\alpha)\in\R\backslash\Q$ et $P\left(\dfrac{\alpha-b}{a}\right)=\alpha$ avec $\dfrac{\alpha-b}{a}\in \R\backslash\Q$.
		\item 
	\end{enumerate}
	
	\subsection{Résultant et discriminant \ccinp{2}}\label{sec:resultant-et-discriminant-etoile2}
	\textcolor{blue}{\hyperref[Résultant]{[Enoncé]}}\\
	\begin{enumerate}
		\item On sait que $(1,X,\dots,X^{m-1})$ et $(1,X,\dots,X^{n-1})$ sont des bases de $\K_{m-1}[X]$ et $\K_{n-1}[X]$ respectivement. Ainsi d'après le cours, la famille $\B=((1,0),(X,0),\dots,(X^{m-1},0),(0,1),(0,X),\dots, (0,X^{n-1}))$ est une base de l'espace vectoriel produit $\K_{m-1}[X]\times\K_{n-1}[X]$.
		\item Soit $((U_1,V_1),(U_2,V_2),\lambda)\in (\K_{m-1}[X]\times\K_{n-1}[X])^2\times\K$.\\
		$\deg(\varphi(U_1,V_1))\leq \max(\deg(PU_1),\deg(QV_1))=n=m-1$ donc $\varphi$ est bien une application.\\
		$\varphi((U_1,V_1)+\lambda(U_2,V_2))=P(U_1+\lambda U_2)+Q(V_1+\lambda V_2)=PU_1+QV_1+\lambda(PU_2+QV_2)=\varphi(U_1,V_1)+\lambda\varphi(U_2+V_2)$ donc $\varphi$ est linéaire.
		\item Soit $p\in \crblanc{0}{m-1}$. Soit $l\in \crblanc{0}{n-1}$.\\
		$\begin{cases}
			\varphi(X^p,0)=PX^p=\displaystyle\sum\limits_{k=0}^n a_kX^{k+p}\\
			\varphi(0,X^l)=QX^l=\displaystyle\sum\limits_{k=0}^m b_kX^{k+l}
		\end{cases}$\\\\
		Donc $\operatorname{Mat}_{B,B_c}(\varphi)=\operatorname{Syl}(P,Q)$.
		\item Supposons d'abord que $P\land Q\ne 1$.Alors d'après l'identité de Bézout, $1\notin \text{Im}(\varphi)$ donc $\varphi$ n'est pas surjective et donc n'est pas bijective.
		Supposons maintenant que $P\land Q=1$. On remarque que $\dim(\K_{m-1}[X]\times\K_{n-1}[X])=n+m=\dim(\K_{n+m-1})[X]$, il suffit donc de montrer au choix l'injectivité ou la surjectivité de $\varphi$. Soit $(U,V)\in \ker\varphi$.\\
		On a $PU=-QV$ donc $Q|PU$. Or $P\land Q=1$ donc d'après le lemme de Bézout, $Q|U$ et donc $n=\deg(Q)\leq \deg(U)\leq m-1$. De même, $P|V$ et donc $m\leq n-1$. Ainsi on a par exemple $n+1\leq m\leq n-1$ ce qui impose $n=m=-\infty$. Ainsi $(U,V)=(0,0)$ et $\varphi$ est injective, donc bijective.\\
		Ainsi, $P\land Q=1\iff\det\varphi\ne 0\iff \det\operatorname{Mat}_{B,B_c}(\varphi)=\operatorname{Res}(P,Q)\ne 0$.
		\item $P=aX^2+bX+c,\ P'=2aX+b$.
		$$\operatorname{Res}(P,P')=
		\begin{vmatrix}
			c&b&0\\
			b&2a&b\\
			a&0&2a
		\end{vmatrix}
		=4a^2c+ab^2-2ab^2=4ac^2-ab^2$$
		Donc $\Delta(P)=\displaystyle\frac{(-1)^{\frac{2(2-1)}{2}}}{a}\operatorname{Res}(P,Q)=-\displaystyle\frac{1}{a}\operatorname{Res}(P,Q)=b^2-4ac$. On retrouve le résultat bien connu.
		\item $P$ est scindé à racines simples si et seulement si toute racine de $P$ n'est pas racine de $P'$. Or dans $\C$, les racines de $P\land P'$ sont les racines communes à $P$ et $P'$. Ainsi $P$ est scindé à racines simples sur $\C$ si et seulement si $P\land P'$ n'a pas de racine complexe. D'après le théorème de d'Alembert-Gauss cela équivaut à ce que $P\land P'$ soit constant puis, étant donné que $P\land P'$ est unitaire, à $P\land P'=1$.\\
		D'après ce qui a été fait précédemment on peut donc affirmer que $P$ est scindé à racines simples sur $\C$ si et seulement si $\operatorname{Res}(P,P')\ne 0$.
	\end{enumerate}
	\textit{Le résultant est un outil intéressant sur certains problèmes car il permet de mettre en évidence une sorte de "continuité" des racines d'un polynôme via le déterminant, qui est lui continu.}
	
	\subsection{Théorème de Liouville : Fermat pour les polynômes \xens{4}}
	\label{sec:theoreme-de-liouville--fermat-pour-les-polynomes}
	\textcolor{blue}{\hyperref[Théorème de Liouville : Fermat pour les polynômes]{[Enoncé]}}\\
	\begin{enumerate}
		\item Notons $D=P\land Q\land R$.\\
		$P^n+Q^n=R^n\implies \left(\displaystyle\frac{P}{D}\right)^n+\left(\displaystyle\frac{Q}{D}\right)^n=\left(\displaystyle\frac{R}{D}\right)^n$. Posons $(\tilde{P},\tilde{Q},\tilde{R})=\left(\left(\displaystyle\frac{P}{D}\right)^n,\left(\displaystyle\frac{Q}{D}\right)^n,\left(\displaystyle\frac{R}{D}\right)^n\right)$ de sorte que $\tilde{P},\tilde{Q},\tilde{R}$ sont premiers entre eux dans leur ensemble. Soit $S$ un facteur irréductible commun à $\tilde{P}$ et $\tilde{Q}$.\\
		$S|\tilde{P}^n+\tilde{Q}^n=\tilde{R}^n$ et comme $S$ est irréductible, $S|\tilde{R}$. Donc $S$ est constant d'où $\tilde{P}\land \tilde{Q}=1$. De même, $\tilde{P}\land \tilde{R}=1$ et $\tilde{Q}\land \tilde{R}=1$.
		\item On calcule:
		\begin{align*}
			P^n+Q^n&=R^n\\
			\iff \left(\displaystyle\frac{P}{Q}\right)^n+1&=\left(\displaystyle\frac{R}{Q}\right)^n\\
			\iff \displaystyle\prod\limits_{i=1}^n{\left(\displaystyle\frac{P}{Q}-\zeta_i\right)}&=\left(\displaystyle\frac{R}{Q}\right)^n\\
			\iff \displaystyle\prod\limits_{i=1}^n{(P-\zeta_iQ)}&=R^n
		\end{align*}
		Ainsi $\forall i\in \crblanc{1}{n},\ T_i=P-\zeta_iQ|R^n$.\\
		Montrons que les $T_i$ sont deux à deux premiers entre eux. On fixe $i,j\in \crblanc{1}{n}$ avec $i\ne j$. Soit $S$ un diviseur commun à $T_i$ et $T_j$.\\
		$S|T_i-T_j=(\zeta_j-\zeta_i)Q$. Or les racines de $X^n+1$ sont toutes distinctes donc $\zeta_j-\zeta_i\ne 0$ et on en déduit que $S|Q$. Mais alors $S|T_i+\zeta_iQ=P$. Donc $S$ est constant c'est à dire $T_i\land T_j=1$.\\
		Soit maintenant $x$ une racine de $T_i$. En notant pour $\alpha\in \C$ et $A\in \C[X],\ v_A(\alpha)$ la multiplicité de $\alpha$ en tant que racine de $A$ ($v_A(\alpha)=0$ si $\alpha$ n'est pas racine de $A$) on calcule:
		$$nv_R(x)=v_{R^n}(x)=v_{\prod\limits_{k=1}^n{T_k}}(x)=\displaystyle\sum\limits_{k=1}^n{v_{T_k}(x)}=v_{T_i}(x)$$
		Ainsi la multiplicité de chaque racine de $T_i$ est un multiple de $n$: $\exists H_i\in \C[X],T_i=H_i^n$.
		\item Supposons que $P,Q$ ou $R$ n'est pas constant. Si $R$ n'est pas constant alors $P$ et $Q$ ne peuvent pas l'être tous les deux à cause de la relation qui les définit. On a donc $\max(\deg(P)\deg(Q))\geq 1$.\\
		On sait que $n\geq 3$ donc on peut au moins considérer $T_1,T_2,T_3$. Or par définition, ces polynômes sont dans Vect$(P,Q)$ qui est de dimension inférieure strictement à $3$. Donc la famille $(T_1,T_2,T_3)$ est liée:
		$$\exists (a,b,c)\in \C^3\setminus \{(0,0,0)\},\ aT_1+bT_2+cT_3=0$$
		posons $\alpha,\beta,\gamma$ des racines $n$-ième de $a,b,-c$ respectivement. Le triplet $(U,V,W)=(\alpha H_1,\beta H_2,\gamma H_3)$ vérifie:\\\\
		$\begin{cases}
			U^n+V^n=W^n\\
			U\land V=U\land W=V\land W=1\\
			\deg(U)\leq \deg(H_1)=\displaystyle\frac{\deg(T_1)}{n}<\deg(T_1)\leq \max(\deg(P),\deg(Q))\\
			\deg(V)<\max(\deg(P),\deg(Q))
		\end{cases}$\\\\\\
		L'ensemble $\{\max(\deg(P),\deg(Q))\ |\ (P,Q,R)\in \C[X]^3,P\land Q=P\land R=Q\land R=1,P^n+Q^n=R^n\}$ est une partie non vide de $\N^*$, elle admet donc un minimum. Considérons $(P_0,Q_0,R_0)\in \C[X]^3$ qui réalise ce minimum. D'après le raisonnement précédent on peut construire $(U_0,V_0,W_0)$ qui contredit la minimalité de $(P_0,Q_0,R_0)$. Ceci est absurde donc $P,Q,R$ sont constants.\\\\
		Finalement, si $(A,B,C)\in \C[X]^3$ tel que $A^n+B^n=C^n$ alors avec $D=A\land B\land C$: $\tilde{A}=\displaystyle\frac{A}{D},\tilde{B}=\displaystyle\frac{B}{D}\text{ et }\tilde{C}=\displaystyle\frac{C}{D}$ sont constants d'où $A=\tilde{A}D,B=\tilde{B}D$ et $C=\tilde{C}D$ sont égaux à une constante multiplicative près.
	\end{enumerate}
	
	\newpage
\section{Correction Espaces vectoriels normés}
	\subsection{Suite de Cauchy \etoile{2}}\label{sec:suite-de-cauchy-etoile-2}
		\textcolor{blue}{\hyperref[Suite de Cauchy]{[Enoncé]}}\\
	Soit $(u_n)\in E^\N$ une suite convergente. On note $l=\unfty{\lim}u_n$.\\
	Soit $\varepsilon>0$.\\
	$\exists N\in \N,\ \forall n\geq N,\ ||u_n-l||\leq \displaystyle\frac{\varepsilon}{2}$.\\
	Alors, $\forall (p,q)\in \llbracket N;+\infty\llbracket,\ ||u_p-u_q||=||u_p-l+l-u_q||\leq ||u_p-l||+||l-u_q||\leq \varepsilon$.\\
	Donc $(u_n)_{n\in \N}$ est une suite de Cauchy.\\\\
	Montrons que $(u_n)$ est bornée, autrement dit que la suite $(||u_n||)_{n\in \N}$ ne tend pas vers $+\infty$.\\
	Supposons par l'absurde que $\unfty{\lim}||u_n||=+\infty$. Fixons $\varepsilon>0$.\\
	$\exists n_0\in \N,\ \forall p>q\geq n_0,\ ||u_p-u_q||\leq \varepsilon$. Et $\exists n_1\in \N,\ \forall p\geq n_1,\ ||u_p||>||u_q||+\varepsilon$.\\
	Donc d'après la seconde inégalité triangulaire, $\forall p\geq N=\max(q,n_1),\ \varepsilon<|\ ||u_p||-||u_q||\ |\leq ||u_p-u_q||\leq \varepsilon$.\\
	Ceci est absurde donc $(u_n)$ est bornée, disons par $M$.\\\\
	$(u_n)_{n\in \N}$ est alors à valeurs dans le compact $B_f(0,M)$ (fermé borné dans $E$ qui est de dimension finie).\\
	$(u_n)_{n\in \N}$ admet donc une valeur d'adhérence $l$. On note $\varphi:\N\to\N$ strictement croissante telle que $u_{\varphi(n)}\unfty{\longrightarrow}l$.\\
	$\forall \varepsilon>0,\ \exists n\in \N,\ \forall k\geq n,\ ||u_{\varphi(n)}-u_n||\leq \varepsilon$.\\
	C'est-à-dire $u_{\varphi(n)}-u_n\unfty{\longrightarrow}0$.\\
	Mais alors par somme, $u_n=u_n-u_{\varphi(n)}+u_{\varphi(n)}\unfty{\longrightarrow}l$.
	\subsection{Théorème de Fréchet-Von Neumann}\label{sec:theoreme-de-frechet-von-neumann}
		\textcolor{blue}{\hyperref[Théorème de Fréchet-Von Neumann-Jordan]{[Enoncé]}}\\
	D'après le cours, on sait que si $\norme{.}$ est euclidienne alors elle vérifie l'identité du parallélogramme.\\
	Supposons que $\norme{.}$ vérifie l'identité du parallélogramme.\\
	Montrons que \[\fonction{\varphi}{E\times E}{R}{(x,y)}{\dfrac{1}{4}\left(\norme{x+y}^2-\norme{x-y}^2\right)}\] est un produit scalaire.
	Il est clair que $\varphi$ est symétrique et définie positive.\\
	Montrons que $\varphi$ est bilinéaire.\\
	Soient $(x,y,z)\in E^2$ et $\lambda\in\R$.\\
	D'après l'identité du parallélogramme, on a : 
	Soient $x,z,y \in V$. On calcule :
	\[
	4\varphi(x+z,y) = \|x+z+y\|^2 - \|x+z-y\|^2.
	\]
	D’après l’identité du parallélogramme appliquée à $(x+z,y)$, $(x,y)$ et $(z,y)$, 
	on obtient après simplification
	\[
	\|x+z+y\|^2 - \|x+z-y\|^2 
	= \big(\|x+y\|^2 - \|x-y\|^2\big) 
	+ \big(\|z+y\|^2 - \|z-y\|^2\big).
	\]
	Ainsi,
	\[
	\varphi(x+z,y) = \varphi(x,y) + \varphi(z,y).
	\]
	Pour $n\in\mathbb{Z}$, l’additivité donne 
	$\langle n x,y\rangle = n\langle x,y\rangle$.  
	Si $m\in\mathbb{N}^\ast$, alors
	\[
	\varphi(x,y) = \varphi(m\cdot \tfrac{1}{m}x, y) 
	= m \varphi( \tfrac{1}{m}x, y)
	\quad\Rightarrow\quad
	\varphi(\tfrac{1}{m}x, y) = \tfrac{1}{m}\varphi(x,y).
	\]
	On en déduit que l’homogénéité vaut pour tous les rationnels, puis, par densité de $\Q$ dans $\R$ et par continuité de la norme, pour tout réel $\lambda\in\mathbb{R}$ :
	\[
	\varphi(\lambda x, y) = \lambda \varphi(x,y).
	\]
	On a donc montré que $\varphi$ est linéaire par rapport à sa première variable. \\
	Donc $\varphi$ est un produit scalaire de norme associée $\norme{.}$. Donc $\norme{.}$ est une norme euclidienne.
	\subsection{Une norme non euclidienne}\label{sec:une-norme-non-euclidienne}
		\textcolor{blue}{\hyperref[Une norme non euclidienne]{[Enoncé]}}\\
	Montrons dans un premier temps que $N$ est une norme.\\
	\begin{itemize}
		\item \underline{Séparation}\\ Soit $P\in\R_n[X]$ tel que $N(P)=0$.\\
		Ainsi pour tout $k\in\crblanc{0}{n}$, $|P(\alpha_k)|=0$ donc $P(\alpha_k)=0$.\\
		Donc $P\in\R_n[X]$ admet au moins $n+1$ racines, ce qui implique que $P=0$.
		\item \underline{Homogénéité}\\ Soient $P\in\R_n[X]$ et $\lambda\in \R$.\\
		\[N(\lambda P)=\sum_{k=0}^{n}|\lambda P(\alpha_k)|=|\lambda|\sum_{k=0}^{n}|P(\alpha_k)|=|\lambda|N(P)\]
		\item \underline{Inégalité triangulaire}\\ Elle découle directement de l'inégalité triangulaire de la valeur absolue sur $R$.
	\end{itemize}
	Montrons maintenant qu'elle n'est pas euclidienne.
	Alors $N$ vérifie l'identité du parallélogramme \ref{Théorème de Fréchet-Von Neumann-Jordan}.
	Donc pour tout $P,Q\in\R_n[X]$ , on a : \[N(P+Q)+N(P-Q)=2(N(P)+N(Q))\]
	Par interpolation de Lagrange, il existe $P, Q\in\R_n[X]$ $P(\alpha k) = \delta_{k,0}$ et $Q(\alpha k) = \delta_{k,n}$ pour tout $k\in\crblanc{0}{n}$.
	Ainsi, on a $N(P+Q)=N(P-Q)=2$ et $N(P)=N(Q)=1$. ce qui contredit l'identité du parallélogramme.
	\subsection{Norme invariante par similitude}\label{sec:norme-invariante-par-similitude}
		\textcolor{blue}{\hyperref[Norme invariante par similitude]{[Enoncé]}}\\
	\subsection{Equivalence des normes dans un espace vectoriel normé de dimension finie}\label{sec:equivalence-des-normes-dans-un-espace-vectoriel-norme-de-dimension-finie}
		\textcolor{blue}{\hyperref[Equivalence des normes dans un espace vectoriel normée de dimension finie]{[Enoncé]}}\\
	\subsection{Normes non équivalentes}\label{sec:normes-non-equivalentes}
		\textcolor{blue}{\hyperref[Normes non équivalentes]{[Enoncé]}}\\
	\subsection{Normes semblables à la norme uniforme sur $\K[X]$}\label{sec:normes-semblables-a-la-norme-uniforme-sur-kx}
	\textcolor{blue}{\hyperref[Normes semblables à la norme uniforme sur KX]{[Enoncé]}}\\
	Il est clair que $N_A$ vérifie l'homogénéité et l'inégalité triangulaire, en revanche elle ne vérifie pas forcément la séparation.\\
	Si $A$ est un ensemble fini, il existe un polynôme qui s'annule en tous les points de A, mais pour autant qui ne soit pas nul (on pense à l'interpolation de Lagrange).\\
	Alors, que si $A$ est infini, cela signifie que pour un polynôme $P$ tel que $N_A(P)=0$, $P$ s'annule une infinité de fois donc $P$ est le polynôme nul.\\
	Ainsi $N_A$ est une norme si et seulement si $A$ est infini.
		
	\subsection{Comparaisons de deux normes sur $\K_n[X]$}\label{sec:comparaison-de-deux-normes-sur-knx}
	\textcolor{blue}{\hyperref[Comparaison de deux normes sur KnX]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item D'après le cours, $\normep{1}{.}$ est une norme sur $K_n[X]$.\\
		Montrons que $\norme{.}$ est une norme.\\
		\textbullet\underline{Séparation} :\\ Soit $P\in\K_n[X]$ tel que $\norme{P}=0$.\\
		 On a alors $\forall k\in\crblanc{0}{n}, |P(k)|=0$ c'est-à-dire : $P(k)=0$.\\
		 Donc $P$ est un polynôme qui admet au moins $n+1$ racines alors qu'il est de degré au plus $n$. Donc $P$ est le polynôme nul.\\
		 \textbullet\underline{Homogénéité} :\\ Soient $P\in\K_n[X]$ et $\lambda\in\K$.\\
		 \[\norme{P}=\sum_{i=0}^{n}|\lambda P(k)|=|\lambda|\sum_{i=0}|P(k)|=|\lambda|\norme{P}\]
		\textbullet\underline{Inégalité triangulaire} :\\ Soient $P$ et $Q$ deux polynômes de $\K_n[X]$.
		\[\norme{P+Q}=\sum_{i=0}^{n}|p(k)+Q(k)|\leq \sum_{i=0}^{n}|P(k)|+\sum_{i=0}^{n}|Q(k)|=\norme{P}+\norme{Q}\]
		Donc $\norme{.}$ est une norme.
		\item Soit $P\in\K_n[X]$.\\
		\begin{align*}
			\normep{1}{P}&\leq \int_{0}^{1}|P(t)|dt\\
			&\leq\int_{0}^{n}|P(t)|dt &\text{car $|P|$ est positif}\\
			&\leq \sum_{i=0}^n\lambda_i|P(k)| &\text{ avec }\lambda_i=\displaystyle\int_a^b|L_i|(x)dx \quad\text{cf. \ref{Intégrales de polynômes}}\\
			&\leq C_n\norme{P} & \text{ où } C_n=\max{\lambda_i, i\in\crblanc{0}{n}}
		\end{align*}
		\item Puisque $\R_n[X]$ est de dimension finie, ces normes sont équivalentes.
		 
	\end{enumerate}
	
		
	\subsection{Comparaisons de normes usuelles sur $\mathcal{C}^0([a,b],\K)$}\label{sec:comparaison-de-normes-usuelles-sur-mathcalc0abk}
		\textcolor{blue}{\hyperref[Comparaisons de normes usuelles sur C0]{[Enoncé]}}\\
		
		
	\subsection{Normes $p$}\label{sec:normes-p}
		\textcolor{blue}{\hyperref[Normes p]{[Enoncé]}}
	\subsubsection{Inégalité de Hölder et Minkowski}
	\begin{enumerate}[leftmargin=*]
		\item Soit $u,v\in \R^*_+$.\\
		On sait que $\ln$ est concave sur $]0,+\infty[$. Donc on en déduit que 
		\[
		\ln(uv)=\frac{1}{p}\ln(u^p)+\frac{1}{q}\ln(v^q)\leq\ln\left(\frac{u^p}{p}+\frac{v^q}{q}\right)
		\]
		Ainsi par croissance de la fonction exponentielle, on en déduit que :
		\[
		uv\leq \frac{u^p}{p}+\frac{v^q}{q}
		\]
		\item On pose pour tout $k\in\crblanc{1}{n}$, $x_k'=\frac{x_k}{\normep{p}{x}}$ et $y_k'=\frac{y_k}{\normep{q}{y}}$
		D'après l'inégalité de Young, on a : 
		\[
		x_k'y_k'\leq \frac{x_k'^p}{p}+\frac{y_k'^q}{q}
		\]
		Donc en sommant, on a :
		\[
		\sum_{k=1}^{n}x_k'y_k'\leq \sum_{k=1}^{n}\frac{x_k'^p}{p}+\frac{y_k'^q}{q}=\frac{1}{p}+\frac{1}{q}=1
		\]
		On en déduit donc l'inégalité de Hölder :
		\[
		\sum_{k=1}^{n}x_ky_k\leq \normep{p}{x}\normep{q}{y}
		\]
		\item \[\forall k\in\crblanc{1}{n}, (x_k+y_k)^p=x_k(x_k+y_k)^{p-1}+y_k(x_k+y_k)^{p-1}\]
		Par sommation et d'après l'inégalité de Hölder :\[
		\sum_{k=1}^{n}(x_k+y_k)^p\leq \normep{p}{x}\normep{q}{(x_k+y_k)^{p-1}}+\normep{p}{y}\normep{q}{(x_k+y_k)^{p-1}}=(\normep{p}{x}+\normep{p}{y})\normep{q}{(x_k+y_k)^{p-1}}
		\]
		Or en remarquant que $q=\frac{p}{p-1}$:\[\normep{q}{(x_k+y_k)^{p-1}}=\left(\sum_{i=1}^{n}(x_k+y_k)^p\right)^{\tfrac{p-1}{p}}=\normep{p}{x+y}^{p-1}\]
		Ainsi, on en déduit que :\[\normep{p}{x+y}^p\leq(\normep{p}{x}+\normep{p}{y})\leq\normep{p}{x+y}^{p-1}\]
		Finalement, puisque les $x_k$ et $y_k$ sont strictement positifs, on a $\normep{p}{x+y}\ne0$ donc : \[\normep{p}{x+y}\leq\normep{p}{x}+\normep{p}{y}\]
		\item 
		\begin{itemize}
		\item \underline{Séparation} : Soit $x\in\K^n$ tel que $\normep{p}{x}=0$.\\
		On a donc pour tout $\sum_{i=1}^{n}|x_i|^p=0$ donc $\forall k\in\crblanc{1}{n}, x_k=0$.\\
		Donc $x=0$.
		\item\underline{Homogénéïté} : Soient $x\in\K^n$ et $\lambda\in\K$.\\
		$$\normep{p}{\lambda x}^p=\sum_{k=1}^{n}|\lambda x_k|^p=|\lambda\sum_{k=1}^{n}| x_k|^p|=|\lambda|\normep{p}{x}$$
		\item\underline{Inégalité triangulaire} : Il s'agit de l'inégalité de Minkowski démontré à la question 3.
	\end{itemize}
		Ainsi, $\normep{p}{.}$ est une norme sur $K^n$.
	\end{enumerate}

	\subsubsection{Equivalence des normes $p$ et $q$}
	\begin{enumerate}
		\item 
		\underline{Première méthode}:\\
		\[\forall x\in\K^n, \normep{p}{x}=\left(\sum_{i=1}^{n}|x_i|^p\right)^{\tfrac{1}{p}}\geq (\normep{\infty}{x}^p)^{\tfrac{1}{p}}=\normep{\infty}{x}\]
		car $\normep{\infty}{x}$ est l'un des termes de cette somme à termes positifs.
		et \[ \normep{p}{x}\leq\left(\sum_{i=1}^{n}\normep{\infty}{x}^p\right)^{\tfrac{1}{p}}=n^{\tfrac{1}{p}}\normep{\infty}{x}\]
		Donc $\normep{p}{.}$ et $\normep{\infty}{.}$ sont équivalentes sur $\K^n$. \\
		\underline{Deuxième méthode}:\\
		$\K^n$ est un espace vectoriel vectoriel de dimension finie donc toutes les normes sur $\K^n$ sont équivalentes. En particulier, $\normep{p}{.}$ et $\normep{\infty}{.}$ sont équivalentes sur $\K^n$.
		\item 
		Il est clair que quand $x=0$, l'inégalité est vérifiée.
		Soit $x\in\K^n$ non nul.
		On applique l'inégalité de Hölder aux $n$-uplets $(|x_1|^p,\dots,|x_n|^p)$ et $(1,\dots,1)$ pour $r=\frac{q}{p}\geq 1$ et $s\in[1,\infty[$ tel que $\frac{1}{r}+\frac{1}{s}=1$. 
		\[
		\sum_{i=1}^{n}|x_i|^p\leq\left(\sum_{i=1}^{n}(|x_i|^p)^r\right)^{\frac{1}{r}}\left(\sum_{i=1}^{n}1^s\right)^{\frac{1}{s}}
		\]
		c'est-à-dire :\[
		\normep{p}{x}^p\leq n^{\frac{1}{s}}\normep{q}{x}^p
		\]
		Or $s=\frac{q}{q-p}$ :
		\[
		\normep{q}{x}^p\leq n^{\frac{q-p}{q}}\normep{q}{x}^p
		\]
		D'où :\[ \normep{p}{x}\leq n^{\frac{1}{p}-\frac{1}{q}}\normep{q}{x}\]
		Par homothétie, on se ramène au cas $\normep{p}{x}=1$.\\
		On a donc pour tout $i\in\crblanc{1}{n}$ $|x_i|\geq 1$\\
		Donc $|x_i|^q\leq |x_i|^p$ pour tout $i\in\crblanc{1}{n}$.\\
		Par conséquent, \[\normep{q}{x}\leq\left(\sum_{i=1}^{n}|x_i|^q\right)^{\frac{1}{q}}=\normep{p}{x}^{\frac{q}{p}}=1\]
		Ainsi, on en déduit le résultat pour tout $x\in\K^n$, \[\normep{q}{x}\leq\normep{p}{x}\]
	\end{enumerate}
	\subsubsection{Norme infinie}
	On a montré précédemment dans la sous-section précédente que : \[\forall p\geq 1, \forall x\in \K^n,\quad \normep{\infty}{x}\leq\normep{p}{x}\leq n^{\frac{1}{p}}\normep{\infty}{x}\]
	On en déduit que $p\mapsto\normep{p}{x}$ admet pour limite $\normep{\infty}{x}$ quand $p\to+\infty$.
	\subsection{Normes de Sobolev}\label{sec:normes-de-sobolev}
		\textcolor{blue}{\hyperref[Normes de Sobolev]{[Enoncé]}}\\
		
	\subsection{Norme duale}\label{sec:norme-duale}
		\textcolor{blue}{\hyperref[Norme duale]{[Enoncé]}}\\
		
	\subsection{Norme à partir d'une famille libre}\label{sec:norme-a-partir-dune-famille-libre}
	\textcolor{blue}{\hyperref[Norme à partir d'une famille libre]{[Enoncé]}}\\
	On montre aisément que $N$ vérifie l'homogénéité et l'inégalité triangulaire.\\
	Montrons que $N$ vérifie la séparation si et seulement si $(x_1,\dots,x_n)$ est libre.\\
	Supposons que $(x_1,\dots,x_n)\in E$ est libre.\\
	Ainsi, pour $\lambda=(\lambda_1,\dots,\lambda_n)\in\R^n$ tel que $N(\lambda)=0$.\\
	On a alors : \[\sum_{k=1}^{n}\lambda_kx_k=0\]
	Donc : $\lambda=0$ car $(x_1,\dots,x_n)\in E$ est libre.\\
	Supposons que $N$ vérifie la séparation.
	$\forall (\lambda_1,\dots,\lambda_n)\in\R^n$, 
	\[\sum_{k=1}^{n}\lambda_kx_k=0 \Longleftrightarrow \norme{\sum_{k=1}^{n}\lambda_kx_k}=0\].
	Donc par séparation, $(\lambda_1,\dots,\lambda_n)=0$.
	
	
		
	\subsection{Quelques normes matricielles}\label{sec:quelques-normes-matricielles}
		\textcolor{blue}{\hyperref[Quelques normes matricielles]{[Enoncé]}}\\
	\subsection{Caractérisation des sous-espaces de dimension finie de $\mathcal{C}^0([0,1],\K)$}\label{sec:caracterisation-des-sous-espaces-de-dimension-finie-de-mathcalc001k}
		\textcolor{blue}{\hyperref[Caractérisation des sous-espaces de dimension finie de C0]{[Enoncé]}}\\
	\subsection{Distance}\label{sec:distance}
		\textcolor{blue}{\hyperref[Distance]{[Enoncé]}}\\
		\begin{enumerate}[leftmargin=*]
			\item \begin{itemize}
				\item $\forall x,y\in E$, $\norme{x-y}=|-1|\norme{y-x}=\norme{y-x}$
				\item $\forall x,y\in E, \norme{x-y}=0\Longleftrightarrow x-y=0\Longleftrightarrow x=y$
				\item $\forall x,y,z\in E, \norme{x-y}=\norme{x-z+z-y}\leq \norme{x-z}+\norme{z-y}$
			\end{itemize}
			Donc $d$ est une distance sur $E$.
			\item On admet que $\varphi:(x,y)\in\R^2\mapsto |x-y|$ est une distance sur $\R$.
			\begin{itemize}
				\item La symétrie vient de la symétrie de la valeur absolue
				\item La séparation vient du fait que $\arctan(x)=0$ admet une unique solution qui est $0$ et donc puisque $\varphi$ est une distance, on a $x=y\Longleftrightarrow \arctan|x-y|=0$
				\item Soient $x,y,z\in\R$.\\
				 D'après l'inégalité triangulaire sur la valeur absolue, on a 
				 \[|x-y|\leq|x-z|+|z-y|\]
				 Comme la fonction $\arctan$ est croissante sur $\R$, on a :
				 \[\arctan|x-y|\leq \arctan\left(|x-z|+|z-y|\right)\]
				 Montrons que pour tout $a,b\in\R_+$ tels que :
				 \[\arctan(a+b)\leq\arctan(a)+\arctan(b)\]
				 On fixe $a\in\R_+$.\\
				 On pose $\fonction{f}{\R_+}{\R}{t}{\arctan(a+t)-\arctan(a)-\arctan(t}$.\\
				 Cette fonction est de classe $\mathcal{C}^1$ sur $\R_+$.
				 \[f'(t)=\frac{1}{1+(a+t)^2}-\frac{1}{1+t^2}\]
				 On a $f'(t)\leq 0$ pour tout $t\geq 0$. Donc $f$ est décroissante sur $\R_+$.\\
				 En particulier, on a : \[\forall t\in\R_+, f(t)\leq f(0)\]
				 i.e. \[\arctan(a+t)-\arctan(t)-\arctan(a)\leq 0\]
				 D'où le résultat.
				 Par conséquent, on a pour $a=|x-z|$ et $b=|z-y|$, on a : 
				 \[\arctan|x-y|\leq \arctan|x-z|+\arctan|z-y|\]			\end{itemize}
				 Donc $d$ est bien une distance.\\
				 Supposons maintenant que $d$ est induite d'une norme.
			On a alors pour tout $\lambda\in\R$ et pour tous $(x,y)\in\R$, 
			\[d(\lambda x,\lambda y)=|\lambda|d(x,y)\]
			Or puisque $\Ima(\arctan)=[-\frac{\pi}{2},\frac{\pi}{2}]$, le résultat ne peut être vérifié pour un $\lambda$ grand (exemple : $\lambda=100$).
			Donc cette distance n'est pas induite d'une norme.
		\end{enumerate}
	\subsection{Distance à une partie}\label{sec:distance-a-une-partie}
		\textcolor{blue}{\hyperref[Distance à une partie]{[Enoncé]}}\\
	\subsection{Distance d'un élément à une partie (1)}\label{sec:distance-dun-element-a-une-partie-1}
		\textcolor{blue}{\hyperref[Distance d'un élément à une partie 1]{[Enoncé]}}\\
	\subsection{Distance d'un élément à une partie
		 (2)}\label{sec:distance-dun-element-a-une-partie-2}
		 \textcolor{blue}{\hyperref[Distance d'un élément à une partie 2]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item On remarque que \[M=\frac{M+M^\top}{2}+\frac{M-M^\top}{2}\] et que $\displaystyle\frac{M+M^\top}{2} \in\mathcal{S}_n(\R)$ et $\displaystyle \frac{M-M^\top}{2}\in\mathcal{A}_n(\R)$.\\
		Donc $\mathcal{S}_n(\R)+\mathcal{A}_n(\R)=\M_{n}(\R)$.\\
		Et soit $M\in\mathcal{S}_n(\R)\cap\mathcal{A}_n(\R)$.\\
		On a alors : 
		\begin{align*}
			M^\top&=M\\
			M^\top&=-M
		\end{align*}
		Donc $M$=0\\
		Par conséquent, on a $\mathcal{S}_n(\R)\oplus\mathcal{A}_n(\R)=\M_{n}(\R)$.
		\item Soient $S\in\mathcal{S}_n(\R)$ et $A\in\mathcal{A}_n(\R)$.\\
		\[\langle A,S\rangle=\Tr(A^\top S)=-\Tr(AS)\]
		et \[\langle S,A\rangle=\Tr(S^\top A)=\Tr(SA)\]
		Donc $\mathcal{S}_n(\R)=(\mathcal{A}_n(\R))^\perp$.
		\item Puisque $\mathcal{S}_n(\R)=(\mathcal{A}_n(\R))^\perp$, on a:\[d(M,\mathcal{S}_n(\R))=\norme{M-\pi_{\mathcal{S}_n(\R)(M)}}\]
		D'après la question 1, on a :\\ $\pi_{\mathcal{S}_n(\R)(M)}=\frac{M+M^\top}{2}$ et $M-\pi_{\mathcal{S}_n(\R)(M)}=\frac{1}{2}(M - M^T) = 
		\begin{pmatrix} 
			0 & -1 & -2 \\ 
			1 & 0 & -1 \\ 
			2 & 1 & 0 
			\end{pmatrix}.$
		Ainsi : \[d(M,\mathcal{S}_n(\R))^2=
		\norme{\frac{M-M^\top}{2}}=\Tr\begin{pmatrix}
	5&2&-1\\
	2&2&2\\
	-1&2&5
	\end{pmatrix}=12\]
	Finalement, on a : \[d(M,\mathcal{S}_n(\R))=2\sqrt{3}\]
	\end{enumerate}
	
		
	\subsection{Passage par les matrices orthogonales}\label{sec:passage-par-les-matrices-orthogonales}
		\textcolor{blue}{\hyperref[Passage par les matrices orthogonales]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item \textbullet\underline{Séparation} : \\
		Soit $X\in\M_n(\R)$ tel que $N(X)=0$.\\
		Donc $\forall A\in\O_n(\R), \normep{\infty}{AX}=0$.\\
		En particulier, $\normep{\infty}{I_nX}=\normep{\infty}{X}=0$.\\
		Donc $X=0$ car $\normep{\infty}{.}$ est une norme.\\
		\textbullet \underline{Homogénéité} :\\
		Soient $X\in\M_n(\R)$ et $\lambda\in\R$.
		\[N(\lambda X)=\max_{A\in\O_n(\R)}\normep{\infty}{\lambda AX}=\max_{A\in\O_n(\R)}|\lambda\normep{\infty}{AX}=|\lambda|N(X)\]
		\textbullet \underline{Inégalité triangulaire} : \\
		$\forall A\in\O_n(\R), \forall X,Y\in\M_n(\R)$, 
		\[\normep{\infty}{A(X+Y)}\leq \normep{\infty}{AX}+\normep{\infty}{AY}\leq N(X)+N(Y)\]
		D'où: \[N(X+Y)\leq N(X)+N(Y)\]
		\item Pour tous $X\in\M_{n,1}(\R)$ et $A\in\O_n(\R)$.\\
		\[N(AX)=\max_{B\in\O_n(\R)}\normep{\infty}{BAX}= \max_{B\in\O_n(\R)}\normep{\infty}{BX}=N(X)\]
		car l'application $B\in\O_n(\R)\mapsto BA$ est bijective.
		\item Soit $X\in\M_{n,1}(\R)$.
		Si $X=0$, il est clair que $N(X)=\normep{2}{X}$.\\
		Sinon, pour $A\in\O(\R)$, \[\normep{\infty}{AX}=\max_{1\leq i\leq n}\left|\sum_{j=1}^{n}a_{i,j}x_j\right|\]
		Soit $i\in\crblanc{1}{n}$. D'après l'inégalité de Cauchy-Schwarz,
		\[\left|\sum_{j=1}^{n}a_{i,j}x_j\right|\leq\left(\sum_{j=1}^{n}a_{i,j}^2\right)^{\frac{1}{2}}\left(\sum_{j=1}^{n}x_j^2\right)^{\frac{1}{2}}=\normep{2}{X}\]
		On en déduit que: \[\normep{\infty}{AX}\leq\normep{2}{X}\].
		Puisque cela vaut pour tout les $A\in\O(\R)$, on obtient, $N(X)\leq \normep{2}{X}$.
		Réciproquement, considérons la ligne $\displaystyle L=\frac{X^\top}{\normep{2}{X}}$
		On peut compléter cette ligne unitaire en une base orthonormée de $\M_{1,n}(\R)$.\\
		On pose $A\in\O(\R)$ la matrice formée par cette base.\\
		On a : \[|(AX)_1|=\normep{2}{X}\]
		et donc : \[\normep{2}{X}\leq\normep{\infty}{AX}\leq N(X)\]
		Par double inégalité : \[N(X)=\normep{2}{X}\]
	\end{enumerate}
	\subsection{Diamètre d'une partie bornée}\label{sec:diametre-dune-partie-bornee}
		\textcolor{blue}{\hyperref[Diamètre d'une partie bornée]{[Enoncé]}}\\
		\begin{enumerate}[leftmargin=*]
			\item Puisque $A$ est bornée, il existe $M\in\R_+$ tel que pour tout $x\in A$ , $N(x)\leq M$.
			D'après l'inégalité triangulaire pour tout $(x,y)\in A^2$
			\[N(x-y)\leq N(x) + N(y)\leq 2M\]
			Ainsi, l'ensemble $\{N(x-y), (x,y)\in A^2\}$ est majoré. Et puisque $A$ est non vide, il l'est également, ce qui justifie l'existence de la borne supérieure.
			\item Supposons que $A\subset B$.\\
			Pour tout $x,y\in A$, \[N(x-y)\leq \delta(B)\] car $x,y$ sont aussi des éléments de $B$.\\
			Puisque $\delta(A)$ est le plus petit majorant, on en déduit bien que $\delta(A)\leq\delta(B)$.
			\item 
			Soient $x,y\in A\cup B$.\\
			Si $x\in A$ et $y\in A$, $N(x-y)\leq \delta(A)\leq \delta(A)+\delta(B)$ car $N$ est une fonction positive.\\
			Idem, si $x\in B$ et $y\in B$.\\
			Dernière possibilité, si $x$ et $y$ sont dans des ensembles différents, par symétrie des rôles de $x$ et $y$ on peut supposer que $x\in A$ et $y\in B$
			 puisque $A\cap B\ne \emptyset$, il existe $z\in A\cap B$.\\
			\[N(x-y)\leq N(x-z)+N(z-y)\leq \delta(A)+\delta(B)\]
			On a donc montrer que pour tout $x,y\in A\cup B$ \[N(x-y)\leq \delta(A)+\delta(B)\]
			ainsi puisque $\delta(A\cup B)$ est le plus petit majorant de $\{N(x-y), x,y\in A\cup B \}$, on en déduit que \[\delta(A\cup B)\leq \delta(A)+\delta(B)\]
			\item 
			D'après ce qui précède, si $x$ et $y$ sont dans le même ensemble, le résultat est vrai.\\
			Supposons comme précédemment que $x\in A$ et $y\in B$.\\
			Par caractérisation séquentielle de la borne inférieur, il existe $(a_n)\in A^\N$ et $(b_n)\in B^\N$ telles que \[N(a_n-b_n)\underset{n\to+\infty}{\longrightarrow}d(A,B)\]
			Soit $(x,y)\in A\cup B$ et soit $n\in \N$.
			\[N(x-y)\leq N(x-a_n)+N(a_n-b_n)+N(b_n+y)\]
			Puisque $x, a_n\in A$ et $y,b_n\in B$, on a :
			\[N(x-y)\leq \delta(A)+N(a_n-b_n)+\delta(B)\]
			Ainsi, par passage à la limite, on en déduit que :
			\[N(x-y)\leq \delta(A)+\delta(B)+d(A,B)\]
			Puisque $\delta(A\cup B)$ est le plus petit majorant de $\{N(x-y), x,y\in A\cup B\}$, on a montré que pour tous 
			\[\delta(A\cup B)\leq \delta(A)+\delta(B)+d(A,B)\] 			
		\end{enumerate}
	\subsection{Détermination d'une borne inférieure}\label{sec:determination-dune-borne-inferieure}
		\textcolor{blue}{\hyperref[Détermination d'une borne inférieure]{[Enoncé]}}\\
	\subsection{Normes usuelles sur $\mathcal{C}^1([0,1],\K)$}\label{sec:normes-usuelles-sur-mathcalc101k}
			\textcolor{blue}{\hyperref[Normes usuelles sur C1]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item \begin{itemize}
			\item Montrons que $N_1$ est une norme.\\
			\textbullet On a déjà que $0\in E$ et $N_1(0)=0$.\\
			Soit $f\in E$ tel que $N_1(f)=0$.\\
			On a alors $\normep{1}{f}=0$ et $\normep{1}{f}=0$ car $N_1(f)$ est la somme de deux termes positifs.\\
			On a alors $f=0$ car $\normep{1}{f}=0$.\\
			\textbullet L'homogénéité est plutôt clair.\\
			\textbullet L'inégalité triangulaire est clair aussi car $\normep{1}{.}$ est une norme.
		\item Montrons que $\N_2$ est une norme.\\
			\textbullet Idem on a encore $N_2(0)=0$.
			Soit $f\in E$ tel que $N_2(f)=0$.\\
			On a $f(0)=0$ et $\normep{1}{f'}=0$.
			Donc $f'$ est nulle et $f(0)=0$.\\
			Par conséquent $f$ est constante (car $f'$ est nulle) égale à $0$ car $f(0)=0$.\\
			\textbullet L'homogénéité et l'inégalité triangulaire est immédiate car $|.|$ et $\normep{1}{.}$ sont des normes.
		\end{itemize}
		Ainsi, $N_1$ et $N_2$ sont des normes.
		\item On sait que pour tout $x\in[0,1]$ on a :
		\[f(x)=f(0)+\int_{0}^{x}f'(t)dt\]
		Ainsi, on a 
		\[|f(x)|\leq |f(0)|+\int_{0}^{x}|f'(t)|dt\]
		Puisque $|f'(t)|\geq $ pour tout $t\in [0,1]$, on a 
		\[|f(x)|\leq |f(0)|+\int_{0}^{1}|f'(t)|dt\]
		Il suffit d'intégrer pour avoir 
		\[N_1(f)\leq N_2(f)\]
		Comme précédemment, on a
		\[f(0)=f(x)-\int_{0}^{x}f'(t)dt\]
		Donc l'inégalité triangulaire de la valeur absolue donne 
		\[|f(0)|\leq |f(x)|+\int_{0}^{x}|f'(t)|dt\leq |f(x)|+\int_{0}^{1}|f'(t)|dt\]
		Donc en intégrant de $0$ à $1$, on a 
		\[|f(0)|\leq N_1(f)\]
		Puisque $\normep{1}{f}\geq 0$, on a $\normep{1}{f'}\leq N_1(f)$.\\
		Par conséquent, \[N_2(f)\leq 2N_1(f)\]
		Donc $N_1$ et $N_2$ sont équivalentes.
	\end{enumerate}
	\subsection{Intersection des boules unités subordonnées d'un espace vectoriel normé de dimension finie}\label{sec:intersection-des-boules-unites-subordonnees-dun-espace-vectoriel-norme-de-dimension-finie}
		\textcolor{blue}{\hyperref[Intersection des boules unités subordonnées d'un espace vectoriel normé de dimension finie]{[Enoncé]}}\\
	\subsection{Modes de convergence}\label{sec:modes-de-convergence}
		\textcolor{blue}{\hyperref[Modes de convergence]{[Enoncé]}}\\
	\subsection{Moyenne des itérés et projection sur l'espace des invariants d'une application linéaire contractante}\label{sec:moyenne-des-iteres-et-projection-sur-lespace-des-invariants-dune-application-lineaire-contractante}
		\textcolor{blue}{\hyperref[Moyenne des itérés et projection sur l'espace des invariants d'une application linéaire contractante]{[Enoncé]}}\\
	\subsection{Matrice de projecteur}\label{sec:matrice-de-projecteur}
		\textcolor{blue}{\hyperref[Matrice de projecteur]{[Enoncé]}}\\
		Puisque $(A^n)$ est une suite converge vers $L$, $(A^{2n})$ converge également vers $L$.\\
		De plus, par continuité de la fonction $M\in\M_p(\R)\mapsto M^2$, on en déduit que $(A^{2n})$ converge vers $L^2$.\\
		Ainsi par unicité de la limite, $L^2=L$, c'est-à-dire $L$ est une matrice de projecteur.
	\subsection{Matrice de rotation}\label{sec:matrice-de-rotation}
		\textcolor{blue}{\hyperref[Matrice de rotation]{[Enoncé]}}\\
	\subsection{Applications contractantes}\label{sec:applications-contractantes}
		\textcolor{blue}{\hyperref[Application contractantes]{[Enoncé]}}\\
	\subsection{Une série vectorielle}\label{sec:une-serie-vectorielle}
		\textcolor{blue}{\hyperref[Une série vectorielle]{[Enoncé]}}\\
	\subsection{Polytopes réguliers d'un espace vectoriel euclidien}\label{sec:polytopes-reguliers-dun-espace-vectoriel-euclidien}
		\textcolor{blue}{\hyperref[Polytopes réguliers d'un espace vectoriel euclidien]{[Enoncé]}}\\
	\newpage
	\section{Correction Suites et séries de fonctions}
	\subsection{Etude d'une suite de fonctions (1)}\label{sec:etude-dune-suite-de-fonctions-1}
		\textcolor{blue}{\hyperref[Etude d'une suite de fonctions 1]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item Soit $x\in [0,1]$.\\
		Pour $n=0$, le résultat est immédiat.\\
		Supposons que pour un certain $n\in\N$, $0\leq P_n(x)\leq \sqrt{x}$.\\
		Alors $x-P_n(x)^2\geq 0$ donc $P_{n+1}\geq P_n(x)\geq 0$ et \[\sqrt{x}-P_{n+1}(x)=(\sqrt{x}-P_n(x))\left(1_\frac{1}{2}(\sqrt{x}+P_n(x))\right)\geq 0\]
		donc $P_{n+1}\leq\sqrt{x}$.
		Ainsi, on a montré par récurrence le résultat.
		\item On reprend l'inégalité précédente, pour tout $n\in\N$ : 
		\[\sqrt{x}-P_{n+1}(x)=(\sqrt{x}-P_n(x))\left(1_\frac{1}{2}(\sqrt{x}+P_n(x))\right)\leq(\sqrt{x}-P_n(x))\left(1-\frac{\sqrt{x}}{2}\right)\]
		On montre cette fois par récurrence que :
		\[0\leq \sqrt{x}-P_n(x)\leq (\sqrt{x}-P_0(x))\left(1-\frac{\sqrt{x}}{2}\right)^n\]
		\item On pose pour tout $n\in \N$, $g_n:t\mapsto t\left(1-\dfrac{t}{2}\right)^n$. L'étude de fonction montre que $g_n$ atteint son maximum en $\dfrac{2}{n+1}$. Ainsi : 
		\[\forall x\in [0,1], \forall n\in \N, 0\leq \sqrt{x}-P_n(x)\leq g_n(x)\leq g\left(\frac{2}{n+1}\right)=\frac{2}{n+1}\left(1-\frac{1}{n+1}\right)^n\leq \frac{2}{n+1}\]
		On en déduit que $(P_n)$ converge uniformément sur $[0,1]$ vers la fonction $x\mapsto \sqrt{x}$.
	\end{enumerate}
	\subsection{Etude d'une suite de fonctions (2)}\label{sec:etude-dune-suite-de-fonction-2}
		\textcolor{blue}{\hyperref[Etude d'une suite de fonctions 2]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item On va montrer par récurrence que pour tout $n\in\N$, 
		\[g_n \text{ est bornée}\]
		Il est clair que $g_0$ est bornée.
		Supposons que pour un certain $n\in\N$, $g_n$ est bornée.\\
		\[\forall x\in [0,1], |g_{n+1}(x)|\leq\int_{0}^{x}|g_{n}(1-t)|dt\leq\int_{0}^{x}\normep{\infty}{g_n}dt=x\normep{\infty}{g_n}\leq \normep{\infty}{g_n}\]
		Donc $g_n$ est bornée pour tout $n\in \N$.\\
		Affinons le résultat, on a montré que pour tout $x\in [0,1]$ et $n\in\N, |g_{n+1}(x)|\leq x\normep{\infty}{g_n}$.\\
		Ainsi, pour tout $n\in\N^*$
		\[|g_{n+1}(x)|\leq\int_{0}^{x}|g_n(1-t)|dt\leq\int_{0}^{x}(1-t)\normep{\infty}{g_{n-1}}\int_{0}^{1}(1-t)\normep{\infty}{g_{n-1}}dt=\frac{1}{2}\normep{\infty}{g_{n-1}}\]
		Ainsi, \[\norme{g_{n+1}}\leq \frac{1}{2}\normep{\infty}{g_{n-1}}\]
		\item A l'aide de la question précédente, on a $\begin{cases}
		\displaystyle	\normep{\infty}{g_{2n}}\leq \frac{1}{2^n}\normep{\infty}{g_0},\\
		\displaystyle 	\normep{\infty}{g_{2n+1}}\leq \frac{1}{2^n}\normep{\infty}{g_1}
		\end{cases}$\\
		On pose $K=\max(\normep{\infty}{g_0}, \normep{\infty}{g_1})$, pour avoir \[\forall n\in\N, \normep{\infty}{g_n}\leq\frac{K}{\sqrt{2}^n}\]
		Comme la série $\displaystyle\sum \frac{1}{\sqrt{2}^n}$ est une série convergente, ainsi on en déduit que $\displaystyle\sum g_n$ converge normalement donc simplement sur $[0,1]$. La fonction $G$ est bien définie sur $[0,1]$.\\
		D'après le théorème fondamental de l'analyse , $g_n$ est dérivable sur $[0,1]$ pour tout $n\in \N$ et $g_n'(x)=g_{n-1}(1-x)$.
		Donc la série $\displaystyle \sum g_n'$ converge normalement donc uniformément sur $[0,1]$. On en déduit que $G$ est dérivable et que 
		\[\forall x\in [0,1], G'(x)=\sum_{n=0}^{+\infty}g_n'(x)=\sum_{n=1}^{\infty}g_{n-1}(1-x)=\sum_{n=0}^{\infty}g_n(1-x)=G(1-x)\]
		Par conséquent, $G'$ est dérivable sur $[0,1]$ et que 
		\[\forall x\in [0,1], G''(x)=-G'(1-x)=-G(x)\]
		\item $G$ est donc solution de l'équation différentielle, $y''+y=0$.\\
		Donc il existe $(\alpha, \beta)\in\R^2$ tel que $G=\alpha \cos+\beta \sin$.\\
		Et de plus pour tout $n\in\N^*$, $g_n(0)=0$ donc $G(0)=1$, et $G'(1)=G(0)=1$. On en déduit que $\alpha=1$ et $\displaystyle\beta=\frac{1+\sin(1)}{\cos(1)}$. 
	\end{enumerate}
	\subsection{Etude d'une suite de fonctions (3)}\label{sec:etude-dune-suite-de-fonctions-3}
		\textcolor{blue}{\hyperref[Etude d'une suite de fonctions 3]{[Enoncé]}}\\
	Soit $x\in\R$\\
	Si $x\in \pi\Z$ alors $f_n(x)=0$.\\
	Si $x\not\in\Z$ alors $|\cos(x)|<1$ d'où par croissance comparées, on a $\lim\limits_{n\to+\infty}f_n(x)=0$.\\
	Donc $(f_n)$ converge simplement vers la fonction nulle.\\
	Montrons que $(f_n)$ ne converge pas uniformément sur $\R$ vers la fonction nulle.\\
	Soit $n\in\N^*$ \[f_n\left(\frac{1}{n}\right)=n\cos\left(\frac{1}{n}\right)^n\sin\left(\frac{1}{n}\right)\]
	On sait que : \[\cos\left(\frac{1}{n}\right)=1-\frac{1}{2n^2}+\o{\frac{1}{n^2}}\]	
	Ainsi, \[n\ln\left(\cos\left(\frac{1}{n}\right)\right)\underset{n\to+\infty}{\sim}\frac{1}{2n}\]
	puis par continuité de l'exponentielle ²\[\exp\left(n\ln\left(\cos\left(\frac{1}{n}\right)\right)\right)=1\]
	On sait également que \[\sin\left(\frac{1}{n}\right)\underset{n\to+\infty}{\sim}\frac{1}{n}\] par conséquent, on a :  
	\[\lim_{n\to+\infty}f_n\left(\frac{1}{n}\right)=1\]
	Donc $(f_n)$ ne converge pas absolument vers la fonction nulle.
	\subsection{Etude d'une suite de fonctions (4)}\label{sec:etude-dune-suite-de-fonctions-4}
		\textcolor{blue}{\hyperref[Etude d'une suite de focntions 4]{[Enoncé]}}\\
	
	\subsection{Etude d'une suite de fonctions 5}\label{sec:etude-dune-suite-de-fonction-5}
		\textcolor{blue}{\hyperref[Etude d'une suite de fonctions 5]{[Enoncé]}}\\
	\subsection{Etude d'une suite de fonctions 6}\label{sec:etude-dune-suite-de-fonction-6}
		\textcolor{blue}{\hyperref[Etude d'une suite de fonctions 6]{[Enoncé]}}\\
	\subsection{Etude d'une suite de fonctions 7}\label{sec:etude-dune-suite-de-fonction-7}
		\textcolor{blue}{\hyperref[Etude d'une suite de fonctions 7]{[Enoncé]}}\\
		
	\subsection{Développement de la cotangente (1)}
	\label{sec:developpement-de-la-cotangente-(1)}
	\textcolor{blue}{\hyperref[Développement de la cotangente (1)]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item Fixons $x\in \R\backslash\Z$.\\
		$f_n(x)=\displaystyle\frac{1}{x}+\sum_{k=1}^n\left(\frac{1}{x-k}+\frac{1}{x+k}\right)=\frac{1}{x}+\sum_{k=1}^n\frac{2x}{x^2-k^2}$.\\
		Or $\dfrac{2x}{x^2-k^2}\ukfty=\bigO{\dfrac{1}{k^2}}$ donc $(f_n(x))_{n\in \N}$ converge par comparaison à une série de Riemann.\\
		Ainsi $(f_n)_{n\in \N}$ converge simplement sur $\R\backslash\Z$ vers $f:x\mapsto\displaystyle\frac{1}{x}+\sum_{k=1}^{+\infty}\frac{2x}{x^2-k^2}$.\\
		\item $\cotan(\pi x)=\dfrac{\cos(\pi x)}{\sin(\pi x)}$ est définie et continue sur $\R\backslash\Z$.\\
		En outre $\forall x\in \R\backslash\Z,\ \cotan(\pi(x+1))=\dfrac{\cos(\pi x+\pi)}{\sin(\pi x+\pi)}=\dfrac{-\cos(\pi x)}{-\sin(\pi x)}=\cotan(\pi x)$.\\
		On remarque ensuite que $f$ est $1$-périodique (c'est un changement d'indice). On peut donc se contenter de montrer que $f$ est continue sur $]0,1[$ et que $g$ est prolongeable par continuité en $0$.
		Les $f_n$ sont continues sur $]0,1[$, montrons qu'elles convergent uniformément vers $f$ sur tout segment de $]0,1[$.\\
		Soit $x\in ]0,1[$. On note $R_n(x):=f(x)-f_n(x)=\displaystyle\sum_{k=n+1}^{+\infty}\frac{2x}{x^2-k^2}$.\\
		$\forall n\in \N^*,\ |R_n(x)|\leq \displaystyle\sum_{k=n+1}^{+\infty}\frac{2}{k^2-x^2}\leq \sum_{k=n+1}^{+\infty}\frac{2}{k(k-1)}=2\sum_{k=n+1}^{+\infty}\left(\frac{1}{k-1}-\frac{1}{k}\right)=\frac{2}{n}$.\\
		Ainsi $\sup\limits_{x\in ]0,1[}|R_n(x)|\leq \dfrac{2}{n}\unfty\longrightarrow0$.\\
		Càd $(f_n)_{n\in \N}$ converge uniformément vers $f$ sur $]0,1[$. On en déduit que $f$ est continue sur $]0,1[$.\\
		Enfin, \begin{align*}
			\pi\cotan(\pi x)&\ =\frac{\pi\cos(\pi x)}{\sin(\pi x)}\\
			&\uxzero=\frac{1}{x-\frac{\pi^2x^3}{6}+\smallo{x^3}}\\
			&\uxzero=\frac{1}{x}\cdot\frac{1}{1-\frac{\pi^2x^2}{6}+\smallo{x^2}}\\
			&\uxzero=\frac{1}{x}\left(1-\frac{\pi^2x^2}{6}+\smallo{x^2}\right)\\
			&\uxzero=\frac{1}{x}-\frac{\pi^2x}{6}+\smallo{x}
		\end{align*}
		Donc $g(x)\uxzero=\displaystyle-\frac{\pi^2x}{6}+\sum_{k=1}^{+\infty}\frac{2x}{k^2-x^2}+\smallo{x}\uxzero=\smallo{1}$.\\
		Càd $g$ est prolongeable par continuité en $0$ en posant $g(0)=0$. Par $1$-périodicité, $g$ est prolongeable par continuité sur $\R$ en posant $g(k)=0$ pour tout entier $k$.
		\item $\displaystyle f\left(\frac{x}{2}\right)+f\left(\frac{x+1}{2}\right)=\sum_{k=-\infty}^{+\infty}\frac{2}{x-2k}+\sum_{k=-\infty}^{+\infty}\frac{2}{x-2k+1}$.
		Or on a en fait montré dans la question précédente qu'on a la convergence normale des séries en jeux sur $]0,1[$. Donc d'après le théorème de sommation par paquets,
		$$f(x)=\frac{f\left(\frac{x}{2}\right)+f\left(\frac{x+1}{2}\right)}{2}$$
		Ensuite,\begin{align*}
			\cotan\left(\frac{\pi x}{2}\right)+\cotan\left(\frac{\pi(x+1)}{2}\right)&=\frac{\cos(\frac{\pi x}{2})\sin(\frac{\pi(x+1)}{2})+\cos(\frac{\pi(x+1)}{2})\sin(\frac{\pi x}{2})}{\sin(\frac{\pi x}{2})\sin(\frac{\pi(x+1)}{2})}\\
			&=\frac{\sin(\pi x+\frac{\pi}{2})}{\sin(\frac{\pi x}{2})\sin(\frac{\pi x}{2}+\frac{\pi}{2})}\\
			&=\frac{\cos(\pi x)}{\sin(\frac{\pi x}{2})\cos(\frac{\pi x}{2})}\\
			&=\frac{2\cos(\pi x)}{\sin(\pi x)}\\
			&=2\cotan(\pi x)
		\end{align*}
		Donc $g(x)=\dfrac{g\left(\frac{x}{2}\right)+g\left(\frac{x+1}{2}\right)}{2}$.\\
		Cette égalité reste vraie en $0$ par continuité. Elle est donc vraie sur $\R$ par $1$-périodicité.
		\item $g$ étant continue sur $[0,1]$, elle y est bornée et atteints ses bornes. Il existe donc $a\in [0,1]$ tel que $g(a)=\max\limits_{x\in [0,1]}g(x)$.\\
		On remarque alors que comme $\displaystyle\frac{a+1}{2}\in [0,1],\ 2g(a)=g\left(\frac{a}{2}\right)+g\left(\frac{a+1}{2}\right)\leq g\left(\frac{a}{2}\right)+g(a)$ i.e $g\left(\dfrac{a}{2}\right)\geq g(a)$. Comme $\dfrac{a}{2}\in [0,1]$, $g(a)=g\left(\dfrac{a}{2}\right)$. Par récurrence immédiate $\forall n\in \N,\ g(a)=g\left(\dfrac{a}{2^n}\right)$. Donc par continuité de $g$ en $0$, $g(a)=g(0)=0$. D'où $g=0$ sur $[0,1]$, puis sur $\R$ par $1$-périodicité.
	\end{enumerate}
	
	\subsection{Etude d'une fonction définie par une série alternée (1)}\label{sec:etude-dune-fonction-definie-par-une-serie-alternee-1}
		\textcolor{blue}{\hyperref[Etude d'une fonction définie par une série alternée 1]{[Enoncé]}}\\
	\subsection{Etude d'une fonction définie par une série alternée (2)}\label{sec:etude-dune-fonction-definie-par-une-serie-alternee-2}
		\textcolor{blue}{\hyperref[Etude d'une fonction définie par une série alternée 2]{[Enoncé]}}\\
	\subsection{Convergence vers une dérivée}\label{sec:convergence-vers-une-derivee}
		\textcolor{blue}{\hyperref[Convergence vers une dérivée]{[Enoncé]}}\\
		On sait que : \[\frac{f(x+h)-f(x)}{h}\underset{h\to 0}{\to}f'(x)\]
		donc \[\frac{f\left(x+\frac{1}{n}\right)-f(x)}{\frac{1}{n}}\underset{n\to +\infty}{\to}f'(x)\]
		Donc $(g_n)$ converge simplement vers $f'$ sur $\R$.\\
		D'après l'inégalité de Taylor Lagrange, on a : 
		\[\left|f\left(x+\frac{1}{n}\right)-f(x)-\frac{1}{n}f'(x)\right|\leq\frac{\normep{\infty}{f''}}{2n^2}\]
		donc \[|g_n(x)-f'(x)|\leq\frac{\normep{\infty}{f''}}{2n}\]
		d'où \[\normep{\infty}{g_n-f'}\leq \frac{\normep{\infty}{f''}}{2n}\to 0\]
		Ainsi $(g_n)$ converge uniformément vers $f'$ sur $\R$.
	\subsection{Limite ponctuelle et uniforme d'une suite de fonctions}\label{sec:limite-ponctuelle-et-uniforme-dune-suite-de-fonctions}
		\textcolor{blue}{\hyperref[Limite ponctuelle et uniforme d'une suite de fonctions]{[Enoncé]}}\\
	\subsection{Convergence des suites de polynômes}\label{sec:convergence-des-suites-de-polynomes}
		\textcolor{blue}{\hyperref[Convergence des suites de polynômes]{[Enoncé]}}\\
	
	
	
	\subsection{Un théorème de Weierstrass sur $\R$ ?}\label{sec:un-theoreme-de-weierstrass-sur-r-}
		\textcolor{blue}{\hyperref[Un théorème de Weierstrass sur R]{[Enoncé]}}\\
	Par hypothèse, la suite $(P_n)$ converge uniformément vers $f$ sur $\R$. Ecrivons la définition de cette convergence pour une distance $\varepsilon=1$.\\
	Il existe un rang $N\in\N$ tel que pour tout $n\geq N$ et pour tout $x\in\R$ :
	\[|P_n(x)-f(x)|\leq 1\]
	Soit $n\geq N$ quelconque. Pour tout $x\in \R$\\
	\[|P_n(x)-P_N(x)|=|P_n(x)-f(x)+f(x)-P_N(x)|\]
	donc \[|P_n(x)-P_N(x)|\leq |P_n(x)-f(x)|+|f(x)-P_N(x)|\leq 2\]
	On pose $Q_n=P_n-P_N$.\\
	Ce polynôme est de degré $0$ car il est borné. En effet, si $Q_n$ n'est pas de degré $0$, on aurait \[\lim\limits_{|x|\to+\infty}|Q_n(x)|=+\infty\]
	Ainsi il existe $c_n\in\R$ tel que $P_n(x)=P_N(x)+c_n$.\\
	Puisque $P_n$ converge simplement vers $f$, on a que $c_n$ converge vers un certain $\lambda\in\R$.\\
	Par conséquent $f=P_n+\lambda$.\\
	Donc $f$ est un polynôme à coefficients dans $\R$. 
	\subsection{Approximation paire}\label{sec:approximation-paire}
		\textcolor{blue}{\hyperref[Approximation paire]{[Enoncé]}}\\
	\subsection{Approximation croissante}\label{sec:approximation-croissante}
		\textcolor{blue}{\hyperref[Approximation croissante]{[Enoncé]}}\\
	\subsection{Interversion Série-Intégrale}\label{sec:interversion-serie-integrale}
		\textcolor{blue}{\hyperref[Interversion Série-Intégrale]{[Enoncé]}}\\
	
	
	\subsection{Série de fonction matricielle}\label{sec:serie-de-fonction-matricielle}
		\textcolor{blue}{\hyperref[Série de fonction matricielle]{[Enoncé]}}\\
	
	\subsection{Fonction $\zeta$ de Riemann}\label{sec:fonction-zeta-de-riemann}
		\textcolor{blue}{\hyperref[Fonction zeta de Riemann]{[Enoncé]}}\\
	
	\subsection{Expression de suites sous forme de séries}\label{sec:expression-de-suites-sous-forme-de-series}
		\textcolor{blue}{\hyperref[Expression de suites sous forme de séries]{[Enoncé]}}\\
	
	\subsection{Etude d'une série de fonctions}\label{sec:etude-dune-serie-de-fonctions}
		\textcolor{blue}{\hyperref[Etude d'une série de fonctions]{[Enoncé]}}\\
	
	\subsection{Théorème de Dini \etoile{4}}\label{sec:theoreme-de-dini-etoile4}
		\textcolor{blue}{\hyperref[Théorème de Dini]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item Soit $\varepsilon>0$.\\
		Tout d'abord, quel que soit $x\in [a,b]$, la suite $(f_n(x))_{n\in \N}$ est croissante et converge vers $f(x)$ donc $\forall n\in \N,\ f_n(x)\leq f(x)$.\\
		Donc $\forall n\in \N,\ f_n\leq f_{n+1}\leq f$.\\
		\underline{$1^{ère}$ méthode :}\\
		Fixons $x\in [a,b]$.\\
		On pose $N\in \N^*$ tel que $\displaystyle\frac{b-a}{N}\leq \frac{\varepsilon}{3}$ et pour $k\in \crblanc{0}{N},\ x_k=\displaystyle a+\frac{k(b-a)}{N}$. $x_0,\dots,x_N$ forme une subdivision régulière de $[a,b]$ donc $\exists k\in \crblanc{0}{N},\ |x_k-x|\leq |x_1-x_0|=\displaystyle\frac{b-a}{N}$.\\
		Ensuite, par convergence simple de la suite $(f_n)_{n\in \N}$, on peut se donner $M\in \N$ tel que $|f(x_k)-f_M(x_k)|\leq \displaystyle\frac{\varepsilon}{3}$.\\
		Enfin $f$ et $f_M$ sont continues sur un segment, d'après le théorème de Heine elles sont uniformément continues sur ce segment. On sait donc que $\exists \eta>0,\ \forall (x,y)\in [a,b]^2,\ |x-y|\leq \eta\implies |f(x)-f(y)|\leq \displaystyle\frac{\varepsilon}{3}$ et $|f_M(x)-f_M(y)|\leq \displaystyle\frac{\varepsilon}{3}$.\\
		Finalement par inégalité triangulaire,\\
		$\forall n\geq M,\ 0\leq f(x)-f_n(x)\leq f(x)-f_M(x)\leq |f(x)-f(x_k)|+|f(x_k)-f_M(x_k)|+|f_M(x_k)-f_M(x)|\leq \varepsilon$.\\
		Ainsi par passage au sup, $\forall n\geq M,\ \normep{\infty,[a,b]}{f-f_n}\leq \varepsilon$ i.e $(f_n)_{n\in \N}$ converge uniformément vers $f$ sur $[a,b]$.\\\\
		\underline{$2^{nd}$ méthode :}\\
		Posons pour tout $n\in \N,\ F_n=\{x\in [a,b],\ f(x)-f_n(x)\geq \varepsilon\}$.\\
		$\forall n\in \N,\ F_{n+1}\subset F_n$. De plus les $F_n$ sont des compacts de $\R$ : en effet si $n\in \N$ et $(x_k)\in F_n^\N$ converge vers $x$ alors $x\in [a,b]$ et $\forall k\in \N,\ f(x_k)-f_n(x_k)\geq \varepsilon$. Donc par continuité de $f$ et $f_n$, en passant à la limite $f(x)-f_n(x)\geq \varepsilon$ et $x\in F_n$. Par caractérisation séquentielle $F_n$ est un fermé inclus dans le compact $[a,b]$, c'est donc un compact de $\R$.\\
		On sait en vertu de la convergence simple de $(f_n)_{n\in \N}$ que $\displaystyle\bigcap_{n\in \N}F_n=\emptyset$. Donc par la contraposé du lemme des compacts emboîtés (cf. \ref{Lemme des compacts emboîtés}), $\exists N\in \N,\ F_N=\emptyset$.\\
		Autrement dit, $\forall n\geq N,\ \forall x\in [a,b],\ 0\leq f(x)-f_n(x)\leq f(x)-f_N(x)<\varepsilon$ ou encore, $\forall n\geq N,\ \normep{\infty}{f-f_n}<\varepsilon$.\\
		Donc $(f_n)_{n\in \N}$ converge uniformément vers $f$ sur $[a,b]$.
		\item Soit $\varepsilon>0$.\\
		Tout d'abord on peut remarquer que $f$ est croissante comme limite simple de fonctions croissantes.\\
		Fixons $x\in [a,b]$. Fixons $N\in \N^*$ tel que $\displaystyle\frac{f(b)-f(a)}{N}\leq \frac{\varepsilon}{4}$.\\
		Comme $f$ est continue d'après le TVI, $\forall k\in \crblanc{0}{N},\ \exists x_k\in [a,b],\ f(x_k)=f(a)+\displaystyle k\frac{f(b)-f(a)}{N}$. De plus par croissance de $f$ on a $x_0\leq x_1\leq \dots\leq x_N$.\\
		$f(x_0),\dots,f(x_N)$ forme une subdivision régulière de $[f(a),f(b)]$ donc il existe $k\in \crblanc{0}{N-1}$ tel que $f(x)\in [f(x_k),f(x_{k+1})]$.\\
		Alors $|f(x)-f(x_k)|\leq |f(x_{k+1})-f(x_k)|=\displaystyle\frac{f(b)-f(a)}{N}\leq \frac{\varepsilon}{4}$.\\
		Par convergence simple on sait qu'il existe $M\in \N$ tel que pour tout $n\geq M$,\\
		$|f(x_k)-f_n(x_k)|\leq \displaystyle\frac{\varepsilon}{4}$ et $|f_n(x_{k+1})-f_n(x_k)-f(x_{k+1})+f(x_k)|\leq \displaystyle\frac{\varepsilon}{4}$.\\
		Donc par croissance des $f_n$ et inégalité triangulaire, $\forall n\geq M$ :
		\begin{align*}
			|f(x)-f_n(x)|&\leq |f(x)-f(x_k)|+|f(x_k)-f_n(x_k)|+|f_n(x_k)-f_n(x)|\\
			&\leq |f(x)-f(x_k)|+|f(x_k)-f_n(x_k)|+|f_n(x_{k+1})-f_n(x_k)|\\
			&\leq |f(x)-f(x_k)|+|f(x_k)-f_n(x_k)|+|f_n(x_{k+1})-f_n(x_k)-f(x_{k+1})+f(x_k)|+|f(x_{k+1})-f(x_k)|\\
			&\leq \varepsilon
		\end{align*}
		Finalement, $\normep{\infty}{f-f_n}\unfty\longrightarrow 0$ et $(f_n)_{n\in \N}$ converge uniformément vers $f$.
	\end{enumerate}
	
	\subsection{Suite de fonction lipschitzienne \etoile{3}}\label{sec:suite-de-fonction-lipschitzienne-etoile3}
		\textcolor{blue}{\hyperref[Suite de fonction lipschitzienne]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item Soit $(x,y)\in [a,b]^2$.\\
		$\forall n\in \N,\ |f_n(x)-f_n(y)|\leq L|x-y|$.\\
		Donc par passage à la limite à l'aide de la convergence simple $|f(x)-f(y)|\leq L|x-y|$.\\
		Ainsi $f$ est $L$-lipschitzienne.
		\item Soit $x\in [a,b]$. Fixons $\varepsilon>0$ et $N\in \N^*$ tel que $\displaystyle\frac{b-a}{N}\leq \frac{\varepsilon}{4L}$. On pose pour $k\in \crblanc{0}{N},\ x_k=a+\displaystyle\frac{k(b-a)}{N}$. $x_0,\dots,x_N$ forme une subdivision régulière de $[a,b]$ donc $\exists k\in \crblanc{0}{N},\ |x_k-x|\leq |x_1-x_0|=\displaystyle\frac{b-a}{N}$.\\
		On a alors par inégalité triangulaire $\forall n\in \N$,\\
		$|f(x)-f_n(x)|\leq |f(x)-f(x_k)|+|f(x_k)-f_n(x_k)|+|f_n(x_k)-f_n(x)|\leq L|x-x_k|+|f(x_k)-f_n(x_k)|+L|x_k-x|\leq |f(x_k)-f_n(x_k)|+\displaystyle\frac{\varepsilon}{2}$.\\
		De plus par convergence simple, $\exists M\in \N,\ \forall n\geq M,\ |f(x_k)-f_n(x_k)|\leq \displaystyle\frac{\varepsilon}{2}$.\\
		Donc, $\forall n\geq M,\ |f(x)-f_n(x)|\leq \varepsilon$. Par passage à la borne sup, $\forall n\geq M,\ \normep{\infty}{f-f_n}\leq \varepsilon$.\\
		$(f_n)_{n\in \N}$ converge donc uniformément vers $f$ sur $[0,1]$.
	\end{enumerate}
	
	\subsection{Phénomène de Runge}\label{sec:phenomene-de-runge}
		\textcolor{blue}{\hyperref[Phénomène de Runge]{[Enoncé]}}\\
	
	\subsection{Théorème de Weierstrass}\label{sec:theoreme-de-weierstrass}
		\textcolor{blue}{\hyperref[Théorème de Weierstrass]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item\begin{enumerate}[label=\alph*.]
		 \item Soit $f,g\in E$.\\
		$\forall x\in\R$
		\begin{align*}
			(f*g)(x)&=\int_{-\infty}^{+\infty}f(x-t)g(t)dt\\
			&=\int_{+\infty}^{-\infty}f(t)g(x-u)(-du)&\text{on pose }u=x-t\\
			&=(g*f)(x) 
		\end{align*}
		Soit $f,g,h\in E$.\\
		$\forall x\in \R$
		\begin{align*}
			((f+g)*h)(x)&=\int_{-\infty}^{+\infty}(f+g)(x-t)h(t)dt\\
			&=\int_{-\infty}^{+\infty}\left[f(x-t)h(t)+g(x-t)h(t)\right]dt\\
			&=(f*h)(x)+(g*h)(x)
		\end{align*}
		\item 
		$\forall x\in\R,\forall \alpha >0$ 
		\begin{align*}
			|f*\chi_n(x)-f(x)|&=\left|\int_{-\infty}^{+\infty}f(x-t)\chi_n(t)dt-f(x)\right|\\
			&=\left|\int_{-\infty}^{+\infty}\left(f(x-t)-f(x)\right)\chi_n(t)dt\right|\\
			&\leq \int_{-\infty}^{+\infty}\left|f(x-t)-f(x)\right|\chi_n(t)dt\\
			&=\int_{|t|<\alpha}\left|f(x-t)-f(x)\right|\chi_n(t)dt+\int_{|t|\geq\alpha}\left|f(x-t)-f(x)\right|\chi_n(t)dt
		\end{align*}
		D'après l'énoncé, $f$ est continue sur un compact donc elle est uniformément continue d'après le théorème de Heine.\\
		Ainsi $\forall \varepsilon>0, \exists \alpha >0, \forall t\in\R, |(x-t)-t|<\alpha \Rightarrow |f(x-t)-f(x)|<\frac{\varepsilon}{2}$.\\
		Par conséquent, \[\int_{|t|<\alpha}|f(x-t)-f(x)|\chi_n(t)dt<\frac{\varepsilon}{2}\int_{|t|<\alpha}\chi_n(t)dt\]
		d'où \[\int_{|t|<\alpha}|f(x-t)-f(x)|\chi_n(t)dt<\frac{\varepsilon}{2}\int_{-\infty}^{+\infty}\chi_n(t)dt=\frac{\varepsilon}{2}\]
		De plus, puisque $f$ est continue à valeurs dans un compact, elle est bornée d'après le théorème des bornes atteintes, ainsi il existe $M\in \R$ tel que :
		\[\int_{|t|\geq\alpha}|f(x-t)-f(x)|\chi_n(t)dt\leq 2M\int_{|t|\geq\alpha}\chi_n(t)dt\]
		Puisque $(\chi_n)$ est une séquence de Dirac, il existe $N\in\N$ tel que $\forall n\geq N$, 
		\[\int_{|t|\geq\alpha}\chi_n(t)dt\leq \frac{\varepsilon}{4M}\]
		Par conséquent, pour tout $n\geq N$, on a :
		\[|(f*\chi_n)(x)-f(x)|\leq \frac{\varepsilon}{2}+2M\frac{\varepsilon}{4M}=\varepsilon\]
		Donc : \[\normep{\infty}{(f*\chi_n)-f}\leq \varepsilon\]
		Finalement, $(f*\chi_n)$ converge uniformément vers $f$ sur $\R$.
		\end{enumerate}
		\item\begin{enumerate}
		 \item Il est clair que $(p_n)$ est une suite de fonctions positives.\\
		Par définition, il a \[\int_{-\infty}^{+\infty}p_n(t)dt=1\]
		Soit $\alpha>0$.\\
		Si $\alpha\geq1$, on a \[\int_{|t|\geq\alpha}p_n(t)dt=0\]
		Si $\alpha<1$, on a 
			\[a_n=2\int_{0}^{1}(1-t^2)^ndt\geq2\int_{0}^{1}t(1-t^2)^ndt=\frac{1}{n+1}\]
		Ainsi, \[\int_{|t|\geq\alpha}p_n(t)dt=\frac{2}{a_n}\int_{\alpha}{1}(1-t^2)^ndt\leq \frac{(1-\alpha^2)^n}{a_n}\leq2(n+1)(1-\alpha^2)^n\]
		Par croissance comparée, 
		\[\lim\limits_{n\to+\infty}\int_{|t|\geq\alpha}p_n(t)dt=0\]
		Donc, $(p_n)$ est une séquence de Dirac.
		\item Soit $n\in\N$ et soit $x\in\R$.\\
		\[(f*p_n)(x)=(p_n*f)(x)=\int_{-\frac{1}{2}}^{\frac{1}{2}}p_(x-t)f(t)dt\]
		Puisque $p_n$ est polynomiale, on peut réécrire $p_n(x-t)$ comme étant de la forme $\sum_{i=0}^{+\infty}q_i(t)x^i$.\\
		Ainsi, 
		\[(f*p_n)(x)=\sum_{i=0}^{+\infty}\int_{-\frac{1}{2}}^{\frac{1}{2}}q_i(t)f(t)dtx^i\]
		(on peut bien intervertir somme et intégrale car la somme est finie.)\\
		Par conséquent, $(f*p_n)$ est polynomiale.\\
		On vient de montrer que $(f*p_n)$ est une suite de fonctions polynomiale qui tend uniformément vers $f$ sur $\R$.\\
		\item Soit $f$ une fonction continue sur un segment $I=[a,b]$ de $\R$.\\
		On prolonge $f$ sur $\R$ de telle sorte que en considérant $[c,d]$ tels que $[a,b]\subset [c,d]$ on puisse prolonger $f$ sur $[c,a]$ par une fonction affine telle que $f(c)=0$ et idem sur $[b,d]$ telle que $f(d)=0$ et que $f(x)=0$ en dehors du segment $[c,d]$.\\
		Ce prolongement de $f$ appartient à $E$.\\
		En procédant à un changement de variable affine, on se ramène à une fonction nulle en dehors de $[-\frac{1}{2},\frac{1}{2}]$, donc la fonction $f$ est alors limite uniforme de fonctions polynomiales sur $[c,d]$ d'après la question précédente, en particulier sur $[a,b]$.
	\end{enumerate}
	\item \begin{enumerate}
	\item Par linéarité, on a pour tout $P\in\R[X]$ 
	\[\int_{0}^{1}f(t)P(t)dt=0\]
	D'après le théorème de Weierstrass, il existe $(P_n)$ une suite de fonctions polynômiales telle que $(P_n)$ converge uniformément vers $f$ sur $[0,1]$.\\
	Donc pour tout $n\in\N$,
	\[\int_{0}^{1}f(t)P_n(t)dt=0\]
	Puisque la convergence est uniforme, on peut intervertir limite et intégrale donc 
	\[\int_{0}^{1}f^2(t)dt=0\]	
	Puisque $f^2$ est continue et positive sur $[0,1]$, $f^2\equiv 0$ et donc $f\equiv 0$.
	\end{enumerate}
	\end{enumerate}
	
	\subsection{Théorème de Chudnovsky \etoile{4}}\label{sec:theoreme-de-chudnovsky-etoile4}
		\textcolor{blue}{\hyperref[Théorème de Chudnovsky]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item Soit $x\in \R$. Posons pour $n\in \N^*$, $x_n=\displaystyle\frac{\lfloor 2^nx\rfloor}{2^n}$. $(x_n)_{n\in \N^*}$ est une suite à valeur dans $\mathcal D$.\\
		De plus $\forall n\in \N^*,\ x_n\leq x\leq x+\displaystyle\frac{1}{2^n}$. Donc $x_n\unfty\longrightarrow x$.\\
		Ainsi $\mathcal D$ est dense dans $\R$.
		\item
		\begin{enumerate}[label=\alph*.]
			\item Soit $x\in ]0,1[$. La suite de terme général $\varphi_n(x)$ est une suite numérique qui vérifie, $\forall n\in \N,\ \varphi_{n+1}(x)=\varphi(\varphi_n(x))$.\\
			$\varphi$ est continue sur $]0,1[$ et une étude de $\varphi$ montre que $\displaystyle\varphi(]0,1[)=]0,1[$ et que $\varphi$ admet un unique point fixe sur $]0,1[$ qui est $\displaystyle\frac{1}{2}$.\\
			De plus, $\forall x\in ]0,1[,\ \varphi(x)-x=x(1-2x)\leq 0$.\\
			Ainsi $(\varphi_n(x))_{n\in \N}$ est décroissante. Elle est minorée donc d'après le théorème de la limite monotone elle converge vers une limite $\ell\in ]0,1[$.\\
			De plus sa limite doit être un point fixe de $\varphi$ donc $\ell=\displaystyle\frac{1}{2}$.\\
			Ainsi $(\varphi_n)_{n\in \N}$ CVS vers la fonction constante égale à $\displaystyle\frac{1}{2}$ sur $]0,1[$ et donc sur $[a,b]$.
			\item D'après l'étude de $\varphi,\ \forall n\in \N^*,\ \varphi_n([a,b])\subset \left[\varphi_{n-1}(c),\displaystyle\frac{1}{2}\right]$ avec $c=\min(\varphi(a),\varphi(b))$.\\
			Ainsi $\forall n\in \N^*,\ \forall x\in [a,b],\ \displaystyle\left|\varphi_n(x)-\frac{1}{2}\right|\leq \frac{1}{2}-\varphi_{n-1}(c)$.\\
			Par conséquent $\forall n\in \N^*,\ \displaystyle\normep{\infty}{\varphi_n-\frac{1}{2}}\leq \frac{1}{2}-\varphi_{n-1}(c)\unfty\longrightarrow 0$.\\
			On conclut que $(\varphi_n)_{n\in \N}$ CVU vers la fonction constante égale à $\displaystyle\frac{1}{2}$ sur $[a,b]$.
		\end{enumerate}
		\item Soient $f,g\in \mathcal Z$. Notons $(P_n)_{n\in \N}$ et $(Q_n)_{n\in \N}$ deux suites de fonctions polynomiales qui convergent uniformément vers $f$ et $g$ respectivement. On peut d'abord remarquer que $f,g$ sont continues comme limites uniformes de fonctions continues (polynomiales).\\
		D'une part, $\forall n\in \N,\ \normep{\infty}{f+g-(P_n+Q_n)}\leq \normep{\infty}{f-P_n}+\normep{\infty}{g-Q_n}\unfty\longrightarrow 0$.\\
		Donc $(P_n+Q_n)_{n\in \N}$, qui est une suite de fonctions polynomiales à coefficients entiers, converge uniformément vers $f+g$ i.e $f+g\in \mathcal Z$.\\
		D'autre part, $\forall n\in \N,\ \normep{\infty}{fg-P_nQ_n}\leq \normep{\infty}{fg-P_ng}+\normep{\infty}{P_ng-P_nQ_n}=\normep{\infty}{g}\normep{\infty}{f-P_n}+\normep{\infty}{P_n}\normep{\infty}{g-Q_n}$.\\
		La suite $(P_n)_{n\in \N}$ converge pour la norme uniforme, elle est donc bornée pour cette norme d'où $\normep{\infty}{fg-P_nQ_n}\unfty\longrightarrow 0$.\\
		Ainsi $(P_nQ_n)_{n\in \N}$, qui est une suite de fonctions polynomiales à coefficients entiers, converge uniformément vers $fg$ i.e $fg\in \mathcal Z$.
		\item D'après la question $2$, $x\mapsto \displaystyle\frac{1}{2}\in \mathcal Z$. De plus on remarque que toutes les fonctions $f$ constantes égales à un entier sont dans $\mathcal Z$ (comme limite de la suite constante égale à $f$) Donc d'après la question $3$, quel que soit $d\in \mathcal D,\ x\mapsto d\in \mathcal Z$. De plus n'importe quelle fonction polynomiale $g$ associé à un monôme est aussi dans $\mathcal Z$ (comme limite de la suite constante égale à $g$)\\
		Ainsi, si $P=\displaystyle\sum_{k=0}^pa_kX^k\in \R[X]$ alors d'après la question $1$ on peut trouver des suites $(d_n^0),\dots,(d_n^p)\in \mathcal D^\N$ telles que $\forall k\in \crblanc{0}{p},\ a_k=\unfty\lim d_n^k$.\\
		En posant pour $n\in \N$, $P_n=\displaystyle\sum_{k=0}^pd_n^kX^k$ on a alors $(P_n)\in \mathcal Z^\N$ et $\normep{\infty}{x\mapsto P(x)-P_n(x)}\unfty\longrightarrow 0$. On en déduit que $\mathcal Z$ contient l'ensemble des fonctions polynomiales à coefficients réels.\\
		Fixons maintenant $f\in \mathcal C([a,b],\R)$. D'après le théorème d'approximation de Weierstrass, il existe une suite $(P_n)_{n\in \N}$ de fonctions polynomiales à coefficients réels convergeant uniformément vers $f$. Finalement, $f\in \mathcal Z$.\\
		\textit{Remarque : on aurait pu formuler la réponse à l'aide du théorème de la double limite.}
		\item Le choix de $a$ et $b$ est important ! En effet si le segment $[a,b]$ contient un entier alors on ne peut pas atteindre toutes les fonctions continues de $[a,b]$:\\
		si $k\in \Z\cap[a,b]$ et si $(P_n)_{n\in \N}$ est une suite de fonctions polynomiales à coefficients entiers convergeant uniformément vers une fonction $P$ alors $(P_n(k))_{n\in \N}$ est une suite d'entier qui converge vers $P(k)$. $P(k)$ est donc un entier (cf. \ref{Topologie de Z}).\\\\
		Le résultat actuel ne permet pas d'obtenir une fonction qui prendrait une valeur complexe car un polynôme à coefficients entiers est à valeurs réelles sur $[a,b]$.\\
		On peut cependant avoir un résultat analogue en considérant des polynômes à coefficients dans l'anneau des entiers de Gauss $\Z[i]=\{a+ib,\ (a,b)\in \Z^2\}$ :\\
		Soit $h:[a,b]\to\C$. On note $h=f+ig$ avec $f$ et $g$ des fonctions réelles. On dispose de $(P_n),(Q_n)\in \Z[X]^\N$ qui convergent uniformément sur $[a,b]$ vers $f$ et $g$ respectivement. Alors $\normep{\infty}{h-(P_n+iQ_n)}\leq \normep{\infty}{f-P_n}+|i|\normep{\infty}{g-Q_n}\unfty\longrightarrow0$ avec $(P_n+iQ_n)\in (\Z[i])[X]^\N$.
	\end{enumerate}
	
	\subsection{Théorème de sélection de Helly}\label{sec:theoreme-de-selection-de-helly}
		\textcolor{blue}{\hyperref[Théorème de sélection de Helly]{[Enoncé]}}\\
	%https://agreg-maths.fr/uploads/versions/842/Theoreme_de_selection_de_Helly.pdf
	%https://les-mathematiques.net/vanilla/discussion/363714/principe-dextraction-diagonale
	
	\newpage
\section{Correction Séries entières}
	\subsection{Lemme d'Abel}\label{sec:lemme-dabel}
		\textcolor{blue}{\hyperref[Lemme d'Abel]{[Enoncé]}}\\
	\subsection{Fonction non développable en série entière}\label{sec:fonction-non-developpable-en-serie-entiere}
	\textcolor{blue}{\hyperref[Fonction non développable en série entière]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item On remarque que :
			\[\lim\limits_{x\to 0}-\frac{1}{x^2}=-\infty\]
		Ainsi, \[\lim\limits_{x\to 0}\exp\left(-\frac{1}{x^2}\right)=0\]
		Donc $f$ est continue sur $\R$.
		\item Montrons que pour tout $n\in \N^*$, \[\exists P_n\in\R[X],\forall x\in \R^* f^{(n)}(x)=P_n\left(\frac{1}{x}\right)f(x)\]
		Le résultat est clair pour $n=0$.\\
		Pour $n=1$, pour tout $x\in\R$ \[f'(x)=\frac{2}{x^3}f(x)\]
		Ainsi, en posant $P_1=2X^3$, le résultat est vérifié.
		Supposons que pour un certain $n\in \N$, il existe $P_n\in \R[X]$ tel que pour tout $x\in\R^*$ $f^{(n)}(x)=P_n\left(\frac{1}{x}\right)f(x)$
		Alors , \[f^{(n+1)}(x)=-\frac{1}{x^2}P_n'\left(\frac{1}{x}\right)f(x)+P_n(x)f'(x)=\left[\frac{2}{x^3}P_n\left(\frac{1}{x}\right)-\frac{1}{x^2}P_n'\left(\frac{1}{x}\right)\right]f(x)\]
		De plus, par croissance comparées, on a \[\lim\limits_{x\to 0}f^{(n)}(x)=0\]
		Donc $f$ est de classe $\mathcal{C}\infty$ sur $\R$ et pour tout $n\in\N, f^{(n)}=0$.
		\item Supposons que $f$ est développable en série entière. 
		Alors d'après la formule de Taylor, \[\forall x\in\R, f(x)=\sum_{n=0}^{+\infty}\frac{f^{(n)}(0)}{n!}x^n\]
		Or d'après la question précédente, cela nous donnerait que $f$ est la fonction nulle, ce qui est absurde.\\
		Donc $f$ n'est pas développable en série entière.
	\end{enumerate}
	
	
	\subsection{CCINP MP 2019}\label{sec:ccinp-mp-2019}
	\textcolor{blue}{\hyperref[CCINP MP 2019]{[Enoncé]}}\\
	\subsection{Série entière de terme général binomial}\label{sec:serie-entiere-de-terme-general-binomial}
	\textcolor{blue}{\hyperref[Série entière de terme général binomial]{[Enoncé]}}\\
	\subsection{Formule de Cauchy}\label{sec:formule-de-cauchy}
	\textcolor{blue}{\hyperref[Formule de Cauchy]{[Enoncé]}}\\
	Soit $r\in[0,R[$, pour tout $\theta\in[0,2\pi[$, $|re^{i\theta}|=r\leq R$.\\
	Puisque que $\sum_{k=0}^{+\infty}a_kx^k$ est une série entière, on peut utiliser la théorème d'interversion série-intégrale : 
	\[\int_{0}^{2\pi}f(re^{i\theta})e^{-in\theta}d\theta=\int_{0}^{2\pi}\sum_{k=0}^{+\infty}a_kr^ke^{i(k-n)\theta}d\theta=\sum_{k=0}^{+\infty}\int_{0}^{2\pi}a_nr^ne^{i(k-n)\theta}d\theta \]
	D'après calculs, on obtient : \[\int_{0}^{2\pi}e^{i(k-n)}d\theta=\begin{cases}
		0 &\mbox{si } k\ne n\\
		2\pi &\mbox{sinon}
	\end{cases}\]
	Ainsi, on en déduit que la formule de Cauchy :
	\[\int_{0}^{2\pi}f(re^{i\theta})e^{-in\theta}d\theta=2\pi a_nr^n\]
	\subsection{Principe des zéros isolés}\label{sec:principe-des-zeros-isoles}
	\textcolor{blue}{\hyperref[Principe des zéros isolés]{[Enoncé]}}\\
	\subsection{Produit de Hadamard}\label{sec:produit-de-hadamard}
	\textcolor{blue}{\hyperref[Produit de Hadamard]{[Enoncé]}}\\
	\subsection{Théorème de Liouville}\label{sec:theoreme-de-liouville}
	\textcolor{blue}{\hyperref[Théorème de Liouville]{[Enoncé]}}\\
	\subsection{Inverse d'une série entière}\label{sec:inverse-dune-serie-entiere}
	\textcolor{blue}{\hyperref[Inverse d'une série entière]{[Enoncé]}}\\
	\subsection{Equivalent de séries entières}\label{sec:equivalent-de-series-entieres}
	\textcolor{blue}{\hyperref[Equivalent de séries entières]{[Enoncé]}}\\
	\subsection{Théorème de d'Alembert-Gauss}\label{sec:theoreme-de-dalembert-gauss}
	\textcolor{blue}{\hyperref[Théorème de d'Alembert-Gauss]{[Enoncé]}}\\
	\subsection{Développement de fraction rationnelle autour de 0}\label{sec:developpement-de-fraction-rationnelle-autour-de-0}
	\textcolor{blue}{\hyperref[Développement de fraction rationnelle autour de 0]{[Enoncé]}}\\
	\subsection{Fonction quasi-polynomiale}\label{sec:fonction-quasi-polynomiale}
	\textcolor{blue}{\hyperref[FOnction quasi-polynomiale]{[Enoncé]}}\\
	\subsubsection{Série génératrice d'une fonction quasi-polynomiale}
	\subsubsection{Partition d'un entier}
	\subsection{Théorème de réalisation de Borel}\label{sec:theoreme-de-realisation-de-borel}
	\textcolor{blue}{\hyperref[Théorème de réalisation de Borel]{[Enoncé]}}\\
	\subsection{Série de Lambert}\label{sec:serie-de-lambert}
	\textcolor{blue}{\hyperref[Série de Lambert]{[Enoncé]}}\\
	\subsection{Somme de Goldbach}\label{sec:somme-de-goldbach}
	\textcolor{blue}{\hyperref[Somme de Goldbach]{[Enoncé]}}\\
	\subsection{Une somme avec l'indicatrice d'Euler}\label{sec:une-somme-avec-lindicatrice-deuler}
	\textcolor{blue}{\hyperref[Une somme avec l'indicatrice d'Euler]{[Enoncé]}}\\
	\subsection{Coefficients définies par des intégrales}\label{sec:coefficients-definies-par-des-integrales}
	\textcolor{blue}{\hyperref[Coefficients définies par des intégrales]{[Enoncé]}}\\
	\subsection{Détermination des coefficients d'un développement en série entière}\label{sec:determination-des-coefficients-dun-developpement-en-serie-entiere}
	\textcolor{blue}{\hyperref[Détermination des coefficients d'un développement en série entière]{[Enoncé]}}\\
	\subsection{Série génératrice du nombre de points à coordonnées entières dans un quart de disque}\label{sec:serie-generatrice-du-nombre-de-points-a-coordonnees-entieres-dans-un-quart-de-disque}
	\textcolor{blue}{\hyperref[Série génératrice du nombre de points à coordonnées entières dans un quart de disque]{[Enoncé]}}\\
	\subsubsection{Nombre de points à coordonnées entières dans un disque}
	\subsubsection{Prolongement du problème}
	\subsection{Nombre d'involution}\label{sec:nombre-dinvolution}
	\textcolor{blue}{\hyperref[Nombre d'involution]{[Enoncé]}}\\
	\subsection{Théorème d'Abel}\label{sec:theoreme-dabel}
		\textcolor{blue}{\hyperref[Théorème d'Abel]{[Enoncé]}}\\
	\subsection{Théorèmes taubériens d'Abel}\label{sec:theoremes-tauberiens-dabel}
		\textcolor{blue}{\hyperref[Théorème taubériens d'Abel]{[Enoncé]}}\\
	\subsubsection{Cas des séries à coefficients positifs}
	\subsubsection{Théorème taubérien faible}
	\subsubsection{Théorème taubérien fort}
	
	\newpage
\section{Correction Topologie}
	\subsection{Normes d'opérateur \ccinp{1}}
	\label{sec:normes-doperateur}
	\textcolor{blue}{\hyperref[Normes d'opérateur]{[Enoncé]}}\\
	Dans tout l'exercice on ne se souciera pas de noter différemment les normes $\normep{\infty}{\cdot},\normep{1}{\cdot},\normep{2}{\cdot}$ de $\M_{p,1}(\R)$ et $\M_{n,1}(\R)$. Il doit être clair aux yeux du lecteur dans quels espaces vivent chaque objets.
	\begin{enumerate}
		\item Soit $X=\begin{pmatrix}x_1\\\vdots\\x_p\end{pmatrix}\in \M_{p,1}(\R)$. Soit $i\in \crblanc{1}{n}$.\\
		$|(AX)_i|=\displaystyle\left|\sum_{j=1}^pA_{ij}x_j\right|\leq \sum_{j=1}^p|A_{ij}||x_j|\leq \normep{\infty}{X}\sum_{j=1}^p|A_{ij}|\leq \left(\max_{1\leq i\leq n}\sum_{j=1}^p|A_{ij}|\right)\normep{\infty}{X}$.\\
		Donc $\normep{\infty}{AX}\leq \displaystyle\left(\max_{1\leq i\leq n}\sum_{j=1}^p|A_{ij}|\right)\normep{\infty}{X}$ i.e $\mid\mid\mid A\mid\mid\mid_\infty\leq \displaystyle\max_{1\leq i\leq n}\sum_{j=1}^p|A_{ij}|$.\\
		Pour qu'un vecteur $X_0$ satisfasse l'égalité, il est nécessaire et suffisant que toutes les inégalités soient des égalités.\\
		Pour la première inégalité il faut que les $A_{ij}x_j$ soient tous de même signe et pour la deuxième il faut que tous les $x_j$ valent $\normep{\infty}{X_0}$. On peut par exemple prendre $x_j=\begin{cases}
			1&\mbox{si }A_{ij}>0\\
			-1&\mbox{si }A_{ij}<0\\
			0&\mbox{si }A_{ij}=0
		\end{cases}$.\\
		Pour la dernière inégalité on se donne $i_0\in \crblanc{1}{n}$ tel que $\displaystyle\sum_{j=1}^p|A_{i_0j}|=\max_{1\leq i\leq n}\sum_{j=1}^p|A_{ij}|$.\\
		Par construction $|(AX_0)_{i_0}|=\displaystyle\max_{1\leq i\leq n}\sum_{j=1}^p|A_{ij}|\normep{\infty}{X_0}$ d'où $\normep{\infty}{AX}\geq \displaystyle\max_{1\leq i\leq n}\sum_{j=1}^p|A_{ij}|\normep{\infty}{X_0}$.\\
		On en déduit que $\mid\mid\mid A\mid\mid\mid_\infty\geq \displaystyle\max_{1\leq i\leq n}\sum_{j=1}^p|A_{ij}|$ puis que $\mid\mid\mid A\mid\mid\mid_\infty=\displaystyle\max_{1\leq i\leq n}\sum_{j=1}^p|A_{ij}|$.
		\item Soit $X=\begin{pmatrix}x_1\\\vdots\\x_p\end{pmatrix}\in \M_{p,1}(\R)$.\\
		$\displaystyle\sum_{i=1}^n|(AX)_i|=\sum_{i=1}^n\left|\sum_{j=1}^pA_{ij}x_j\right|\leq \sum_{i=1}^n\sum_{j=1}^p|A_{ij}||x_j|=\sum_{j=1}^p|x_j|\sum_{i=1}^n|A_{ij}|\leq \normep{1}{X}\left(\max_{1\leq j\leq p}\sum_{i=1}^n|A_{ij}|\right)$.\\
		Donc $\normep{1}{AX}\leq \displaystyle\left(\max_{1\leq j\leq n}\sum_{i=1}^n|A_{ij}|\right)\normep{1}{X}$ i.e $\mid\mid\mid A\mid\mid\mid_1\leq \displaystyle\max_{1\leq j\leq p}\sum_{i=1}^n|A_{ij}|$.\\
		Pour qu'un vecteur $X_0$ satisfasse l'égalité, il est nécessaire et suffisant que toutes les inégalités soient des égalités.\\
		Pour la première inégalité il faut que les $A_{ij}x_j$ soient tous de même signe et pour la deuxième il suffit que pour $j_0$ qui maximise la somme $\displaystyle\sum_{i=1}^n|A_{ij}|$ $x_{j_0}=1$ et que $x_j=0$ pour $j\ne j_0$. On peut par exemple prendre $X_0=e_{j_0}$ où $(e_1,\dots,e_p)$ est la base canonique de $\M_{p,1}(\R)$.\\
		Pour la deuxième inégalité on se donne $j_0\in \crblanc{1}{p}$ tel que $\displaystyle\sum_{i=1}^n|A_{ij_0}|=\max_{1\leq j\leq p}\sum_{i=1}^n|A_{ij}|$.\\
		Par construction $\displaystyle\sum_{i=1}^n|(AX_0)_i|=\sum_{i=1}^n|A_{ij_0}|=\max_{1\leq j\leq p}\sum_{i=1}^n|A_{ij}|\normep{1}{X_0}$ d'où $\normep{1}{AX}\geq \displaystyle\max_{1\leq j\leq p}\sum_{i=1}^n|A_{ij}|\normep{1}{X_0}$.\\
		On en déduit que $\mid\mid\mid A\mid\mid\mid_1\geq \displaystyle\max_{1\leq j\leq p}\sum_{i=1}^n|A_{ij}|$ puis que $\mid\mid\mid A\mid\mid\mid_1=\displaystyle\max_{1\leq j\leq p}\sum_{i=1}^n|A_{ij}|$.
		\item Notons $\proscal{\cdot}{\cdot}$ le produit scalaire associé à $\normep{2}{\cdot}$. Encore une fois, on ne différencie par les notations dans $\M_{p,1}(\R)$ et $\M_{n,1}(\R)$. Soit $X\in \M_{p,1}(\R)$.\\
		$\normep{2}{AX}^2=\proscal{AX}{AX}=X^\top A^\top AX=\proscal{X}{A^\top AX}$.\\
		La matrice $A^\top A\in \M_p(\R)$ est symétrique réelle positive donc diagonalisable avec $\T{Sp}(A^\top A)\subset\R_+$. Il existe donc une base $(X_1,\dots,X_p)$ orthonormée de $\M_{p,1}(\R)$ formée de vecteurs propres de $A^\top A$. On note $\lambda_k$ la valeur propre associée à $X_k$ pour $k\in \crblanc{1}{p}$. On note aussi $X=\displaystyle\sum_{k=1}^pt_kX_k$.\\
		Alors $A^\top AX=\displaystyle\sum_{k=1}^pt_kA^\top AX_k=\sum_{k=1}^pt_k\lambda_kX_k$. Donc
		$$\normep{2}{AX}^2=\sum_{i=1}^p\sum_{j=1}^pt_it_j\lambda_j\proscal{X_i}{X_j}=\sum_{k=1}^nt_k^2\lambda_k\leq \max\left(\T{Sp}(A^\top A)\right)\sum_{k=1}^pt_k^2=\max\left(\T{Sp}(A^\top A)\right)\normep{2}{X}^2$$
		Ainsi $\mid\mid\mid A\mid\mid\mid_2\leq \sqrt{\max\T{Sp}(A^\top A)}$.\\
		De plus, pour $k$ tel que $\lambda_k=\max\T{Sp}(A^\top A)$, $\normep{2}{AX_k}^2=\lambda_k^2\normep{2}{X_k}^2=\lambda_k^2$.\\
		Ainsi $\mid\mid\mid A\mid\mid\mid_2=\sqrt{\max\T{Sp}(A^\top A)}$.
	\end{enumerate}
	
	\subsection{$\Z$ est fermé \etoile{1}}
	\label{sec:z-est-ferme-etoile1}
	\textcolor{blue}{\hyperref[Z est fermé]{[Enoncé]}}\\
	\label{Topologie de Z}
	Soit $(u_n)\in \Z^\N$ de limite $\ell\in \C$.\\
	$\exists N\in \N,\ \forall n\geq N,\ |u_n-\ell|<\displaystyle\frac{1}{2}$.\\
	Alors si $n\geq N,\ |u_n-u_{n+1}|\leq |u_n-\ell|+|\ell-u_{n+1}|<1$.\\
	Comme $(u_n,u_{n+1})\in \Z,\ |u_n-u_{n+1}|\in \N$.\\
	Donc $\forall n\geq N,\ u_n=u_{n+1}$. Ainsi $u_n\unfty{\longrightarrow}u_N$.\\
	Par unicité de la limite, $\ell=u_N\in \Z$.
	
	\subsection{Orthogonalité et topologie \ccinp{2}}
	\label{sec:orthogonalite-et-topologie}
	\textcolor{blue}{\hyperref[Orthogonalité et topologie]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item Soit $y\in E$. On sait que $\varphi_y\in \L(E)$.\\
		De plus d'après l'inégalité de Cauchy-Schwartz, $\forall x\in E,\ |\varphi_y(x)|\leq \norme y\norme x$.\\
		Donc $\varphi_y$ est continue.
		\item Pour $y\in E$ on note $\tilde\varphi_y={\varphi_y}_{|F}$ la restriction de $\varphi_y$ à $F$.\\
		Posons $\varphi:y\in E\mapsto \tilde\varphi_y$. On sait que $\varphi\in \L(E,F^*)$ où $F^*$ est le dual de $F$, l'ensemble des formes linéaires sur $F$ (continues). Montrons qu'elle est continue pour la norme $\normep{E^*}{\cdot}$ subordonnée à la norme $\norme{\cdot}$ de $E$. Soient $x,y\in E$.\\
		$|\varphi(y)(x)|=|\tilde\varphi_y(x)|\leq \norme y\norme x$ donc $\normep{E^*}{\varphi(y)}\leq \norme y$ d'où $\mid\mid\mid\varphi\mid\mid\mid\leq 1$.\\
		Ainsi $\varphi$ est continue et donc $F^\bot=\{y\in E,\ \forall x\in F,\ \proscal{x}{y}=0\}=\{y\in E,\ \tilde\varphi_y=0_{F^*}\}=\varphi^{-1}(0_{F^*})$ est un fermé de $E$.
		\item D'après la question précédente $(F^\bot)^\bot$ est fermé, il suffit donc de montrer que $F\subset (F^\bot)^\bot$. Fixons $x\in F$.\\
		Soit $y\in F^\bot$. Par définition de $F^\bot$, $\proscal{x}{y}=0$. Donc $x\in (F^\bot)^\bot$.\\
		Ainsi $(F^\bot)^\bot$ est un fermé qui contient $F$ et par suite $\overline F\subset (F^\bot)^\bot$.
	\end{enumerate}
	
	\subsection{Ensemble des valeurs d'adhérence d'une suite \centraleponts{3}}
	\label{sec:ensemble-des-valeurs-dadherence-dune-suite}
	\textcolor{blue}{\hyperref[Ensemble des valeurs d'adhérence d'une suite]{[Enoncé]}}\\
	On raisonne par double inclusion.\\
	Soit $\ell$ une valeur d'adhérence de $u:=(u_n)_{n\in \N}$. Fixons $n\in \N$.\\
	Notons $\varphi:\N\to\N$ strictement croissante telle que $\upfty\lim u_{\varphi(p)}=\ell$. $\varphi(n)\unfty\longrightarrow\infty$ donc $\exists N\in \N,\ \forall p\geq N,\ \varphi(p)\geq n$. Ainsi $(u_{\varphi(p)})_{p\geq N}$ est une suite à valeurs dans $\{u_k,\ k\geq n\}$ de limite $\ell$ : $\ell\in \overline{\{u_k,\ k\geq n\}}$.\\
	On en déduit que $V\subset \displaystyle\bigcap_{n\in \N}\overline{\{u_k,\ k\geq n\}}$.\\
	Réciproquement soit $\ell\in \displaystyle\bigcap_{n\in \N}\overline{\{u_k,\ k\geq n\}}$.\\
	On va construire par récurrence une extractrice $\psi$ telle que $(u_{\psi(p)})_{p\in \N}$ tend vers $\ell$.\\
	$\ell\in \overline{\{u_k,\ k\geq 0\}}\implies \exists k_0\in \N,\ \norme{\ell-u_{k_0}}<1=\dfrac{1}{2^0}$.\\
	Supposons que l'on dispose pour un certain $p\in \N$ d'entiers $k_0<\cdots<k_p$ tels que $\forall j\in \crblanc{0}{p},\ \norme{\ell-u_{k_j}}<\dfrac{1}{2^j}$.\\
	Alors $\ell\in \overline{\{u_k,\ k\geq k_p\}}\implies \exists k_{p+1}\in \N,\ \norme{\ell-u_{k_{p+1}}}<\dfrac{1}{2^{p+1}}$.\\
	On définit alors $\psi:\N\to\N$ par $\forall p\in \N,\ \psi(p)=k_p$. Par construction $\psi$ est strictement croissante et de plus, $\forall p\in \N,\ \norme{\ell-u_{\psi(p)}}<\dfrac{1}{2^p}$. Donc $u_{\psi(p)}\upfty\longrightarrow\ell$ d'où $\ell\in V$.\\
	On en déduit que $V=\displaystyle\bigcap_{n\in \N}\overline{\{u_k,\ k\geq n\}}$. $V$ est un fermé en tant qu'intersection de fermés.\\
	\textit{Remarque : une manière plus simple/naturelle de traiter l'exercice est de caractériser le fait que $\ell$ soit une valeur d'adhérence de $u$ par le fait qu'il existe une infinité de terme de la suite $u$ à une distance inférieure à $\varepsilon$ de $\ell$. Cette caractérisation peut se voir comme définition d'une valeur d'adhérence et est parfois plus utile que le point de vue suite extraite.}
	
	\subsubsection{Une application \etoile{4}}
	\label{sec:une-application}
	\textcolor{blue}{\hyperref[Une application]{[Enoncé]}}\\
	\begin{enumerate}
		\item Soit $z\in \C$. Si $z$ est une racine de l'unité alors la suite $(z^n)_{n\in \N}$ stationne à $1$ qui est donc sa seule valeur d'adhérence.\\
		Supposons maintenant que $z$ n'est pas une racine de l'unité. Cela revient à supposer, si l'on écrit $z=e^{2i\pi\theta}$ avec $\theta\in \R$, que $\theta$ est irrationnel.\\
		On va alors montrer que $\Z+\theta\Z$ est dense dans $\R$. Pour cela on utilise l'exercice classique qui montre que les sous-groupes de $(\R,+)$ sont monogènes ou dense dans $\R$.\\
		On montre aisément que $\Z+\theta\Z$ est un sous-groupe de $(\R,+)$. Montrons qu'il n'est pas monogène. Par l'absurde on suppose qu'il existe $a\in \R$ tel que $\Z+\theta\Z=a\Z$.\\
		Alors on sait qu'il existe un entier $k$ tel que $1=ak$. On en déduit que $a=\displaystyle\frac{1}{k}\in \Q$. Nonobstant on sait aussi qu'il existe un entier $m$ tel que $\theta=am$. Donc $\theta\in \Q$ ce qui est absurde.\\
		Ainsi $\Z+\theta\Z$ n'est pas monogène, il est donc dense dans $\R$.\\
		On en déduit par continuité et $1$-périodicité de la fonction $f:x\in \R\mapsto e^{2i\pi x}$ que $f(\Z+\theta\Z)=\{e^{2ki\pi\theta},\ k\in \Z\}=\{e^{2in\pi\theta},\ n\in \N\}=\{z^n,\ n\in \N\}$ est dense dans $f(\R)=\U$.\\
		En particulier $1$ est une valeur d'adhérence de la suite $(z^n)_{n\in \N}$.
		\item Construisons une extractrice par extractions successives :\\
		D'après la question précédente on dispose de $\varphi_1:\N\to\N$ strictement croissante telle que $z_1^{\varphi_1(n)}\unfty\longrightarrow1$.\\
		Supposons que pour un certain $k\in \crblanc{1}{m}$ on dispose de $\psi_{k-1}$ telle que $$\begin{pmatrix}z_1^{\psi_{k-1}(n)}\\\vdots\\z_{k-1}^{\psi_{k-1}(n)}\end{pmatrix}\unfty\longrightarrow\begin{pmatrix}1\\\vdots\\1\end{pmatrix}$$
		$\left(z_k^{\psi_{k-1}(n)}\right)_{n\in \N}$ est à valeur dans le compact $\U$ donc quitte à extraire on peut supposer qu'elle converge vers un certain $\lambda\in \U$.\\
		Ainsi $\begin{pmatrix}1\\\vdots\\1\\\lambda\end{pmatrix}$ est une valeur d'adhérence de $\begin{pmatrix}z_1^n\\\vdots\\z_k^n\end{pmatrix}$. Mais quel que soit $p\in \N$, $\begin{pmatrix}1\\\vdots\\1\\\lambda^p\end{pmatrix}$ est une valeur d'adhérence de $\begin{pmatrix}z_1^n\\\vdots\\z_k^n\end{pmatrix}$. En effet en notant $\eta$ une extractrice qui fait converger la suite vers $\begin{pmatrix}1\\\vdots\\1\\\lambda\end{pmatrix}$, il suffit de considérer $\xi(n)=p\eta(n)$.\\
		On considère désormais la suite $(\lambda^n)_{n\in \N}$. D'après la question précédente, cette suite admet 1 pour valeur d'adhérence.\\
		Par conséquent, comme l'ensemble des valeurs d'adhérence de $\begin{pmatrix}z_1^n\\\vdots\\z_k^n\end{pmatrix}_{n\in \N}$ est fermé, $\begin{pmatrix}1\\\vdots\\1\end{pmatrix}$ est une valeur d'adhérence de $\begin{pmatrix}z_1^n\\\vdots\\z_k^n\end{pmatrix}_{n\in \N}$.\\
		Par récurrence, pour tout $k\in \crblanc{1}{m}$ $\begin{pmatrix}1\\\vdots\\1\end{pmatrix}$ est une valeur d'adhérence de $\begin{pmatrix}z_1^n\\\vdots\\z_k^n\end{pmatrix}_{n\in \N}$. En particulier $\begin{pmatrix}1\\\vdots\\1\end{pmatrix}$ est une valeur d'adhérence de $\begin{pmatrix}z_1^n\\\vdots\\z_m^n\end{pmatrix}_{n\in \N}$.
		\item Notons $M=\max\limits_{1\leq k\leq n}|a_k|$. Il est clair que si $M<1$ alors $\displaystyle\left|\sum_{k=1}^na_k^m\right|\leq nM^m\underset{m\to+\infty}{\longrightarrow}0$ d'où $\displaystyle\sum_{k=1}^na_k^m\underset{m\to+\infty}{\longrightarrow}0$.\\
		Supposons maintenant $M>1$. On note $K=\{k\in \crblanc{1}{n},\ |a_k|=M\}$.\\
		$\forall k\in K,\ \dfrac{a_k}{M}\in \U$. Donc d'après la question précédente on peut trouver une extractrice $\varphi$ telle que $\forall k\in K,\ \left(\dfrac{a_k}{M}\right)^{\varphi(m)}\underset{m\to\infty}{\longrightarrow}1$.\\
		Donc $\displaystyle\sum_{k=1}^na_k^{\varphi(m)}=M^{\varphi(m)}\left(\sum_{k\in K}\left(\dfrac{a_k}{M}\right)^{\varphi(m)}+\sum_{k\notin K}\left(\dfrac{a_k}{M}\right)^{\varphi(m)}\right)\underset{m\to+\infty}{\sim}|K|M^{\varphi(m)}\underset{m\to+\infty}{\longrightarrow}+\infty$ ce qui est absurde.\\
		Enfin, si $M=1$ le même calcul donne $\underset{m\to+\infty}{\lim}\displaystyle\sum_{k=1}^na_k^m=|K|$.\\
		Au final, si $\left(\displaystyle\sum_{k=1}^na_k^m\right)_{m\in \N}$ converge alors $\forall k\in \crblanc{1}{n},\ |a_k|\leq 1$ et la limite est un entier entre $1$ et $k$, égal au nombre des $a_k$ de module $1$.
	\end{enumerate}
	
	\subsection{Ensemble des suites convergente vers 0 \centraleponts{3}}
	\label{sec:ensemble-des-suites-convergents-vers-0}
	\textcolor{blue}{\hyperref[Ensemble des suites convergents vers 0]{[Enoncé]}}\\
	On note $V$ l'ensemble des suites de $\K^\N$ convergeant vers $0$.\\
	Tout d'abord c'est bien une partie de $\ell^\infty$ puisqu'une suite convergente est bornée. Ensuite, donnons nous $((u_n^k)_{k\in \N})_{n\in \N}\in V^\N$ une suite de suites convergeant vers $0$ qui converge vers une suite $U$ dans $(\ell^\infty,\normep{\infty}{\cdot})$.\\
	La suite des limites $\ukfty\lim u_n^k$ converge vers $0$ puisqu'elle est constante égale à $0$. De plus $(u_n)_{n\in \N}$ converge uniformément vers $U$. Alors d'après le théorème de la double limite $U$ converge vers $\unfty\lim\ukfty\lim u_n^k=0$.\\
	Ainsi $V$ est fermé.
	
	\subsubsection{Ensemble des suites convergentes \etoile{3} (HP)}
	\label{sec:ensemble-des-suites-convergentes}
	\textcolor{blue}{\hyperref[Ensemble des suites convergentes]{[Enoncé]}}\\
	On note $C$ l'ensemble des suites convergentes de $\K^\N$. C'est bien une partie de $\ell^\infty$ puisqu'une suite convergente est bornée.\\
	Soit $(u_n^k)_{n\in \N}\in C^\N$ une suite de suites convergentes qui converge vers une suite $U=(U_n)_{n\in \N}$ dans $(\ell^\infty,\normep{\infty}{\cdot})$. On note pour tout $n\in \N$, $\ell_n=\ukfty\lim u_n^k$.\\
	Montrons que la suite des limites $(\ell_n)_{n\in \N}$ converge. On va montrer qu'elle est de Cauchy ce qui justifiera qu'elle converge (cf.\ref{Suite de Cauchy}).\\
	Soit $\varepsilon>0$.\\
	$\normep{\infty}{u_n-U}\unfty\longrightarrow0$ donc $\exists N\in \N,\ \forall p,q\geq N,\ \normep{\infty}{u_p-u_q}<\dfrac{\varepsilon}{3}$.\\
	Pour tout $n\in\N$, $u_n^k\unfty\longrightarrow\ell_n$ donc $\exists K_n\in \N,\ \forall k\geq K_n,\ |u_n^k-\ell_n|<\dfrac{\varepsilon}{3}$.\\
	Soient $p\geq N$ et $k\geq \max(K_p,K_N)$.
	$$|\ell_p-\ell_N|\leq |\ell_p-u_p^k|+|u_p^k-u_N^k|+|u_N^k-\ell_N|\leq |u_p^k-\ell_p|+\normep{\infty}{u_p-u_N}+|u_N^k-\ell_N|<\varepsilon$$
	On conclut comme la question précédente avec le théorème de la double limite.
	
	\subsection{Calcul d'adhérence \xens{3}}
	\label{Calcul d'adhérence corrigé}
	\textcolor{blue}{\hyperref[Calcul d'adhérence]{[Enoncé]}}
	Soit $r_n\in E^\N$ convergente. On note $r$ sa limite. $\forall n\in \N,\ \exists (p_n,q_n)\in (\N^*)^2,\ r_n=\displaystyle\frac{1}{p_n}+\frac{1}{q_n}$.\\
	On rappelle qu'une suite d'entier qui converge stationne et que donc la limite d'une suite d'entiers naturels non nuls est un entier naturel non nul (cf.$\Z$ est fermé).\\
	On distingue des cas suivant si $(p_n)$, $(q_n)$ sont bornées ou non.\\
	Si $(p_n)$ et $(q_n)$ sont bornées alors quitte à extraire, on peut supposer que $(p_n)$ converge vers une limite $p\in \N^*$. Alors $\unfty\lim\dfrac{1}{q_n}=\unfty\lim r_n-\dfrac{1}{p_n}=r-\dfrac{1}{p}$. $(q_n)$ est bornée donc $\unfty\lim\dfrac{1}{q_n}\ne 0$ et donc $(q_n)$ converge vers $q:=\dfrac{1}{r-\dfrac{1}{p}}\in \N^*$. Ainsi $r=\dfrac{1}{p}+\dfrac{1}{n}$ avec $p,q\in \N^*$.\\
	Supposons qu'une des suites $(p_n),(q_n)$ est bornée et que l'autre ne l'est pas. On suppose sans perte de généralité que $(p_n)$ n'est pas bornée et que $(q_n)$ l'est.
	On montre (cf. lemme des pics dans l'exo de Bolzano 
	Weierstrass) que de toute suite réelle on peut extraire une suite monotone. Donc quitte à extraire on peut supposer $(p_n)$ monotone. $(p_n)$ n'est pas décroissante puisque étant minorée elle serait bornée. $(p_n)$ est donc une suite croissante non bornée : elle diverge vers $+\infty$.\\
	Ainsi $\dfrac{1}{q_n}=r_n-\dfrac{1}{p_n}\unfty\longrightarrow r$. Comme $(q_n)$ est bornée, $r\ne 0$ et donc $(q_n)$ converge vers une limite $q\in \N^*$ puis $r=\unfty\lim \dfrac{1}{p_n}+\dfrac{1}{q_n}=\dfrac{1}{q}$.\\
	Enfin supposons $(p_n)$ et $(q_n)$ non bornées. Quitte à extraire on peut supposer $(p_n)$ croissante, et donc de limite $+\infty$. Alors $\dfrac{1}{q_n}\unfty\longrightarrow r$. Si $r\ne 0$, $(q_n)$ converge vers $\dfrac{1}{r}$ et est donc bornée. On en déduit que $r=0$.\\
	Ainsi $\overline E=\{0\}\cup\left\{\dfrac{1}{n},\ n\in \N^*\right\}\cup E$.\\\\
	\textit{Remarque : On aurait aussi pu extraire de manière à ce que $(p_n)$ et $(q_n)$ soient bornée(s)/monotone(s), ce qui revient à dire qu'un produit cartésien de compacts est compact. Cela nous évite d'avoir à montrer que $\left(\dfrac{1}{q_n}\right)_{n\in \N}$ converge à chaque fois.}
	
	\subsection{Partie ouverte et fermée simultanément \centraleponts{3}}
	\label{sec:partie-ouverte-et-fermee-simultanement}
		\textcolor{blue}{\hyperref[Partie ouverte et fermée simultanément]{[Enoncé]}}\\
		\textbf{Je rajouterai un joli dessin}\\
		$E\subset \overline E\implies E=\overline E$ et $\overline \emptyset=\displaystyle\bigcap_{F \T{ fermé dans }E}F\subset\bigcap_{r>0}B_f(0,r)=\emptyset\implies \overline \emptyset=\emptyset$. Donc $E$ et $\emptyset$ sont fermés. Leurs complémentaires sont donc ouverts i.e $E$ et $\emptyset$ sont ouverts et fermés dans $E$.\\
		Fixons maintenant une partie $A\subset E$ ouverte et fermée dans $E$. Supposons qu'elle est non vide et donnons nous $a\in A$. On fixe $b\in E\backslash\{a\}$.\\
		Posons $\fonction{\varphi}{[0,1]}{[a,b]}{t}{(1-t)a+tb}$. On note $s=\sup\{t\in [0,1],\ \varphi(t)\in A\}$ qui est bien définie puisque $\varphi(0)=a\in A$. On remarque d'ailleurs que le caractère ouvert de $A$ assure que $s>0$. On va montrer que $s=1$.\\
		Montrons d'abord que le sup est atteint. On sait qu'il existe une suite $s_n\in [0,1]^\N$ telle que $s_n\unfty\longrightarrow s$ et $\forall n\in \N,\ \varphi(s_n)\in A$.\\
		$\varphi$ est continue car affine donc $\varphi(s_n)\unfty\longrightarrow\varphi(s)$.\\
		De plus $A$ est fermée donc $(\forall n\in \N,\ \varphi(s_n)\in A)\implies \varphi(s)\in A$. Ainsi $s\in \{t\in [0,1],\ \varphi(t)\in A\}$.\\
		Supposons maintenant par l'absurde $s<1$. Comme $A$ est ouverte, $\varphi(s)\in A\implies\exists r>0,\ B(\varphi(s),r)\subset A$. On peut toujours supposer $r\leq 1$. Mais alors pour $s'=\dfrac{s+r}{2}\in [0,1]$,
		$$\norme{\varphi(s')-\varphi(s)}=\norme{(s'-s)(b-a)}=(s'-s)\norme{b-a}=\dfrac{r-s}{2}\norme{b-a}$$
		$\dfrac{r-s}{2}\norme{b-a}<r\iff r-s<\dfrac{2r}{\norme{b-a}}\iff r<\dfrac{\norme{b-a}s}{\norme{b-a}-2}$ donc quitte à prendre $r$ plus petit on peut considérer que l'inégalité est vérifiée. (elle l'est automatiquement si $\norme{b-a}=2$).\\
		Ainsi $s'>s$ et $s'\in \{t\in [0,1],\ \varphi(t)\in A\}$. Ceci est absurde donc $s=1$ et par suite $b\in A$.\\
		Finalement $A=E$.
	
	\subsection{Opérations sur les adhérences/intérieurs}
	\label{Opérations sur les adhérences/intérieurs corrigé}
	\textcolor{blue}{\hyperref[Opérations sur les adhérences/intérieurs]{[Corrigé]}}\\
	
	\subsection{Les sept espaces de Kuratowski \etoile{3}}
	\label{sec:les-sept-espaces-de-kuratowski}
	\textcolor{blue}{\hyperref[Les sept espaces de Kuratowski]{[Enoncé]}}\\
	Il n'y a pas vraiment de méthode pour trouver un tel ensemble. On peut essayer de le construire par étape. Il faut jouer avec des parties de $\R$ dont on connaît l'adhérence/l'intérieur comme par exemple les intervalles.\\
	On veut $\T A\ne\ring{\T A}$ et $\T A\ne \overline{\T A}$ il faut donc déjà une partie ni ouverte ni fermée. Prenons par exemple $I=[0,1[$.\\
	Cela ne suffit pas puisque $\overline I=[0,1]=\overline{\ring I}$ par exemple. Un intervalle ne suffit donc pas, essayons avec plusieurs. Prenons $J=[0,1[\cup ]1,2[$. Pour faciliter les calculs on a les relations de l'exercice précédant (cf.[l'exo que j'ai rajouté avant]).
	On a
	$$\ring J=]0,1[\cup]1,2[,\ \overline J=[0,2],\ \ring{\overline J}=]0,2[, \overline{\ring J}=[0,2]$$
	On peut éviter la dernière égalité en prenant $J'=J\cup \{3\}$ : $\overline{J'}=[0,2]\cup\{3\}$ et $\overline{\ring{J'}}=[0,2]$.\\
	On sait aussi que $\overline \Q=\R$ et $\ring \Q=\emptyset$ (car $\R/\Q$ est dense dans $\R$).\\
	Finalement $\T A=[0,1[\cup]1,2[\cup\{3\}\cup(]4,5[\cap\Q)$ fonctionne :
	$$\ring{\T A}=]0,1[\cup ]1,2[,\ \overline{\T A}=[0,2]\cup\{3\}\cup[4,5],\ \ring{\overline{\T A}}=]0,2[\cup]4,5[,\ \overline{\ring{\T A}}=[0,2],\ \ring{\overline{\ring{\T A}}}=]0,2[,\ \overline{\ring{\overline{\T A}}}=[0,2]\cup[4,5]$$

	\subsection{Intérieur d'un sous-espace \telecom{2}}
	\label{sec:interieur-dun-sev}
	\textcolor{blue}{\hyperref[Intérieur d'un sev]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item Supposons que $F$ est ouvert. Soit $x\in E\backslash\{0\}$.\\
		$0\in F$ donc comme $F$ est ouvert, $\exists r>0,\ B(0,r)\subset F$. $y=\dfrac{r}{2\norme x}x\in B(0,r)$ donc $y\in F$. Puis comme $F$ est un espace vectoriel, $x=\dfrac{2\norme x}{r}y\in F$.\\
		Ainsi $F=E$.
		\item Supposons que $\ring F\ne \emptyset$. Il existe donc $x_0\in F$ et $r>0$ tel que $B(x_0,r)\subset F$. Soit $x\in E\backslash\{0\}$.\\
		$y=x_0+\dfrac{r}{2\norme x}x\in B(x_0,r)$ donc comme $F$ est un espace vectoriel et comme $x_0\in F$,\\
		$x=\dfrac{2\norme x}{r}(y-x_0)\in F$.\\
		Ainsi $F=E$.
	\end{enumerate}
	
	\subsection{Adhérence d'un sous-espace \centraleponts{3}}
	\label{sec:adherence-dun-sev}
	\textcolor{blue}{\hyperref[Adhérence d'un sev]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
	\item $F\subset \overline F$ donc $0\in \overline F$. Fixons $x,y\in \overline F$ et $\lambda\in \K$.\\
	Il existe des suites $(x_n),(y_n)\in F^\N$ qui convergent respectivement vers $x$ et $y$.\\
	Alors comme $F$ est un espace vectoriel $(x_n+\lambda y_n)\in F^\N$. De plus, $x_n+\lambda y_n\unfty\longrightarrow x+\lambda y$. Donc $x+\lambda y\in \overline F$.\\
	On en déduit que $\overline F$ est un sous-espace vectoriel de $E$.
	\item \underline{$1^{\T{ère}}$ méthode :}\\
	Soit $(x_n)\in F^\N$ une suite qui converge vers $x\in E$. Puisque $(x_n)$ converge, elle est bornée. Il existe donc $M>0$ telle que $\forall n\in \N,\ x_n\in B_f(0,M)$. Alors $(x_n)$ est une suite de $K:=F\cap B_f(0,M)$ qui est un fermé relatif à $F$ borné. Comme $F$ est de dimension finie, $K$ est compact et donc $(x_n)$ admet une valeur d'adhérence dans $K$, a fortiori dans $F$.\\
	$x$ étant la seule valeur d'adhérence de $(x_n)$, on en déduit que $x\in F$ puis que $F$ est fermé.\\\\
	\underline{$2^{\T{nd}}$ méthode :}\\
	Soit $(x_n)\in F^\N$ une suite qui converge vers $x\in E$. Fixons une base $(e_1,\dots,e_d)$ de $F$. On la complète en une base $(e_i)_{i\in I}$ de $E$.\\
	$\forall n\in \N,\ \exists a_1^n,\dots,a_d^n\in \K,\ x_n=\displaystyle\sum_{k=1}^da_k^ne_k$. On note aussi $x=\displaystyle\sum_{j\in J}a_je_j$ où $J$ est une sous-famille finie de $I$.\\
	Comme $(x_n)$ converge vers $x$ dans $E$, il y a convergence coordonnées par coordonnées.\\
	Alors $\forall j\in J\backslash\crblanc{1}{d},\ a_j=\unfty\lim 0=0$. Par conséquent $x=\displaystyle\sum_{j=1}^da_je_j\in F$.\\
	\textit{Remarque : Cette preuve repose sur l'existence d'une base dans un espace vectoriel quelconque, ce qui se déduit du théorème de la base incomplète qui est équivalent à l'axiome du choix (ou plutôt au lemme de Zorn). La première preuve permet d'éviter de telles considérations.}\\\\
	\underline{$3^{\T{ème}}$ méthode :} (hors-programme)\\
	On montre qu'un sous-espace vectoriel de dimension finie d'un espace vectoriel normé est complet et donc a fortiori fermé (cf. l'exo qui montre que $\R$ est complet \ref{R est complet} : je vais rajouter des questions pour arriver à ce résultat).
	\item Soit $a\in E$ tel que $E=H\oplus\Vect(a)$. Supposons que $H$ n'est pas fermé dans $E$. Alors il existe une suite $(h_n)\in H^\N$ qui converge vers un élément $x\in E\backslash H$.\\
	On sait alors qu'il existe un couple $(h,\lambda)\in H\times\K^*$ tel que $x=h+\lambda a$. Fixons $y=h'+\lambda'a\in E$.\\
	$y-\dfrac{\lambda'}{\lambda}x=h'-\dfrac{\lambda'}{\lambda}h\in H$.\\
	Ainsi $\lambda y=\lambda y-\lambda'x+\lambda'x=\unfty\lim \lambda h'-\lambda'h+\lambda' h_n$ avec $\forall n\in \N,\ \lambda h'-\lambda'h+\lambda'h_n\in H$. Ainsi $\lambda y\in\overline H$ et comme $\overline H$ est un espace vectoriel et $\lambda\ne 0$, $y\in \overline H$.\\
	Par conséquent $\overline H=E$ c'est-à-dire $H$ est dense dans $E$.
	\end{enumerate}
	
	\subsection{Graphe fermé \centraleponts{3}}
	\label{sec:graphe-ferme}
	\textcolor{blue}{\hyperref[Graphe fermé]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item Supposons $f$ continue. Soit $(x_n,y_n)\in G^\N$ convergeant vers $(x,y)\in \R^2$ i.e $x=\unfty\lim x_n$ et $y=\unfty\lim y_n$.\\
		$\forall n\in \N,\ y_n=f(x_n)$. Donc comme $f$ est continue, $f(x_n)\unfty\longrightarrow f(x)$. Par unicité de la limite $y=f(x)$ i.e $(x,y)\in G$.
		\item Supposons $f$ bornée et $G$ fermé. Soient $x\in \R$ et $(x_n)\in \R^\N$ convergeant vers $x$.\\
		$(f(x_n))$ est une suite bornée de $\R$, d'après le théorème de Bolzano-Weierstrass elle admet une sous-suite $f(x_{\varphi(n)})$ convergente. On note $\ell$ sa limite.\\
		$((x_{\varphi(n)},f(x_{\varphi(n)}))$ est une suite convergente de $G$, sa limite est donc dans $G$. Par conséquent $(x,\ell)\in G$, c'est-à-dire $\unfty\lim f(x_{\varphi(n)})=\ell=f(x)$.\\
		Ainsi $f$ est continue.
		\item La fonction $f:x\mapsto\begin{cases}
			\dfrac{1}{|x|}&\mbox{si }x\ne 0\\
			0&\mbox{si }x=0
		\end{cases}$ fournit un contre-exemple.\\
		En effet, si $\left(x_n,\dfrac{1}{|x_n|}\right)\unfty\longrightarrow(x,y)\in \R^2$ alors :
		\begin{itemize}
			\item Si $x\ne 0$ on se retrouve dans le cas de la question 1 et $y=\dfrac{1}{|x|}$;
			\item Si $x=0$ alors $y=+\infty$ ce qui est absurde.
		\end{itemize}
		Par conséquent le graphe de $f$ est fermé, pourtant $f$ n'est pas continue en $0$.
	\end{enumerate}
	
	\subsection{Application linéaire continue \telecom{2}}
	\label{sec:application-lineaire-continue}
	\textcolor{blue}{\hyperref[Application linéaire continue]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item On pose $\varphi:f\in \mathcal C([0,1],\R)\mapsto f(1)$.\\
		$\forall f\in \mathcal C([0,1],\R),\ |\varphi(f)|\leq \normep{\infty}{f}$ donc $\varphi\in E^*$.\\
		Pourtant, pour $f_n:x\mapsto x^n$, $\dfrac{\normep{1}{f_n}}{|\varphi(f_n)|}=\dfrac{1}{n+1}\unfty\longrightarrow0$. Donc $\varphi\notin F^*$.
		\item On montre aisément que : \[\normep{1}{f}\leq \normep{\infty}{f}\]
		Ainsi pour une application $\varphi$ continue sur $F$, on a : 
		\[\exists C\in\R_+,\forall f\in\mathcal{C}^0([0,1],\R), \; |\varphi(f)|\leq C\normep{1}{f}\leq C\normep{\infty}{f}\]
		Et donc $\varphi$ est continue sur $E$.
	\end{enumerate}
	
	\subsection{Application linéaire non continue \centraleponts{2}}
	\label{sec:application-lineaire-non-continue}
	\textcolor{blue}{\hyperref[Application linéaire non continue]{[Enoncé]}}\\
	Oui : On considère l'opérateur de dérivation $D:f\in E\mapsto f'$ et la suite des fonctions $f_n:x\mapsto e^{nx}$. On remarque alors que $D(f_n)=nf_n$\\
	Si $N$ est une norme sur $E$ alors $\dfrac{N(D(f_n))}{N(f_n)}=n\unfty\longrightarrow+\infty$. Donc $D$ n'est pas continue sur $(E,N)$.
		
	\subsection{Polynômes réels de degré $n$ scindés à racines simples sur $\R$ \xens{4}}
	\label{sec:polynomes-reels-de-degre-n-scindes-a-racines-simples-sur-r-etoile4}
	\textcolor{blue}{\hyperref[Polynômes réels de degré n scindés à racines simples sur R]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item Soit $P=\Lambda\displaystyle\prod\limits_{i=1}^n(X-x_i)\in A$ avec $x_1<\dots<x_n$. On fixe $(a_0,\dots,a_n)\in \R^{n+1}$ telle que,
		$$a_0<x_1<a_1<x_2<\dots<a_{n-1}<x_n<a_n$$
		On pose l'application $\fonction{\psi}{\R_n[X]}{\R^{n+1}}{P}{(P(a_0),\dots,P(a_n))}$.\\
		D'après le TVI, $\forall i\in \crblanc{0}{n-1},\ P(a_i)P(a_{i+1})<0$.\\
		Ainsi, $P\in U=\displaystyle\psi^{-1}\left(\prod\limits_{i=0}^n(-1)^i\R^*_+\right)\cup\psi^{-1}\left(\prod\limits_{i=0}^n(-1)^{i+1}\R^*_+\right)$.\\
		$\displaystyle\prod\limits_{i=0}^n(-1)^i\R^*_+$ et $\displaystyle\prod\limits_{i=0}^n(-1)^{i+1}\R^*_+$ sont des ouverts de $\R^{n+1}$ et $\psi$ est continue car linéaire sur $\R_n[X]$ qui est de dimension finie, donc $U$ est un ouvert de $\R_n[X]$.\\
		Enfin, un polynôme de $U$ est dans $A$ car il est de degré inférieur à $n$ et change $n+1$ fois de signe.\\
		On a donc montré que de tout polynôme de $A$ on peut construire un ouvert inclus dans $A$ et contenant ce polynôme : $A$ est ouvert.
		\item On va montrer que l'adhérence de $A$ est l'ensemble $S$ des polynômes de degré $n$ scindés sur $\R$.\\
		Fixons $P=\Lambda\displaystyle\prod\limits_{i=1}^n(X-x_k)\in S$. (Les $x_i$ sont donc potentiellement égaux).\\
		Posons pour tout $k\in \N,\ P_k=\Lambda\displaystyle\prod_{i=1}^n(X-y_{k,i})$ avec $\forall i\in \crblanc{1}{n},\ y_{k,i}=x_i-\displaystyle\frac{1}{k+i}$.\\
		Soient $k\in \N$ et $i,j\in \crblanc{1}{n}$ distincts.\\
		Si $x_i=x_j$ alors $y_{k,i}\ne y_{k,j}$.\\
		Sinon, $|y_{k,i}-y_{k,j}|=\displaystyle\left|x_i-x_j-\left(\frac{1}{k+j}-\frac{1}{k+i}\right)\right|\geq \left||x_i-x_j|-\left|\frac{1}{k+j}-\frac{1}{k+i}\right|\right|=\left||x_i-x_j|-\frac{|i-j|}{(k+j)(k+i)}\right|$.\\
		Or APCR $\left(k\geq\displaystyle\displaystyle\sqrt{\frac{|i-j|}{|x_i-x_j|}}-\min(i,j)\right)$, $\displaystyle|x_i-x_j|>\frac{|i-j|}{(k+j)(k+i)}$ d'où $\displaystyle\left||x_i-x_j|-\frac{|i-j|}{(k+j)(k+i)}\right|>0$.\\
		Ainsi, $P_k\in A$.\\
		Comme $P_k\ukfty{\longrightarrow}P$, on a $P\in \overline{A}$ puis $S\subset \overline{A}$.\\\\
		Il reste à montrer que $S$ est fermé.\\
		On rappelle que $\R_n[X]$ est fermé en tant que sous-espace vectoriel de dimension finie.\\
		On se donne une suite $(Q_k)=\left(\Lambda_k\displaystyle\prod\limits_{i=1}^n(X-z_{k,i})\right)\in S^\N$ qui converge vers un polynôme $Q=\Lambda\displaystyle\prod\limits_{i=1}^n(X-z_i)\in \R_n[X]$ avec $z_1,\dots,z_n$ des complexes. On travaillera ici avec la norme uniforme afin que la suite de fonction polynomiale associée à $(Q_k)$ converge uniformément, et a fortiori simplement, vers la fonction polynomiale associée à $Q$.\\
		Tout d'abord, chacun des coefficients de $Q$ est limite des coefficients de $(Q_k)$ donc $\Lambda_k\ukfty{\longrightarrow}\Lambda$.\\
		Montrons ensuite que si $P$ est dans $S$ de coefficient dominant $\mu$, alors $\forall \omega\in \C,\ |P(\omega)|\geq |\mu||\text{Im}(\omega)|^n$.\\
		Soient $P=\mu\displaystyle\prod\limits_{i=1}^n(X-\omega_i)\in S$ et $\omega\in \C$.\\
		$|P(\omega)|=|\mu|\displaystyle\prod\limits_{i=1}^n|\omega-\omega_i|\geq |\mu|\prod\limits_{i=1}^n\text{Im}(\omega-\omega_i)$.\\
		Or $\forall i\in \crblanc{1}{n},\ \omega_i\in \R\implies \text{Im}(\omega-\omega_i)=\text{Im}(\omega)$.\\
		Ainsi, $|P(\omega)|\geq|\mu|\displaystyle\prod\limits_{i=1}^n\text{Im}(\omega)=|\mu||\text{Im}(\omega)|^n$.\\
		On peut alors écrire, $\forall i\in \crblanc{1}{n},\ \forall k\in \N,\ |Q_k(z_i)|\geq |\Lambda_k||\text{Im}(z_i)|^n$.\\
		d'où en passant à la limite, $\forall i\in \crblanc{1}{n},\ 0=|Q(z_i)|\geq |\Lambda||\text{Im}(z_i)|^n$.\\
		$\Lambda$ étant non nul en tant que coefficient dominant, on sait alors que $\forall i\in\crblanc{1}{n},\ \text{Im}(z_i)=0$ ou encore que $\forall i\in \crblanc{1}{n},\ z_i\in \R$ ou encore que $Q\in S$.\\\\
		Finalement $\overline{A}=S$.
	\end{enumerate}
	
	\subsection{Lemme de Riemann-Lebesgue \centraleponts{3}}
	\label{sec:lemme-de-riemann-lebesgue-etoile3}
	\textcolor{blue}{\hyperref[Lemme de Riemann-Lebesgue]{[Enoncé]}}\\
	\begin{itemize}[leftmargin=*]
		\item Posons $(x_0,\dots,x_n)$ une subdivision de $[a,b]$ adaptée à $\phi$, c'est à dire telle que $x_0=a<x_1<\dots<x_{n-1}<x_n=b$ et que $\phi$ soit constante sur les intervalles $]x_k,x_{k+1}[$ pour $k\in \crblanc{0}{n-1}$. On note $\alpha_k=\phi(x_k)$.\\
		$\left|\displaystyle\int_a^b e^{i\lambda t}\phi(t)dt\right|=\left|\displaystyle\sum\limits_{k=0}^{n-1}\int_{x_k}^{x_{k+1}}e^{i\lambda t}\phi(t)dt\right|=\left|\displaystyle\sum\limits_{k=0}^{n-1}\int_{x_k}^{x_{k+1}}e^{i\lambda t}\alpha_kdt\right|=\left|\displaystyle\sum\limits_{k=0}^{n-1}\frac{\alpha_k(e^{i\lambda x_{k+1}}-e^{i\lambda x_k})}{i\lambda}\right|\leq\displaystyle\sum\limits_{k=0}^{n-1}\frac{2|\alpha_k|}{\lambda}\underset{\lambda\to +\infty}{\longrightarrow}0$.\\
		\item $\phi$ est limite uniforme d'une suite de fonctions en escaliers $(\phi_n)_{n\in \N}$ sur $[a,b]$:\\
		Posons $I_n:\lambda\mapsto \displaystyle\int_a^b\phi_n(t)e^{i\lambda t}dt$ et $I:\lambda\mapsto \displaystyle\int_a^b\phi(t)e^{i\lambda t}dt$.\\ $\forall n\in \N,\ \forall \lambda\in \R,\ |I(\lambda)-I_n(\lambda)|\leq\displaystyle\int_a^b|\phi(t)-\phi_n(t)|\cdot e^{i\lambda t}|dt\leq (b-a)||\phi-\phi_n||_{\infty,[a,b]}$.\\
		Donc $\forall n\in \N,\ ||I-I_n||_{\infty,\R}\leq (b-a)||\phi-\phi_n||_{\infty,[a,b]}$. D'où $||I-I_n||_{\infty,\R}\unfty{\longrightarrow}0$ et $(I_n)_{n\in \N}$ converge uniformément vers $I$ sur $\R$.\\
		Ainsi d'après le théorème de la double limite :\\
		$$\lim\limits_{\lambda\to +\infty}I(\lambda)=\lim\limits_{\lambda\to +\infty}\unfty{\lim}I_n(\lambda)=\unfty{\lim}\lim\limits_{\lambda\to +\infty}I_n(\lambda)=\unfty{\lim}0=0$$
		\item Soit $\varepsilon>0$. Puisque $\phi$ est intégrable sur $\R$, les intégrales $\displaystyle\int_0^{+\infty}||\phi(t)||dt$ et $\displaystyle\int_{-\infty}^0||\phi(t)||dt$ convergent.\\
		Donc $\lim\limits_{b\to +\infty}\displaystyle\int_b^{+\infty}||\phi(t)||dt=0$ et $\lim\limits_{a\to -\infty}\displaystyle\int_{-\infty}^a||\phi(t)||dt=0$.\\
		Ainsi, $\exists (a,b)\in \R^2,\ a<b\land\displaystyle\int_b^{+\infty}||\phi(t)||dt<\frac{\varepsilon}{3}\land\displaystyle\int_{-\infty}^a||\phi(t)||dt<\frac{\varepsilon}{3}$.\\
		Aussi, d'après la question précédente, $\lim\limits_{\lambda\to +\infty}\left|\displaystyle\int_a^b\phi(t)e^{i\lambda t}dt\right|=0$.\\
		Donc $\exists \lambda_0\in \R,\ \forall \lambda>\lambda_0,\ \left|\displaystyle\int_a^b\phi(t)e^{i\lambda t}dt\right|<\displaystyle\frac{\varepsilon}{3}$.\\
		Finalement,
		\begin{align*}
			\forall \lambda>\lambda_0,\ \left|\displaystyle\int_{-\infty}^{+\infty}\phi(t)e^{i\lambda t}dt\right|&\leq \left|\displaystyle\int_{-\infty}^a\phi(t)e^{i\lambda t}dt\right|+\left|\displaystyle\int_a^b\phi(t)e^{i\lambda t}dt\right|+\left|\displaystyle\int_b^{+\infty}\phi(t)e^{i\lambda t}dt\right|\\
			&<\displaystyle\int_b^{+\infty}||\phi(t)||dt+\frac{\varepsilon}{3}+\displaystyle\int_{-\infty}^a||\phi(t)||dt\\
			&<\varepsilon
		\end{align*}
		C'est à dire $\lim\limits_{\lambda\to +\infty}\displaystyle\int_{-\infty}^{+\infty}\phi(t)e^{i\lambda t}dt=0$.
	\end{itemize}
	
	\subsection{Borel-Lebesgue (HP)}
	\label{sec:borel-lebesgue}
	\textcolor{blue}{\hyperref[Borel-Lebesgue]{[Enoncé]}}\\
	Par souci de facilité, on raccourcira Borel-Lebesgue par BL et Bolzano-Weierstrass par BW.\\
	Montrons que BL-compact implique BW-compact.\\
	Supposons que $E$ est BL-compact.\\
	Soit $(x_n)$ une suite de $E$.\\
	Supposons que $(x_n)$ n'a pas de valeur d'adhérence.\\
	Alors pour tout $y\in E$, il existe un ouvert de $E$, $U_y$ qui contient $y$ tel que \[\{k, x_k\in U_y\}\; \text{est fini}\]
	La famille $(U_y)$ est un recouvrement de $E$ donc il existe une famille finie $(y_1,\dots, y_p)$ telle que :
	\[\bigcup_{i=1}^{p}U_{y_i}=E\]
	donc \[\{{k, x_k\in E}\}\; \text{est fini}\]
	ce qui est absurde.\\
	Réciproquement montrons que BW-compact implique BL-compact.\\
	Supposons que $E$ est BW-compact.\\
	On pose $d(x,y)=\norme{x-y}$ pour tout $(x,y)\in E^2$.
	Soit $(U_i)_{i\in I}$ un recouvrement de $E$ par des ouverts.\\
	On a la proposition suivante : \[\exists r>0 \text{ tel que } \forall x\in E, \exists i_x \text{ tel que } B(x,r)\subset U_{i_x}\]
	En effet, si ce n'est pas le cas, il existe $(x_n)\in E^\N$ tel que pour tout $i\in I$, $B\left(x,\frac{1}{n}\right)\not\subset U_{i}$.\\
	Passant à une sous-suite $x_{\varphi(n)}$, on a que : 
	\[x_{\varphi(n)}\to x\]
	Or il existe $i\in I$ tel que $x\in U_i$ donc il existe $\varepsilon >0$ tel que $B(x,\varepsilon)\subset U_i$ car $U_i$ est un ouvert.
	Soit $n\in \N$, \[d(x,x_{\varphi(n)})+\frac{1}{\varphi(n)}<\varepsilon\]
	de sorte que \[B\left(x_{\varphi(n)},\frac{1}{\varphi(n)}\right)\subset B(x,\varepsilon)\subset U_i\]
	ce qui est absurde.
	Il suffit de montrer que le recouvrement $E=\bigcup_{x\in E} B(x,r)$ admet un sous-recouvrement fini.\\
	En effet, s'il existe $x_1,\dots, x_n \in E$ tels que $E=\bigcup_{i=1}^n B(x_i,r)$ alors pour tout $i\in\crblanc{1}{n}$, $\exists j_i\in I$, $B(x_i,r)\supset U_{j_i}$ donc $\bigcup_{i=1}^n U_{j_i}=E$.\\
	S'il n'existe pas de sous-recouvrement fini de $E\bigcup_{i=1}^n B(x_i,r)$, on peut construire récursivement une suite $(x_n)$ comme suit : 
	\begin{enumerate}[label=\roman*.]
		\item $x_0$ un point quelconque de $E$
		\item $\forall n\in \N, x_n\not\in\bigcap_{i=1}^{n-1}B(x_i,r)$
	\end{enumerate}
	l'existence de $x_n$ est garantie si $E$ ne peut pas être recouvert par des boules de rayon $r$.\\
	Ainsi :
	\[\forall n\in \N, \forall m<n, d(x_m, x_n)>r\]
	Donc la suite $(x_n)$ n'a pas de sous-suite de Cauchy, ce qui est impossible car $E$ est BW-compact.
	
	\subsection{Parties compactes d'un espace vectoriel normé de dimension finie \etoile{2}}
	\label{sec:parties-compactes-dun-espace-vectoriel-norme-de-dimension-finie}
	\textcolor{blue}{\hyperref[Parties compactes d'un espace vectoriel normé de dimension finie]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item Soit $K\subset E$ une partie compacte. Soit $(x_n)\in K^\N$ qui converge vers $x\in E$.\\
		Comme $K$ est compacte, la suite $(x_n)$ admet une valeur d'adhérence dans $K$. Par ailleurs $(x_n)$ converge vers $x$ donc sa seule valeur d'adhérence est $x$. On en déduit que $x\in K$ et donc que $K$ est fermée.
		\item Soient $F\subset K\subset E$ avec $F$ fermée et $K$ compacte. Soit $(x_n)\in F^\N$.\\
		$(x_n)\in K^\N$ donc comme $K$ est compacte, il existe une sous-suite $(y_n)$ de $(x_n)$ qui converge dans $K$. Or $(y_n)\in F^\N$ donc comme $F$ est fermée, $(y_n)$ converge dans $F$.\\
		Ainsi $F$ est compacte.
		\item Montrons que le produit cartésien de deux compacts de $E$ est compact. On procédera ensuite par récurrence sur le nombre de compacts dans le produit.\\
		Soit $K_1,K_2$ deux compacts de $E$. Soit $(u_n,v_n)$ une suite de vecteurs de $K_1\times K_2$.\\
		Comme $K_1$ est compact, il existe une extractrice $\varphi$ telle que $(u_{\varphi(n)})$ converge dans $K_1$. Alors $(v_{\varphi(n)})\in K_2^\N$ donc comme $K_2$ est compact, il existe une extractrice $\psi$ telle que $(v_{\varphi\circ\psi(n)})$ converge dans $K_2$. Alors $(u_{\varphi\circ\psi(n)})$ converge en tant que sous-suite d'une suite convergente. De plus sa limite est dans $K_1$. On conclut que $(u_{\varphi\circ\psi(n)},v_{\varphi\circ\psi(n)})$ converge dans $K_1\times K_2$.\\
		Ainsi $K_1\times K_2$ est compact.\\
		Supposons que tout produit cartésiens de $p$ compacts de $E$ est un compact de $E$. Fixons $K_1,\dots,K_{p+1}$ des compacts de $E$. Alors par hypothèse de récurrence $\displaystyle\prod_{i=1}^pK_i$ est compact. Puis par ce que l'on vient de démontrer, $\displaystyle\left(\prod_{i=1}^pK_i\right)\times K_{p+1}=\prod_{i=1}^{p+1}K_i$ est compact.
		\item C'est le théorème de Bolzano-Weierstrass.
		\item On fixe une base $(e_1,\dots,e_d)$ de $E$.\\
		On dispose d'un isomorphisme $f:E\to \R^d$. Comme $E$ et $\R^d$ sont de dimensions finies, $f$ et $f^{-1}$ sont continues. On sait de plus que l'image directe d'une partie compacte/bornée par une application continue est une partie compacte/bornée et que l'image réciproque d'une partie fermée par une application continue est fermée. Ainsi une partie $A$ de $E$ est compacte/fermée/bornée ssi $f(A)$ est compacte/fermée/bornée dans $\R^d$. Il suffit donc de montrer le résultat dans $\R^d$.\\
		Soit $K$ un compact de $\R^d$. D'après la question 1, $K$ est fermé dans $\R^d$. Supposons par l'absurde que $K$ n'est pas bornée.\\
		Alors il existe une suite $(x_n)\in K^\N$ telle que $\norme{x_n}\unfty\longrightarrow+\infty$. $K$ est compact donc il existe une sous-suite $(y_n)$ de $(x_n)$ qui converge. Mais alors par continuité de $\norme{\cdot}$ qui est $1$-lipschitzienne, $(\norme{y_n})$ converge. Par ailleurs $\norme{y_n}\unfty\longrightarrow+\infty$ comme suite extraite de $(\norme{x_n})$. Ceci est absurde d'où $K$ est borné.\\
		Réciproquement, soit $K$ une partie fermée bornée de $\R^d$. On rappelle que toutes les normes de $\R^n$ sont équivalentes, donc $K$ est bornée pour la norme uniforme; càd qu'il existe $M\geq 0$ tel que $K\subset\{x\in \R^d,\ \normep{\infty}{x}\leq M\}=[-M,M]^d$. Or d'après les questions 3 et 4 $[-M,M]^d$ est un compact de $\R^d$. Enfin $K$ est fermée donc d'après la question 2, $K$ est compacte.
	\end{enumerate}
	
	\subsection{Somme de sous-espaces \centraleponts{3}}
	\label{sec:somme-de-sous-espaces}
	\textcolor{blue}{\hyperref[Somme de sous-espaces]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item Soient $A,B$ des compacts de $E$. On munit $E^2$ de la norme $\normep{1}{\cdot}:(a,b)\mapsto \norme a+\norme b$. L'application
		$$\fonction{s}{E^2}{E}{(a,b)}{a+b}$$
		est linéaire et de plus, $\forall (a,b)\in E^2,\ \norme{s(a,b)}\leq \normep{1}{(a,b)}$. Donc $s$ est continue. On sait que $A\times B$ est compact dans $E^2$ comme produit de compacts donc $s(A\times B)=A+B$ est compact dans $E$.
		\item Soient $K$ un compact et $F$ un fermé de $E$. Fixons $(z_n)\in (K+F)^\N$ une suite convergente de limite $z\in E$.\\
		$\forall n\in \N,\ \exists (k_n,f_n)\in K\times F,\ z_n=k_n+f_n$. Comme $K$ est compact, on peut extraire de $k_n$ une suite $(k_{\varphi(n)})$ convergente. On note $k$ sa limite.\\
		Alors par différence $f_{\varphi(n)}=z_{\varphi(n)}-k_{\varphi(n)}\unfty\longrightarrow z-k:=f$. De surcroît $F$ est fermé donc $f\in F$. Ainsi $z=k+f$ avec $(k,f)\in K\times F$.\\
		On conclut que $K+F$ est fermé dans $E$.
		\item On ne peut pas assurer que la somme de deux fermés est fermée :
		\begin{itemize}
			\item Dans $E=\R^2$ pour $F_1=\R\times\{0\}$ et $F_2=f^{-1}([1,+\infty[)$ avec $f:(x,y)\mapsto xy$, $F_1+F_2=\R\times \R^*$ n'est pas fermé.
			\item Dans $E=\R$ on peut prendre $F_1=\Z$ et $F_2=\pi\Z$. On montre classiquement (cf. sous-groupes de $\R$) que $\overline{F_1+F_2}=\R$.
		\end{itemize}
	\end{enumerate}
	
	\subsection{Un théorème du point fixe \centraleponts{3}}
	\label{Théorème du point fixe corrigé}
	\textcolor{blue}{\hyperref[Théorème du point fixe]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item On considère $g:x\mapsto \norme{f(x)-x}$. On remarque que $f$ est continue (cela découle directement de la propriété que vérifie $f$) donc $g$ est continue par composition de fonctions continues. $K$ est compact donc $g$ atteint son minimum sur $K$. Notons $a$ qui réalise ce minimum. Supposons $f(a)\ne a$.\\
		Alors $g(f(a))\norme{f^2(a)-f(a)}<\norme{f(a)-a}=g(a)$ ce qui est absurde. Ainsi $f(a)=a$.\\
		Montrons l'unicité. Soit $b\ne a$ tel que $f(b)=b$.\\
		Alors $\norme{b-a}=\norme{f(b)-f(a)}<\norme{b-a}$ ce qui est absurde. Donc $b=a$.
		\item On note pour tout $n\in \N,\ x_n=f^n(x_0)$.\\
		$\forall n\in \N,\ \norme{x_{n+1}-a}=\norme{f(x_n)-f(a)}\leq \norme{x_n-a}$\\
		La suite $(\norme{x_n-a})_{n\in \N}$ est décroissante et minorée (par $0$), d'après le théorème de la limite monotone elle converge vers un réel $\ell$. Or la suite $(x_n)_{n\in \N}$ est à valeurs dans $K$ qui est compact, on peut donc en extraire une suite $(x_{\varphi(n)})_{n\in \N}$ qui converge vers une vecteur $x\in K$. Par continuité de $f$, $x_{\varphi(n)+1}=f(x_{\varphi(n)})\unfty\longrightarrow f(x)$.\\
		On sait que $\unfty\lim\norme{x_{\varphi(n)}-a}=\unfty\lim\norme{x_{\varphi(n)+1}}=\norme{\ell-a}$. Par ailleurs, $\unfty\lim\norme{x_{\varphi(n)}-a}=\norme{x-a}$ et $\unfty\lim\norme{x_{\varphi(n)+1}-a}=\norme{f(x)-a}$. Par unicité de la limite, $\norme{x-a}=\norme{f(x)-a}=\norme{f(x)-f(a)}$. Donc $x=a$.\\
		On a montré que la seule valeur d'adhérence de $(x_n)_{n\in \N}$ est $a$, càd $\unfty\lim f^n(x_0)=a$.
	\end{enumerate}
	
	\subsection{Théorème de Heine \etoile{2}}
	\label{sec:theoreme-de-heine}
	\textcolor{blue}{\hyperref[Théorème de Heine]{[Enoncé]}}\\
	Soient $(E,\normep{E}{\cdot}),(F,\normep{F}{\cdot})$ deux espaces vectoriels normés, $K$ un compact de $E$ et $f:K\to F$ continue. Fixons $\varepsilon>0$.\\
	\underline{$1^{\T{ère}}$ méthode} :\\
	On note $d_E:(x,y)\in E^2\mapsto \normep{E}{x-y}$ et $d_F:(x,y)\in F^2\mapsto \normep{F}{x-y}$ ainsi que $X=\{(x,y)\in K^2,\ d_F(f(x),f(y))\geq \varepsilon\}$. On vérifie que $d_E$ et $d_F$ sont $1$-lipschitziennes et donc continues. On en déduit que $g:(x,y)\in E^2\mapsto d_F(f(x),f(y))$ est continue.\\
	$X=g^{-1}([\varepsilon,+\infty[)$ est fermé dans $K^2$ qui est compact, c'est donc un compact. Ainsi $d_E$ est minorée sur $X$ et atteint sa borne inférieure sur $X$. On note $\eta$ cette borne inférieure. Fixons $(x,y)\in K^2$ tels que $\normep{E}{x-y}<\eta$.\\
	Par définition de $\eta$, $(x,y)\notin X$ alors $\normep{F}{f(x)-f(y)}=d_F(f(x),f(y))<\varepsilon$.\\
	Ainsi $f$ est uniformément continue.\\\\
	\underline{$2^{\T{ème}}$ méthode :}\\
	On raisonne par contraposée. Supposons que $f$ n'est pas uniformément continue. Alors :
	$$\exists \varepsilon>0,\ \forall n\in \N^*,\ \exists (x_n,y_n)\in K^2,\ \left(\normep{E}{x_n-y_n}\leq\dfrac{1}{n}\land \normep{F}{f(x_n)-f(y_n)}\geq \varepsilon\right)$$
	Comme $K$ est compact on peut extraire une suite $(x_{\varphi(n)})$ qui converge vers un vecteur $x\in K$. Mais alors $\forall n\in \N^*,\ \normep{E}{x-y_{\varphi(n)}}\leq \normep{E}{x-x_{\varphi(n)}}+\normep{E}{x_{\varphi(n)}-y_{\varphi(n)}}\unfty\longrightarrow 0$. Autrement dit $\unfty\lim y_{\varphi(n)}=x$. Pourtant $(f(y_{\varphi(n)}))_{n\in \N^*}$ ne converge par vers $f(x)$ puisque APCR,
	$$\normep{F}{f(x)-f(y_{\varphi(n)})}\geq \normep{F}{f(x_{\varphi(n)})-f(y_{\varphi(n)})}-\normep{F}{f(x)-f(x_{\varphi(n)})}\geq \frac{\varepsilon}{2}$$
	
	\subsection{Lemme des compacts emboîtés \telecom{1}}
	\label{sec:lemme-des-compacts-emboites-etoile1}
	\textcolor{blue}{\hyperref[Lemme des compacts emboités]{[Enoncé]}}\\
	\label{Lemme des compacts emboîtés corrigé}
	$\forall n\in \N,\ \exists x_n\in K_n$. De plus, $\forall n\in \N,\ K_{n+1}\subset K_n\subset K_0$.\\
	Donc $(x_n)_{n\in \N}$ est à valeurs dans $K_0$ qui est compact.\\
	Ainsi il existe $\varphi:\N\to\N$ strictement croissante telle que $(x_{\varphi(n)})_{n\in \N}$ converge. On note $x$ sa limite.\\
	On va montrer que $x\in K$.\\
	Soit $n\in \N$. $\exists n_0\in \N,\ \varphi(n_0)\geq n$.\\
	La suite $(x_{\varphi(k)})_{k\geq n_0}$ est à valeur dans  $K_n\supset K_{\varphi(n_0)}$ qui est un fermé. Ainsi sa limite $x\in K_{n}$ puis, $x\in K=\displaystyle\bigcap\limits_{n\in \N} K_n$.\\
	
	\subsection{Théorème de Baire \xens{5} (HP)}
	\label{sec:theoreme-de-baire-etoile5}
	\textcolor{blue}{\hyperref[Théorème de Baire]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item Soit $(\Omega_n)\in E^{\N^*}$ une suite d'ouverts denses dans $E$.\\
		Soit $V$ un ouvert non vide de $E$. On va montrer que $V\cap\displaystyle\bigcap\limits_{n\in \N^*}\Omega_n\ne \emptyset$.\\
		$\Omega_1$ et $V$ sont ouvert donc $V\cap \Omega_1$ est ouvert comme intersection finie d'ouvert. De plus $\Omega_1$ est dense dans $E$ donc $V\cap \Omega_1\ne\emptyset$.\\
		Alors, $\exists x_1\in V\cap \Omega_1$ et $\exists \varepsilon_1\in \R^*_+,\ B(x_1,\varepsilon_1)\subset V\cap \Omega_1$.\\
		Et alors, $\exists r_1=\displaystyle\frac{\varepsilon_1}{2}\in \R^*_+,\ B_f(x_1,r_1)\subset V\cap \Omega_1$. Quitte à prendre plus petit on peut supposer $r_1\leq 1$.\\
		On va alors construire par récurrence des suites $(x_n)_{n\in \N^*}$ et $(r_n)_{n\in \N^*}$ telles que :
		$$\begin{cases}
			\forall n\in \N^*,\ r_n\leq \displaystyle\frac{1}{n}\\
			\forall n\in \llbracket 2;+\infty\llbracket,\ B_f(x_n,r_n)\subset U_n=\Omega_n\cap B(x_{n-1},r_{n-1})\\
			B_f(x_1,r_1)\subset\Omega_1\cap V
		\end{cases}$$\\
		Supposons que $r_{n-1}$ est bien définit pour un certain entier $n\geq 2$.\\
		$U_n=\Omega_n\cap B(x_{n-1},r_{n-1})$ est ouvert comme intersection finie d'ouvert. De plus, $\Omega_n$ est dense dans $E$ donc $U_n\ne \emptyset$.\\
		Alors, $\exists x_n\in U_n$ et $\exists \varepsilon_n\in \R^*_+,\ B(x_n,\varepsilon_n)\subset U_n$.\\
		Et alors, $\exists r_n=\displaystyle\frac{\varepsilon_n}{2}\in \R^*_+,\ B_f(x_n,r_n)\subset U_n$. Quitte à prendre plus petit on peut supposer $r_n\leq \displaystyle\frac{1}{n}$.\\\\
		Montrons que la suite $(x_n)_{n\in \N^*}$ est de Cauchy.\\
		Soit $k>n$ deux entiers non nuls.\\
		Par définition, $x_k\in B(x_n,r_n)$ donc $||x_n-x_k||<r_n\leq \displaystyle\frac{1}{n}$. Ainsi, $(x_n)_{n\in \N^*}$ est de Cauchy.\\\\
		Or $E$ est complet donc $(x_n)_{n\in \N^*}$ converge. On note $x$ sa limite.\\
		Toujours par définition, $\forall n\in \N^*,\ \forall k\geq n,\ x_k\in B_f(x_n,r_n)$. Toutes ces boules sont des fermés donc par caractérisation séquentielle, $x\in \displaystyle\bigcap\limits_{n\in \N^*}B_f(x_n,r_n)$.\\
		Et donc, $x\in \displaystyle\bigcap\limits_{n\in \N^*}\Omega_n$. et $x\in V$ car $x\in B_f(x_1,r_1)$.\\
		Ainsi, $x\in V\cap\displaystyle\bigcap\limits_{n\in \N^*}\Omega_n$.
		\item Soit $(\Omega_n)\in E^\N$ une suite d'ouverts denses dans $E$.\\
		Alors pour tout $n\in \N$, $\Omega_n^c$ le complémentaire dans $E$ de $\Omega_n$ est fermé et $\overline{\Omega_n}=E$ d'où $\ring{(\Omega_n^c)}=(\overline{\Omega_n})^c=\emptyset$. Ainsi par passage au complémentaire,
		$$\displaystyle\overline{\bigcap\limits_{n\in \N}\Omega_n}=E\iff \widering{\bigcup\limits_{n\in \N}\Omega_n^c}=\emptyset$$
	\end{enumerate}
	\subsubsection{$\R$ n'est pas dénombrable \etoile{1} (HP)}
	On montre que $\R$ est complet (cf. \ref{R est complet}).\\
	Supposons que $\R$ est dénombrable. Pour tout $x\in\R$, $\{x\}$ est un fermé de $\R$ d'intérieur vide. Donc d'après le théorème de Baire $\R=\displaystyle\bigcup_{x\in \R}\{x\}$ est d'intérieur vide. Ceci est absurde donc $\R$ n'est pas dénombrable.
	
	\subsubsection{Base d'un espace de Banach \etoile{3} (HP)}
	Soit $E$ un espace de Banach. Supposons par l'absurde que $E$ admette une base dénombrable $\B=(e_n)_{n\in \N}$.\\
	On pose pour $n\in \N,\ F_n=\Vect(e_0,\dots,e_n)$. Fixons $n\in \N$.\\
	$F_n$ est un sous-espace vectoriel de $E$. Il est d'intérieur vide car c'est un sous-espace strict de $E$ (cf. \ref{Intérieur d'un sev}) et il est fermé dans $E$ car il est de dimension finie (cf. \ref{Adhérence d'un sev}).\\
	On peut écrire $E=\displaystyle\bigcup_{n\in \N} F_n$ donc d'après le théorème de Baire on en déduit que $E$ est d'intérieur vide ce qui est absurde.
	
	\subsubsection{Densité des fonctions nulle part dérivables (2) \etoile{4} (HP)}
	Notons $I=[0,1]$ et $E=\mathcal C^0(I,\K)$.\\
	\begin{enumerate}
		\item Soit $f\in A^c$. Il existe alors un point $x\in I$ en lequel $f$ est dérivable.\\
		C'est à dire que la quantité $\displaystyle\frac{f(x)-f(y)}{x-y}$ admet une limite finie quand $y\to x$.\\
		$f$ étant continue sur $I$, la fonction $\fonction{Y}{I\setminus\{x\}}{\K}{y}{\displaystyle\frac{f(x)-f(y)}{x-y}}$ est continue sur $I\setminus\{x\}$ et prolongeable par continuité en $x$.\\
		$I$ étant un segment on en déduit que $Y$ est bornée sur $I$. Ainsi $\exists N\in \N,\ N\geq {||f||}_\infty$ et donc $f\in F_N$.
		\item Soit $n\in \N$.\\
		Soit $(f_k)\in F_n^\N$ qui converge (uniformément) vers $f\in E$.\\
		$(*) : \forall k\in \N,\ \exists x_k\in I,\ \forall y\in I,\ |f_k(x_k)-f_k(y)|\leq n|x_k-y|$\\
		$(x_k)_{k\in \N}$ est une suite à valeur dans $I$ qui est compact donc il existe une suite extraite $(x_{\varphi(k)})_{k\in \N}$ qui converge. Notons $x$ sa limite.\\
		Soit $k\in \N$.\\
		$|f_{\varphi(k)}(x_{\varphi(x_k)})-f(x)|\leq |f_{\varphi(k)}(x_{\varphi(x_k)})-f(x_{\varphi(k)})|+|f(x_{\varphi(k)})-f(x)|\leq {||f_{\varphi(k)}-f||}_\infty+|f(x_{\varphi(k)})-f(x)|$.\\\\
		Or, $|f(x_{\varphi(k)})-f(x)|\ukfty{\longrightarrow}0$ par continuité de $f$ et ${||f_{\varphi(k)}-f||}_\infty\ukfty{\longrightarrow}0$ par convergence uniforme.\\
		Donc $f_{\varphi(k)}(x_{\varphi(x_k)})\ukfty{\longrightarrow}f(x)$.\\
		Par passage à la limite dans $(*)$ on obtient directement $f\in F_n$.
		\item Soit $n\in \N$.\\
		D'après le théorème de Weierstrass, il existe une fonction polynomiale $P$ telle que ${||f-P||}_\infty\leq\displaystyle\frac{\varepsilon}{2}$.\\
		$g_0$ est continue et ${||g_N||}_\infty=\displaystyle\frac{\varepsilon}{4}$
		On a ${||f-g||}_\infty\leq {||f-P||}_\infty+{||g_N||}_\infty\leq\displaystyle\frac{\varepsilon}{2}+\frac{\varepsilon}{4}<\varepsilon$.\\
		Ensuite, $\forall x,y\in I,\ |g(x)-g(y)|\geq |g_N(x)-g_N(y)|-|P(x)-P(y)|$.\\
		De plus, $\forall x\in I,\ \exists k\in \crblanc{0}{2N-1},\ x\in \left[\displaystyle\frac{k}{2N},\frac{k+1}{2N}\right]$.\\
		Soit alors $y\in \left[\displaystyle\frac{k}{2N},\frac{k+1}{2N}\right]$.\\
		$|g_N(x)-g_N(y)|=\displaystyle\frac{\varepsilon N}{2}|x-y|$.\\
		Aussi, par le théorème des accroissements finis, $|P(x)-P(y)|\leq {||P'||}_\infty|x-y|$.\\
		Par conséquent, $\forall x\in I,\ \exists y\in I,\ |g(x)-g(y)|>\left(\displaystyle\frac{\varepsilon N}{2}-{||P'||}_\infty\right)|x-y|$.\\
		Il suffit alors de prendre $N\geq \displaystyle\frac{2}{\varepsilon}(n+{||P'||}_\infty)$ pour obtenir $g\in F_n^c$.
		\item On montré que $(F_n)_{n\in \N}$ est une suite de fermé d'intérieur vide de $E$. D'après le théorème de Baire, $\displaystyle\bigcup\limits_{n\in \N}F_n$ est donc d'intérieur vide.\\
		Mais alors d'après la question $1$, $\widering{A^c}\subset \displaystyle\widering{\bigcup\limits_{n\in \N}F_n}=\emptyset$ d'où $\widering{A^c}=\emptyset$ c'est à dire $A$ est dense dans $E$.
	\end{enumerate}

	\subsubsection{Lemme de Croft \etoile{4} (HP)}
\begin{enumerate}[leftmargin=*]
	\item Soit $\varepsilon>0$. Par uniforme continuité $\exists \eta>0,\ \forall (x,y)\in (\R^*_+)^2,\ |x-y|\leq\eta\implies |f(x)-f(y)|<\dfrac{\varepsilon}{2}$.\\
	On sait que $\unfty\lim f(n\eta)=0$ donc $\exists N\in \N^*,\ \forall n\geq N,\ |f(n\eta)|<\dfrac{\varepsilon}{2}$.\\
	Soit $x\geq N\eta$. On pose $n=\left\lfloor\dfrac{x}{\eta}\right\rfloor$ de sorte que $|x-n\eta|\leq \eta$ et $n\geq N$.\\
	On a alors $|f(x)|\leq |f(x-n\eta)|+|f(n\eta)|<\varepsilon$.\\
	On a montré que $\forall x\geq N\eta,\ |f(x)|<\varepsilon$ i.e $f$ admet une limite nulle en $+\infty$.
	\item Fixons $\varepsilon>0$. On pose pour $n\in \N,\ F_n=\{x>0,\ \forall p\geq n,\ |f(px)|\leq\varepsilon\}$. Par continuité de $f$, l'application $g_n:x\mapsto |f(nx)|$ est continue et par suite les ensembles $F_{n,p}:=\{x>0,\ |f(px)|<\varepsilon\}=g_n^{-1}([0,\varepsilon])$ sont fermés d'où $F_n=\displaystyle\bigcap_{p\geq n}F_{n,p}$ est fermé. Par hypothèse $\displaystyle\bigcup_{n\in \N} F_n=\R^*_+$. $\R^*_+$ n'est pas d'intérieur vide donc d'après la contraposée du théorème de Baire il existe un entier naturel $n$ tel que $\ring F_n\ne\emptyset$.\\
	Ainsi il existe $0<\alpha<\beta$ tels que $\forall y>0,\ y\in ]\alpha,\beta[\implies \forall p\geq n,\ |f(py)|<\varepsilon$.\\
	Autrement dit, $\forall z>0,\ z\in \displaystyle\bigcup_{p\geq n}\ ]p\alpha,p\beta[\implies |f(z)|<\varepsilon$.\\
	Or pour $p>p_0:=\max\left(n,\left\lfloor\dfrac{\alpha}{\beta-\alpha}\right\rfloor\right),\ (p+1)\alpha\geq p\beta$. Donc $\displaystyle\bigcup_{p>p_0}\ ]p\alpha,p\beta[\ =\ ](p_0+1)\alpha,+\infty[$.\\
	On a montré que si $y>(p_0+1)\alpha$ alors $|f(y)|<\varepsilon$. Ainsi $f$ admet une limite nulle en $+\infty$.
	\item Ce n'est malheureusement pas aussi simple...\\
	On va poser $f=\mathbbm 1_A$ avec $A$ non majoré et tel que le quotient de deux éléments distincts de $A$ ne soit jamais rationnel. En effet $A$ non majoré assure que $f$ n'ait pas de limite en $+\infty$. En outre, si $mx\leq nx\in A$ alors $\displaystyle\frac{n}{m}\in \Q$ est un quotient d'éléments de $A$ et donc $n=m$. Ceci assure que pour tout $x>0,\ nx\notin A$ APCR et donc $\unfty\lim f(nx)=0$.\\
	On peut considérer $A=\{\pi^k,\ k\in \Z\}$ l'ensemble des puissances entières de $\pi$. $\pi>1$ donc $A$ n'est pas majoré et de plus pour tout $m<n\in \N$, si $\pi^{n-m}\in \Q$ alors $\pi$ est racine du polynôme à coefficients rationnels $X^{n-m}-\pi^{n-m}$. Il est bien connu que $\pi$ est transcendant donc ceci est absurde d'où $\pi^{n-m}\notin \Q$. On en déduit aussi $\pi^{m-n}\notin \Q$.\\
	En fait il suffit de prendre l'ensemble des puissances entières de n'importe quel nombre transcendant réel positif. Sans même en expliciter on sait qu'il en existe car les nombres algébriques sont dénombrables. $\R_+$ étant non dénombrable il contient une infinité de nombres transcendants.
\end{enumerate}

	\subsubsection{Caractérisation des endomorphismes continus nilpotents dans un espace de Banach \etoile{3} (HP)}
	\begin{enumerate}[leftmargin=*]
		\item Posons pour $n\in \N^*,\ F_n=\{x\in E,\ f^n(x)=0\}$. $F_n$ est fermé.\\
		$\displaystyle\bigcup_{n\in \N^*}F_n=E$. Donc d'après le théorème de Baire il existe $N\in \N^*$ tel que $\ring F_N\ne \emptyset$. On dispose donc d'un vecteur $a\in E$ et d'un réel $r>0$ tel que $B_f(a,r)\subset F_N$.\\
		$\forall x\in E\setminus\{0\},\ f^N(x)=\displaystyle\frac{\norme x}{r}\left[f^N\left(a+\frac{x}{\norme x}r\right)-f^N(a)\right]=0$.\\
		Donc $f$ est nilpotent.\\
		\textit{Remarque : On pourra noter que dans un espace de dimension finie les hypothèses de continuité et de complétude sont automatiquement vérifiées.}
		\item On note $E=\R[X]$. Posons $D\in \mathcal L(E)$ l'endomorphisme de dérivation. Pour $P\in E$ on pose $N(P)=\displaystyle\sum_{n=0}^{+\infty}|P^{(n)}(0)|$.\\
		Vérifions que $N$ est une norme sur $E$. On fixe $P,Q\in E$ et $\lambda\in \R$.\\
		Tout d'abord, $N$ est bien une application de $E$ dans $\R_+$ pour tout $P\in E$ la suite $(P^{(n)}(0))_{n\in \N}$ est nulle au moins à partir du rang $\deg P+1$. Ensuite,
		\begin{itemize}
			\item $N(\lambda P)=\displaystyle\sum_{n=0}^{\deg P+1}|\lambda P^{(n)}(0)|=|\lambda|N(P)$.
			\item $N(P+Q)=\displaystyle\sum_{n=0}^{\deg(P+Q)+1}|P^{(n)}(0)+Q^{(n)}(0)|\leq \sum_{n=0}^{\deg(P+Q)+1}|P^{(n)}(0)|+\sum_{n=0}^{\deg(P+Q)+1}|Q^{(n)}(0)|\leq N(P)+N(Q)$.
			\item Si $N(P)=0$ alors comme $\forall n\in \N,\ |P^{(n)}(0)|\geq 0$, on sait que $\forall n\in \N,\ |P^{(n)}(0)|=P^{(n)}(0)=0$.\\
			Ainsi d'après la formule de Taylor, $P=\displaystyle\sum_{n=0}^{+\infty}\frac{P^{(n)}(0)}{n!}X^n=0$.
		\end{itemize}
		De plus, $D$ est continue pour cette norme. En effet, $\forall P\in E,\ N(D(P))=\displaystyle\sum_{n=1}^{+\infty}|P^{(n)}(0)|\leq N(P)$.\\
		$D$ n'est pas nilpotent : $D^n$ n'est pas nul puisque $\Ker(D^n)=\R_{n-1}[X]\ne E$. Pourtant $\forall P\in E,\ D^{\deg P+1}(P)=0$.
	\end{enumerate}
	
	\subsubsection{Caractérisation des polynômes réels \etoile{5} (HP)}
	\begin{enumerate}[leftmargin=*]
		\item L'hypothèse de l'énoncé se traduit en $\R=\displaystyle\bigcup_{n\in \N} F_n$. Pour tout $n\in \N$, $F_n=(f^{(n)})^{-1}(\{0\})$ est fermé car $f^{(n)}$ est continue. Donc d'après la contraposée du théorème de Baire, $\widering{\displaystyle\bigcup_{n\in \N} F_n}=\ring \R=\R\ne\emptyset\implies \exists N\in \N,\ \ring F_N\ne\emptyset$.
		\item \begin{enumerate}[label=\alph*.]
			\item $x\in \ring F_N$ donc $f^{(N)}$ s'annule sur un voisinage ouvert de $x$. Donc si $k\geq N$, $f^{(k)}$ s'annule sur ce même voisinage et en particulier en $x$.
			\item La série de Taylor de $f$ converge en tout point $x\in I$ puisque $$\displaystyle\sum_{k=0}^{\infty}\dfrac{f^{(k)}(x)}{k!}(y-x)^k=\sum_{k=0}^{N-1}\dfrac{f^{(k)}(x)}{k!}(y-x)^k$$
			$I$ étant un voisinage ouvert de $x$, $f$ est égale sur $I$ à sa série de Taylor en $x$, qui est une fonction polynomiale.
		\end{enumerate}
		\item \begin{enumerate}[label=\alph*.]
			\item On sait que les connexes par arcs de $\R$ sont les intervalles. Si $J$ contient une de ses bornes, disons son sup $v$, alors comme $\Omega$ est ouvert, on peut trouver $\varepsilon>0$ tel que $v+\varepsilon\in \Omega$. Mais alors $J\cup [v,v+\varepsilon]\subset \Omega$ ce qui contredit la maximalité de $J$. De manière analogue, $J$ ne contient pas sa borne inférieure $u$ et donc $J=]u,v[$ est ouvert.
			\item $x_0\in \Omega$ donc il existe un entier naturel $n$ tel que $x_0\in \ring F_n$ et donc il existe un intervalle ouvert $I_0$ tel que $x_0\in I\subset F_n$. Or comme $x_0\in J$ et comme $I$ est connexe par arcs, $I\subset J$. Alors $x_0\in I\subset F_n\cap J$. De plus, $I$ est non vide donc la question précédente donne l'existence d'un polynôme $P$ tel que $\forall y\in I,\ f(y)=P(y)$.
			\item $x_0\in I$ donc $A$ est non vide. De plus $A$ est connexe par arcs, en effet si $y<z\in A$ alors $\forall t\in [0,1],\ [x_0,ty+(1-t)z]\subset [x_0,z]\implies ty+(1-t)z\in A$. Donc $A$ est connexe par arcs.\\
			Ainsi comme $A$ contient un élément $x_0\in J$, $A\subset J$.
			\item Supposons $s\in \Omega$. Notons $p\in \N$ tel que $s\in \ring F_p$. Alors $\exists \varepsilon\in ]0,s-x_0],\ I':=]s-\varepsilon,s+\varepsilon[\subset F_p$. D'après la question 2, $\exists Q\in \R[X],\ \forall y\in I',\ f(y)=Q(y)$.\\
			$f$ et $Q$ coïncident sur l'intervalle $I'$, il en va donc de même pour leurs dérivées successives. Par ailleurs $f$ et $P$ coïncident sur le connexe par arcs $A$, il en va donc de même pour leurs dérivées successives.
			Mais alors en $y=s-\varepsilon\in A\cap I'$, $\forall k\in \N,\ P^{(k)}(y)=f^{(k)}(y)=Q^{(k)}(y)$. On en déduit que $P=Q$ et donc que $s+\varepsilon\in A$ ce qui contredit la maximalité de $s$. On en déduit que $s\notin\Omega$.\\
			Par conséquent, $s\notin J$. Pourtant $A\subset J\implies s\leq \sup J$, donc comme $J$ est un intervalle, $s=\sup J$.
			\item On montre de la même manière qu'en notant $B=\{x\leq x_0\ |\ \forall y\in [x,x_0],\ f(y)=P(y)\}$, $B$ est un intervalle et on a $\inf B=\inf J$. $A\cup B$ est l'union de deux intervalles non disjoints ($x_0\in A\cap B$), c'est donc aussi un intervalle. En outre, $A\cup B\subset J$ et $\inf A\cup B=\inf J$ et $\sup A\cup B=\sup J$. Ainsi $J=A\cup B$ i.e $\forall y\in J,\ f(y)=P(y)$.
		\end{enumerate}
		\item \begin{enumerate}[label=\alph*.]
			\item Soit $x\in \Phi$. Supposons $x$ isolé dans $\Phi$. Alors il existe $\varepsilon>0$ tel que $I_-:=]x-\varepsilon,x[\subset \Omega$ et $I_+:=]x,x+\varepsilon[\subset \Omega$. $I_-$ et $I_+$ Etant des intervalles de $\Omega$, la question 3 assure que $f$ est polynomiale sur $I_-$ et $I_+$. On note $P_-$ et $P_+$ tels que $\forall y\in I_-,\ f(y)=P_-(y)$ et $\forall y\in I_+,\ f(y)=P_+(y)$.\\
			D'après le théorème de la limite de la dérivée, $\forall n\in \N,\ P_-^{(n)}(x)=f^{(n)}(x)=P_+^{(n)}(x)$. En particulier $x\in\ring F_{\max(deg(P),\deg(Q))+1}$ ce qui est absurde. Donc $\Phi$ n'a pas de point isolé.
			\item $\Omega$ est ouvert en tant que réunion d'ouverts donc $\Phi$ est fermé. Ainsi si $(x_n)\in \Phi^\N$ est de Cauchy alors comme $\R$ est complet elle converge dans $\R$. Mais comme $\Phi$ est fermé, elle converge dans $\Phi$.\\
			Par conséquent $\Phi$ est complet.
			\item $\Phi=\R\cap\Phi=\displaystyle\left(\bigcup_{n\in \N} F_n\cap\Phi\right)=\bigcup_{n\in \N}(\Phi\cap F_n)$. On a supposé $\Phi$ non vide donc on peut se donner $x\in \Phi$. On sait que $x$ n'est pas isolé dans $\Phi$ donc $x$ appartient à l'intérieur \underline{dans $\Phi$} de $\Phi$ :
			$$\forall \varepsilon>0,\ \exists x_\varepsilon\in \Phi,\ |x-x_\varepsilon|<\varepsilon$$
			Notons pour toute partie $X\subset \Phi,\ \ring X_\Phi=\{x\in X,\ \exists \varepsilon>0,\ \emptyset\ne]x-\varepsilon,x+\varepsilon[\cap\Phi\subset X\}$ l'intérieur de $X$ dans $\Phi$.\\
			Les $\Phi\cap F_n$ sont des fermés de $\Phi$ dont la réunion est d'intérieur non vide dans $\Phi$, d'après la contraposé du théorème de Baire $\exists n_0\in \N,\ \widering{(\Phi\cap F_n)}_\Phi\ne\emptyset$.\\
			Autrement dit il existe un intervalle ouvert $I$ tel que $\emptyset\ne I\cap\Phi\subset F_{n_0}$.
			\item Comme $x$ n'est pas isolé dans $\Phi$, $\forall n\in \N^*,\ \exists x_n\in \Phi\backslash\{x\},\ |x-x_n|<\dfrac{1}{n}$. $(x_n)_{n\in \N}$ converge vers $x$ et est APCR à valeurs dans $I$ (car c'est un ouvert). Quitte à réindicer on peut supposer $(x_n)_{n\in \N}$ à valeurs dans $I\cap\Phi\backslash\{x\}$. De plus d'après le lemme des pics (cf.\ref{Théorème de Bolzano-Weierstrass}) on peut extraire de $(x_n)_{n\in \N}$ une suite monotone. Cette suite converge toujours vers $x$ et ne stationne pas à $x$, on peut donc la supposer strictement monotone quitte à enlever des termes.
			\item Supposons $(x_k)_{k\in \N}$ strictement croissante. Alors $\forall k\in \N,\ x_k<x_{k+1}$ et $f^{(n_0)}(x_{k-1})=f^{(n_0)}(x_k)=f^{(n_0)}(x_{k+1})=0$. D'après le théorème de Rolle il existe une suite $(y^1_k)_{k\in \N^*}$ telle que $\forall k\in \N,\ x_{k-1}<y^1_k<x_k<y^1_{k+1}<x_{k+1}<x$ et $f^{(n_0+1)}(y^1_k)=0$.\\
			On construit comme ceci par récurrence des suites $(y^p_k)_{k\in \N^*}$ telles que $\forall p\in \N^*,\ \forall k\in \N^*,\ x_{k-1}<y^p_k<y^{p+1}_k<x$ et $f^{(n_0+p)}(y^p_k)=0$.\\
			Par construction $\forall p\in \N^*,\ y^p_k\ukfty\longrightarrow x$ et $(y^p_k)_{k\in \N^*}\in F_{n_0+p}^{\N^*}$. Donc comme les $F_n,\ n\geq n_0$ sont des fermés, $\forall n\geq n_0,\ x\in F_n$.
			\item Soit $J=]u,v[$ ($u,v\in \overline\R$) une composante connexe par arcs de $I\cap\Omega$. On remarque que $I=(I\cap\Phi)\sqcup(I\cup\Omega)$. Comme $I\cap\Phi\ne\emptyset$, $u\ne-\infty$ ou $v\ne+\infty$. Donc $u\in I\cap\Phi$ ou $v\in I\cap\Phi$. Supposons $v\in I\cap\Phi$, alors d'après la question précédente, $\forall n\geq n_0,\ f^{(n)}(v)=0$. Par ailleurs $J$ est un connexe par arcs de $\Omega$ donc d'après la question 3, $\exists P\in \R[X],\ \forall y\in J,\ f(y)=P(y)$.\\
			Il suit $\forall n\geq n_0,\ P^{(n)}(v)=f^{(n)}(v)=0$. Puis par la formule de Taylor, $\deg(P)<n_0$ d'où $P^{(n_0)}=0$ et enfin $\forall y\in J,\ f^{(n_0)}(y)=0$ i.e $J\subset F_{n_0}$. On peut faire le même raisonnement si $u\in I\cap\Phi$.
			\item $I$ est la réunion de $I\cap\Phi$ et des composantes connexes par arcs de $I\cap\Omega$. Tous ces ensembles sont inclus dans $F_{n_0}$ donc $I\subset F_{n_0}$. Et puis comme $I$ est ouvert, $I\subset \ring F_{n_0}\subset \Omega$.
		\end{enumerate}
		\item $I\subset \Omega\implies I\cap\Phi=\emptyset$. Cela contredit la définition de $I$ donc une hypothèse qu'on a fait est fausse. La seule hypothèse qu'on a fait est celle qui dit que $\Phi$ est non vide. On en déduit donc que $\Omega=\R$.\\
		Sa seule composante connexe par arcs est donc $\R$ et la question 3 conclut l'exercice.
	\end{enumerate}
	
	\textit{Remarque : Le résultat analogue pour les fonctions polynomiales complexes (fonctions entières) est vrai et surprenamment (ou pas) largement plus simple à démontrer.}
	\subsubsection{Un raffinement \etoile{1} (HP)}
	\begin{enumerate}[leftmargin=*]
		\item Il suffit de considérer $\Omega=\displaystyle\bigcup_{(n,d)\in \N\times D}\ring F_{n,d}$ avec $F_{n,d}=\{x\in \R,\ f^{(n)}(x)=d\}$. Le reste de la démonstration ne change pas.
		\item Application directe de la question 1 avec $D=\Q$.
	\end{enumerate}
	
	\subsection{Volume d'une (hyper)boule \xens{4} (HP)}
	\label{sec:volume-dune-hyperboule-etoile3}
	\textcolor{blue}{\hyperref[Volume d'une (hyper)boule]{[Enoncé]}}\\
	\begin{enumerate}
		\item $n\in \N^*$.\\
		Tout d'abord, en posant le changement de variable $y_i=\displaystyle\frac{x_i}{R}$ pour tout $i\in \crblanc{1}{n}$,\\
		$V_n(R)=\displaystyle\idotsint_{(y_1,\dots,y_n)\in \B_n(1)}(Rdy_1)\dots(Rdy_n)=R^nV_n(1)$. Il suffit donc de déterminer $V_n(1):=V_n$ pour tout $n\in \N^*$.\\
		$\forall (x_1,\dots,x_{n+1})\in\B_{n+1}(1)\iff\left(-1\leq x_{n+1}\leq 1\land(x_1,\dots,x_n)\in \B_n\left(\displaystyle\sqrt{1-x_{n+1}^2}\right)\right)$\\
		Donc $V_{n+1}=\displaystyle\int_{-1}^1\left(\idotsint_{(x_1,\dots,x_n)\in \B_n\left(\displaystyle\sqrt{1-x_{n+1}^2}\right)}dx_1\dots dx_n\right)dx_{n+1}=\int_{-1}^1V_n\left(\displaystyle\sqrt{1-x_{n+1}^2}\right)dx_{n+1}$.\\
		Et donc $V_{n+1}=\displaystyle\int_{-1}^1\left(\displaystyle\sqrt{1-x^2}\right)^nV_ndx=2V_n\int_0^1\left(\displaystyle\sqrt{1-x^2}\right)^ndx$.\\
		Posons $x=\cos(\theta)\ :\ (*)$.\\
		$\displaystyle\int_0^1\left(\displaystyle\sqrt{1-x^2}\right)^ndx=\int_0^{\pi/2}\left(\displaystyle\sqrt{1-\cos^2(\theta)}\right)^n\sin(\theta)d\theta=\int_0^{\pi/2}\sin^{n+1}(\theta)d\theta$.\\
		On reconnaît l'intégrale de Wallis et on montre alors classiquement que :
		\begin{itemize}
			\item $\displaystyle\int_0^1\left(\sqrt{1-x^2}\right)^{2m}dx=\frac{2^{2m}(m!)^2}{(2m+1)!}$\\
			\item $\displaystyle\int_0^1\left(\sqrt{1-x^2}\right)^{2m-1}dx=\frac{(2m)!}{2^{2m}(m!)^2}\cdot\frac{\pi}{2}$
		\end{itemize}
		Montrons par récurrence que pour tout entier naturel non nul $n$,\\
		$V_n=
		\begin{cases}
			\displaystyle\frac{\pi^m}{m!}&\mbox{si }n=2m\\\\
			\displaystyle\frac{2^{2m+1}m!}{(2m+1)!}\pi^m&\mbox{si }n=2m+1
		\end{cases}$\\
		Pour $n=1$ :\\
		$V_1=\displaystyle\int_{-1}^1dx=2=\displaystyle\frac{2^1\pi^0}{1!}$.\\
		Supposons le résultat vrai pour un certain $n\in \N^*$.\\
		Si $n$ est pair alors on écrit $n=2m$.\\
		D'après $(*)$ on sait que $V_{n+1}=2V_{2m}\displaystyle\frac{2^{2m}(m!)^2}{(2m+1)!}$.\\
		Par hypothèse de récurrence on a $V_{2m+1}=\displaystyle\frac{2^{2m+1}m!}{(2m+1)!}\pi^m$.\\
		Et si $n$ est impair alors on écrit $n=2m-1$.\\
		D'après $(*)$ on sait que $V_{n+1}=2V_{2m-1}\displaystyle\frac{(2m)!}{2^{2m}(m!)^2}\cdot\frac{\pi}{2}$.\\
		Par hypothèse de récurrence on a $V_{2m}=\displaystyle\frac{\pi^m}{m!}$ ce qui conclut la récurrence.\\\\
		Finalement, $\forall n\in \N^*,\ V_n(R)= \begin{cases}
			\displaystyle\frac{\pi^m}{m!}R^{2m}&\mbox{si }n=2m\\\\
			\displaystyle\frac{2^{2m+1}m!}{(2m+1)!}\pi^mR^{2m+1}&\mbox{si }n=2m+1
		\end{cases}$\\
		\textit{Remarque : On retrouve les formules bien connus $V_1(R)=2R,\ V_2(R)=\pi R^2$ et $V_3(R)=\displaystyle\frac{4}{3}\pi R^3$.}
		\item La formule de Stirling $n!\unfty\sim\displaystyle\left(\frac{n}{e}\right)^n\sqrt{2\pi n}$ donne $\lim\limits_{m\to+\infty}V_{2m}(R)=0=\lim\limits_{m\to+\infty}V_{2m+1}(R)$. Donc $V_n(R)\unfty\longrightarrow 0$.\\
		Ce résultat montre que quand on augmente la dimension de l'espace, les boules ont tendances à se "contracter" en leur centre. Cela peut paraître surprenant car on pourrait penser que le volume ne fait qu'augmenter avec la dimension, comme il le fait pour des petites dimensions i.e celles auxquelles nous sommes habitués $n=1,2,3$.\\
		En fait le calcul donne pour la boule unité :\\
		$V_1=2,\ V_2=\pi\approx3,14,\ V_3=\displaystyle\frac{4\pi}{3}\approx4,19,\ V_4=\frac{\pi^2}{2}\approx4,93,\ V_5=\frac{8\pi^2}{15}\approx5,26,\ V_6=\frac{\pi^3}{6}\approx5,16$.\\
		A partir de $n=6$ le volume ne cesse de décroître.
	\end{enumerate}
	
	\subsection{Partie fermée bornée non compacte \centraleponts{3}}
	\label{sec:partie-fermee-bornee-non-compacte-etoile3}
	\textcolor{blue}{\hyperref[Partie fermée bornée non compacte]{[Enoncé]}}\\
	On se place dans l'espace vectoriel $E=\R[X]$ que l'on muni de la norme uniforme $\normep{\infty}{\displaystyle\sum\limits_{n=0}^{+\infty}a_nX^n}=\sup\{|a_n|,\ n\in \N\}$ et on va montrer que la boule unité fermé $B=B_f(0,1)$ est fermée et bornée mais pas compacte dans $E$. (C'est un cas particulier du théorème de compacité de Riesz \ref{Théorème de compacité de Riesz})\\
	Tout d'abord, $B$ est évidemment fermée et bornée. Supposons par l'absurde que $B$ est compacte.\\
	$\forall n\in \N,\ \normep{\infty}{X^n}=1$ donc $(X^n)\in B^\N$. Par conséquent il existe une suite extraite $(X^{\varphi(n)})_{n\in \N}$ qui converge.\\
	Or, si $n\in \N$ alors $\varphi(n+1)>\varphi(n)$ d'où $\normep{\infty}{X^{\varphi(n+1)}-X^{\varphi(n)}}=2$.\\
	Pourtant, $X^{\varphi(n+1)}-X^{\varphi(n)}\unfty{\longrightarrow}0$.\\
	Ceci est absurde donc $B$ n'est pas compacte.\\
	(On a d'ailleurs montré que la sphère unité n'est pas compacte ce qui est plus fort).
	
	\subsection{Théorème de compacité de Riesz \centraleponts{4}}
	\label{sec:theoreme-de-compacite-de-riesz-etoile4}
	\textcolor{blue}{\hyperref[Théorème de compacité de Riesz]{[Enoncé]}}\\
	\label{Théorème de compacité de Riesz corrigé}
	\begin{enumerate}[leftmargin=*]
		\item \begin{enumerate}[label=\alph*.]
			\item d$(x,F)=\inf\limits_{y\in F}||x-y||$.\\
			$\forall y\in F,\ ||x-y||\geq 0$. Alors par caractérisation séquentielle de la borne inférieure puis de l'adhérence,\\
			d$(x,F)=0\iff \exists (y_n)\in F^\N,\ ||x-y_n||\unfty{\longrightarrow}0\iff \exists (y_n)\in F^\N,\ y_n\unfty{\longrightarrow}x\iff x\in \overline{F}=F$.\\
			Donc d$(x,F)>0$.
			\item $2\delta>\delta=\text{d}(x,F)$ donc par définition de la borne inférieure $\exists v\in F,\ ||x-v||\leq 2\delta$.\\
			De plus comme $v\in F,\ ||x-v||\geq \text{d}(x,F)>0$.
			\item Soit $y\in F$.\\
			$||u-y||=\displaystyle\frac{||\ x-v-||x-v||y\ ||}{||x-v||}$.\\
			Or $v+||x-v||y\in F$ donc $||\ x-v-||x-v||y\ ||\geq \delta$.\\
			Ainsi d'après la question précédente $\displaystyle\frac{1}{2}$ est un minorant de $\{||x-y||,\ y\in F\}$. On en déduit que d$(u,F)\geq \displaystyle\frac{1}{2}$.
		\end{enumerate}
		\item On suppose que $E$ n'est pas de dimension finie. On peut alors se donner une suite $(e_n)\in E^\N$ libre.\\
		Posons pour tout $n\in \N,\ F_n=\text{Vect}(e_0,\dots,e_n)$.\\
		Soit $n\in \N$. $F_n$ est un sous-espace vectoriel de $E$ de dimension finie donc d'après le cours c'est un fermé de $E$. De plus, $F_n\ne E$ car $e_{n+1}\notin F_n$ par liberté.\\
		On peut donc à l'aide de la question $1$ construire un vecteur $u_n\in B\cap F_{n+1}$ tel que d$(u_n,F_n)\geq \displaystyle\frac{1}{2}$. (On prend $u_n=\displaystyle\frac{e_{n+1}-v_n}{||e_{n+1}-v_n||}$ pour un certain $v_n\in F_n$)\\
		Supposons par l'absurde que $B$ est compacte. On peut alors extraire une suite $(u_{\varphi(n)})_{n\in \N}$ qui converge.\\
		Mais alors $u_{\varphi(n+1)}-u_{\varphi(n)}\unfty{\longrightarrow}0$. Et de plus, $\forall n\in \N,\ \varphi(n+1)\geq \varphi(n)+1$. Donc $\forall n\in \N,\ u_{\varphi(n)}\in F_{\varphi(n)+1}\subset F_{\varphi(n+1)}$.\\
		On en déduit que $\forall n\in \N,\ ||u_{\varphi(n+1)}-u_{\varphi(n)}||\geq \text{d}(u_{\varphi(n+1)},F_{\varphi(n+1)})\geq \displaystyle\frac{1}{2}$.\\
		Ceci est absurde donc $B$ n'est pas compacte.
	\end{enumerate}
	
	\subsection{Sphère et boule unité \centraleponts{3}}
	\label{sec:sphere-et-boule-unite-etoile3}
	textcolor{blue}{\hyperref[Sphère et boule unité]{[Enoncé]}}\\
	$S$ est un fermé inclus dans $B$ donc si $B$ est fermée alors $S$ l'est aussi.\\
	Supposons que $S$ soit compacte.\\
	Donnons nous une suite $(x_n)\in B^\N$.\\
	Si $(x_n)_{n\in \N}$ est nulle APCR alors elle converge. Supposons maintenant que ce n'est pas le cas.\\
	On peut donc extraire une suite $(y_n)_{n\in \N}$ de $(x_n)_{n\in \N}$ dont tous les termes sont non nuls.\\
	Considérons la suite $(z_n)_{n\in \N}$ définie par $\forall n\in \N,\ z_n=\displaystyle\frac{y_n}{||y_n||}$.\\
	La suite $(||y_n||)_{n\in \N}$ est une suite réelle bornée (par $1$) donc d'après le théorème de Bolzano-Weierstrass, il existe une suite extraite $(||y_{\varphi(n)}||)_{n\in \N}$ qui converge.\\
	Comme $z_{\varphi(n)}\in S^\N$, on peut extraire une suite $(z_{\varphi\circ\psi(n)})_{n\in \N}$ qui converge. Mais alors on sait que $(||y_{\varphi\circ\psi(n)}||)_{n\in \N}$ converge comme suite extraite de $(||y_{\varphi(n)}||)_{n\in \N}$. Ainsi par produit, la suite $(y_{\varphi\circ\psi(n)})_{n\in \N}=(||y_{\varphi\circ\psi(n)}||z_{\varphi\circ\psi(n)})_{n\in \N}$ converge.\\
	Ainsi, $B$ est compacte par caractérisation séquentielle.
	
	\subsection{Principe du maximum pour les polynômes \xens{3}}
	\label{sec:principe-du-maximum-pour-les-polynomes}
	\textcolor{blue}{\hyperref[Principe du maximum pour les polynômes]{[Enoncé]}}\\
	
	\subsection{Applications $1$-lipschitzienne surjective sur un compact \centraleponts{4}}
	\label{sec:applications-1-lipschitzienne-surjective-sur-un-compact}
	\textcolor{blue}{\hyperref[Applications 1-lipschitzienne sujective sur un compact]{[Enoncé]}}\\
	
	\subsection{Une isométrie conserve les milieux \centraleponts{4}}
	\label{sec:une-isometrie-conserve-les-milieux}
	\textcolor{blue}{\hyperref[Une isométrie conserve les milieux]{[Enoncé]}}\\
	
	\subsection{Fonctions coercives \centraleponts{3}}
	\label{sec:fonctions-coercives}
	\textcolor{blue}{\hyperref[Fonctions coercives]{[Enoncé]}}\\
	
	\subsection{Homéomorphisme de compacts \centraleponts{3}}
	\label{sec:homeomorphisme-de-compacts}
	\textcolor{blue}{\hyperref[Homéomorphisme de compacts]{[Enoncé]}}\\
	
	\subsection{Distance à un fermé}
	\label{sec:distance-a-un-ferme}
	\textcolor{blue}{\hyperref[Distance à un fermé]{[Enoncé]}}\\
	
	\subsection{Diamètre et frontière}
	\label{sec:diametre-et-frontiere}
	\textcolor{blue}{\hyperref[Diamètre et frontière]{[Enoncé]}}\\
	
	\subsection{Frontière \ccinp{2}}
	\label{sec:frontiere}
	\textcolor{blue}{\hyperref[Frontière]{[Enoncé]}}\\
	On sait que $\Fr(F)$ est un fermé donc $\Fr(F)=\overline{\Fr(F)}$.
	Montrons que $\Fr(F)$ est d'intérieur vide.\\
	Soit $x\in\Fr(F)$.\\
	Alors pour tout $r>0$, la boule $B(x,r)$ contient des points de $\ring F$ qui ne sont par conséquent pas dans $\Fr(F)$.\\
	Ainsi aucune boule n'est contenue dans $\Fr(F)$, ce qui donne que : \[\mathring{\Fr(F)}=\emptyset\]
	Ainsi, on a :\[\Fr(\Fr(F))=\overline{\Fr(F)}\setminus\mathring{\Fr(F)}=\Fr(F)\]
	
	\subsection{Projeté sur un convexe compact \centraleponts{3}}
	\label{sec:projete-sur-un-convexe-compact}
	\textcolor{blue}{\hyperref[Projeté convexe]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item La fonction $h\in H\mapsto \norme{x-h}$ est continue sur $H$ qui est un compact donc elle admet un minimum. Il existe donc $h_0\in H$ tel que \[d(x,H)=\norme{x-h_0}\]
		Supposons qu'il existe $h_1\in H$ tel que $\norme{x-h_1}=\norme{x-h_0}=d(x,H)$ et $h_1\ne h_0.$\\
		D'après l'identité du parallélogramme : 
		\[\norme{\frac{h_0+h_1}{2}}^2+\norme{\frac{h_0+h_1}{2}-x}^2=\frac{1}{2}\left(\norme{h_1-x}^2+\norme{h_0-x}^2\right)=\frac{1}{2}d(x,H)^2\]
		Puisque $H$ est convexe, $\frac{h_0+h_1}{2}\in H$, d'où $\norme{\frac{h_0+h_1}{2}-x}\geq d(x,H)$.\\
		Ainsi, on a déduit que : $\displaystyle\norme{\frac{h_0+h_1}{2}}\leq 0$, ce qui impose que $\displaystyle\norme{\frac{h_0+h_1}{2}}=0$.
		Ainsi, \[\norme{\frac{h_0+h_1}{2}-x}^2=\frac{1}{2}d(x,h^2)\leq d(x,H)^2\]
		ce qui est absurde par définition de $d(x,H)$.\\
		Donc il existe un unique point $h_0\in H$ tel que $d(x,H)=\norme{x-h_0}$.
		\item Soit $y\in H$.\\On pose $q:t\in[0,1]\mapsto \norme{x-th_0-(1-t)(y-h_0)}$.\\
		On remarque que pour tout $t\in[0,1]$ \[q(t)^2=\norme{x-h_0-(1-t)(h_0-y)}^2=d(x,H)^2+(1-t)^2\norme{y-h_0}-2(1-t)\langle x-h_0,y-h_0\rangle\]
		Puisque $H$ est convexe, on en déduit que pour tout $t\in[0,1]$ $th_0+(1-t)y\in H$.\\
		Ainsi pour tout $t\in[0,1]$, $q(t)^2\geq d(x,H)^2$, par conséquent : 
		\[\forall t\in[0,1], \, 2(1-t)\langle x-h_0,y-h_0\rangle\leq(1-t)^2\norme{y-h_0} \]
		Donc, \[\forall t\in[0,1[, \, 2\langle x-h_0,y-h_0\rangle\leq(1-t)\norme{y-h_0} \]
		Et donc en faisant tendre $t$ vers $1^-$ : \[\langle x-h_0,y-h_0\rangle\leq 0\]
		Ce résultat étant vrai pour tout $y\in H$, on a \[\forall y\in H, \, \langle x-h_0,y-h_0\rangle\leq 0\]
		Réciproquement, supposons que :
		\[\forall y\in H, \, \langle x-h_0,y-h_0\rangle\leq 0\]
		On continue d'étudier la fonction $q$.
		On a toujours pour tout $t\in[0,1]$ : \[q(t)^2=\norme{x-h_0-(1-t)(h_0-y)}^2=\norme{x-h_0}^2+(1-t)^2\norme{y-h_0}-2(1-t)\langle x-h_0,y-h_0\rangle\]
		Donc \[q(t)=\norme{x-h_0-(1-t)(h_0-y)}^2\geq \norme{x-h_0}^2\]
		En particulier pour $t=0$, on a : \[q(0)=\norme{x-y}\geq \norme{x-h_0}\]
		Et donc, on a $d(x,H)=\norme{x-h_0}$
	\end{enumerate}
	
	\subsection{Convexité de l'adhérence et de l'intérieur \centraleponts{3}}
	\label{sec:convexite-de-ladherence-et-de-linterieur}
	\textcolor{blue}{\hyperref[Convexité de l'adhérence et de l'intérieur]{[Enoncé]}}\\
	Montrons que $\overline{A}$ est convexe.\\
	Soient $x,y\in \overline{A}$.\\
	Il existe $(x_n)\in A^\N$ (resp. $(y_n)\in\A^\N$) tel que $\lim\limits_{n\to +\infty}x_n=x$ (resp. $\lim\limits_{n\to +\infty}y_n=y$)
	On a : \[\forall \lambda \in[0,1], \forall n\in\N, \lambda x_n+(1-\lambda)y_n\in A \quad\text{(car $A$ est convexe)}\]
	et \[\forall \lambda\in[0,1], \lambda x_n+(1-\lambda)y_n\underset{n\to+\infty}{\to}\lambda x+(1-\lambda)y\]
	donc : \[\lambda x+(1-\lambda)y\in \overline{A}\]
	Montrons que $\ring A$ est convexe.\\
	\textbf{Ce serait bien de faire un joli dessin}\\
	Soient $x,y\in \ring{A}$.\\
	Il existe $\varepsilon_1>0$ et $\varepsilon_2>0$ tels que $B(x,\varepsilon_1)\subset A$ et $B(y,\varepsilon_2)\subset A$.\\
	Posons $\varepsilon=\min(\varepsilon_1,\varepsilon_2)$.\\
	Soit $\lambda\in[0,1]$. Posons $z=\lambda x +(1-\lambda)y$.\\
	Soit $v\in B(z,\varepsilon)$.\\
	On pose $x'= x+(v-z)$ et $y'=y+(v-z)$.\\
	\[x'+\lambda(y'-x')=z\]
	On a choisi $x'$ et $y'$ de sorte que $x'\in B(x,\varepsilon_1)$ donc $x'\in A$ et $y'\in B(y,\varepsilon_2)$ donc $y'\in A$.\\
	Donc par convexité $v\in A$ et donc $B(z,\varepsilon)\subset A$.\\
	Par conséquent $z\in \ring A$ d'où $\ring A$ est convexe.\\
	
	\subsection{Fonctions positivement homogènes}
	\label{sec:fonctions-positivement-homogenes}
	\textcolor{blue}{\hyperref[FOnctions positivement homogènes]{[Enoncé]}}\\
	
	\subsection{Enveloppe convexe}\label{sec:enveloppe-convexe}
	\textcolor{blue}{\hyperref[Enveloppe convexe]{[Enoncé]}}\\
	
	\subsection{Théorème de Carathéodory \centraleponts{3}}
	\label{sec:theoreme-de-caratheodory}
	\textcolor{blue}{\hyperref[Théorème de Carathéodory]{[Enoncé]}}\\
	
	\subsubsection{Enveloppe convexe d'une partie compacte \centraleponts{2}}
	\label{sec-enveloppe-convexe-d'une-partie-compacte}
	\textcolor{blue}{\hyperref[Enveloppe convexe d'une partie compacte]{[Enoncé]}}
	
	\subsection{Théorème de Krein-Milman}
	\label{sec:theoreme-de-krein-milman}
	\textcolor{blue}{\hyperref[Théorème de Krein-Milman]{[Enoncé]}}\\
	
	\subsection{Epigraphe \ccinp{1}}
	\label{sec:epigraphe}
	\textcolor{blue}{\hyperref[Epigraphe]{[Enoncé]}}\\
	
	\subsection{Partie convexe dense de $\R^n$ \xens{4}}
	\label{sec:partie-convexe-dense-de-rn}
	\textcolor{blue}{\hyperref[Partie convexe dense de R^n]{[Enoncé]}}\\
	On fixe $n\in \N^*$.\\
	\underline{$1^{\T{ère}}$ méthode :} Par récurrence\\
	Montrons par récurrence sur $m\in \N^*$ la propriété $\P(m)$: "Si $E$ est un espace euclidien de dimension $m$ alors la seule partie de $E$ convexe et dense dans $E$ est $E$."\\
	Soit $E$ un espace vectoriel normé de dimension $1$. Soit $A$ une partie convexe et dense dans $E$. On dispose d'un isomorphisme $f:E\to \R$. Celui-ci est continu car $E$ est de dimension finie, il envoie donc une partie convexe et dense dans $E$ sur une partie convexe (par linéarité) et dense dans $\R$ (par continuité). Il suffit de montrer que $f(A)=\R$ puisque par bijectivité de $f$ cela donne $A=f^{-1}(\R)=E$.\\
	Soit $a\in \R$. Par densité de $f(A)$, $\exists \alpha,\beta\in f(A),\ |a-1-\alpha|<1$ et $|a+1-\beta|<1$.\\
	Par construction $a\in [\alpha,\beta]$ donc par convexité $a\in f(A)$.\\
	Ainsi $f(A)=\R$ et par suite $A=E$.\\
	Supposons $\P(m-1)$ pour un certain entier $m\geq 2$. On se donne un produit salaire $\proscal{\cdot}{\cdot}$ sur $E$.\\
	Comme notre hypothèse porte sur des espaces de dimension $m-1$ il serait agréable de travailler avec des hyperplans. On remarque qu'en notant $\mathcal H$ l'ensemble des hyperplans de $E$ on a $E=\displaystyle\bigcup_{H\in \mathcal H}H$ et $A=E\cap A=\displaystyle\bigcup_{H\in \mathcal H}H\cap A$. L'idée va être de montrer que $A\cap H$ est une partie convexe et dense dans $H$. En premier lieu, elle est convexe comme intersection de deux parties convexes (un sev est convexe). Montrons que $A\cap H$ est dense dans $H$.\\
	Soit $H$ un hyperplan de $E$ et $a\in E$ unitaire tel que $H=\Vect(a)^\bot$. Fixons $\varepsilon>0$. On cherche un vecteur $h_A\in A\cap H$ tel que $\norme{h-h_A}<\varepsilon$. Faisons un dessin dans $\R^2$ :\\
	\begin{center}
		\begin{tikzpicture}
			\draw[thick,black,->] (0,-1) -- (0,3.5) node[anchor=south west] {$H$};
			\draw[thick,black,->] (-5,0) -- (5,0) node[anchor=north west] {$\Vect(a)$};
			\draw (0,0) node[anchor=north west] {$0$};
			\draw (-1.5,1.5) circle (1.5);
			\filldraw (-1.5,1.5) circle (0.05) node[anchor=north west] {$h-\varepsilon a$};
			\draw (1.5,1.5) circle (1.5);
			\draw[thick,<->] (-1.5,1.5) -- ({-1.5+1.5*cos(5*pi/4 r)},{1.5+1.5*sin(5*pi/4 r)});
			\draw ({-1.5+0.75*cos(5*pi/4 r)},{1.5+0.75*sin(5*pi/4 r)}) node[anchor=south east] {$\varepsilon$};
			\filldraw (1.5,1.5) circle (0.05) node[anchor=north west] {$h+\varepsilon a$};
			\filldraw[blue] ({-1.5+cos(2*pi/3 r)},{1.5+sin(2*pi/3 r)}) circle (0.05) node[anchor=north east] {$h^-$};
			\filldraw[blue] ({1.5+0.5*cos(7*pi/8 r)},{1.5+0.5*sin(7*pi/8 r)}) circle (0.05) node[anchor=south west] {$h^+$};
			\draw[thick,blue] ({-1.5+cos(2*pi/3 r)},{1.5+sin(2*pi/3 r)}) -- ({1.5+0.5*cos(7*pi/8 r)},{1.5+0.5*sin(7*pi/8 r)});
			\filldraw[blue] (0,{((3+cos(7*pi/8 r))/(6+cos(7*pi/8 r)-2*cos(2*pi/3 r))))*(1.5+sin(2*pi/3 r))+(1-((3+cos(7*pi/8 r))/(6+cos(7*pi/8 r)-2*cos(2*pi/3 r))))*(1.5+0.5*sin(7*pi/8 r))}) circle (0.05) node[anchor=south west] {$h_A$};
			\draw[dashed] (-1.5,1.5) -- (1.5,1.5);
			\draw[thick,green,->] (0,0) -- (1,0) node[anchor=north west] {$a$};
			\draw[thick,red,->] (0,0) -- (0,1.5) node[anchor=north west] {$h$};
		\end{tikzpicture}
	\end{center}
	On aimerait trouver des vecteurs $h^-,h^+\in A$ qui forment respectivement un angle obtus et aigu avec le vecteur $a$. De sorte que le segment $[h^-,h^+]\subset A$ coupe $H$ (ensemble des vecteurs normaux à $a$). Le point d'intersection $h_A$ sera dans $H\cap A$. Pour qu'il respecte la condition de densité il suffit de travailler "pas trop loin" de $h$.\\
	Par densité de $A$, $\exists h^-,h^+\in A,\ \norme{h^--(h-\varepsilon a)}<\varepsilon,\norme{h^+-(h+\varepsilon a)}<\varepsilon$.\\
	Par construction :
	$$\proscal{h^-}{a}=\proscal{h^--h+\varepsilon a}{a}+\proscal{h-\varepsilon a}{a}=\proscal{h^--h+\varepsilon a}{a}-\varepsilon\T{ et }|\proscal{h^--h+\varepsilon a}{a}|\leq \norme{h^--h+\varepsilon a}\norme{a}<\varepsilon$$
	Donc $\proscal{h^-}{a}<0$. On montre de même $\proscal{h^+}{a}>0$.\\
	D'après le TVI l'application $t\in [0,1]\mapsto\proscal{th^++(1-t)h^-}{a}$ s'annule en un certain $t_0$. On note $h_A=t_0h^++(1-t_0)h^-$. $h_A\in A$ par convexité et $h_A\in H$ car $\proscal{h_A}{a}=0$.\\
	En outre, $\norme{h-h_A}=\norme{t_0(h-h^+)+(1-t_0)(h-h^-)}\leq t_0\norme{h-h^+}+(1-t_0)\norme{h-h^-}$.\\
	Or $\norme{h-h^-}\leq \norme{h-h^--\varepsilon a}+\norme{\varepsilon a}<2\varepsilon$. De même $\norme{h-h^+}<2\varepsilon$.\\
	Donc $\norme{h-h_A}<2\varepsilon$. Il suffit de refaire le même raisonnement en remplaçant $\varepsilon$ par $\dfrac{\varepsilon}{2}$ pour obtenir le résultat voulu.\\
	Ainsi par hypothèse de récurrence $H\cap A=A$ et par suite $E=A$.\\
	Finalement, $\forall m\in \N^*,\ \mathcal P(m)$. En particulier $\mathcal P(n)$ donne le résultat.
	\\\\
	\underline{$2^{\T{nd}}$ méthode :} A l'intérieur d'un hypercube\\
	Pour tout $x\in \R^n$ l'ensemble $A-x=\{a-x,\ a\in A\}$ est convexe et dense dans $\R^n$. Comme $x\in A\iff 0\in A-x$ quitte à translater on peut se contenter de montrer $0\in A$.\\
	L'idée est de voir $0$ comme élément de l'hypercube de côté $1$ centré en $0$.\\
	\begin{center}
		\begin{tikzpicture}
			\draw[thick,black,->] (0,-4) -- (0,4);
			\draw[thick,black,->] (-4,0) -- (4,0);
			\draw (0,0) node[anchor=north west] {$0$};
			\draw[thick,black] (-3,-3) -- (3,-3) -- (3,3) -- (-3,3) -- cycle;
			\filldraw (-3,-3) circle (0.05) node[anchor=north east] {$P_{-1,-1}$};
			\filldraw (3,-3) circle (0.05) node[anchor=north west] {$P_{1,-1}$};
			\filldraw (3,3) circle (0.05) node[anchor=south west] {$P_{1,1}$};
			\filldraw (-3,3) circle (0.05) node[anchor=south east] {$P_{-1,1}$};
			\foreach \X in {-1,1} {
				\foreach \Y in {-1,1} {
					\draw ({\X*3},{\Y*3}) circle (1.5);
					\filldraw[blue] ({\X*3+cos((6+2*\X+5*\Y)*pi/13 r)},{\Y*3+sin((4+11*\Y+\X)*pi/7 r)}) circle (0.05) node[anchor=north] {$Q_{\X,\Y}$};
				}
			}
			\filldraw[blue,opacity=0.3] ({-3+cos(-pi/13)},{-3+sin(-8*pi/7 r)}) -- ({3+cos(3*pi/13 r)},{-3+sin(-6*pi/7 r)}) -- (2,{3+sin(2*pi/7 r)}) -- ({-3+cos(9*pi/13 r)},3);
			\filldraw[red] (-2.725,0) circle (0.05) node[anchor=north east] {$Q_{-1}$};
			\filldraw[red] (2.9,0) circle (0.05) node[anchor=north west] {$Q_1$};
			\draw[thick,red] (-2.725,0) -- (2.9,0);
		\end{tikzpicture}
	\end{center}
	Les sommets de l'hypercube sont les points $P_\varepsilon$ de coordonnées $\varepsilon=(\varepsilon_1,\dots,\varepsilon_n)\in \{-1,1\}^n$. Par densité on peut trouver des points $Q_\varepsilon\in A$ dont on note $(\eta_1,\dots,\eta_n$) les coordonnées tels que $\normep{\infty}{P_\varepsilon-Q_\varepsilon}\leq \dfrac{1}{2}$. Alors $0$ est dans le polytope de sommets $(Q_\varepsilon)_{\varepsilon\in \{-1,1\}^n}$. En effet la condition $\normep{\infty}{P_\varepsilon-Q_\varepsilon}\leq\dfrac{1}{2}<1$ assure que la $i$-ème coordonnée $\eta_i$ de $Q_\varepsilon$ est de même signe que la $i$-ème coordonnée $\varepsilon_i$ de $P_\varepsilon$. Autrement dit il y a un $Q_\varepsilon$ dans chaque "cadran" de $\R^n$, et donc l'enveloppe convexe de ces points contient $0$. Pour le montrer de manière plus rigoureuse on peut montrer par récurrence sur le nombre de coordonnées nulles que les points $Q_\varepsilon$ de coordonnées $(\eta_1,\dots,\eta_{n-r},0\dots,0)$ avec $\varepsilon=(\varepsilon_1,\dots,\varepsilon_{n-r})\in \{-1,1\}^{n-r}$ sont dans l'enveloppe convexe des $(Q_\varepsilon)_{\varepsilon\in \{-1,1\}^n}$ et donc dans $A$ :\\
	C'est évidemment vrai pour $r=0$. Supposons que ce soit vrai pour un certain $r\in \crblanc{0}{n-1}$. Fixons $(\varepsilon_1,\dots,\varepsilon_{n-r-1})\in \{-1,1\}^{n-r-1}$.\\
	On note $(\eta_1,\dots,\eta_{n-r-1},\alpha,0,\dots,0)$ les coordonnées de $Q_{(\varepsilon_1,\dots,\varepsilon_{n-r-1},-1)}$ et $(\eta_1,\dots,\eta_{n-r-1},\beta,0,\dots,0)$ celles de de $Q_{(\varepsilon_1,\dots,\varepsilon_{n-r-1},1)}$. Par le TVI l'application $t\in [0,1]\mapsto (\eta_1,\dots,\eta_{n-r-1},t\alpha+(1-t)\beta,0,\dots,0)$ s'annule. Autrement dit $(\eta_1,\dots,\eta_{n-r-1},0,\dots,0)\in [Q_{(\eta_1,\dots,\eta_{r-n-1},\alpha)},Q_{(\eta_1,\dots,\eta_{n-r-1},\beta)}]$.\\
	Donc par hypothèse de récurrence le point de coordonnées $(\eta_1,\dots,\eta_{n-r-1},0,\dots,0)$ est combinaison convexe des $(Q_\varepsilon)_{\varepsilon\in \{-1,1\}^n}$.\\
	Ainsi par récurrence la propriété est vrai pour tout $r\in \crblanc{0}{n}$, en particulier pour $n=r$ on obtient $0\in A$.
	\\\\
	\underline{$3^{\T{ème}}$ méthode :}\\
	
	\subsection{Partie convexe et ouverte de $\R^n$ \xens{4}}
	\label{sec:partie-convexe-et-ouverte-de-rn}
	\textcolor{blue}{\hyperref[Partie convexe et ouverte de R^n]{[Enoncé]}}\\
	Si $A$ est vide l'énoncé est évidemment vrai, on suppose donc que ce n'est pas le cas.
	\begin{enumerate}
		\item Quitte à passer par un isomorphisme (qui transforme une partie convexe en une partie convexe par linéarité et une partie ouverte en une partie ouverte par continuité de l'isomorphisme réciproque) on peux travailler dans $\C$ vu comme un $\R$-espace vectoriel. En outre quitte à appliquer une rotation (isométrie vectorielle) on peut supposer que $A$ contient un réel positif. L'idée va être de projeter $A$ sur le cercle unité, càd de considérer $B:=\left\{\dfrac{z}{|z|},\ z\in A\right\}=\{e^{i\arg(z)},\ z\in A\}$ :\\
		\begin{center}
			\begin{tikzpicture}
				\draw[thick,->] (-4,0) -- (4,0);
				\draw[thick,->] (0,-4) -- (0,4);
				\draw (0,0) node[anchor=north west] {$0$};
				\draw[blue] (0,0) circle (2);
			\end{tikzpicture}
		\end{center}
		Remarquons que la convexité de $A$ impose que si $a\in A$ alors $-a\notin A$ (sinon $0\in A$). Donc $B$ n'a pas de points antipodaux.\\
		Par hypothèse $1\in B$. L'ensemble $\{\alpha\in [0,\pi],\ e^{i\alpha}\in B\}$ est non vide (il contient $1$) et majoré, on note alors $\alpha_0$ sa borne supérieure. On note de même $\beta_0$ la borne inférieure de $\{\beta\in ]-\pi,0],\ e^{i\beta}\in B\}$. On note enfin $\delta=\max(\alpha_0,\pi+\beta_0)$. On va vérifier que $\Vect_\R(e^{i\delta })\subset \C\backslash A$.\\
		Si $\alpha_0=\pi$ ou $\beta_0=-\pi$ alors $\Vect_\R(e^{i\delta})=\R$ ne fonctionne pas. Commençons donc par montrer que ces cas sont exclus.\\
		Pour cela on va montrer que $B$ est ouvert dans $S$. Soit $a\in A$ et $b=\dfrac{a}{|a|}$. Il s'agit de montrer :
		$$\exists\varepsilon>0,\ \forall b'\in S,\ |b'-b|<\varepsilon\implies b'\in B$$
		ou encore qu'il existe un arc de cercle contenu dans $B$ et contenant $b$ en son intérieur.\\
		On peut déjà remarquer que si $a,a'\in A$ alors par convexité l'arc de cercle formé par $\dfrac{a}{|a|}$ et $\dfrac{a'}{|a'|}$ est $\{e^{i((1-t)\arg(a)+t\arg(a'))},\ t\in [0,1]\}=\left\{\dfrac{(1-t)a+ta'}{|(1-t)a+ta'|},\ t\in [0,1]\right\}\subset B$. Ceci justifie que l'ensemble des arguments des éléments de $B$ est une partie connexe par arcs de $\R$, c'est donc un intervalle. Il suffit donc de trouver des éléments de $B$ ayant un argument strictement supérieur/inférieur à celui de $b$.\\
		Par caractère ouvert de $A$, $\exists \xi>0,\ \forall z\in \C,\ |z-a|<\xi\implies z\in A$. Notons $a=|a|e^{i\theta}$ et posons $z_1:=|a|e^{i(\theta+\eta)}$, $z_2:=|a|e^{i(\theta-\eta)}$ avec $\eta>0$ tel que $|e^{i\eta}-1|<\dfrac{\xi}{|a|}$ (continuité de $t\mapsto e^{it}$ en $0$). Alors $|z_1-a|=|a||e^{i\eta}-1|<\xi$ et $|z_2-a|=|a||e^{-i\eta}-1|=|a|\left|\overline{e^{-i\eta}-1}\right|=|a||e^{i\eta}-1|<\xi$. Donc $z_1,z_2\in A$. Ainsi $e^{i(\theta-\eta)},e^{i(\theta+\eta)}\in B$ avec $b=e^{i\theta}$ ce qui permet de conclure que $B$ est ouvert dans $S$.\\
		Ainsi comme $1\in B$ par hypothèse et comme $B$ est ouvert dans $S$ on dispose de $e^{i\varphi},e^{-i\varphi}\in B$ avec et $0<\varphi<\pi$. Ceci justifie $\alpha_0<\pi$ car sinon $-e^{-i\varphi}=e^{\pi-i\varphi}\in B$ car il est dans l'arc de cercle formé par $e^{i(\pi-\varphi/2)}\in B$ et $1$. De même $\beta_0>-\pi$. Cela justifie $\delta>0$ et $\pi-\delta>0$.\\
		Supposons par l'absurde qu'il existe $z\in \Vect_\R(e^{i\delta})\cap A$. Alors $\dfrac{z}{|z|}=\pm e^{i\delta}\in B$. Si $\dfrac{z}{|z|}=e^{i\delta}$ alors comme $B$ est ouvert dans $S$ il existe $0<\eta\leq\pi-\delta$ tel que $e^{i(\delta+\eta)}\in B$ ce qui contredit la maximalité de $\delta$.\\
		De même si $\dfrac{z}{|z|}=-e^{i\delta}=e^{i(\delta-\pi)}\in B$ alors il existe $0<\eta<\delta$ tel que $e^{i(\delta-\pi-\eta)}\in B$. Or $-\pi<\delta-\pi-\eta<\delta-\pi\leq\beta_0$ ce qui est absurde.\\
		Finalement $\Vect_\R(e^{i\delta})\subset \C\backslash A$.
		\item C'est le même principe. On munit $\R^n$ de sa norme euclidienne usuelle $\norme{\cdot}$ et on considère $B:=\left\{\dfrac{a}{\norme a},\ a\in A\right\}$. C'est pas simple à écrire faut que je réfléchisse encore...
	\end{enumerate}
	
	\subsection{Connexité de l'espace \etoile{2}}
	\label{sec:connexité-de-l'espace}
	\textcolor{blue}{\hyperref[Connexité de l'espace]{[Enoncé]}}\\
	En général en oral un bon dessin peut convaincre l'examinateur.
	\begin{enumerate}[leftmargin=*]
		\item Soient $a<0<b$. D'après le TVI, dans $\R$ tout chemin continu de $a$ à $b$ s'annule. Donc $\R^*$ n'est pas connexe par arcs. Ensuite $\R^*=\R^*_+\bigsqcup\R^*_-$. Ces deux ensembles sont des intervalles donc sont convexes et a fortiori connexes par arcs. Ce sont donc les composantes connexes par arcs de $\R^*$.
		\item Soit $\theta\in ]-\pi,\pi]$. Montrons que $\U\backslash\{e^{i\theta}\}$ est connexe par arcs. Soit $z_1\ne z_2\in \U\backslash\{e^{i\theta}\}$. Sans perte de généralité $\exists \theta_1<\theta_2\in ]\theta,\theta+2\pi[,\ z_1=e^{i\theta_1},z_2=e^{i\theta_2}$.\\
		$[\theta_1,\theta_2]\cap(\theta+2\pi\Z)=\emptyset$ donc le chemin $\gamma(t)=e^{i((1-t)\theta_1+t\theta_2)}$ est continu à valeur dans $\U\backslash\{e^{i\theta}\}$ et relie $z_1$ à $z_2$.\\
		Soit maintenant $\alpha<\beta\in]-\pi,\pi]$. Montrons que $\U\backslash\{e^{i\alpha},e^{i\beta}\}$ n'est pas connexe par arcs. Soient $\theta,\theta'\in \R$ tels que $-\pi<\theta<\alpha<\theta'<\beta$. Soit $\gamma:[0,1]\to\U\backslash\{e^{i\alpha},e^{i\beta}\}$ un chemin continu de $e^{i\theta}$ à $e^{i\theta'}$. $\forall t\in [0,1],\ \exists! f(t)\in ]-\pi,\pi],\ \gamma(t)=e^{if(t)}$. En outre $f$ est continue. En effet si $t\in [0,1]$ et si $(t_n)\in [0,1]^\N$ converge vers $t$ alors $f$ étant bornée, quitte à extraire on peut supposer que $f(t_n)$ converge vers un certain $L\in ]-\pi,\pi]$. On en déduit par continuité de $\gamma$, $\gamma(t_n)\unfty\longrightarrow e^{if(t)}$ et par continuité de $\exp$, $\gamma(t_n)\unfty\longrightarrow e^{iL}$. Ainsi comme $L,f(t)\in ]-\pi,\pi]$, $f(t)=L$.\\
		En particulier on a choisi $\theta,\theta'$ tels que $\alpha\in [\theta,\theta']$ et $f(0)=\theta$ et $f(1)=\theta'$. Donc d'après le TVI $\exists t\in [0,1],\ f(t)=\beta$. Mais alors $\gamma(t)=e^{i\beta}$ ce qui est absurde.\\\\
		\textit{Remarque : avec le résultat de l'exercice suivant on peut donner une autre preuve. Pour $\U\backslash\{z\}$ on considère la tangente au cercle unité passant par $z$. $\U\backslash\{z\}$ est alors inclus dans l'un des demi-plans (Un demi-plan est connexe par arcs) définis par la tangente.\\
		Pour $\U\backslash\{z,z'\}$ on considère la droite formée par $z$ et $z'$. Le cercle unité n'est contenu dans aucun des demi-plans définis par la droite.}
		\begin{multicols}{2}
		\begin{tikzpicture}
			\draw[thick,->] (-3,0) -- (3,0);
			\draw[thick,->] (0,-3) -- (0,3);
			\draw (0,0) node[anchor=north west] {$0$};
			\draw[blue] (0,0) circle (2);
		\end{tikzpicture}
		\\
		\begin{tikzpicture}
			\draw[thick,->] (-3,0) -- (3,0);
			\draw[thick,->] (0,-3) -- (0,3);
			\draw (0,0) node[anchor=north west] {$0$};
			\draw[blue] (0,0) circle (2);
		\end{tikzpicture}
		\end{multicols}
		Soit $\mathcal C\subset\U$ connexe par arcs. $\forall z\in \overline{\mathcal C},\ \exists!\theta(z)\in ]-\pi,\pi],\ z=e^{i\theta(z)}$. On montre comme on l'a fait pour $f$ avant que $\theta$ est continue. Donc $\theta(\mathcal C)$ est un connexe par arcs de $\R$ : c'est un intervalle.\\
		On a montré qu'il existe un intervalle $I$ tel que $\mathcal C=\{e^{it},\ t\in I\}$, c'est-à-dire que $\mathcal C$ est un arc de cercle (en considérant $\U$ comme un arc de cercle).
		\item Soient $z_1,\dots,z_N\in \C$. Notons $\tilde\C:=\C\backslash\{z_1,\dots,z_N\}$, $z\ne z'\in \tilde\C$, $u=z'-z$ et $\delta:=\dfrac{1}{3|u|}\min\limits_{1\leq i\ne j\leq N}|z_i-z_j|$. Quitte à réindicer on peut noter $\{z_1,\dots,z_n\}=\{z_1,\dots,z_N\}\cap[z,z']$ où $\forall i\in \crblanc{1}{n-1},\ [z,z_i]\subset [z,z_{i+1}]$ (les $z_i$ sont rangés par ordre d'apparition dans le segment $[z,z']$). On note alors pour $i\in \crblanc{0}{n},\ x_{i+1}=\begin{cases}
			z_{i+1}-\delta u&\mbox{si }i\leq n-1\\
			z'&\mbox{si }i=n
		\end{cases}$ et $y_i=\begin{cases}
			z&\mbox{si }i=0\\
			z_i+\delta u&\mbox{si }i\geq 1
		\end{cases}$.
		On relie $z$ à $z'$ par $\gamma$ le chemin composé de :
		\begin{itemize}
			\item $\tau_i(t)=(1-t)y_i+tx_{i+1}$ (translation de $y_i$ à $x_{i+1}$);
			\item $r_i(t)=z_i-\delta e^{i\pi t}u$ (rotation de centre $z_i$ et de rayon $\delta$ de $x_i$ à $y_i$);
		\end{itemize}
		Soit $i\in \crblanc{1}{n}$. Par définition $\tau_{i-1}([0,1])=[z_{i-1}+\delta u,z_i-\delta u]\subset ]z_{i-1},z_i[\subset \tilde\C$. $\delta$ est aussi choisi pour que $x_i-y_{i-1}=\lambda u$ avec $\lambda>0$.\\
		Et $\forall t\in [0,1],\ \forall j\in \crblanc{1}{N},\ |r_i(t)-z_j|\geq \left||z_i-z_j|-\delta|u|\right|\geq |z_i-z_j|-\delta|u|\geq 3|u|\delta-\delta|u|=2\delta|u|>0$. Donc $r([0,1])\subset\tilde\C$.\\
		Ainsi on a construit des chemins continus à valeurs dans $\tilde\C$ reliant $y_i$ à $x_{i+1}$ puis $x_{i+1}$ à $y_{i+1}$. Finalement $z=y_0$ est relié à $z'=x_n$ par un chemin continu à valeurs dans $\tilde\C$.
		\item Soient $D_1,\dots,D_N$ des droites de $\R^3$. Soient $x\ne y\in \R^3\backslash\displaystyle\bigcup_{n=1}^ND_n$. On peut trouver un plan $P$ de $\R^3$ qui contient $x,y$ et qui ne contient aucune des droites $D_n,\ 1\leq n\leq N$. Alors l'intersection de $P$ et d'une droite $D_n$ est vide ou réduite à un point. Ainsi par la question 2 on peut trouver un chemin continu reliant $x$ et $y$ dans $\left(\R^3\backslash\displaystyle\bigcup_{n=1}^ND_n\right)\cap P=P\backslash\displaystyle\bigcup_{n=1}^N(P\cap D_n)$.
	\end{enumerate}
	
	\subsection{Complémentaire d'un hyperplan \centraleponts{3}}
	\label{sec:complementaire-dun-hyperplan}
	\textcolor{blue}{\hyperref[Complémentaire d'un hyperplan]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item Soit $\varphi\in E^*$ telle que $H=\ker\varphi$. On note $H^+=\{x\in E,\ \varphi(x)>0\}$ et $H^-=\{x\in E,\ \varphi(x)<0\}=-H^+$. On a $H=H^+\cup H^-$.\\
		Si $t\in [0,1]$ et si $x_1,x_2\in H^+$ alors $\varphi(tx_1+(1-t)x_2)=t\varphi(x_1)+(1-t)\varphi(x_2)>0$. Donc $H^+$ et convexe et a fortiori connexe par arcs. De même $H^-$ est connexe par arcs.\\
		Enfin, si $E\backslash H$ est connexe par arcs alors comme $\varphi$ est continue (linéaire sur $E$ de dimension finie) $\varphi(E\backslash H)$ est connexe par arcs. Or on sait que $E\backslash H\ne\emptyset$ donc pour $a\in E\backslash H$, $\forall \lambda\in \R^*,\ \lambda=\varphi\left(\dfrac{\lambda}{\varphi(a)}\lambda\right)$. Donc $\varphi(E\backslash H)=\R^*$ ce qui est absurde.
		\item Notons $(e_1,\dots,e_d)$ une base de $F$ que l'on complète en une base $(e_1,\dots,e_n)$ de $E$. Soit $x\in E\backslash F$. Il s'écrit $x=\displaystyle\sum_{k=1}^na_ke_k$ avec $(a_{d+1},\dots,a_n)\ne (0,\dots,0)$. On note $i\in \crblanc{d+1}{n}$ tel que $a_i\ne 0$. Si $a_i>0$ alors on peut relier $x$ à $e_i$ par $x(t)=(1-t)x+te_i\in E\backslash F$. Et si $a_i<0$ alors on peut relier $x$ à $-e_i$ par le même chemin.\\
		Ensuite, pour tout $i\ne j\in \crblanc{d+1}{n}$, $[e_i,e_j]\subset \Vect(e_{d+1},\dots,e_n)\backslash\{0\}\subset E\backslash F$ et $[-e_i,e_j]\subset \Vect(e_{d+1},\dots,e_n)\backslash\{0\}\subset E\backslash F$. Comme $d\leq n-2$, on peut toujours trouver $j\ne i\in\crblanc{d+1}{n}$ donc $e_i$ et $-e_i$ sont reliés par un chemin continu dans $E\backslash F$ d'où $F$ est connexe par arcs.
		\item En voyant $E$ comme un $\R$-espace vectoriel de dimension $2n$, $H$ est un sous-espace de $E$ de dimension $2n-2$. D'après la question 2, $E\backslash H$ est connexe par arcs.
	\end{enumerate}
	
	\subsection{Composantes connexes par arcs du complémentaire de la réunion de plusieurs hyperplans \xens{5}}
	\label{sec:composantes-connexes-par-arcs-du-complementaire-de-la-reunion-de-plusieurs-hyperplans}
	\textcolor{blue}{\hyperref[Composantes connexes par arcs du complémentaire de la réunion de plusieurs hyperplans]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item
		\begin{enumerate}[label=\alph*.]
			\item On note pour tout $i\in \crblanc{1}{r},\ H_i=\ker f_i$ ainsi que $U=\R^n\backslash \displaystyle\bigcup_{i=1}^r H_i$. Puisque la famille des formes linéaires est libre dans $(\R^n)^*$ qui est de dimension $\dim(\R^n)=n$, $r\leq n$.\\
			Faisons un dessin dans $\R^2$ et $\R^3$ pour comprendre ce qu'il se passe. Dans $\R^2$ un hyperplan est une droite vectorielle.\\
			\begin{multicols}{2}
			\begin{tikzpicture}
				\filldraw[opacity=.5,fill=red,draw=none] ({3*cos(1/2 r)},{3*sin(1/2 r)}) -- ({-3*cos(1/2 r)},{-3*sin(1/2 r)}) -- (0,-3) -- (3,-3) -- (3,0);
				\filldraw[opacity=.5,fill=green,draw=none] ({-3*cos(1/2 r)},{-3*sin(1/2 r)}) -- ({3*cos(1/2 r)},{3*sin(1/2 r)}) -- (0,3) -- (-3,3) -- (-3,0);
				\draw[black] (0,0) node[anchor=north west] {$0$};
				\draw[black,thick,->] (-3,0) -- (3,0);
				\draw[black,thick,->] (0,-3) -- (0,3);
				\filldraw[black,thick] ({-3*cos(1/2 r)},{-3*sin(1/2 r)}) -- ({3*cos(1/2 r)},{3*sin(1/2 r)}) node[anchor=south west] {$(H_1)$};
			\end{tikzpicture}
			\\
			\begin{tikzpicture}
				\filldraw[opacity=.5,fill=cyan,draw=none] ({-3*cos(1/2 r)},{-3*sin(1/2 r)}) -- (0,0) -- ({-3*cos(1 r)},{-3*sin(1 r)});
				\filldraw[opacity=.5,fill=yellow,draw=none] ({3*cos(1/2 r)},{3*sin(1/2 r)}) -- (0,0) -- ({3*cos(1 r)},{3*sin(1 r)});
				\filldraw[opacity=.5,fill=red,draw=none] ({3*cos(1/2 r)},{3*sin(1/2 r)}) -- (0,0) -- ({-3*cos(1 r)},{-3*sin(1 r)}) -- (0,-3) -- (3,-3) -- (3,0);
				\filldraw[opacity=.5,fill=green,draw=none] ({-3*cos(1/2 r)},{-3*sin(1/2 r)}) -- (0,0) -- ({3*cos(1 r)},{3*sin(1 r)}) -- (0,3) -- (-3,3) -- (-3,0);
				\draw[black] (0,0) node[anchor=north west] {$0$};
				\draw[black,thick,->] (-3,0) -- (3,0);
				\draw[black,thick,->] (0,-3) -- (0,3);
				\filldraw[black,thick] ({-3*cos(1/2 r)},{-3*sin(1/2 r)}) -- ({3*cos(1/2 r)},{3*sin(1/2 r)}) node[anchor=south west] {$(H_1)$};
				\filldraw[black,thick] ({3*cos(1 r)},{3*sin(1 r)}) -- ({-3*cos(1 r)},{-3*sin(1 r)}) node[anchor=north east] {$(H_2)$};
			\end{tikzpicture}
			\end{multicols}
			Chaque région colorée est une partie non vide de $\R^2\backslash (H_1\cup H_2)$ connexe par arcs et elles recouvrent $\R^2\backslash (H_1\cup H_2)$. Ce sont donc les composantes connexes par arcs de $\R^2\backslash (H_1\cup H_2)$. On voit que chaque $H_1$ sépare $\R^2$ en deux demi-plans puis que $H_2$ sépare ces deux demi-plans en deux.\\
			Et dans $\R^3$ en prenant $H_1$, $H_2$, $H_3$ les 3 plans définies par les axes :\\
			\textbf{Apprendre à faire des dessins en 3D requis}\\
			$H_1$ sépare l'espace en deux, $H_2$ sépare les demi-espaces créés en deux, $H_3$ sépare les quarts d'espaces restant...\\
			Sur ces exemples le nombre de composantes connexes par arcs de $U$ (le nombre de "régions") semble être $2^r$. C'est ce que l'on va montrer.\\
			Remarquons que pour une forme linéaire non nulle $f\in (\R^n)^*$, $\R^n\backslash\ker f$ a exactement deux composantes connexes par arcs qui sont $\{x\in \R^n,\ f(x)>0\}$ et $\{x\in \R^n,\ f(x)<0\}$ (cf. l'exo précédent). Ainsi si $g$ est une forme linéaire non colinéaire à $f$, les "régions" de $\R^n\backslash(\ker f\cup\ker g)$ sont données par les combinaisons de signe possible pour $f(x),g(x)$ : $f(x)>0,g(x)>0$ ou $f(x)>0,g(x)<0$ ou $f(x)<0,g(x)>0$ ou $f(x)<0,g(x)<0$.\\
			Concrètement on note $U=\R^n\backslash\displaystyle\bigcup_{i=1}^r\ker f_i$ ainsi que $S=\{-1,1\}^r$ et on pose pour $\varepsilon=(\varepsilon_1,\dots,\varepsilon_r)\in S$
			$$C_\varepsilon=\{x\in U,\ \forall i\in \crblanc{1}{r},\ \varepsilon_if_i(x)>0\}$$
			On va montrer que les composantes connexes par arcs de $U$ sont exactement les $C_\varepsilon$ pour $\varepsilon\in S$. Fixons $\varepsilon\in S$. Comme les $f_i$ forment une famille libre l'application
			$$\fonction{\Phi}{\R^n}{\R^r}{x}{(f_1(x),\dots,f_r(x))}$$
			est surjective. En effet sa matrice dans les bases canoniques $(u_1,\dots,u_n)$ de $\R^n$ et $(v_1,\dots,v_r)$ de $\R^r$ est $(f_i(u_j))_{\substack{1\leq i\leq r\\1\leq j\leq n}}$ qui est de noyau nul donc de rang $r$ par le théorème du rang. En particulier, $\exists x\in \R^n,\ \Phi(x)=\varepsilon$. Alors $x\in C_\varepsilon$ et par suite $C_\varepsilon\ne\emptyset$.\\
			Ensuite, si $x,y\in C_\varepsilon$ alors $[x,y]\in C_\varepsilon$ donc $C_\varepsilon$ est connexe par arcs.\\
			Enfin on a clairement $U=\displaystyle\bigsqcup_{\varepsilon\in S}C_\varepsilon$.\\
			Ainsi $\R^n\backslash\displaystyle\bigcup_{i=1}^r\ker f_i$ a $|S|=2^r$ composantes connexes par arcs.
			\item Montrons que $U$ est connexe par arcs. Soient $x\ne y\in U$. L'application
			$$\fonction{P}{\C}{\C}{z}{\displaystyle\prod_{i=1}^rf_i((1-z)x+zy)}$$
			est polynomiale donc s'annule un nombre fini de fois et de plus, $P(0)\ne 0$ et $P(1)\ne 0$. Or on sait que $\C$ privé d'un nombre fini de points est connexe par arcs (cf.\ref{Connexité de l'espace}). Donc il existe un chemin continu $\gamma$ de 0 à 1 tel que $P\circ \gamma$ ne s'annule pas. $\tilde\gamma:t\mapsto (1-\gamma(t))x+\gamma(t)y$ est donc un chemin continue de $x$ à $y$ à valeurs dans $U$.
		\end{enumerate}
		\item 
	\end{enumerate}
	
	\subsection{Sphères d'un $\R$-espace vectoriel \centraleponts{3}}
	\label{sec:spheres-dun-r-espace-vectoriel}
	\textcolor{blue}{\hyperref[Sphères d'un R espace vectoriel]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
	\item Soient \(x,y\in S\).\\
	Supposons que $x\ne -y$.
	On pose :
	\[
	\fonction{\gamma}{[0,1]}{S}{t}{\displaystyle\frac{(1-t)x+ty}{\norme{(1-t)x+ty}}} .
	\]
	Cette application est continue sur $[0,1]$.
	On vérifie aisément que $\gamma(0)=x$ et $\gamma(1)=y$.\\
	Donc $\gamma$ est un chemin continue de $x$ vers $y$.
	Supposons que $x=-y$.
	On choisit un point $z\in S$ tels que $z\ne x$ et $z\ne y$.\\
	Ainsi d'après ce qui précède, il existe un chemin continu entre $x$ et $z$ et un autre chemin continu entre $y$ et $z$. Donc par transitivité, il existe un chemin continu entre $x$ et $y$.
	Donc $S$ est connexe par arcs.
	\item Soit $S'$ une sphère de rayon $r>0$ et de centre $a$.
	L'application \[\fonction{f}{S}{S'}{x}{r(x+a)}\] est une application continue de $S$ dans $S'$ car affine.\\
	Puisque l'on a montré que $S$ est connexe par arcs, l'image de $S$ par $f$ est connexe par arcs.\\
	Or cette image est $S'$ donc $S'$ est connexe par arcs
	\end{enumerate}
	
	\subsection{Théorème du passage à la douane \centraleponts{3}}
	\label{sec:theoreme-du-passage-a-la-douane}
	\textcolor{blue}{\hyperref[Théorème du passage à la douane]{[Enoncé]}}\\
	Soit $C\subset E$ connexe par arcs telle que $C\cap A\ne\emptyset$ et $C\cap(E\backslash A)\ne\emptyset$. On fixe $a\in C\cap A$ et $b\in C\cap(E\backslash A)$. $C$ est connexe par arcs donc $\exists \gamma\in \mathcal C^0([0,1],E),\ \gamma(0)=a,\gamma(1)=b$. Si $b\in \T{Fr}(A)$ on a fini. Supposons que ce n'est pas le cas, càd comme $b\notin \ring A$ que $b\notin \overline A$.\\
	Notons $s=\sup\{t\in [0,1],\ \gamma(t)\in \overline A\}$ qui est bien définie puisque $\gamma(0)=a\in A$. On va montrer que $\gamma(s)\in \T{Fr}(A)$.\\
	Par caractérisation séquentielle de la borne supérieure on se donne une suite $t_n\in [0,1]^\N$ qui converge vers $s$ et telle que $\forall n\in \N,\ \gamma(t_n)\in \overline A$. Par continuité de $\gamma$, $\gamma(t_n)\unfty\longrightarrow\gamma(s)$ puis par caractérisation séquentielle de l'adhérence, $\gamma(s)\in \overline A$. On en déduit comme $\gamma(1)=b\notin \overline A$ que $s<1$. Supposons par l'absurde que $\gamma(s)\in \ring A$. Alors $\exists \varepsilon>0,\ B(\gamma(s),\varepsilon)\subset A$. Quitte à prendre plus petit on peut supposer $\varepsilon<1$.\\
	Par continuité de $\gamma$ on se donne $1-s\geq \delta>0$ tel que $\forall s'\in [0,1],\ |s'-s|\leq \delta\implies |\gamma(s')-\gamma(s)|<\varepsilon$. On a vu que $s<1$ donc $s<s+\delta:=s'\in [0,1]$. De plus, $|s'-s|=\delta$ donc $|\gamma(s')-\gamma(s)|<\varepsilon$ i.e $\gamma(s')\in B(\gamma(s),\varepsilon)$ d'où $\gamma(s')\in A\subset \overline A$.\\
	Ceci est absurde donc $\gamma(s)\in \T{Fr}(A)$.
	
	\subsection{Condition nécessaire de la connexité par arc \etoile{1}}
	\label{sec:condition-necessaire-de-la-connexite-par-arc}
	\textcolor{blue}{\hyperref[Condition nécessaire de la connexité par arc]{[Enoncé]}}\\
	On sait que l'image d'un connexe par arcs par une application continue est connexe par arcs.\\
	Par conséquent, $f(C)$ est connexe par arcs.\\
	Puisque $f(C)\subset\{0,1\}$, on en déduit que : \[f(C)=\{0\}, f(C)=\{1\} \text{ ou } f(C)=\{0,1\}\]
	Or $\{0,1\}$ n'est pas connexe par arcs, donc $f(C)\ne\{0,1\}$.\\
	Dans les deux cas restant $f(C)$ est un singleton (qui est bien connexe par arcs), donc $f$ est constante sur $C$.
	
	\subsection{Entre un ensemble et son adhérence}
	\label{sec:entre-un-ensemble-et-son-adherence}
	\textcolor{blue}{\hyperref[Entre un ensemble et son aadhérence]{[Enoncé]}}\\
	
	\subsection{Continuité d'applications matricielles}
	\label{sec:continuite-dapplications-matricielles}
	\textcolor{blue}{\hyperref[Continuité d'applicaiton matricielles]{[Enoncé]}}\\
	
	\subsection{Points de continuité du polynôme minimal}\label{sec:points-de-continuite-du-polynome-minimal}
	\textcolor{blue}{\hyperref[Points de continuité du polynôme minimal]{[Enoncé]}}\\
	
	\subsection{Exponentielle matricielle et topologie}\label{sec:exponentielle-matricielle-et-topologie}
	\textcolor{blue}{\hyperref[Exponentielle matricielle et topologie]{[Enoncé]}}\\
	
	\subsection{Lemme du déterminant}\label{sec:lemme-du-determinant}
	\textcolor{blue}{\hyperref[Lemme du déterminant]{[Enoncé]}}\\
	\begin{enumerate}
		\item Soit $(U,V)\in\mathcal{M}_{n,1}(\K)^2$.
		On remarque que $\det(I_n+UV^\top)=(-1)^n\chi_{UV^\top}(-1)$.
		\\O d'après \ref{rg1}, $\operatorname{rg}(UV^\top)=1$ et $\operatorname{Sp}(UV^\top)=\{0,\Tr(UV^\top)\}$.
		\\Donc $\det(I_n+UV^\top)=(-1)^n(-1)^{n-1}(-1-\Tr(UV^\top))=1+\Tr(V^\top U)=1+V^\top U$.
		\item L'idée ici est d'utiliser la densité de GL$_n(\R)$\\Soient $M\in \text{GL}_n(\R)$ et $(U,V)\in\mathcal{M}_n(\R)^2$.
		$\det(M^{-1})\det(M+UV^\top)=\det(I_n+M^{-1}UV^\top)$.\\ la multiplication par une matrice inversible conserve le rang donc on a encore $\operatorname{rg}(M^{-1}UV^\top)=1$.\\
		Donc $\det(I_n+M^{-1}UV^\top)=1+\Tr(M^{-1}UV^\top)=1+\Tr(V^\top M^{-1}U)=1+V^\top M^{-1}U$.
		\\ Par conséquent, $\det(M+UV^\top)=\det(M)+V^\top\det(M)M^{-1}U=\det(M)+V^\top\operatorname{Com}(M)^\top U$ car $\det(M)I_n=M\operatorname{Com}(M)^\top$.
		\\Finalement, puisque GL$_n(\R)$ est dense dans $\mathcal{M}_n(\R)$ et que $\det$ est continue sur $\mathcal{M}_n(\R)$ car $\det(M)$ est polynomiale en les coefficients de $M$; la relation est vérifiée pour toute matrice de $\mathcal{M}_n(\R)$.
	\end{enumerate}
	
	\subsection{Matrice de déterminant $1$ \etoile{3}}
	\label{sec:matrice-de-determinant-1-etoile3}
	\textcolor{blue}{\hyperref[Matrice de déterminant 1]{[Enoncé]}}\\
	\begin{enumerate}
		\item On considère le morphisme de groupe $\det:\text{GL}_n(\K)\to \K^*$.\\
		SL$_n(\K)=\ker(\det)$ donc SL$_n(\K)$ est un sous-groupe de GL$_n(\K)$.
		\item L'application déterminant étant continue car polynomiale en les coefficients de la matrice SL$_n(\K)=\ker(\det)=\det^{-1}(\{1\})$ donne aussi que SL$_n(\K)$ est fermé.
		\item Pour $\varepsilon\in \R^*$ on pose $M_\varepsilon=\text{diag}\left(\varepsilon,\displaystyle\frac{1}{\varepsilon},1,\dots,1\right)\in \M_n(\R)$.\\
		$\forall \varepsilon\in \R^*,\ M_\varepsilon\in \text{SL}_n(\R)$.\\
		Et, $||M_\varepsilon||=\displaystyle\sqrt{\Tr(M_\varepsilon^\top M_\varepsilon)}=\sqrt{\varepsilon^2+\frac{1}{\varepsilon^2}+n-2}\underset{\varepsilon\to +\infty}{\longrightarrow}+\infty$.\\
		Donc SL$_n(\R)$ n'est pas borné. SL$_n(\C)$ ne l'est pas car il contient SL$_n(\R)$ (Il peut prendre la norme définie par $\norme M=\Tr(\overline M^\top M)$ qui se trouve coïncider avec celle que l'on a utilisé sur $\M_n(\R)$).
		\item On va montrer que le complémentaire de SL$_n(\K)$ est dense dans $\M_n(\K)$.\\
		Soit $M\in \M_n(\K)$. Si $M\notin \text{SL}_n(\K)$ la suite constante égale à $M$ est une suite à valeurs dans le complémentaire de SL$_n(\K)$ qui converge vers $M$.\\
		Supposons que $M\in \text{SL}_n(\K)$.\\
		Posons pour tout $k\in \N^*,\ M_k=M-\displaystyle\frac{1}{k}I_n$. $(M_k)_{k\in \N^*}$ converge vers $M$.\\
		La suite $(\det(M_k))_{k\in \N^*}=\left((-1)^n\chi_M\left(\displaystyle\frac{1}{k}\right)\right)_{k\in \N^*}$ ne prend qu'un nombre fini de fois la valeur $1$ car sinon $\chi_M$ serait constant égal à $1$ (alors qu'il est de degré $n$).
		Ainsi APCR $\det(M_k)\ne 1$ i.e $M_k\notin \text{SL}_n(\K)$.\\
		On en déduit que SL$_n(\K)$ est d'intérieur vide.
		\item On rappelle qu'une matrice de transvection est une matrice de la forme\\
		$T_{ij}(\lambda)=I_n+\lambda E_{ij}$ avec $\lambda\in \K^*$ et $(i,j)\in\crblanc{1}{n}^2,\ i\ne j$.\\
		Soit $M\in \text{SL}_n(\K)$. Il existe $i_1,\dots,i_r,j_1,\dots,j_r\in \crblanc{1}{n}$ avec $i_k\ne j_k$ pour tout $k\in \crblanc{1}{r}$ ainsi que $\lambda_1,\dots,\lambda_r\in \K^*$ tels que :\\
		$$M=T_{i_1j_1}(\lambda_1)\dots T_{i_rj_r}(\lambda_r)$$
		On pose $\gamma:t\in [0,1]\mapsto T_{i_1j_1}(t\lambda_1)\dots T_{i_rj_r}(t\lambda_r)$.\\
		La fonction $f:(A_1,\dots,A_r)\in\M_n(\K)^r\mapsto A_1\dots A_r$ est continue car $r$-linéaire avec $\dim(\M_n(\K))<+\infty$.\\
		Pour toute matrice de transvection $T_{ij}(\lambda)$ la fonction $\varphi_{ij}(\lambda) :t\in [0,1]\mapsto T_{ij}(t\lambda)=I_n+t\lambda E_{ij}$ est continue car affine. Par conséquent la fonction $h:t\in [0,1]\mapsto (T_{i_1j_1}(t\lambda_1),\dots,T_{i_rj_r}(t\lambda_r))$ est continue car toutes ses composantes le sont.\\
		Enfin $\gamma=f\circ h$ est continue.\\
		$\gamma(0)=I_n$ et $\gamma(1)=M$.\\
		On en déduit que SL$_n(\K)$ est connexe par arcs.
	\end{enumerate}
	
	\subsection{Ensembles de matrices de rang fixé}
	\label{sec:ensembles-de-matrices-de-rang-fixe}
	\textcolor{blue}{\hyperref[Ensembles de matroces de rang fixé]{[Enoncé]}}\\
	
	\subsection{Densité des matrices inversibles \etoile{3}}
	\label{sec:densite-des-matrices-inversibles-etoile3}
	\textcolor{blue}{\hyperref[Densité des matrices inversibles]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item Soit $M\in \M_n(\K)$. On pose pour $k\in \N^*$, $M_k=M-\displaystyle\frac{1}{k}I_n$. Il est clair que $M_k\ukfty\longrightarrow M$.\\
		On remarque que $\forall k\in \N^*,\ M_k\in \text{GL}_n(\K)\iff \det(M_k)\ne 0\iff \displaystyle\frac{1}{k}\notin\text{Sp}(M)$. Or on sait que le spectre d'une matrice est un ensemble fini, c'est l'ensemble des racines d'un polynôme. Ainsi pour $k> \displaystyle\frac{1}{\min\limits_{\lambda\in \text{Sp}(M)\setminus\{0\}}|\lambda|}$, on sait que $\displaystyle\frac{1}{k}\notin \text{Sp}(M)$.\\
		La suite $(M_k)_{k\in \N^*}$ est donc à valeurs dans GL$_n(\K)$ APCR ce qui justifie que GL$_n(\K)$ est dense dans $\M_n(\K)$ par caractérisation séquentielle.
		\item Soit $(A,B)\in M_n(\K)$. D'après la question $1$ il existe une suite $(B_k)\in \text{GL}_n(\K)^\N$ de limite $B$.\\
		Or $\forall k\in \N,\ AB_k=B_k^{-1}(B_kA)B_k$. Donc pour tout $k\in \N$, $AB_k$ et $B_kA$ sont semblables. Elles ont donc même polynôme caractéristique.\\
		Ensuite, les applications de $\M_n(\K)$, $L:M\mapsto MA$, $R:M\mapsto AM$ et $\chi:M\mapsto \chi_M$ sont continues. En effet les deux premières sont linéaires sur $\M_n(\K)$ qui est de dimension finie et pour la dernière, les coefficients de $\chi_M$ sont polynomiaux en les coefficients de $M$ : ils sont issus d'un déterminant d'un polynôme en $M$. On en déduit par composition des limites que $\chi_{AB}=\ukfty\lim\chi_{AB_k}$ et $\chi_{BA}=\ukfty\lim\chi_{B_kA}$.\\
		Ainsi par unicité de la limite, $\chi_{AB}=\chi_{BA}$.
		\item Soit $(A,B)\in M_n(\K)$. D'après la question $1$ il existe une suite $(B_k)\in \text{GL}_n(\K)^\N$ de limite $B$.\\
		Or $\forall k\in \N,\ AB_k=B_k^{-1}(B_kA)B_k$. Donc pour tout $k\in \N$, $AB_k$ et $B_kA$ sont semblables.\\
		Montrons si $M,N\in \M_n(\K)$ sont semblables alors $\exp(M)$ et $\exp(N)$ le sont aussi. On note $M=PNP^{-1}$ avec $P\in \text{GL}_n(\K)$.\\
		On montre classiquement par récurrence que $\forall n\in \N,\ M^n=PN^nP^{-1}$. De plus l'application $\varphi : L\in \M_n(\K)\mapsto PLP^{-1}$ est linéaire. Donc $\forall R\in \K[X],\ R(M)=PR(N)P^{-1}$. En particulier, $\forall n\in \N,\ \displaystyle\sum_{k=0}^n\frac{M^k}{k!}=P\left(\sum_{k=0}^n\frac{N^k}{k!}\right)P^{-1}$. Les deux sommes ont pour limite respective $\exp(M)$ et $\exp(N)$ et $\varphi$ est continue car linéaire sur $\M_n(\K)$ qui est de dimension finie; par passage à la limite $\exp(M)=P\exp(N)P^{-1}$.\\
		\textit{Remarque on a obtenu un résultat plus fort puisqu'on connaît la matrice de passage}\\
		On en déduit que $\forall k\in \N,\ \chi_{\exp(AB_k)}=\chi_{\exp(B_kA)}$. Comme vu précédemment les applications de $\M_n(\K)$, $L:M\mapsto MA$, $R:M\mapsto AM$ et $\chi:M\mapsto \chi_M$ sont continues.\\
		Montrons que l'application $\exp:M\in \M_n(\K)\mapsto\exp(M)$ est continue. Soit $M\in \M_n(\K)$. On se donne une norme d'algèbre $\norme.$ sur $\M_n(\K)$ (on sait qu'il en existe d'après le cours sur les normes d'opérateur).\\
		Pour tout $n\in \N$, l'application $f_n:M\mapsto \displaystyle\frac{M^n}{n!}$ est continue pour la norme $\norme.$ car les coefficients de $f(M)$ sont polynomiaux en ceux de $M$. Par définition $\displaystyle\sum_{n\in \N}f_n$ converge simplement vers $\exp$.\\
		De plus, dans $\R_+\cup\{+\infty\}$, $\displaystyle\sum_{n=0}^{+\infty}\norme{\frac{M^n}{n!}}\leq \sum_{n=0}^{+\infty}\frac{{\norme M}^n}{n!}=\exp(M)<+\infty$.\\
		Ainsi la série $\displaystyle\sum_{n\in \N}f_n$ converge normalement (a fortiori uniformément) vers $\exp$ sur $\M_n(\K)$. D'après le théorème de transfert de continuité $\exp$ est continue sur $\M_n(\K)$.\\
		Finalement, par composition des limites, $\chi_{\exp(AB)}=\ukfty\lim\chi_{\exp(AB_k)}$ et $\chi_{\exp(BA)}=\ukfty\lim\chi_{\exp(B_kA)}$.\\
		Ainsi par unicité de la limite, $\chi_{\exp(AB)}=\chi_{\exp(BA)}$.
	\end{enumerate}
	
	\subsection{Comatrice et topologie}
	\label{sec:comatrice-et-topologie}
	\textcolor{blue}{\hyperref[Comatrice et toplogie]{[Enoncé]}}\\
	
	\subsection{Groupe orthogonal \etoile{1}}
	\label{sec:groupe-orthogonal-etoile1}
	\textcolor{blue}{\hyperref[Groupe orthogonal]{[Enoncé]}}\\
	Soient $U,V\in \O_n(\R)$.\\
	Vérifions que $\O_n(\R)$ est un sous-groupe de GL$_n(\R)$ :
	\begin{itemize}
		\item $V$ est inversible d'inverse $V^\top$ donc $\O_n(\R)\subset \text{GL}_n(\R)$;
		\item $(UV^{-1})^\top UV^{-1}=(V^{-1})^\top U^\top UV^{-1}=(V^\top)^{-1}V^{-1}=VV^{-1}=I_n$ donc $UV^{-1}\in \O_n(\R)$.
	\end{itemize}
	Ensuite, $\O_n(\R)\subset \M_n(\R)$ qui est de dimension finie donc il suffit de montrer que $\O_n(\R)$ est fermé et borné.\\
	Pour la norme ${||.||}_2:M\mapsto \displaystyle\sqrt{\Tr(M^\top M)},\ {||V||}_2=\displaystyle\sqrt{\Tr(I_n)}=\displaystyle\sqrt{n}$ d'où $\O_n(\R)$ est borné.\\
	On aurait aussi pu prendre la norme ${||.||}_\infty:M\mapsto \max\limits_{1\leq i,j\leq n}|M_{ij}|$ : On sait que la famille des colonnes de $V$ forme une base orthonormée de $\M_{n,1}(\R)$ pour son produit scalaire canonique. Alors en notant $C_1,\dots,C_n$ les colonnes de $V$,\\
	$\forall j\in \crblanc{1}{n},\ ||C_j||^2=\displaystyle\sum\limits_{i=1}^nV_{ij}^2=1$. Donc $\forall i,j\in\crblanc{1}{n},\ |V_{ij}|\leq 1$. D'où ${||V||}_\infty\leq 1$.\\
	Enfin, $\O_n(\R)=f^{-1}(\{I_n\})$ avec $f:M\in \M_n(\R)\mapsto M^\top M$.\\
	Or les coefficients de $M^\top M$ sont polynomiaux en ceux de $M$ donc $f$ est continue.\\
	On en déduit, comme $\{I_n\}$ est fermé, que $\O_n(\R)$ est fermé.\\\\
	On remarque que $\det(\O_n(\R))=\{-1,1\}$ n'est pas connexe par arcs.\\
	L'application $\det:\M_n(\R)\to \R$ est continue car polynomiale en les coefficients de la matrice donc $\O_n(\R)$ ne peut pas être connexe par arcs.
	
	\subsection{Groupe (spécial) unitaire \etoile{3}}
	\label{sec:groupe-special-unitaire-etoile3}
	\textcolor{blue}{\hyperref[Groupe (spécial) unitaire]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item On vérifie que $\fonction{\varphi}{\M_n(\C)}{\M_n(\C)}{M}{\overline{M}}$ est un morphisme d'algèbre.\\
		Soient $A,B\in U_n(\C)$.\\
		Vérifions que $U_n(\C)$ est un sous-groupe de GL$_n(\C)$ :
		\begin{itemize}
			\item $I_n\in U_n(\C)$
			\item $A$ est inversible d'inverse $\overline{A}^\top$ donc $U_n(\R)\subset \text{GL}_n(\C)$;
			\item $\overline{(AB^{-1})}^\top AB^{-1}=(\overline{A}\cdot\overline{B^{-1}})^\top=\left(\overline{B^{-1}}\right)^\top \left(\overline{A}\right)^\top AB^{-1}=\left(\overline{B}^\top\right)^{-1}B^{-1}=BB^{-1}=I_n$ donc $AB^{-1}\in U_n(\C)$.
		\end{itemize}
		Montrons ensuite que $U_n(\C)$ est compact.\\
		$U_n(\C)\subset \M_n(\C)$ qui est de dimension finie il suffit donc $U_n(\C)$ montrer que $U_n(\C)$ est fermé et borné.\\
		On commence par vérifier que l'application $||.||:M\mapsto \displaystyle\sqrt{\Tr\left(\overline{M}^\top M\right)}=\sqrt{\sum\limits_{1\leq i,j\leq n}|M_{ij}|^2}$ définie une norme (qu'on dit hermitienne) sur $\M_n(\C)$.\\ $||A||=\displaystyle\sqrt{\Tr(I_n)}=\displaystyle\sqrt{n}$ d'où $U_n(\C)$ est borné.\\
		Enfin, $U_n(\C)=g^{-1}(\{I_n\})$ avec $g:M\in \M_n(\C)\mapsto \overline{M}^\top M$.\\
		Or les parties réelles et imaginaires des coefficients de $\overline{M}^\top M$ sont polynomiales en celles de $M$ donc $g$ est continue.\\
		On en déduit, comme $\{I_n\}$ est fermé, que $U_n(\C)$ est fermé.\\\\
		Montrons maintenant que $\widering{U_n(\C)}=\emptyset$.\\
		$U_n(\C)$ est inclus dans l'ensemble $\mathcal{Z}=\{M\in \M_n(\C),\ |\det(M)|=1\}$.\\
		Or si $M\in \mathcal{Z}$ alors en posant pour tout $k\in \N^*,\ M_k=M-\displaystyle\frac{1}{k}I_n$ on a :
		\begin{itemize}
			\item $(M_k)_{k\in \N^*}$ converge vers $M$
			\item APCR $M_k\notin \mathcal{Z}$ puisque sinon il existerait une infinité de $k\in \N^*$ pour lequel $\det(M_k)\ne 0$. Pour chacun de ces $k$ on aurait $\displaystyle\frac{1}{k}\in \operatorname{Sp}(M)$ et donc $M$ aurait une infinité de valeurs propres.
		\end{itemize}
		Ainsi, aucune matrice de $\mathcal{Z}$ n'est intérieure à $\mathcal{Z}$.\\
		Finalement, $\widering{U_n(\C)}\subset \ring{\mathcal{Z}}=\emptyset$ est vide.\\\\
		Pour $SU_n(\C)$ on remarque que $SU_n(\C)=U_n(\C)\cap \text{SL}_n(\C)$ où SL$_n(\C)$ désigne l'ensemble des matrices complexes dont le déterminant vaut $1$.\\
		SL$_n(\C)=\ker(\det)$ c'est donc un sous-groupe de GL$_n(\C)$ et donc $SU_n(\C)$ est un sous-groupe de GL$_n(\C)$.\\
		De plus comme l'application $\det$ est continue on obtient aussi que SL$_n(\C)$ est fermé et donc que $SU_n(\C)$ est compact en tant que fermé inclus dans un compact ($U_n(\C)$).\\
		Enfin $SU_n(\C)\subset U_n(\C)\implies \widering{SU_n(\C)}=\emptyset$.
		\item \begin{enumerate}[label=\alph*.]
			\item On résonne par récurrence sur la taille $n$ de la matrice.\\
			En préambule on montre que l'application $\fonction{\langle\ ,\ \rangle}{\M_{n,1}(\C)^2}{\R_+}{(X,Y)}{\overline{X}^\top Y}$ définie un produit hermitien (équivalent des produits scalaires sur un espace pré-hilbertien) sur $\M_{n,1}(\C)$. On note $N$ la norme associée.\\
			$n=1$ :\\
			$U_1(\C)$ est isomorphe à $\U$ donc le résultat est vrai.\\
			Soit $n\geq 2$ On suppose le résultat vrai pour $U_{n-1}(\C)$. Fixons $M\in U_n(\C)$.\\
			$\chi_M$ est scindé sur $\C$ dont $M$ admet une valeur propre $\lambda$. Notons $X$ un vecteur propre associé.\\
			$MX=\lambda X\implies \overline{M}\ \overline{X}=\overline{\lambda}\ \overline{X}\implies \overline{X}^\top\overline{M}^\top=\overline{\lambda}\ \overline{X}^\top$.\\
			Par conséquent, $\overline{X}^\top\overline{M}^\top MX=(\overline{\lambda}\ \overline{X}^\top) (\lambda\ X)=|\lambda|^2\overline{X}^\top X$ et $\overline{X}^\top\overline{M}^\top MX=\overline{X}^\top I_nX=\overline{X}^\top X$.\\
			Or, $\overline{X}^\top X=N(X)\ne 0$ puisque $X\ne 0$.\\
			Ainsi $|\lambda|^2=1$ c'est à dire $|\lambda|=1$ c'est à dire $\exists \theta_1\in \R,\ \lambda=e^{i\theta_1}$.\\
			De plus, puisque $X$ est non nul on peut poser $e_1=\displaystyle\frac{X}{N(X)}$ et compléter $(e_1)$ en une base $(e_1,\dots,e_n)$ de $\M_{n,1}(\C)$ orthonormée pour le produit hermitien dont $N$ est issue.\\
			On sait alors que pour $Q$ la matrice dont les colonnes sont $e_1,\dots,e_n$ on a $Q\in U_n(\C)$ et,
			$$QMQ^{-1}=\left(\begin{array}{c|ccc}
				e^{i\theta_1}& 0 & \dots& 0\\
				\hline
				0            &   &      & \\
				\vdots       &   &  M'  & \\
				0            &   &      & \\
			\end{array}\right)$$
			Vérifions que $M'\in U_{n-1}(\C)$ :\\
			D'une part, on sait que $QMQ^{1}\in U_n(\C)$ car $(U_n(\C),\times)$ est un groupe. C'est à dire que $\overline{QMQ^{-1}}^\top QMQ^{-1}=I_n$.\\\\
			D'autre part, $\overline{QMQ^{-1}}^\top QMQ^{-1}=\left(\begin{array}{c|ccc}
				e^{-i\theta_1}& 0 & \dots               & 0\\
				\hline
				0            &   &                      & \\
				\vdots       &   &  \overline{M'}^\top  & \\
				0            &   &                      & \\
			\end{array}\right)\left(\begin{array}{c|ccc}
				e^{i\theta_1}& 0 & \dots& 0\\
				\hline
				0            &   &      & \\
				\vdots       &   &  M'  & \\
				0            &   &      & \\
			\end{array}\right)=\left(\begin{array}{c|ccc}
				1            & 0 & \dots                   & 0\\
				\hline
				0            &   &                         & \\
				\vdots       &   &  \overline{M'}^\top M'  & \\
				0            &   &                         & \\
			\end{array}\right)$
			Donc $\overline{M'}^\top M'=I_{n-1}$ i.e $M'\in U_{n-1}(\C)$.\\
			On peut alors appliquer l'hypothèse de récurrence à $M'$ :\\
			$\exists P'\in U_{n-1}(\C),\ \exists (\theta_2,\dots,\theta_n)\in \R^{n-1},\ M'=P'\text{diag}(e^{i\theta_2},\dots,e^{i\theta_n})(P')^{-1}$.\\
			On pose alors enfin $P=\left(\begin{array}{c|ccc}
				e_1          & 0 & \dots& 0\\
				\hline
				0            &   &      & \\
				\vdots       &   &  P'  & \\
				0            &   &      & \\
			\end{array}\right)$ et on vérifie que $M=P\text{diag}(e^{i\theta_1},\dots,e^{i\theta_n})P^{-1}$.
			\item Soit $M\in U_n(\C)$. $\exists P\in U_n(\C),\ \exists (\theta_1,\dots,\theta_n)\in \R^n,\ M=P\text{diag}(e^{i\theta_1},\dots,e^{i\theta_n})P^{-1}$.\\
			On pose $\fonction{\gamma}{[0,1]}{U_n(\C)}{t}{P\text{diag}(e^{ti\theta_1},\dots,e^{ti\theta_n})P^{-1}}$. Il est clair que $\forall t\in [0,1],\ \text{diag}(e^{ti\theta_1},\dots,e^{ti\theta_n})\in U_n(\C)$. Donc comme $(U_n(\C),\times)$ est un groupe, $\forall t\in [0,1],\ \gamma(t)\in U_n(\C)$ : $\gamma$ est bien une application.\\
			De plus, la fonction $\alpha: M\in U_n(\C)\mapsto PMP^{-1}$ est continue car linéaire sur $U_n(\C)\subset \M_n(\C)$ avec $\M_n(\C)$ de dimension finie et la fonction $\beta: t\in [0,1]\mapsto \text{diag}(e^{ti\theta_1},\dots,e^{ti\theta_n})$ est continue car chacune de ses composantes l'est. Par conséquent $\gamma=\alpha\circ\beta$ est continue.\\
			Enfin, $\gamma(0)=I_n$ et $\gamma(1)=M$.\\
			Chaque matrice de $U_n(\C)$ est reliable par un chemin continue dans $U_n(\C)$ à la matrice identité donc $U_n(\C)$ est connexe par arcs.\\\\
			Pour $SU_n(\C)$ il suffit de remarquer que $M=P\text{diag}(e^{i\theta_1},\dots,e^{i\theta_n})P^{-1}\in SU_n(\C)\iff \displaystyle\prod\limits_{k=1}^ne^{i\theta_k}=1\iff \sum\limits_{k=1}^n\theta_k\equiv 0[2\pi]$.\\
			La même application fait alors l'affaire.
		\end{enumerate}
	\end{enumerate}
	
	\subsection{Partie compacte et stable par produit de GL$_n(\K)$ \etoile{3}}
	\label{sec:partie-compacte-et-stable-par-produit-de-glnk-etoile3}
	\textcolor{blue}{\hyperref[Partie compacte et stable par produit de GLn(K)]{[Enoncé]}}\\
	On se donne $G$ une telle partie. Comme elle est non vide on se donne un élément $A\in G$. La stabilité par produit donne par récurrence immédiate $\forall n\in \N^*,\ A^n\in G$.\\
	Ensuite comme $G$ est compacte on sait qu'il existe une application $\varphi:\N\to\N^*$ strictement croissante telle que $(A^{\varphi(n)})_{n\in \N}$ converge vers une matrice $B\in G$.\\
	On sait que l'inversion matricielle est continue (cf. \ref{Continuité d'applicaiton matricielles}) donc $A^{-\varphi(n)}\unfty\longrightarrow B^{-1}$.\\
	Par stricte croissance de $\varphi$, $\varphi(n+2)-\varphi(n)-1>0$ d'où $(A^{\varphi(n+2)-\varphi(n)-1})\in G^\N$.\\
	De plus $(M,N,P)\mapsto MNP$ est trilinéaire sur $\M_n(\K)$ qui est de dimension finie.\\
	Elle est donc continue et, $A^{\varphi(n+2)}A^{-\varphi(n)}A^{-1}\unfty\longrightarrow BB^{-1}A^{-1}=A^{-1}$. Donc $A^{-1}\in G$ par caractérisation séquentielle d'une partie fermée.\\
	$G$ est une partie non vide de GL$_n(\K)$, stable par produit et passage à l'inverse : c'est un sous-groupe de GL$_n(\K)$.
	
	\subsection{Intérieur des matrices diagonalisable \etoile{5}}
	\label{sec:interieur-des-matrices-diagonalisable-etoile5}
	\textcolor{blue}{\hyperref[Intérieur des matrices diagonalisables]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item Tout d'abord, $\B_n(\R)\subset \mathcal{D}_n(\R)$.
		Montrons que $\B_n(\R)$ est ouvert dans $\M_n(\R)$.\\
		On note $A$ l'ensemble des polynôme unitaire de degré $n$ scindé à racines simples sur $\R[X]$ et $\fonction{\Phi}{\M_n(\R)}{\R[X]}{M}{\chi_M}$. $\B_n(\R)=\Phi^{-1}(A)$ et $\Phi$ est continue car les coefficients de $\chi_M$ sont polynomiaux en ceux de $M$. On va alors montrer que $A$ est ouvert dans $\R_n[X]$.\\
		Soit $P=\displaystyle\prod\limits_{i=1}^n(X-x_i)\in A$ avec $x_1<\dots<x_n$. On fixe $(a_0,\dots,a_n)\in \R^{n+1}$ telle que,
		$$a_0<x_1<a_1<x_2<\dots<a_{n-1}<x_n<a_n$$
		On pose l'application $\fonction{\psi}{B}{\R^{n+1}}{P}{(P(a_0),\dots,P(a_n))}$ où $B$ désigne l'ensemble des polynômes unitaires de degré $n$ de $\R[X]$.\\
		D'après le TVI, $\forall i\in \crblanc{0}{n-1},\ P(a_i)P(a_{i+1})<0$.\\
		Ainsi, $P\in U=\displaystyle\psi^{-1}\left(\prod\limits_{i=0}^n(-1)^i\R^*_+\right)\cup\psi^{-1}\left(\prod\limits_{i=0}^n(-1)^{i+1}\R^*_+\right)$.\\
		$\displaystyle\prod\limits_{i=0}^n(-1)^i\R^*_+$ et $\displaystyle\prod\limits_{i=0}^n(-1)^{i+1}\R^*_+$ sont des ouverts de $\R^{n+1}$ et $\psi$ est continue car linéaire sur $\R_n[X]$ qui est de dimension finie, donc $U$ est un ouvert de $\R_n[X]$.\\
		Enfin, un polynôme de $U$ est dans $A$ car il est unitaire de degré $n$ et change $n+1$ fois de signe.\\
		On a donc montré que de tout polynôme de $A$ on peut construire un ouvert inclus dans $A$ et contenant ce polynôme : $A$ est ouvert.\\
		Ainsi $\B_n(\R)$ est ouvert.\\\\
		Donnons nous ensuite une matrice $M\in \mathcal{D}_n(\R)\setminus \B_n(\R)$. Il existe $\lambda\in \C$, une matrice diagonale $D\in \M_{n-2}(\C)$ et une matrice $P\in \text{GL}_n(\C)$ tels que $M=\left(\begin{array}{cc|ccc}
			\lambda &  0     & 0 & \dots& 0\\
			0       &\lambda & 0 & \dots& 0\\
			\hline
			0        & 0      &   &      & \\
			\vdots   & \vdots &   &  D   & \\
			0        & 0      &   &      & \\
		\end{array}\right)P^{-1}$.\\
		On pose, pour $k\in \N^*,\ M_k=$
		$P\left(\begin{array}{cc|ccc}
			\lambda & 1/k    & 0 & \dots& 0\\
			0       &\lambda & 0 & \dots& 0\\
			\hline
			0        & 0      &   &      & \\
			\vdots   & \vdots &   &  D   & \\
			0        & 0      &   &      & \\
		\end{array}\right)P^{-1}$.\\
		$(M_k)_{k\in \N^*}$ converge vers $M$ et $\forall k\in \N^*,\ M_k\notin \mathcal{D}_n(\R)$.\\
		Ceci montre que $M$ n'est pas dans l'intérieur de $\mathcal{D}_n(\R)$.\\\\
		Finalement, $\widering{\mathcal{D}_n(\R)}=\B_n(\R)$.
		\item Pour montrer que $\B_n(\C)$ est ouvert on utilise le résultant (cf. \ref{Résultant}).\\
		$\B_n(\C)=\varphi^{-1}(\C^*)$ pour $\fonction{\varphi}{\M_n(\C)}{\C}{M}{\operatorname{Res}(\chi_M,\chi_M')}$. Les coefficients de $\chi_M$ sont polynomiaux en ceux de $M$ et les coefficients de $\chi_M'$ sont polynomiaux en ceux de $\chi_M$ donc $\varphi$ est polynomiale en les coefficients de $M$ (c'est un calcul de déterminant) et donc continue.\\\\
		La suite du raisonnement est identique au cas $\K=\R$ :\\
		Donnons nous une matrice $M\in \mathcal{D}_n(\C)\setminus \B_n(\C)$. Il existe $\lambda\in \C$, une matrice diagonale $D\in \M_{n-2}(\C)$ et une matrice $P\in \text{GL}_n(\C)$ tels que $M=\left(\begin{array}{cc|ccc}
			\lambda &  0     & 0 & \dots& 0\\
			0       &\lambda & 0 & \dots& 0\\
			\hline
			0        & 0      &   &      & \\
			\vdots   & \vdots &   &  D   & \\
			0        & 0      &   &      & \\
		\end{array}\right)P^{-1}$.\\
		On pose, pour $k\in \N^*,\ M_k=$
		$P\left(\begin{array}{cc|ccc}
			\lambda & 1/k    & 0 & \dots& 0\\
			0       &\lambda & 0 & \dots& 0\\
			\hline
			0        & 0      &   &      & \\
			\vdots   & \vdots &   &  D   & \\
			0        & 0      &   &      & \\
		\end{array}\right)P^{-1}$.\\
		$(M_k)_{k\in \N^*}$ converge vers $M$ et $\forall k\in \N^*,\ M_k\notin \mathcal{D}_n(\C)$.\\
		Ceci montre que $M$ n'est pas dans l'intérieur de $\mathcal{D}_n(\C)$.\\\\
		Finalement, $\widering{\mathcal{D}_n(\C)}=\B_n(\C)$.
	\end{enumerate}
	
	\subsection{Adhérence des matrices diagonalisables \etoile{3}}
	\label{sec:adherence-des-matrices-diagonalisables-etoile3}
	\textcolor{blue}{\hyperref[Adhérence des matrices diagonalisables]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item Soit $M\in \M_n(\C)=\mathcal{T}_n(\C)$. On note $\lambda_1,\dots,\lambda_n$ les valeurs propres de $M$, potentiellement égales. Il existe $P$ une matrice inversible et $T$ une matrice triangulaire supérieure telles que $M=PTP^{-1}$.\\
		Posons, pour $k\in \N,\ M_k=P\left(T+\text{diag}\left(\displaystyle\frac{1}{k+1},\dots,\frac{1}{k+n}\right)\right)P^{-1}$.\\
		La suite $(M_k)_{k\in \N}$ converge vers $M$. De plus si $k\in \N$, les valeurs propres de $M_k$ sont les $\mu_{k,i}=\lambda_i+\displaystyle\frac{1}{k+i}$ pour $1\leq i\leq n$ soient distincts.\\
		Soit $i,j\in \crblanc{1}{n}$ distincts.\\
		Si $\lambda_i=\lambda_j$ alors $\mu_{k,i}\ne \mu_{k,j}$.\\
		Et si $\lambda_i\ne\lambda_j$ alors $|\mu_{k,i}-\mu_{k,j}|=\displaystyle\left|\lambda_i-\lambda_j-\left(\frac{1}{k+j}-\frac{1}{k+i}\right)\right|\geq \left|\ |\lambda_i-\lambda_j|-\left|\frac{1}{k+j}-\frac{1}{k+j}\right|\ \right|$.\\
		APCR, $\displaystyle\left|\ |\lambda_i-\lambda_j|-\left|\frac{1}{k+j}-\frac{1}{k+j}\right|\ \right|=|\lambda_i-\lambda_j|-\left|\frac{1}{k+j}-\frac{1}{k+j}\right|>0$ car $|\lambda_i-\lambda_j|>0$.\\
		Ainsi APCR $M_k$ est diagonalisable car elle a $n$ valeurs propres distinctes.
		\item \begin{enumerate}[label=\alph*.]
			\item Supposons $P$ est scindé sur $\R[X]$. On écrit $P=\displaystyle\prod\limits_{k=1}^d(X-x_k)$. On sait alors que $\forall k\in \crblanc{1}{d},\ x_k\in \R$.\\
			Fixons $z\in \C$.\\
			Pour tout $k\in \crblanc{1}{d},\ |z-x_k|=\displaystyle\sqrt{\text{Re}(z-x_k)^2+\text{Im}(z-x_k)^2}\geq |\text{Im}(z-x_k)|=|\text{Im}(z)|$ car $x_k$ est réel.\\
			Donc, $|P(z)|=\displaystyle\prod\limits_{k=1}^d|z-x_k|\geq \prod\limits_{k=1}^d|\text{Im}(z)|=|\text{Im}(z)|^d$\\
			Réciproquement si $\forall z\in \C,\ |P(z)|\geq |\text{Im}(z)|^d$ alors pour toute racine $z$ de $P$ on a $|\text{Im}(z)|^d\leq 0$ d'où $\text{Im}(z)=0$ c'est à dire $z\in \R$.\\
			On sait que $P$ est scindé sur $\C$ et donc $P$ est scindé sur $\R$.
			\item Comme $\mathcal{D}_n(R)\subset \mathcal{T}_n(\R)$ on a $\overline{\mathcal{D}_n(R)}\subset \overline{\mathcal{T}_n(\R)}$.\\
			Par le même raisonnement qu'en question $1$ on montre que $\mathcal{T}_n(\R)\subset \overline{\mathcal{D}_n(\R)}$.\\
			Il reste donc à montrer que $\mathcal{T}_n(\R)$ est fermé dans $\M_n(\R)$.\\
			Soit $(M_k)\in \mathcal{T}_n(\R)^\N$ convergente.\\
			L'application $M\in \M_n(\R)\mapsto \chi_M$ est continue car les coefficients de $\chi_M$ sont polynomiaux en ceux de $M$ d'où $\chi_{M_k}\ukfty{\longrightarrow}\chi_M$.\\
			Soit $z$ une racine de $\chi_M$.\\
			D'après la question précédente, $\forall k\in \N,\ |\chi_{M_k}(z)|\geq |\text{Im}(z)|^n$.\\
			Donc par passage à la limite, $|\text{Im}(z)|^n\leq |\chi_M(z)|=0$ c'est à dire $z\in \R$.\\
			Ainsi $\chi_M$ est scindé sur $\R$ i.e $M\in \mathcal{T}_n(\R)$.\\\\
			Finalement $\overline{\mathcal{D}_n(\R)}=\mathcal{T}_n(\R)$.
		\end{enumerate}
	\end{enumerate}
	
	\subsection{Une preuve de Cayley-Hamilton (1) \etoile{2}}
	\label{sec:une-preuve-de-cayley-hamilton-1-etoile2}
	\textcolor{blue}{\hyperref[Une preuve de Cayley-Hamilton (1)]{[Enoncé]}}\\
	\begin{enumerate}
		\item Notons $\lambda_1,\dots,\lambda_n$ les valeurs propres de $A$, potentiellement égale. Il existe une matrice inversible $P$ telle que $A=P\text{diag}(\lambda_1,\dots,\lambda_n)P^{-1}$. Notons $\chi_A=\displaystyle\sum\limits_{k=0}^na_kX^k$.\\
		On calcule :
		\begin{align*}
			\chi_A(A)&=\sum\limits_{k=0}^na_k\left(P\text{diag}(\lambda_1,\dots,\lambda_n)P^{-1}\right)^k\\
			&=\sum\limits_{k=0}^nP\text{diag}\left(\lambda_1^k,\dots,\lambda_n^k\right)P^{-1}\\
			&=P\text{diag}\left(\sum\limits_{k=0}^na_k\lambda_1^k,\dots,\sum\limits_{k=0}^na_k\lambda_n^k\right)P^{-1}\\
			&=P\text{diag}(\chi_A(\lambda_1),\dots,\chi_A(\lambda_n))P^{-1}\\
			&=P\text{diag}(0,\dots,0)P^{-1}\\
			&=0
		\end{align*}
		\item On montre que l'ensemble des matrices à coefficients complexes diagonalisables est dense dans $\M_n(\C)$ (cf. \ref{Adhérence des matrices diagonalisables}).\\
		Soit $A\in \M_n(\C)$. On se donne une suite $(A_k)_{k\in\N}$ de matrices diagonalisables qui converge vers $A$.\\
		D'après la question $1,\ \forall k\in \N,\ \chi_{A_k}(A_k)=0$.\\
		Or l'application $M\in\M_n(\C)\mapsto \chi_M(M)$ est continue car les coefficients de $\chi_M(M)$ sont polynomiaux en ceux de $M$.\\
		Ainsi par passage à la limite, $\chi_A(A)=0$.
	\end{enumerate}
	
	\subsection{Dimension du commutant d'une matrice}
	\label{sec:dimension-du-commutant-dune-matrice}
	\textcolor{blue}{\hyperref[Dimension du commutant d'une matrice]{[Enoncé]}}\\
	
	\subsection{Topologie et réduction}
	\label{sec:topologie-et-reduction}
	\textcolor{blue}{\hyperref[Topologie et réduction]{[Enoncé]}}\\
	
	\subsection{Groupe spécial orthogonal et connexité}
	\label{sec:groupe-special-orthogonal-et-connexite}
	\textcolor{blue}{\hyperref[Groupe spécial orthogonal et connexité]{[Enoncé]}}\\
	
	\subsection{Matrices inversibles et connexité}
	\label{sec:matrices-inversibles-et-connexite}
	\textcolor{blue}{\hyperref[Matrices inversibles et connexité]{[Enoncé]}}\\
	
	\subsection{Matrices nilpotentes et connexité}
	\label{sec:matrices-nilpotentes-et-connexite}
	\textcolor{blue}{\hyperref[Matrices nilpotentes et connexité]{[Enoncé]}}\\
	
	\subsection{Raffinement sur les disques de Gershgorin}
	\label{sec:raffinement-sur-les-disques-de-gershgorin}
	\textcolor{blue}{\hyperref[Raffinament sur les disques de Gershgorin]{[Enoncé]}}\\
	
	\subsection{Matrices stochastiques et bistochastiques}
	\label{sec:matrices-stochastiques-et-bistochastiques}
	\textcolor{blue}{\hyperref[Matrices stochastiques et bistochatiques]{[Enoncé]}}\\
	
	\subsection{Théorème de Birkhoff-Von Neumann \etoile{4}}
	\label{sec:theoreme-de-birkhoff-von-neumann-etoile4}
	\textcolor{blue}{\hyperref[Théorème de Birkhoff-Von Neumann]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item Soit $P\in \text{Conv}(\mathcal P_n)$. $\exists (\lambda_1,\dots,\lambda_n)\in (\R_+)^n,\ \exists (\sigma_1,\dots,\sigma_n)\in \mathcal S_n^n,\ \begin{cases}
			\displaystyle\sum_{k=1}^n\lambda_k=1\\
			\displaystyle\sum_{k=1}^n\lambda_kP_{\sigma_k}=P
		\end{cases}$.\\
		Alors $P\in\M{n}{\R_+}$ et $\forall i\in \crblanc{1}{n}$,
		\begin{align*}
			\sum_{j=1}^nP_{ij}&=\sum_{j=1}^n\sum_{k=1}^n\lambda_k(P_{\sigma_k})_{ij}\\
			&=\sum_{k=1}^n\sum_{j=1}^n\lambda_k\delta_{i\sigma_k(j)}\\
			(\text{par bijectivité de }\sigma_k)\ &=\sum_{k=1}^n\lambda_k\sum_{j=1}^n\delta_{ij}\\
			&=\sum_{k=1}^n\lambda_k\\
			&=1
		\end{align*}
		De même, $\displaystyle\sum_{j=1}^nP_{ji}=1$.\\
		Ainsi $P\in \B_n$.
		\item \begin{enumerate}[label=\alph*.]
			\item $B$ ne peut pas avoir de colonne/ligne nulle. Il y a donc exactement un coefficient non nul par ligne et par colonne. Mais alors la condition $"\forall i\in \crblanc{1}{n},\ \displaystyle\sum_{j=1}^nB_{ij}=\sum_{j=1}^nB_{ji}=1"$ impose qu'ils valent tous $1$ : $B$ est une matrice de permutation.
			\item Montrons que $(A_i)_{1\leq i\leq n}$ vérifie la condition (ii) du théorème de Hall. Fixons $I\subset \crblanc{1}{n}$ et notons $A_I=\displaystyle\bigcup_{i\in I}A_i$.\\
			\begin{align*}
				\Card(A_I)&=\sum_{j\in A_I}1\\
				&=\sum_{j\in A_I}\sum_{i=1}^nB_{ij}\\
				\text{(Les sommes sont finies) }&=\sum_{i=1}^n\sum_{j\in A_I}B_{ij}\\
				&\geq\sum_{i\in I}\sum_{j\in A_I}B_{ij}\\
				(\text{par définition de }A_I)\ &=\sum_{i\in I}\sum_{j=1}^nB_{ij}\\
				&=\sum_{i\in I}1\\
				&=\Card(I)
			\end{align*}
			Alors d'après le théorème de Hall (cf.\ref{Théorème de Hall}), $\exists (j_1,\dots,j_n)\in \displaystyle\prod_{i=1}^nA_i,\ \forall (k,l)\in \crblanc{1}{n}^2,\ (k\ne l\implies j_k\ne j_l)$.\\
			Posons $\fonction{\sigma}{\crblanc{1}{n}}{\crblanc{1}{n}}{k}{j_k}$. $\sigma\in S_n$ puisqu'elle est injective par construction.\\
			On pose aussi $\lambda=\min\left\{B_{ij},\ j\in \displaystyle\bigcup_{i=1}^nA_i\right\}$. $\lambda<1$ car sinon on aurait $m=n$.\\
			Enfin, posons $B_0=\displaystyle\frac{1}{\lambda}(B-P_\sigma)$.\\
			Le choix de $\lambda$ garantit que $B_0\in \M_n(\R_+)$ et $\forall i\in \crblanc{1}{n}$,\\
			$\displaystyle\sum_{j=1}^n(B_0)_{ij}=\frac{1}{1-\lambda}\left(\sum_{j=1}^nB_{ij}-\lambda\sum_{j=1}^n(P_\sigma)_{ij}\right)=\frac{1}{1-\lambda}(1-\lambda)=1$. Ainsi $B_0\in \B_n$.\\
			De plus, en notant $j_0$ un indice tel que $B_{ij_0}=\lambda$, on remarque que $(B_0)_{ij_0}=0$ alors que $B_{ij_0}\ne 0$ par définition des $A_i$.\\
			$B_0$ est donc bien une matrice bistochastique ayant au moins un coefficient nul de plus que $B$.
		\end{enumerate}
		\item Par hypothèse de récurrence, $B_0\in \text{Conv}(\mathcal P_n)$. Donc $\exists (\lambda_1,\dots,\lambda_n)\in (\R_+)^n,\ \exists (P_1,\dots,P_n)\in \mathcal P_n^n,\ \begin{cases}
			\displaystyle\sum_{k=1}^n\lambda_k=1\\        \displaystyle\sum_{k=1}^n\lambda_kP_k=B_0
		\end{cases}$.\\
		Posons pour tout $k\in \crblanc{1}{n}$, $\mu_k=(1-\lambda)\lambda_k,\ P'_k=P_k$ ainsi que $\mu_{n+1}=\lambda$ et $P'_{n+1}=P_\sigma$. On a :\\
		\begin{itemize}
			\item $\forall k\in \crblanc{1}{n+1},\ \mu_k\geq 0,\ P_k\in \mathcal P_n$
			\item $\displaystyle\sum_{k=1}^{n+1}\mu_k=\lambda+(1-\lambda)\sum_{k=1}^n\lambda_k=\lambda+(1-\lambda)=1$;
			\item $\displaystyle\sum_{k=1}^{n+1}\mu_kP'_k=\lambda P_\sigma+(1-\lambda)\sum_{k=1}^n\lambda_kP_k=\lambda P_\sigma +(1-\lambda)B_0=B$.
		\end{itemize}
		Ainsi par récurrence, pour tout $m\in \crblanc{n}{n^2}$, toute matrice bistochastique ayant exactement $m$ coefficients non nuls appartient à l'enveloppe convexe de $\mathcal P_n$. Ceci rassemble toutes les matrices bistochastiques d'où $\B_n\subset \text{Conv}(\mathcal P_n)$ puis $\B_n=\text{Conv}(\mathcal P_n)$.
	\end{enumerate}
	
	\subsubsection{Points extrémaux des matrices bistochastiques}
	
	
	\subsubsection{Points extrémaux des matrices orthogonales}
	
	\newpage
\section{Correction Fonctions à valeurs vectorielles}
	\subsection{Point fixe de l'exponentielle complexe}
	\label{sec:point-fixe-de-lexponentielle-complexe}
	\textcolor{blue}{\hyperref[Point fixe de l'exponentielle complexe]{[Enoncé]}}\\
	
	\subsection{Théorème du relèvement}
	\label{sec:theoreme-du-relevement}
	\textcolor{blue}{\hyperref[Théorème du relèvement]{[Enoncé]}}\\
	
	\subsection{Equation fonctionnelle de l'exponentielle matricielle \etoile{3}}
	\label{sec:equation-fonctionnelle-de-lexponentielle-matricielle-etoile3}
	\textcolor{blue}{\hyperref[Equation fonctionnelle de l'exponentielle matricielle]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item On remarque déjà que $\varphi(0)=\varphi(0)^2$ et que $\forall (s,t)\in \R^2,\ \varphi(s)\varphi(t)=\varphi(s+t)=\varphi(t)\varphi(s)$.\\
		Alors si l'on fixe $s\in \R$ et que l'on dérive par rapport à $t$ en $0$ :\\
		$\varphi$ est dérivable en $s$ et $\varphi(s)\varphi'(0)=\varphi'(s)=\varphi'(0)\varphi(s)$.\\
		Notons $C_1(s),\dots,C_n(s)$ les colonnes de $\varphi(s),\ \fonction{f}{\M_{n,1}(\K)^n}{\M_n(\K)}{(C_1,\dots,C_n)}{\begin{array}{c|c|c}
				(C_1&\dots&C_n) 
		\end{array}}$ et $\fonction{g}{\R}{\M_{n,1}(\K)^n}{s}{(C_1(s),\dots,C_n(s))}$.\\
		$f$ est linéaire et $g$ est dérivable car toutes ses composantes le sont. Ainsi $\forall s\in \R,\ \varphi'(s)=(f\circ g)'(s)=f(g'(s))=\begin{array}{c|c|c}
			(C_1'(s)&\dots&C_n'(s)) 
		\end{array}$. Par conséquent,\\
		$\forall s\in \R,\ \varphi'(s)=\varphi'(0)\varphi(s)\implies \forall s\in \R,\ \forall k\in \crblanc{1}{n},\ C_k'(s)=\varphi'(0)C_k(s)\implies \forall s\in \R,\ \forall k\in \crblanc{1}{n},\ C_k(s)=e^{s\varphi'(0)}C_k(0)\implies \forall s\in \R,\ \varphi(s)=e^{s\varphi'(0)}\varphi(0)$.\\
		De plus, on montre que comme $\varphi'(0)$ et $\varphi(0)$ commutent, $e^{s\varphi'(0)}$ et $\varphi(0)$ commutent pour tout réel $s$ (par continuité du produit matriciel ou en montrant que $e^{s\varphi'(0)}$ est un polynôme en $\varphi'(0)$ par exemple).\\
		Réciproquement donnons nous $A$ une matrice de projection ainsi que $B$ une matrice commutant avec $A$ et vérifions que $\varphi:x\mapsto Ae^{xB}$ vérifie : $\forall (s,t)\in \R^2,\ \varphi(s+t)=\varphi(s)\varphi(t)$.\\
		On sait que $A$ commute avec $e^{xB}$ quel que soit $x\in \R$ et que si $M$ et $N$ commutent, $e^{M+N}=e^Me^N$ d'où :\\
		$\forall (s,t)\in \R^2,\ \varphi(s)\varphi(t)=Ae^{sB}Ae^{tB}=e^{sB}A^2e^{tB}=e^{sB}Ae^{tB}=Ae^{sB}e^{tB}=Ae^{(s+t)B}=\varphi(s+t)$.
		\item $\varphi$ est un morphisme de groupes donc $\varphi(0)=I_n$. Fixons $T>0$ et $s\in R$. En intégrant par rapport à $t$ entre $0$ et $T$ :\\
		$\varphi(s)\displaystyle\int_0^T\varphi(t)dt=\int_0^T\varphi(s+t)dt=\int_s^{s+T}\varphi(t)dt$.\\
		Montrons que $A(T)=\displaystyle\int_0^T\varphi(t)dt$ est inversible pour $T$ assez petit.\\
		Soit $\varepsilon>0$.\\
		D'après le théorème fondamental de l'analyse, $A$ est $\mathcal C^1$ sur $\R$ et $A(T)\underset{T\to 0}{=}A(0)+TA'(0)+\smallo{T}\underset{T\to 0}{=}TI_n+\smallo{T}$. Ainsi $\displaystyle\frac{1}{T}A(T)\underset{T\to 0}{\longrightarrow}I_n$ d'où $\displaystyle\frac{1}{T^n}\det(A(T))\underset{T\to 0}{\longrightarrow}1$ c'est à dire $\det(A(T))\underset{T\to 0}{\sim}T^n$.\\
		Or $T^n>0$ lorsque $T>0$. Donc $\exists T_1\in \R^*_+,\ \det(A(T_1))>0$.\\
		Ainsi, pour $T=T_1,\ \varphi(s)=A(T_1)^{-1}(\Phi(s+T_1)-\Phi(s))$. Cette dernière expression est $\mathcal C^1$ en $s$ donc $\varphi$ est $\mathcal C^1$ sur $\R$ et on se retrouve dans le cas de la question précédente.
	\end{enumerate}
	
	\subsection{Formule de Trotter-Kato \etoile{2}}
	\label{sec:formule-de-trotter-kato-etoile2}
	\textcolor{blue}{\hyperref[Formule de Trotter-Kato]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item Soit $M\in \M_n(\K)$. Par récurrence immédiate, $\forall n\in \N,\ \norme{M^n}\leq \norme{M}^n$.\\
		Comme toutes les sommes qu'on va écrire convergent, par inégalité triangulaire,\\
		$\norme{e^M}=\displaystyle\norme{\sum_{n=0}^{+\infty}\frac{M^n}{n!}}\leq \sum_{n=0}^{+\infty}\norme{\frac{M^n}{n!}}\leq \sum_{n=0}^{+\infty}\frac{\norme{M}^n}{n!}=e^{\norme{M}}$.\\
		Ainsi, $\displaystyle\norme{\exp\left(\frac{A}{k}\right)\exp\left(\frac{B}{k}\right)}\leq \norme{\exp\left(\frac{A}{k}\right)}\norme{\exp\left(\frac{B}{k}\right)}\leq \exp\left(\frac{\norme{A}}{k}\right)\exp\left(\frac{\norme{B}}{k}\right)=\exp\left(\frac{\norme{A}+\norme{B}}{k}\right)$.
		\item D'après le cours, pour tout $M\in \M{n}{K},\ f:t\mapsto e^{tM}$ est $\mathcal C^1$ sur $\R$ et $\forall t\in \R,\ f'(t)=Me^{tM}$.\\
		Ainsi $h$ est $\mathcal C^1$ sur $\R$ par opérations et $\forall t\in \R,\ h'(t)=Ae^{tA}e^{tB}+e^{tA}Be^{tB}-(A+B)e^{t(A+B)}$.\\
		On en déduit le développement limité en $0$ de $h$ à l'ordre $1$ :\\
		$h(t)\utzero{=}h(0)+th'(0)+\bigO{t^2}\utzero{=}\bigO{t^2}$.\\
		Or $\displaystyle\frac{1}{k}\ukfty{\longrightarrow}0$ donc $h\displaystyle\left(\frac{1}{k}\right)=X_k-Y_k\ukfty{=}\bigO{\frac{1}{k^2}}$.
		\item $\displaystyle\sum_{i=0}^{k-1}X_k^i(X_k-Y_k)Y_k^{k-i-1}=\sum_{i=0}^{k-1}X_k^{i+1}Y_k^{k-i-1}-\sum_{i=0}^{k-1}X_k^iY_k^{k-i}=\sum_{i=1}^{k}X_k^iY_k^{k-i}-\sum_{i=0}^{k-1}X_k^iY_k^{k-i}=X_k^k-Y_k^k$.
		\item On sait que $\forall k\in \N^*,\ Y_k^k=\exp(A+B)$.Or, $\forall k\in \N^*$.\\
		$\norme{X_k^k-Y_k^k}\leq \displaystyle\sum_{i=0}^{k-1}\norme{X_k}^i\norme{X_k-Y_k}\norme{Y_k}^{k-i-1}=\norme{X_k-Y_k}\sum_{i=0}^{k-1}\exp\left(\frac{\norme{A}+\norme{B}}{k}\right)^{k-1}=\norme{X_k-Y_k}k\exp\left(\frac{\norme{A}+\norme{B}}{k}\right)^{k-1}$.\\
		Et $\displaystyle k\norme{X_k-Y_k}\ukfty{=}\bigO{\frac{1}{k}}$ et $\displaystyle\exp\left(\frac{\norme{A}+\norme{B}}{k}\right)^{k-1}=\exp\left(\frac{k-1}{k}(\norme{A}+\norme{B})\right)\ukfty{\longrightarrow}\exp(\norme{A}+\norme{B})$.\\
		Donc $\norme{X_k^k-Y_k^k}\ukfty{=}\bigO{\displaystyle\frac{1}{k}}$ d'où $\displaystyle\ukfty{\lim}\left(\exp\left(\frac{A}{k}\right)\exp\left(\frac{B}{k}\right)\right)^k=\exp(A+B)$.
	\end{enumerate}
	
	\subsection{Série entière de matrice \etoile{2}}
	\label{sec:serie-entiere-de-matrice-etoile2}
	\textcolor{blue}{\hyperref[Série entière de matrice]{[Enoncé]}}\\
	On sait que pour tout $M\in \M_n(\K),\ \displaystyle\sum_{n\in \N}\frac{M^n}{n!}$ converge absolument vers $e^M$. Donc d'après le théorème de Fubini :
	\begin{align*}
		e^{iA}+e^{-iA}&=\displaystyle\sum_{n=0}^{+\infty}\frac{i^n}{n!}A^n+\sum_{n=0}^{+\infty}\frac{(-i)^n}{n!}A^n\\
		&=\sum_{n=0}^{+\infty}\frac{i^{2n}}{(2n)!}A^{2n}+\sum_{n=0}^{+\infty}\frac{i^{2n+1}}{(2n+1)!}A^{2n+1}+\sum_{n=0}^{+\infty}\frac{(-i)^{2n}}{(2n)!}A^{2n}+\sum_{n=0}^{+\infty}\frac{(-i)^{2n+1}}{(2n+1)!}A^{2n+1}\\
		&=2\sum_{n=0}^{+\infty}\frac{i^{2n}}{(2n)!}A^{2n}=2\cos(A)
	\end{align*}
	On montre de même que $e^{iA}-e^{-iA}=2i\sin(A)$. De plus, $iA$ et $-iA$ commutent donc $e^{iA}e^{-iA}=e^{iA-iA}=I_n$\\
	Ainsi, $\cos^2(A)+\sin^2(A)=\displaystyle\left(\frac{e^{iA}+e^{-iA}}{2}\right)^2+\left(\frac{e^{iA}-e^{-iA}}{2i}\right)^2=\frac{1}{4}\left[e^{2iA}+2I_n+e^{-2iA}-\left(e^{2iA}-2I_n+e^{-2iA}\right)\right]=I_n$.
	
	\subsection{Expression d'un projecteur}
	\label{sec:expression-dun-projecteur}
	\textcolor{blue}{\hyperref[Expression d'un projecteur]{[Enoncé]}}\\
	
	\subsection{Une preuve analytique de Cayley-Hamilton}
	\label{sec:une-preuve-analytique-de-cayley-hamilton}
	\textcolor{blue}{\hyperref[Une preuve analytique de Cayley-Hamilton]{[Enoncé]}}\\
	\newpage
	
	\subsection{Exemple de fonctions lipschitzienne}
	\label{sec:exemple-de-fonctions-lipschitzienne}
	\textcolor{blue}{\hyperref[Exemple de fonction lipschitzienne]{[Enoncé]}}\\
	
	\subsection{Condition de continuité sur un espace vectoriel normé}
	\label{sec:condition-de-continuite-sur-un-espace-vectoriel-norme}
	\textcolor{blue}{\hyperref[Condition de continuité sur un espace vecoriel normé]{[Enoncé]}}\\
	
	\subsection{Application linéaire (2)}
	\label{sec:application-lineaire-2}
	\textcolor{blue}{\hyperref[Application linéaire 2]{[Enoncé]}}\\
	
	\subsection{Mouvement à force centrale}
	\label{sec:mouvement-a-force-centrale}
	\textcolor{blue}{\hyperref[Mouvement à force centrale]{[Enoncé]}}\\
	
	\subsection{Dérivée d'un produit de deux matrices}
	\label{sec:derivee-dun-produit-de-deux-matrices}
	\textcolor{blue}{\hyperref[Dérivée d'un produit de deux matrices]{[Enoncé]}}\\
	
	\subsection{Inégalité des accroissements finis pour un espace euclidien}
	\label{sec:inegalite-des-accroissements-finis-pour-un-espace-euclidien}
	\textcolor{blue}{\hyperref[Inégalité des accroissements finis pour un espace euclidien]{[Enoncé]}}\\

\section{Correction Equations différentielles}
	\subsection{Equations différentielles du premier ordre}
	\label{sec:equations-differentielles-du-premier-ordre}
	\textcolor{blue}{\hyperref[Equations différentielles du premier ordre]{[Enoncé]}}\\
	
	\subsection{Equations différentielles du second ordre}
	\label{sec:equations-differentielles-du-second-ordre}
	\textcolor{blue}{\hyperref[Equations différentielles du second ordre]{[Enoncé]}}\\
	
	\subsection{Une équation quasi-différentielle \ccinp{1}}
	\label{Une équation quasi-différentielle corrigé}
	\textcolor{blue}{\hyperref[Une équation quasi-différentielle]{[Enoncé]}}\\
	Soit $f:\R\to\C$ de classe $\mathcal C^1$ solution de l'équation. Alors $x\mapsto f(-x)$ est de classe $\mathcal C^1$ d'où $f$ est de classe $\mathcal C^2$.\\
	En dérivant dans l'équation : $\forall x\in \R,\ f''(x)=-f'(-x)=-f(x)$.\\
	Ainsi $f$ est solution de l'équation différentielle $y''+y=0$ sur $\R$.\\
	L'ensemble des solutions de cette équation est $\Vect(\cos,\sin)$.\\
	Réciproquement, si $f\in \Vect(\cos,\sin)$ alors $f$ est de classe $\mathcal C^1$ sur $\R$ et $\forall x\in \R,\ f'(x)=f(-x)$.
	
	\subsection{Problèmes de raccordement}
	\label{sec:problemes-de-raccordement}
	\textcolor{blue}{\hyperref[Problème de raccordement]{[Enoncé]}}\\
	
	\subsection{Suite d'équations différentielles}
	\label{sec:suite-dequations-differentielles}
	\textcolor{blue}{\hyperref[Suite d'équations différentielles]{[Enoncé]}}\\
	
	\subsection{Equation de Bernoulli (1)}
	\label{sec:equation-de-bernoulli-1}
	\textcolor{blue}{\hyperref[Equation de Bernoulli 1]{[Enoncé]}}\\
	
	\subsection{Equation de Bernoulli (2)}
	\label{sec:equation-de-bernoulli-2}
	\textcolor{blue}{\hyperref[Equation de Bernoulli (2)]{[Enoncé]}}\\
	
	\subsection{Etude asymptotique des solutions d'une équation différentielle \centraleponts{4}}
	\label{sec:etude-asymptotique-des-solutions-dune-equation-differentielle-etoile4}
	\textcolor{blue}{\hyperref[Etude asymptotique des solution d'une équation différentielle]{[Enoncé]}}\\
	\begin{enumerate}
		\item $f$ est solution de $(E) : y'+ay=f'+af$ sur $\R_+$.\\
		Les solutions de $(E)$ sur $\R_+$ sont les fonctions $\fonction{f_C}{\R_+}{\C}{x}{Ce^{-ax}+e^{-ax}\displaystyle\int_0^x(f'(t)+af(t))e^{at}dt}$ avec $C\in \C$.\\
		Soit $C\in \C$ tel que $f=f_C$.\\
		D'une part, $|Ce^{-ax}|=|C|e^{-\Re(a)x}\uxfty{\longrightarrow}0$ car $-\Re(a)<0$.\\
		D'autre part, $(f'(t)+af(t))e^{at}\utfty{=}\smallo{e^{at}}$ et $\displaystyle\int_0^{+\infty}e^{at}dt$ diverge car $\Re(a)>0$ donc,\\
		$\displaystyle\int_0^x(f'(t)+af(t))e^{at}dt\uxfty{=}\smallo{\displaystyle\int_0^xe^{at}dt}\uxfty{=}\smallo{e^{ax}}$.\\\\
		D'où $\lim\limits_{+\infty}f=\lim\limits_{+\infty}{f_C}=0$.
		\item Notons $j=e^{\frac{2i\pi}{3}}$ et $g=f'-jf$. Alors $g'-\overline{j}g=f''+f'+f$ admet une limite nulle en $+\infty$. Comme $\Re(-\overline{j})>0$,la question $1$ montre que $g$ admet une limite nulle en $+\infty$. et alors, comme $\Re(-j)>0$, encore d'après la question $1$, $f$ admet une limite nulle en $+\infty$.
		\item Soit $P\in \C[X]$ un polynôme dont toutes les racines sont à parties réelles strictement négatives. Notons $n=\deg(P)$ et donnons nous une fonction $f\in \mathcal{C}^n(\R_+,\C)$ telle que $\lim\limits_{+\infty}P(D)(f)=0$.\\
		Raisonnons par récurrence sur le degré de $P$.\\
		Si $n=0$ il n'y a rien à démontrer.\\
		Supposons que $n\geq 1$ et que le résultat est vrai pour les polynômes de degré $n-1$. On se donne une racine $a$ de $P$ pour écrire $P=(X-a)Q$ avec $\deg(Q)=n$. Posons $g=Q(D)(f)$. Alors $g'-ag=D\circ Q(D)(f)-aQ(D)(f)=P(D)(f)$ admet une limite nulle en $+\infty$. Or $\Re(-a)>0$ donc d'après la question $1$, $g$ admet une limite nulle en $+\infty$. Et alors d'après l'hypothèse de récurrence, $f$ admet une limite nulle en $+\infty$.\\
		Par récurrence, le résultat est vrai pour tout $n\in \N$.
	\end{enumerate}
	
	\subsection{Inéquation différentielle}\label{sec:inequation-differentielle}
		\textcolor{blue}{\hyperref[Inéquation différentielle]{[Enoncé]}}\\
	
	\subsection{Solution $2\pi$-périodique d'une équation différentielle}\label{sec:solution-2pi-periodique-dune-equation-differentielle}
		\textcolor{blue}{\hyperref[Solution 2pi-périodique d'une équation différentielle]{[Enoncé]}}\\
	
	\subsection{Superposition de solutions}\label{sec:superposition-de-solutions}
		\textcolor{blue}{\hyperref[Superposition de solutions]{[Enoncé]}}\\
	
	\subsection{Fonction de Bessel}\label{sec:fonction-de-bessel}
		\textcolor{blue}{\hyperref[FOnction de Bessel]{[Enoncé]}}\\
	\subsection{Développement de la cotangente (2)}\label{sec:developpement-de-la-cotangente-2}
		\textcolor{blue}{\hyperref[Développement de la cotangente 2]{[Enoncé]}}\\
	\subsection{Wronskien}\label{sec:wronskien}
		\textcolor{blue}{\hyperref[Wronskien]{[Enoncé]}}\\
	
	\subsection{Utilité du wronskien}\label{sec:utilite-du-wronskien}
		\textcolor{blue}{\hyperref[Utilité du wronskien]{[Enoncé]}}\\
	
	\subsection{Principe d'entrelacement des zéros de Sturm}\label{sec:principe-dentrelacement-des-zeros-de-sturm}
		\textcolor{blue}{\hyperref[Principe d'entrelacement des zéros de Sturm]{[Enoncé]}}\\
	
	\subsection{Solution qui s'annule}\label{sec:solution-qui-sannule}
		\textcolor{blue}{\hyperref[Solution qui s'annule]{[Enoncé]}}\\
	
	\subsection{Solution qui s'annule une infinité de fois}\label{sec:solution-qui-sannule-une-infinite-de-fois}
		\textcolor{blue}{\hyperref[Solution qui s'annule une infinité de fois]{[Enoncé]}}\\
	
	\subsection{Lemme de Grönwall}\label{sec:lemme-de-gronwall}
		\textcolor{blue}{\hyperref[Lemme de Gröwall]{[Enoncé]}}\\
	
	\subsubsection{Application du lemme de Grönwall}
	
	
	\subsection{Théorème de Floquet}\label{sec:theoreme-de-floquet}
		\textcolor{blue}{\hyperref[Théorème de Floquet]{[Enoncé]}}\\
	
	\subsection{Méthode de Lagrange (1)}\label{sec:methode-de-lagrange-1}
		\textcolor{blue}{\hyperref[Méthode de Lagrange 1]{[Enoncé]}}\\
	
	\subsection{Méthode de Lagrange (2)}\label{sec:methode-de-lagrange-2}
		\textcolor{blue}{\hyperref[Méthode de Lagrange 2]{[Enoncé]}}\\
	
	\subsection{Equation différentielle matricielle non linéaire}\label{sec:equation-differentielle-matricielle-non-lineaire}
		\textcolor{blue}{\hyperref[Equation différentielle matricielle non linéaire]{[Enoncé]}}\\
	
	\subsection{Système dynamique}\label{sec:systeme-dynamique}
	\textcolor{blue}{\hyperref[Système dynamique]{[Enoncé]}}\\
	
	\subsection{Solutions de norme constante \etoile{3}}\label{sec:solutions-de-norme-constante-etoile3}
		\textcolor{blue}{\hyperref[Solutions de norme constante]{[Enoncé]}}\\
	Supposons que $A\in \mathcal A_n(\R)$.\\
	Soit $X$ une solution du système différentiel $Y'=AY$. On sait que $\forall t\in \R,\ X(t)=e^{tA}X(0)$.\\
	Or $\forall t\in \R,\ e^{tA}\in \O_n(\R)$. En effet, par continuité de la transposition, $\forall t\in \R,\ \left(e^{tA}\right)^\top=e^{tA^\top}=e^{-tA}=\left(e^{tA}\right)^{-1}$.\\
	Ainsi, $\forall t\in \R,\ \norme{X(t)}=\norme{X(0)}$.\\\\
	Réciproquement, supposons que $X'=AX\implies \forall t\in \R,\ \norme{X(t)}=\norme{X(0)}$.\\
	Donnons nous une solution $X$ du système différentiel.\\
	En notant $X_0=X(0),\ \forall t\in \R,\ \norme{X(t)}^2=\norme{X_0}^2\iff X(t)^\top X(t)=X_0^\top X_0\iff X_0^\top e^{tA^\top}e^{tA}X_0=X_0^\top X_0$.\\
	On fait un développement à l'ordre $1$ en $0$ :\\
	$X_0^\top(I_n+tA^\top+\smallo{t})(I_n+tA+\smallo{t})X_0\utzero{=}X_0^\top X_0$ c'est à dire $X_0^\top X_0\utzero{=}X_0^\top X_0+tX_0^\top(A^\top+A)X_0+t^2X_0^\top A^\top AX_0+\smallo{t}\utzero{=}X_0^\top X_0+tX_0^\top(A+A^\top)X_0+\smallo{t}$.\\
	Ainsi $tX_0^\top(A^\top+A)X_0+\smallo{t}\utzero{=}0$ puis $X_0^\top(A^\top+A)X_0=0$ par unicité du développement limité.\\
	Ceci est vrai pour tout $X_0\in \M_{n,1}(\R)$ puisque $t\mapsto e^{tA}X_0$ est solution du système différentiel quel que soit $X_0\in \M_{n,1}(\R)$.\\
	Or $A^\top+A$ est symétrique réelle donc d'après le théorème spectral elle est diagonalisable. Donnons nous $\lambda\in \text{Sp}(A^\top+A)$ et $X_\lambda$ un vecteur propre associé.\\
	$X_\lambda^\top(A^\top+A)X_\lambda=0\implies X_\lambda^\top(\lambda X_\lambda)=\lambda\norme{X_\lambda}^2=0\implies \lambda=0$.\\
	Ainsi $A^\top+A$ est semblable à la matrice nulle et est donc nulle, c'est à dire $A=-A^\top$ ou encore $A\in \mathcal A_n(\R)$.
	
	\subsection{Exponentielles de matrices qui commutent \etoile{2}}\label{sec:exponentielles-de-matrices-qui-commutent-etoile2}
		\textcolor{blue}{\hyperref[Exponentielles de matrices qui commutent]{[Enoncé]}}\\
	\begin{enumerate}[leftmargin=*]
		\item On sait d'après le cours que $f_M$ est $\mathcal C^1$ sur $\R$ quel que soit $M\in \M_n(\R)$ et $\forall t\in \R,\ f_M'(t)=Me^{tM}=e^{tM}M$. De plus l'application $h:(M,N)\in \M_n(\R)^2\mapsto AB$ est bilinéaire. Ainsi $g=t\in \R \mapsto h(f_{A+B}(t),f_{-B}(t))$ est $\mathcal C^1$ sur $\R$ et,\\
		$\forall t\in \R,\ g'(t)=h(f_{A+B}'(t),f_{-B}(t))+h(f_{A+B}(t),f_{-B}'(t))=(A+B)e^{t(A+B)}e^{-tB}+e^{t(A+B)}(-B)e^{-tB}$.\\
		Montrons que si deux matrices $M$ et $N$ commutent alors $M$ et $e^N$ commutent. On pose pour tout $p\in \N,\ S_p=\displaystyle\sum_{k=0}^p\frac{N^k}{k!}$. Fixons $p\in \N$.\\
		Comme $S_p$ est un polynôme en $N$ on a $h(M,S_p)=MS_p=S_pM=h(S_p,M)$. Or l'application $h$ est bilinéaire et donc continue car $\M_n(\R)$ est de dimension finie.\\
		Ainsi comme $S_p\upfty{\longrightarrow}e^N$, on a $h(M,e^N)=h(e^N,M)$ c'est à dire $Me^N=e^NM$.\\
		On en déduit comme $-B$ et $A+B$ commutent que $\forall t\in \R,\ h'(t)=(A+B)e^{t(A+B)}e^{-tB}-Be^{t(A+B)}e^{-tB}=Ae^{t(A+B)}e^{-tB}$.\\
		Ainsi $f_A$ et $g$ vérifient le problème de Cauchy
		$\begin{cases}
			y'=Ay\\
			y(0)=I_n
		\end{cases}$.\\
		Par unicité de la solution d'un problème de Cauchy $g=f_A$.\\
		Donc en sachant que $\forall t\in \R,\ e^{-tB}=\left(e^{tB}\right)^{-1}$,
		$$\forall t\in \R,\quad e^{t(A+B)}=e^{tA}e^{tB}$$
		\item Supposons que $\forall t\in \R,\ e^{t(A+B)}=e^{tA}e^{tB}$.\\
		On sait que quel que soit $M\in \M_n(\R),\ f_M$ est de classe $\mathcal C^2$ sur $\R$. Alors en dérivant deux fois,\\
		$$\forall t\in \R,\quad (A+B)e^{t(A+B)}=e^{tA}Ae^{tB}+e^{tA}Be^{tB}=e^{tA}(A+B)e^{tB}$$
		Puis,
		$$\forall t\in \R,\quad (A+B)^2e^{t(A+B)}=e^{tA}A(A+B)e^{tB}+e^{tA}(A+B)Be^{tB}$$
		En particulier pour $t=0$ :
		$$(A+B)^2=A(A+B)+(A+B)B$$
		C'est à dire :
		$$A^2+AB+BA+B^2=A^2+AB+AB+B^2$$
		Ou encore :
		$$BA=AB$$
	\end{enumerate}
	
	\subsection{Lemme de Hochshild}\label{sec:lemme-de-hochshild}
		\textcolor{blue}{\hyperref[Lemme de Hochsild]{[Enoncé]}}\\
	\newpage
\section{Correction Calcul différentiel}
	
	\subsection{Calcul de dérivées partielles}\label{sec:calcul-de-derivees-partielles-1}
		\textcolor{blue}{\hyperref[Calcul de dérivées partielles 1]{[Enoncé]}}\\
	
	\subsection{Existence de dérivées partielles}\label{sec:existence-de-derivees-partielles}
		\textcolor{blue}{\hyperref[Existence de dérivées partielles]{[Enoncé]}}\\
	
	\subsection{Etude d'une fonction}\label{sec:etude-dune-fonction}
		\textcolor{blue}{\hyperref[Etude d'une fonction]{[Enoncé]}}\\
	
	\subsection{Une équation fonctionnelle \etoile{2}}\label{sec:une-equation-fonctionnelle-etoile2}
		\textcolor{blue}{\hyperref[Une équation fonctionnelle]{[Enoncé]}}\\
	\begin{enumerate}
		\item Soit $f$ une fonction constante égale à $c$ solution $(1)$.
		On a donc $2c=2c^2$ donc $c=0$ ou $c=1$.
		Ainsi $f:x\to0$ et $f:x\to1$.
		\item 
		\begin{enumerate}[label=\alph*.]
			\item Pour $x=0$ et $y=0$, on a: $2f(0)=2f(0)^2$ donc $f(0)=1$ ou $f(0)=0$.
			\\Supposons que $f(0)=0$.
			$\forall x\in\R,\quad2f(x)=2f(0)F(x)=0$.
			On obtient donc que $f$ est constamment nulle sur $\R$, ce qui est absurde.
			\\Donc $f(0)=1$.
			\\ Soit $x\in\R$, 
			$$\forall y\in\R, f'(x+y)-f'(x-y)=2f(x)f'(y)$$
			En particulier, pour $x=0,y=0$, $2f'(0)=0.$
			\item Pour $x=0$, pour tout $y\in\R$, $f(y)+f(-y)=2f(y)$.
			\\On en déduit bien que $f$ est paire.
		\end{enumerate}
		\item 
		\begin{enumerate}[label=\alph*.]
			\item Les fonctions $(x,y)\mapsto x+y$ et $(x,y)\mapsto x-y$ sont de classe $\mathcal{C}^2$ sur $\R^2$.Et $f$ est de classe $\mathcal{C}^2$ sur $\R$.
			\\Donc $F$ est de classe $\mathcal{C}^2$
			\item $\forall (x,y)\in \R^2,$:
			$$\begin{cases}
				&\dpartial{F}{2}{x}=f''(x+y)+f''(x-y), \\
				&\dpartial{F}{2}{y}=f''(x+y)+f''(x-y),\\
				&\dpartials{F}{x}{xy}=\dpartials{F}{y}{x}=f''(x+y)-f''(x-y)
			\end{cases}$$
			\item On remarque que $\dpartial{F}{2}{x}=\dpartial{F}{2}{y}$.
			On a également: $$\forall(x,y)\in\R^2:\begin{cases}
				&\dpartial{F}{2}{x}(x,y)=2f'(x)f(y),\\
				&\dpartial{F}{2}{y}(x,y)=2f(x)f'(y)
			\end{cases}$$
			Donc $$\forall(x,y)\in\R^2, f''(x)f(y)=f(x)f''(y),$$
			donc pour $y=0$, $f''(x)-\alpha f(x)=0$ avec $\alpha=f''(0)$.
			\item Si $\alpha>0$, alors $f=x\mapsto \ch(\sqrt{\alpha}x)$.
			\\ Si $\alpha=0$, alors $f=x\mapsto 1$
			\\Si $\alpha<0$, alors $f=x\mapsto \cos(\sqrt{|\alpha|}x)$.
		\end{enumerate}
		\item On vérifie que tous ses solutions trouvées conviennes.
	\end{enumerate}
	
	\subsection{Application linéaire}\label{sec:application-lineaire}
		\textcolor{blue}{\hyperref[Application linéaire]{[Enoncé]}}\\
	\subsection{Opérateurs vectoriels}\label{sec:operateurs-vectoriels}
		\textcolor{blue}{\hyperref[Opérateurs vectoriels]{[Enoncé]}}\\
	\subsection{Laplacien en polaires}\label{sec:laplacien-en-polaires}
		\textcolor{blue}{\hyperref[Laplacien en polaires]{[Enoncé]}}\\
	
	\subsection{Fonction harmonique}\label{sec:fonction-harmonique}
		\textcolor{blue}{\hyperref[Fonction harmoinique]{[Enoncé]}}\\
	
	\subsection{Mines ponts MP 2016}\label{sec:mines-ponts-mp-2016}
		\textcolor{blue}{\hyperref[Mines ponts MP 2016]{[Enoncé]}}\\
	
	\subsection{Différentielle de l'exponentielle matricielle}\label{sec:differentielle-de-lexponentielle-matricielle}
		\textcolor{blue}{\hyperref[Différentielle de l'exponentielle matricielle]{[Enoncé]}}\\
	
	\subsection{Différentielle de la norme euclidienne}\label{sec:differentielle-de-la-norme-euclidienne}
		\textcolor{blue}{\hyperref[Différentielle de la norme euclidienne]{[Enoncé]}}\\
	\subsection{Différentielle de l'inversion matricielle}\label{sec:differentielle-de-linversion-matricielle}
		\textcolor{blue}{\hyperref[Différentielle de l'inversion matricielle]{[Enoncé]}}\\
	\subsection{Gradient et différentielle du déterminant}\label{sec:gradient-et-differentielle-du-determinant}
		\textcolor{blue}{\hyperref[Gradient et différentielle du déterminant]{[Enoncé]}}\\
	\subsection{Espace tangent aux matrices orthogonales en l'identité}\label{sec:espace-tangent-aux-matrices-orthogonales-en-lidentite}
	\textcolor{blue}{\hyperref[Espace tangent aux matrices orthogonales en l'identité]{[Enoncé]}}\\
	Soit $A\in \mathcal A_n(\R)$. On pose $f:t\in \R\mapsto e^{tA}$.\\
	Par continuité de la transposition, qui est linéaire sur $\M_n(\R)$, un espace vectoriel normé de dimension finie,\\
	$\forall t\in \R,\ \left(e^{tA}\right)^\top=e^{(tA)^\top}=e^{-tA}=\left(e^{tA}\right)^{-1}$.\\
	Ainsi $f$ est à valeurs dans $\O_n(\R)$.\\
	De plus $f$ est dérivable sur $\R$ et $\forall t\in \R,\ f'(t)=Ae^{tA}$.\\
	On a donc $f(0)=I_n$ et $f'(0)=A$ d'où $f\in T_{I_n}(\O_n(\R))$.\\\\
	Réciproquement, donnons nous $A\in T_{I_n}(\O_n(\R))$.\\
	Il existe $\varepsilon>0$ et $\gamma:]-\varepsilon,\varepsilon[\to\O_n(\R)$ dérivable en $0$ telle que $\gamma(0)=I_n$ et $\gamma'(0)=A$.\\
	$(*) :\forall t\in ]-\varepsilon,\varepsilon[,\ \gamma(t)^\top\gamma(t)=I_n$.\\
	Par linéarité de la transposition, $\psi:t\mapsto\gamma(t)^\top$ est dérivable en $0$ et $\psi'(0)=\gamma'(0)^\top=A^\top$.\\
	On peut alors dériver la relation $(*)$ en $0$:
	$$\gamma'(0)\gamma(0)^\top+\gamma(0)\gamma'(0)^\top=A^\top+A=0$$
	Ainsi $A^\top=-A$ c'est à dire $A\in \mathcal A_n(\R)$.
	
	\subsection{Vecteur propre d'un endomorphisme auto-adjoint}\label{sec:vecteur-propre-dun-endomorphisme-auto-adjoint}
		\textcolor{blue}{\hyperref[Vecteur propre d'un endomorhpsime auto-adjoint]{[Enoncé]}}\\
	
	\subsection{Quotient de Rayleigh}\label{sec:quotient-de-rayleigh}
		\textcolor{blue}{\hyperref[Quotient de Rayleigh]{[Enoncé]}}\\
	
	\subsection{Différentielle du déterminant}\label{sec:differentielle-du-determinant}
		\textcolor{blue}{\hyperref[Différentielle du déterminant]{[Enoncé]}}\\
	
	\subsection{Equation de d'Alembert}\label{sec:equation-de-dalembert}
		\textcolor{blue}{\hyperref[Equation de d'Alembert]{[Enoncé]}}\\
	
	\subsection{Utilisation des extrémas liés (1)}\label{sec:utilisation-des-extremas-lies-1}
		\textcolor{blue}{\hyperref[Utilisation des extrema liés 1]{[Enoncé]}}\\
	
	\subsection{Utilisation des extrémas liés (2)}\label{sec:utilisation-des-extremas-lies-2}
		\textcolor{blue}{\hyperref[Utilisation des extrema liés 2]{[Enoncé]}}\\
	\subsection{Utilisation des extrémas liés (3)}\label{sec:utilisation-des-extremas-lies-3}
		\textcolor{blue}{\hyperref[Utilisation des extrema liés 3]{[Enoncé]}}\\
	\subsection{Sinus complexe}\label{sec:sinus-complexe}
		\textcolor{blue}{\hyperref[Sinus complexe]{[Enoncé]}}\\
	
	\subsection{Entropie}\label{sec:entropie}
		\textcolor{blue}{\hyperref[Entropie]{[Enoncé]}}\\
	\subsection{Fonction convexe sur $\R^n$}\label{sec:fonction-convexe-sur-rn}
		\textcolor{blue}{\hyperref[Fonction convexe sur R^n]{[Enoncé]}}\\
	\subsection{Chemin le plus court entre deux points}\label{sec:chemin-le-plus-court-entre-deux-points}
	\textcolor{blue}{\hyperref[Chemin le plus court entre deux points]{[Enoncé]}}\\
	\subsection{Fonction homogène}\label{sec:fonction-homogene}
		\textcolor{blue}{\hyperref[Fonction homogène]{[Enoncé]}}\\
	
	\subsection{Problème de Dirichlet et principe du maximum}\label{sec:probleme-de-dirichlet-et-principe-du-maximum}
		\textcolor{blue}{\hyperref[Problème de Dirichlet et principe faible du maximum]{[Enoncé]}}\\
	
	\subsection{La méthode des moindres carrés}\label{sec:la-methode-des-moindres-carres}
		\textcolor{blue}{\hyperref[La méthode des moindres carrés]{[Enoncé]}}\\
	
	\subsection{Equation de la chaleur}\label{sec:equation-de-la-chaleur}
		\textcolor{blue}{\hyperref[Equation de la chaleur]{[Enoncé]}}\\
	
	
	\newpage
\section{Correction Divers}
	\subsection{Développement décimal propre d'un réel}\label{sec:developpement-decimal-propre-dun-reel}
		\textcolor{blue}{\hyperref[Développement décimal propre d'un réel]{[Enoncé]}}\\
	\subsubsection{Une caractéristique des rationnels}
	\subsection{Distribution du premier chiffre des puissances de 2}\label{sec:distribution-du-premier-chiffre-des-puissances-de-2}
		\textcolor{blue}{\hyperref[Distribution du premier chiffre des puissances de 2]{[Enoncé]}}\\
	\subsection{Série de Engel}\label{sec:serie-de-engel}
		\textcolor{blue}{\hyperref[Série de Engel]{[Enoncé]}}\\
	\subsection{Théorème de Müntz}\label{sec:theoreme-de-muntz}
	\textcolor{blue}{\hyperref[Théorème de Muntz]{[Enoncé]}}\\
	
	
	
	
\end{document}